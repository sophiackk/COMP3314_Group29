nohup: ignoring input
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0175403
	speed: 0.0148s/iter; left time: 29.9826s
	iters: 200, epoch: 1 | loss: 0.9974996
	speed: 0.0106s/iter; left time: 20.4099s
Epoch: 1 cost time: 2.2142324447631836
Epoch: 1, Steps: 213 | Train Loss: 1.0557556 Vali Loss: 1.0255414 Test Loss: 0.9916943
Validation loss decreased (inf --> 1.025541).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0078219
	speed: 0.0066s/iter; left time: 11.9251s
	iters: 200, epoch: 2 | loss: 1.0235714
	speed: 0.0059s/iter; left time: 10.1608s
Epoch: 2 cost time: 1.3043169975280762
Epoch: 2, Steps: 213 | Train Loss: 1.0121065 Vali Loss: 1.0288657 Test Loss: 0.9922045
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9619867
	speed: 0.0076s/iter; left time: 12.1940s
	iters: 200, epoch: 3 | loss: 0.9921042
	speed: 0.0076s/iter; left time: 11.3913s
Epoch: 3 cost time: 1.6560389995574951
Epoch: 3, Steps: 213 | Train Loss: 1.0050592 Vali Loss: 1.0259627 Test Loss: 0.9895780
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0272887
	speed: 0.0089s/iter; left time: 12.3704s
	iters: 200, epoch: 4 | loss: 0.9799578
	speed: 0.0082s/iter; left time: 10.6094s
Epoch: 4 cost time: 1.79118013381958
Epoch: 4, Steps: 213 | Train Loss: 1.0014869 Vali Loss: 1.0258232 Test Loss: 0.9891273
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9993631
	speed: 0.0068s/iter; left time: 7.9870s
	iters: 200, epoch: 5 | loss: 1.0440803
	speed: 0.0062s/iter; left time: 6.7319s
Epoch: 5 cost time: 1.3783235549926758
Epoch: 5, Steps: 213 | Train Loss: 0.9992435 Vali Loss: 1.0252484 Test Loss: 0.9887225
Validation loss decreased (1.025541 --> 1.025248).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9972803
	speed: 0.0074s/iter; left time: 7.1649s
	iters: 200, epoch: 6 | loss: 1.0157659
	speed: 0.0066s/iter; left time: 5.7507s
Epoch: 6 cost time: 1.4569237232208252
Epoch: 6, Steps: 213 | Train Loss: 0.9986386 Vali Loss: 1.0246123 Test Loss: 0.9886923
Validation loss decreased (1.025248 --> 1.024612).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9634180
	speed: 0.0077s/iter; left time: 5.7691s
	iters: 200, epoch: 7 | loss: 0.9812314
	speed: 0.0067s/iter; left time: 4.4061s
Epoch: 7 cost time: 1.4772298336029053
Epoch: 7, Steps: 213 | Train Loss: 0.9975362 Vali Loss: 1.0249379 Test Loss: 0.9887821
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0117446
	speed: 0.0073s/iter; left time: 3.9470s
	iters: 200, epoch: 8 | loss: 1.0164638
	speed: 0.0065s/iter; left time: 2.8504s
Epoch: 8 cost time: 1.4152734279632568
Epoch: 8, Steps: 213 | Train Loss: 0.9973979 Vali Loss: 1.0250349 Test Loss: 0.9886531
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0315976
	speed: 0.0076s/iter; left time: 2.4820s
	iters: 200, epoch: 9 | loss: 1.0039682
	speed: 0.0070s/iter; left time: 1.5890s
Epoch: 9 cost time: 1.5406982898712158
Epoch: 9, Steps: 213 | Train Loss: 0.9968740 Vali Loss: 1.0242566 Test Loss: 0.9887315
Validation loss decreased (1.024612 --> 1.024257).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9682341
	speed: 0.0076s/iter; left time: 0.8612s
	iters: 200, epoch: 10 | loss: 1.0045381
	speed: 0.0069s/iter; left time: 0.0972s
Epoch: 10 cost time: 1.524573564529419
Epoch: 10, Steps: 213 | Train Loss: 0.9967592 Vali Loss: 1.0257369 Test Loss: 0.9887413
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9887315034866333, mae:0.7903132438659668
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0081667
	speed: 0.0079s/iter; left time: 16.1345s
	iters: 200, epoch: 1 | loss: 1.0177824
	speed: 0.0073s/iter; left time: 14.1212s
Epoch: 1 cost time: 1.6487932205200195
Epoch: 1, Steps: 213 | Train Loss: 1.0539842 Vali Loss: 1.0285870 Test Loss: 0.9931558
Validation loss decreased (inf --> 1.028587).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0151974
	speed: 0.0119s/iter; left time: 21.7044s
	iters: 200, epoch: 2 | loss: 1.0410665
	speed: 0.0097s/iter; left time: 16.6928s
Epoch: 2 cost time: 2.0991296768188477
Epoch: 2, Steps: 213 | Train Loss: 1.0125590 Vali Loss: 1.0258138 Test Loss: 0.9904726
Validation loss decreased (1.028587 --> 1.025814).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0328922
	speed: 0.0086s/iter; left time: 13.8124s
	iters: 200, epoch: 3 | loss: 0.9731777
	speed: 0.0081s/iter; left time: 12.1522s
Epoch: 3 cost time: 1.7677226066589355
Epoch: 3, Steps: 213 | Train Loss: 1.0057214 Vali Loss: 1.0259980 Test Loss: 0.9902055
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9792206
	speed: 0.0088s/iter; left time: 12.2222s
	iters: 200, epoch: 4 | loss: 0.9919702
	speed: 0.0081s/iter; left time: 10.5093s
Epoch: 4 cost time: 1.7837717533111572
Epoch: 4, Steps: 213 | Train Loss: 1.0016250 Vali Loss: 1.0234845 Test Loss: 0.9886721
Validation loss decreased (1.025814 --> 1.023484).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9894924
	speed: 0.0070s/iter; left time: 8.2214s
	iters: 200, epoch: 5 | loss: 0.9920442
	speed: 0.0064s/iter; left time: 6.9436s
Epoch: 5 cost time: 1.4257292747497559
Epoch: 5, Steps: 213 | Train Loss: 1.0000971 Vali Loss: 1.0255967 Test Loss: 0.9887331
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9933218
	speed: 0.0083s/iter; left time: 7.9738s
	iters: 200, epoch: 6 | loss: 0.9815008
	speed: 0.0079s/iter; left time: 6.8117s
Epoch: 6 cost time: 1.7246644496917725
Epoch: 6, Steps: 213 | Train Loss: 0.9981430 Vali Loss: 1.0240152 Test Loss: 0.9886895
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9748330
	speed: 0.0088s/iter; left time: 6.6350s
	iters: 200, epoch: 7 | loss: 0.9906487
	speed: 0.0081s/iter; left time: 5.3061s
Epoch: 7 cost time: 1.7834439277648926
Epoch: 7, Steps: 213 | Train Loss: 0.9975825 Vali Loss: 1.0253847 Test Loss: 0.9887096
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9847021
	speed: 0.0089s/iter; left time: 4.8108s
	iters: 200, epoch: 8 | loss: 1.0335078
	speed: 0.0082s/iter; left time: 3.6242s
Epoch: 8 cost time: 1.8142476081848145
Epoch: 8, Steps: 213 | Train Loss: 0.9972241 Vali Loss: 1.0250460 Test Loss: 0.9887490
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9689132
	speed: 0.0090s/iter; left time: 2.9369s
	iters: 200, epoch: 9 | loss: 0.9922076
	speed: 0.0079s/iter; left time: 1.7893s
Epoch: 9 cost time: 1.708754301071167
Epoch: 9, Steps: 213 | Train Loss: 0.9975440 Vali Loss: 1.0245738 Test Loss: 0.9887403
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9886723160743713, mae:0.7903351783752441
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0131817
	speed: 0.0079s/iter; left time: 16.1436s
	iters: 200, epoch: 1 | loss: 1.0113045
	speed: 0.0072s/iter; left time: 13.9552s
Epoch: 1 cost time: 1.585552453994751
Epoch: 1, Steps: 213 | Train Loss: 1.0530765 Vali Loss: 1.0261605 Test Loss: 0.9915832
Validation loss decreased (inf --> 1.026160).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0361637
	speed: 0.0068s/iter; left time: 12.3586s
	iters: 200, epoch: 2 | loss: 0.9924473
	speed: 0.0063s/iter; left time: 10.8330s
Epoch: 2 cost time: 1.3877606391906738
Epoch: 2, Steps: 213 | Train Loss: 1.0126913 Vali Loss: 1.0234708 Test Loss: 0.9899995
Validation loss decreased (1.026160 --> 1.023471).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0234129
	speed: 0.0086s/iter; left time: 13.7552s
	iters: 200, epoch: 3 | loss: 0.9925591
	speed: 0.0080s/iter; left time: 12.0386s
Epoch: 3 cost time: 1.7432849407196045
Epoch: 3, Steps: 213 | Train Loss: 1.0057081 Vali Loss: 1.0259346 Test Loss: 0.9904935
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0238643
	speed: 0.0060s/iter; left time: 8.3903s
	iters: 200, epoch: 4 | loss: 0.9847094
	speed: 0.0054s/iter; left time: 6.9917s
Epoch: 4 cost time: 1.1945629119873047
Epoch: 4, Steps: 213 | Train Loss: 1.0018124 Vali Loss: 1.0240041 Test Loss: 0.9890414
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0227845
	speed: 0.0083s/iter; left time: 9.8347s
	iters: 200, epoch: 5 | loss: 1.0295763
	speed: 0.0079s/iter; left time: 8.5532s
Epoch: 5 cost time: 1.7315919399261475
Epoch: 5, Steps: 213 | Train Loss: 1.0000171 Vali Loss: 1.0243847 Test Loss: 0.9885284
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0050043
	speed: 0.0066s/iter; left time: 6.4125s
	iters: 200, epoch: 6 | loss: 0.9720920
	speed: 0.0057s/iter; left time: 4.9173s
Epoch: 6 cost time: 1.2586405277252197
Epoch: 6, Steps: 213 | Train Loss: 0.9985259 Vali Loss: 1.0253551 Test Loss: 0.9886623
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0376878
	speed: 0.0064s/iter; left time: 4.8034s
	iters: 200, epoch: 7 | loss: 1.0129969
	speed: 0.0056s/iter; left time: 3.6254s
Epoch: 7 cost time: 1.2160930633544922
Epoch: 7, Steps: 213 | Train Loss: 0.9977597 Vali Loss: 1.0249221 Test Loss: 0.9886016
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9899996519088745, mae:0.7907657027244568
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0229020
	speed: 0.0129s/iter; left time: 25.8229s
	iters: 200, epoch: 1 | loss: 1.0156872
	speed: 0.0097s/iter; left time: 18.4133s
Epoch: 1 cost time: 2.0681073665618896
Epoch: 1, Steps: 210 | Train Loss: 1.0532879 Vali Loss: 1.0291479 Test Loss: 0.9883301
Validation loss decreased (inf --> 1.029148).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0241016
	speed: 0.0075s/iter; left time: 13.5203s
	iters: 200, epoch: 2 | loss: 1.0157303
	speed: 0.0072s/iter; left time: 12.1001s
Epoch: 2 cost time: 1.5531282424926758
Epoch: 2, Steps: 210 | Train Loss: 1.0141132 Vali Loss: 1.0291138 Test Loss: 0.9892672
Validation loss decreased (1.029148 --> 1.029114).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0082576
	speed: 0.0070s/iter; left time: 11.0624s
	iters: 200, epoch: 3 | loss: 1.0152509
	speed: 0.0067s/iter; left time: 9.8811s
Epoch: 3 cost time: 1.4455759525299072
Epoch: 3, Steps: 210 | Train Loss: 1.0082527 Vali Loss: 1.0260794 Test Loss: 0.9859092
Validation loss decreased (1.029114 --> 1.026079).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0125855
	speed: 0.0075s/iter; left time: 10.2948s
	iters: 200, epoch: 4 | loss: 1.0028862
	speed: 0.0070s/iter; left time: 8.8813s
Epoch: 4 cost time: 1.5251967906951904
Epoch: 4, Steps: 210 | Train Loss: 1.0053258 Vali Loss: 1.0255952 Test Loss: 0.9854915
Validation loss decreased (1.026079 --> 1.025595).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9896068
	speed: 0.0076s/iter; left time: 8.8245s
	iters: 200, epoch: 5 | loss: 0.9990376
	speed: 0.0069s/iter; left time: 7.2749s
Epoch: 5 cost time: 1.4795219898223877
Epoch: 5, Steps: 210 | Train Loss: 1.0036613 Vali Loss: 1.0255125 Test Loss: 0.9852321
Validation loss decreased (1.025595 --> 1.025512).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0120426
	speed: 0.0066s/iter; left time: 6.2982s
	iters: 200, epoch: 6 | loss: 0.9923932
	speed: 0.0062s/iter; left time: 5.2864s
Epoch: 6 cost time: 1.3467555046081543
Epoch: 6, Steps: 210 | Train Loss: 1.0026472 Vali Loss: 1.0260584 Test Loss: 0.9850492
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0078590
	speed: 0.0071s/iter; left time: 5.2954s
	iters: 200, epoch: 7 | loss: 0.9917375
	speed: 0.0061s/iter; left time: 3.8826s
Epoch: 7 cost time: 1.2995820045471191
Epoch: 7, Steps: 210 | Train Loss: 1.0020609 Vali Loss: 1.0251126 Test Loss: 0.9849989
Validation loss decreased (1.025512 --> 1.025113).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0192363
	speed: 0.0076s/iter; left time: 4.0453s
	iters: 200, epoch: 8 | loss: 1.0018507
	speed: 0.0071s/iter; left time: 3.0480s
Epoch: 8 cost time: 1.5330028533935547
Epoch: 8, Steps: 210 | Train Loss: 1.0019578 Vali Loss: 1.0251776 Test Loss: 0.9849860
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0033661
	speed: 0.0078s/iter; left time: 2.5114s
	iters: 200, epoch: 9 | loss: 1.0086256
	speed: 0.0071s/iter; left time: 1.5711s
Epoch: 9 cost time: 1.5365936756134033
Epoch: 9, Steps: 210 | Train Loss: 1.0017827 Vali Loss: 1.0259306 Test Loss: 0.9850022
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0276923
	speed: 0.0074s/iter; left time: 0.8250s
	iters: 200, epoch: 10 | loss: 1.0015342
	speed: 0.0069s/iter; left time: 0.0762s
Epoch: 10 cost time: 1.5043609142303467
Epoch: 10, Steps: 210 | Train Loss: 1.0017296 Vali Loss: 1.0258340 Test Loss: 0.9850067
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.984998881816864, mae:0.7884235382080078
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0273646
	speed: 0.0079s/iter; left time: 15.9077s
	iters: 200, epoch: 1 | loss: 1.0042852
	speed: 0.0068s/iter; left time: 12.8717s
Epoch: 1 cost time: 1.4500153064727783
Epoch: 1, Steps: 210 | Train Loss: 1.0539796 Vali Loss: 1.0310918 Test Loss: 0.9901435
Validation loss decreased (inf --> 1.031092).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0080109
	speed: 0.0091s/iter; left time: 16.3140s
	iters: 200, epoch: 2 | loss: 0.9920326
	speed: 0.0076s/iter; left time: 12.8898s
Epoch: 2 cost time: 1.6297669410705566
Epoch: 2, Steps: 210 | Train Loss: 1.0140986 Vali Loss: 1.0266777 Test Loss: 0.9883802
Validation loss decreased (1.031092 --> 1.026678).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0151299
	speed: 0.0088s/iter; left time: 13.8757s
	iters: 200, epoch: 3 | loss: 1.0135807
	speed: 0.0083s/iter; left time: 12.3362s
Epoch: 3 cost time: 1.7989184856414795
Epoch: 3, Steps: 210 | Train Loss: 1.0085315 Vali Loss: 1.0272231 Test Loss: 0.9868892
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9869355
	speed: 0.0070s/iter; left time: 9.5503s
	iters: 200, epoch: 4 | loss: 1.0007794
	speed: 0.0065s/iter; left time: 8.2104s
Epoch: 4 cost time: 1.43463134765625
Epoch: 4, Steps: 210 | Train Loss: 1.0052615 Vali Loss: 1.0250225 Test Loss: 0.9858267
Validation loss decreased (1.026678 --> 1.025023).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0109907
	speed: 0.0081s/iter; left time: 9.3500s
	iters: 200, epoch: 5 | loss: 1.0250969
	speed: 0.0077s/iter; left time: 8.1632s
Epoch: 5 cost time: 1.6739778518676758
Epoch: 5, Steps: 210 | Train Loss: 1.0036684 Vali Loss: 1.0269365 Test Loss: 0.9858279
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0181619
	speed: 0.0091s/iter; left time: 8.6310s
	iters: 200, epoch: 6 | loss: 1.0068102
	speed: 0.0084s/iter; left time: 7.1150s
Epoch: 6 cost time: 1.8318190574645996
Epoch: 6, Steps: 210 | Train Loss: 1.0030161 Vali Loss: 1.0255058 Test Loss: 0.9852818
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9833426
	speed: 0.0091s/iter; left time: 6.7302s
	iters: 200, epoch: 7 | loss: 0.9905562
	speed: 0.0084s/iter; left time: 5.3624s
Epoch: 7 cost time: 1.8110337257385254
Epoch: 7, Steps: 210 | Train Loss: 1.0024523 Vali Loss: 1.0257192 Test Loss: 0.9852124
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0222567
	speed: 0.0089s/iter; left time: 4.7371s
	iters: 200, epoch: 8 | loss: 0.9905620
	speed: 0.0082s/iter; left time: 3.5490s
Epoch: 8 cost time: 1.776369333267212
Epoch: 8, Steps: 210 | Train Loss: 1.0020284 Vali Loss: 1.0256526 Test Loss: 0.9851711
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9962186
	speed: 0.0090s/iter; left time: 2.8935s
	iters: 200, epoch: 9 | loss: 1.0017021
	speed: 0.0083s/iter; left time: 1.8313s
Epoch: 9 cost time: 1.7967569828033447
Epoch: 9, Steps: 210 | Train Loss: 1.0017991 Vali Loss: 1.0255377 Test Loss: 0.9851711
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9858266115188599, mae:0.7887300252914429
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0178031
	speed: 0.0091s/iter; left time: 18.2379s
	iters: 200, epoch: 1 | loss: 0.9945549
	speed: 0.0084s/iter; left time: 15.9267s
Epoch: 1 cost time: 1.825881004333496
Epoch: 1, Steps: 210 | Train Loss: 1.0525511 Vali Loss: 1.0281647 Test Loss: 0.9888236
Validation loss decreased (inf --> 1.028165).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0105842
	speed: 0.0091s/iter; left time: 16.3660s
	iters: 200, epoch: 2 | loss: 1.0400088
	speed: 0.0084s/iter; left time: 14.1329s
Epoch: 2 cost time: 1.8125367164611816
Epoch: 2, Steps: 210 | Train Loss: 1.0139328 Vali Loss: 1.0290825 Test Loss: 0.9884186
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0004497
	speed: 0.0091s/iter; left time: 14.3401s
	iters: 200, epoch: 3 | loss: 0.9960772
	speed: 0.0083s/iter; left time: 12.3258s
Epoch: 3 cost time: 1.7999162673950195
Epoch: 3, Steps: 210 | Train Loss: 1.0087134 Vali Loss: 1.0267812 Test Loss: 0.9863583
Validation loss decreased (1.028165 --> 1.026781).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9999871
	speed: 0.0092s/iter; left time: 12.5619s
	iters: 200, epoch: 4 | loss: 0.9982442
	speed: 0.0084s/iter; left time: 10.6560s
Epoch: 4 cost time: 1.812774896621704
Epoch: 4, Steps: 210 | Train Loss: 1.0053778 Vali Loss: 1.0274770 Test Loss: 0.9858351
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0044870
	speed: 0.0091s/iter; left time: 10.5163s
	iters: 200, epoch: 5 | loss: 1.0036342
	speed: 0.0083s/iter; left time: 8.8388s
Epoch: 5 cost time: 1.8054578304290771
Epoch: 5, Steps: 210 | Train Loss: 1.0036239 Vali Loss: 1.0264132 Test Loss: 0.9853517
Validation loss decreased (1.026781 --> 1.026413).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9909028
	speed: 0.0091s/iter; left time: 8.6891s
	iters: 200, epoch: 6 | loss: 0.9972379
	speed: 0.0084s/iter; left time: 7.1064s
Epoch: 6 cost time: 1.8068170547485352
Epoch: 6, Steps: 210 | Train Loss: 1.0025758 Vali Loss: 1.0265954 Test Loss: 0.9852086
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9887492
	speed: 0.0091s/iter; left time: 6.7073s
	iters: 200, epoch: 7 | loss: 1.0128410
	speed: 0.0083s/iter; left time: 5.3414s
Epoch: 7 cost time: 1.807149887084961
Epoch: 7, Steps: 210 | Train Loss: 1.0022855 Vali Loss: 1.0253378 Test Loss: 0.9851652
Validation loss decreased (1.026413 --> 1.025338).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0239881
	speed: 0.0095s/iter; left time: 5.0188s
	iters: 200, epoch: 8 | loss: 1.0086513
	speed: 0.0088s/iter; left time: 3.7919s
Epoch: 8 cost time: 1.903507947921753
Epoch: 8, Steps: 210 | Train Loss: 1.0019893 Vali Loss: 1.0254958 Test Loss: 0.9851596
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0048347
	speed: 0.0090s/iter; left time: 2.9027s
	iters: 200, epoch: 9 | loss: 1.0422252
	speed: 0.0083s/iter; left time: 1.8399s
Epoch: 9 cost time: 1.8057801723480225
Epoch: 9, Steps: 210 | Train Loss: 1.0016439 Vali Loss: 1.0251365 Test Loss: 0.9851414
Validation loss decreased (1.025338 --> 1.025136).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0337927
	speed: 0.0092s/iter; left time: 1.0165s
	iters: 200, epoch: 10 | loss: 1.0130249
	speed: 0.0084s/iter; left time: 0.0926s
Epoch: 10 cost time: 1.8225042819976807
Epoch: 10, Steps: 210 | Train Loss: 1.0018225 Vali Loss: 1.0252318 Test Loss: 0.9851518
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9851412177085876, mae:0.7884612083435059
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0255892
	speed: 0.0194s/iter; left time: 37.9656s
	iters: 200, epoch: 1 | loss: 1.0172167
	speed: 0.0133s/iter; left time: 24.8260s
Epoch: 1 cost time: 2.78560209274292
Epoch: 1, Steps: 206 | Train Loss: 1.0519505 Vali Loss: 1.0310875 Test Loss: 0.9902618
Validation loss decreased (inf --> 1.031088).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0090574
	speed: 0.0091s/iter; left time: 15.9334s
	iters: 200, epoch: 2 | loss: 1.0123616
	speed: 0.0083s/iter; left time: 13.7599s
Epoch: 2 cost time: 1.765507459640503
Epoch: 2, Steps: 206 | Train Loss: 1.0143294 Vali Loss: 1.0299386 Test Loss: 0.9899347
Validation loss decreased (1.031088 --> 1.029939).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0146315
	speed: 0.0090s/iter; left time: 14.0042s
	iters: 200, epoch: 3 | loss: 1.0035782
	speed: 0.0083s/iter; left time: 11.9914s
Epoch: 3 cost time: 1.752671480178833
Epoch: 3, Steps: 206 | Train Loss: 1.0095996 Vali Loss: 1.0285169 Test Loss: 0.9876817
Validation loss decreased (1.029939 --> 1.028517).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0189548
	speed: 0.0076s/iter; left time: 10.2132s
	iters: 200, epoch: 4 | loss: 0.9964327
	speed: 0.0070s/iter; left time: 8.7263s
Epoch: 4 cost time: 1.502516746520996
Epoch: 4, Steps: 206 | Train Loss: 1.0069865 Vali Loss: 1.0268465 Test Loss: 0.9867385
Validation loss decreased (1.028517 --> 1.026847).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9883199
	speed: 0.0071s/iter; left time: 8.0693s
	iters: 200, epoch: 5 | loss: 1.0087525
	speed: 0.0068s/iter; left time: 7.0992s
Epoch: 5 cost time: 1.482574462890625
Epoch: 5, Steps: 206 | Train Loss: 1.0057684 Vali Loss: 1.0264467 Test Loss: 0.9864354
Validation loss decreased (1.026847 --> 1.026447).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0013467
	speed: 0.0081s/iter; left time: 7.5336s
	iters: 200, epoch: 6 | loss: 1.0010643
	speed: 0.0078s/iter; left time: 6.4736s
Epoch: 6 cost time: 1.6579060554504395
Epoch: 6, Steps: 206 | Train Loss: 1.0048236 Vali Loss: 1.0263447 Test Loss: 0.9862946
Validation loss decreased (1.026447 --> 1.026345).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0037142
	speed: 0.0080s/iter; left time: 5.7716s
	iters: 200, epoch: 7 | loss: 1.0026751
	speed: 0.0072s/iter; left time: 4.4826s
Epoch: 7 cost time: 1.520934820175171
Epoch: 7, Steps: 206 | Train Loss: 1.0046894 Vali Loss: 1.0262504 Test Loss: 0.9861829
Validation loss decreased (1.026345 --> 1.026250).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9907070
	speed: 0.0083s/iter; left time: 4.3214s
	iters: 200, epoch: 8 | loss: 1.0040060
	speed: 0.0079s/iter; left time: 3.3163s
Epoch: 8 cost time: 1.7375800609588623
Epoch: 8, Steps: 206 | Train Loss: 1.0046853 Vali Loss: 1.0261233 Test Loss: 0.9861256
Validation loss decreased (1.026250 --> 1.026123).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9898912
	speed: 0.0085s/iter; left time: 2.6670s
	iters: 200, epoch: 9 | loss: 1.0187821
	speed: 0.0072s/iter; left time: 1.5344s
Epoch: 9 cost time: 1.5339608192443848
Epoch: 9, Steps: 206 | Train Loss: 1.0045973 Vali Loss: 1.0262005 Test Loss: 0.9861245
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0071515
	speed: 0.0085s/iter; left time: 0.9076s
	iters: 200, epoch: 10 | loss: 1.0167884
	speed: 0.0080s/iter; left time: 0.0559s
Epoch: 10 cost time: 1.704313039779663
Epoch: 10, Steps: 206 | Train Loss: 1.0043596 Vali Loss: 1.0262729 Test Loss: 0.9861222
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9861255884170532, mae:0.7885664701461792
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0233465
	speed: 0.0076s/iter; left time: 14.8950s
	iters: 200, epoch: 1 | loss: 1.0265510
	speed: 0.0070s/iter; left time: 13.0250s
Epoch: 1 cost time: 1.5088982582092285
Epoch: 1, Steps: 206 | Train Loss: 1.0528634 Vali Loss: 1.0307363 Test Loss: 0.9897938
Validation loss decreased (inf --> 1.030736).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0296657
	speed: 0.0078s/iter; left time: 13.6035s
	iters: 200, epoch: 2 | loss: 1.0072138
	speed: 0.0073s/iter; left time: 12.0049s
Epoch: 2 cost time: 1.5448648929595947
Epoch: 2, Steps: 206 | Train Loss: 1.0145808 Vali Loss: 1.0300455 Test Loss: 0.9895438
Validation loss decreased (1.030736 --> 1.030046).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9981593
	speed: 0.0074s/iter; left time: 11.5287s
	iters: 200, epoch: 3 | loss: 1.0080882
	speed: 0.0067s/iter; left time: 9.6420s
Epoch: 3 cost time: 1.4213695526123047
Epoch: 3, Steps: 206 | Train Loss: 1.0094288 Vali Loss: 1.0274149 Test Loss: 0.9879740
Validation loss decreased (1.030046 --> 1.027415).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0075308
	speed: 0.0091s/iter; left time: 12.2874s
	iters: 200, epoch: 4 | loss: 1.0205164
	speed: 0.0083s/iter; left time: 10.3295s
Epoch: 4 cost time: 1.7678489685058594
Epoch: 4, Steps: 206 | Train Loss: 1.0070644 Vali Loss: 1.0266111 Test Loss: 0.9865906
Validation loss decreased (1.027415 --> 1.026611).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0063102
	speed: 0.0078s/iter; left time: 8.8202s
	iters: 200, epoch: 5 | loss: 1.0137056
	speed: 0.0071s/iter; left time: 7.3454s
Epoch: 5 cost time: 1.5125513076782227
Epoch: 5, Steps: 206 | Train Loss: 1.0056515 Vali Loss: 1.0263512 Test Loss: 0.9862422
Validation loss decreased (1.026611 --> 1.026351).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0071150
	speed: 0.0079s/iter; left time: 7.3216s
	iters: 200, epoch: 6 | loss: 1.0065185
	speed: 0.0077s/iter; left time: 6.3679s
Epoch: 6 cost time: 1.631542682647705
Epoch: 6, Steps: 206 | Train Loss: 1.0051399 Vali Loss: 1.0262264 Test Loss: 0.9861242
Validation loss decreased (1.026351 --> 1.026226).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0043143
	speed: 0.0074s/iter; left time: 5.3824s
	iters: 200, epoch: 7 | loss: 0.9996563
	speed: 0.0066s/iter; left time: 4.1416s
Epoch: 7 cost time: 1.4219269752502441
Epoch: 7, Steps: 206 | Train Loss: 1.0047111 Vali Loss: 1.0260326 Test Loss: 0.9860240
Validation loss decreased (1.026226 --> 1.026033).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0140563
	speed: 0.0070s/iter; left time: 3.6461s
	iters: 200, epoch: 8 | loss: 1.0105598
	speed: 0.0065s/iter; left time: 2.7039s
Epoch: 8 cost time: 1.3811602592468262
Epoch: 8, Steps: 206 | Train Loss: 1.0045848 Vali Loss: 1.0259234 Test Loss: 0.9860001
Validation loss decreased (1.026033 --> 1.025923).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9973456
	speed: 0.0087s/iter; left time: 2.7352s
	iters: 200, epoch: 9 | loss: 1.0030559
	speed: 0.0081s/iter; left time: 1.7353s
Epoch: 9 cost time: 1.7479181289672852
Epoch: 9, Steps: 206 | Train Loss: 1.0045648 Vali Loss: 1.0260218 Test Loss: 0.9859980
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0070509
	speed: 0.0091s/iter; left time: 0.9686s
	iters: 200, epoch: 10 | loss: 1.0032785
	speed: 0.0084s/iter; left time: 0.0586s
Epoch: 10 cost time: 1.7866334915161133
Epoch: 10, Steps: 206 | Train Loss: 1.0042491 Vali Loss: 1.0259451 Test Loss: 0.9859995
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9860000014305115, mae:0.7884975671768188
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0219179
	speed: 0.0092s/iter; left time: 17.9652s
	iters: 200, epoch: 1 | loss: 1.0159174
	speed: 0.0084s/iter; left time: 15.5592s
Epoch: 1 cost time: 1.7787952423095703
Epoch: 1, Steps: 206 | Train Loss: 1.0511145 Vali Loss: 1.0312998 Test Loss: 0.9914237
Validation loss decreased (inf --> 1.031300).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0049742
	speed: 0.0092s/iter; left time: 16.0998s
	iters: 200, epoch: 2 | loss: 1.0090761
	speed: 0.0084s/iter; left time: 13.9085s
Epoch: 2 cost time: 1.788844347000122
Epoch: 2, Steps: 206 | Train Loss: 1.0144783 Vali Loss: 1.0285342 Test Loss: 0.9882890
Validation loss decreased (1.031300 --> 1.028534).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0141633
	speed: 0.0092s/iter; left time: 14.2922s
	iters: 200, epoch: 3 | loss: 0.9980679
	speed: 0.0086s/iter; left time: 12.4431s
Epoch: 3 cost time: 1.8321778774261475
Epoch: 3, Steps: 206 | Train Loss: 1.0097729 Vali Loss: 1.0278926 Test Loss: 0.9875317
Validation loss decreased (1.028534 --> 1.027893).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0067271
	speed: 0.0075s/iter; left time: 10.1268s
	iters: 200, epoch: 4 | loss: 1.0186092
	speed: 0.0067s/iter; left time: 8.2724s
Epoch: 4 cost time: 1.414808750152588
Epoch: 4, Steps: 206 | Train Loss: 1.0070776 Vali Loss: 1.0268018 Test Loss: 0.9866005
Validation loss decreased (1.027893 --> 1.026802).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9967100
	speed: 0.0080s/iter; left time: 9.0537s
	iters: 200, epoch: 5 | loss: 1.0209517
	speed: 0.0071s/iter; left time: 7.4074s
Epoch: 5 cost time: 1.531036138534546
Epoch: 5, Steps: 206 | Train Loss: 1.0057873 Vali Loss: 1.0264452 Test Loss: 0.9865100
Validation loss decreased (1.026802 --> 1.026445).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0041561
	speed: 0.0086s/iter; left time: 7.9940s
	iters: 200, epoch: 6 | loss: 1.0254809
	speed: 0.0077s/iter; left time: 6.4211s
Epoch: 6 cost time: 1.6390924453735352
Epoch: 6, Steps: 206 | Train Loss: 1.0051407 Vali Loss: 1.0261381 Test Loss: 0.9862785
Validation loss decreased (1.026445 --> 1.026138).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0022883
	speed: 0.0071s/iter; left time: 5.1278s
	iters: 200, epoch: 7 | loss: 1.0084018
	speed: 0.0068s/iter; left time: 4.2424s
Epoch: 7 cost time: 1.456275463104248
Epoch: 7, Steps: 206 | Train Loss: 1.0048708 Vali Loss: 1.0261028 Test Loss: 0.9861130
Validation loss decreased (1.026138 --> 1.026103).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0034761
	speed: 0.0092s/iter; left time: 4.7555s
	iters: 200, epoch: 8 | loss: 1.0024577
	speed: 0.0084s/iter; left time: 3.4989s
Epoch: 8 cost time: 1.7732913494110107
Epoch: 8, Steps: 206 | Train Loss: 1.0045274 Vali Loss: 1.0259943 Test Loss: 0.9860877
Validation loss decreased (1.026103 --> 1.025994).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0024109
	speed: 0.0084s/iter; left time: 2.6171s
	iters: 200, epoch: 9 | loss: 1.0115699
	speed: 0.0079s/iter; left time: 1.6858s
Epoch: 9 cost time: 1.6951723098754883
Epoch: 9, Steps: 206 | Train Loss: 1.0044045 Vali Loss: 1.0260454 Test Loss: 0.9860685
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0211123
	speed: 0.0091s/iter; left time: 0.9774s
	iters: 200, epoch: 10 | loss: 0.9994231
	speed: 0.0084s/iter; left time: 0.0586s
Epoch: 10 cost time: 1.7814605236053467
Epoch: 10, Steps: 206 | Train Loss: 1.0044964 Vali Loss: 1.0260879 Test Loss: 0.9860690
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9860876798629761, mae:0.7885973453521729
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0232158
	speed: 0.0173s/iter; left time: 31.8498s
Epoch: 1 cost time: 2.5096547603607178
Epoch: 1, Steps: 194 | Train Loss: 1.0533103 Vali Loss: 1.0313534 Test Loss: 0.9842513
Validation loss decreased (inf --> 1.031353).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0196886
	speed: 0.0076s/iter; left time: 12.4501s
Epoch: 2 cost time: 1.392101526260376
Epoch: 2, Steps: 194 | Train Loss: 1.0160703 Vali Loss: 1.0308732 Test Loss: 0.9833872
Validation loss decreased (1.031353 --> 1.030873).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0154887
	speed: 0.0093s/iter; left time: 13.4884s
Epoch: 3 cost time: 1.827871322631836
Epoch: 3, Steps: 194 | Train Loss: 1.0118970 Vali Loss: 1.0283303 Test Loss: 0.9817860
Validation loss decreased (1.030873 --> 1.028330).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9992265
	speed: 0.0096s/iter; left time: 12.0521s
Epoch: 4 cost time: 1.7445073127746582
Epoch: 4, Steps: 194 | Train Loss: 1.0097884 Vali Loss: 1.0284063 Test Loss: 0.9809886
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0106083
	speed: 0.0093s/iter; left time: 9.8783s
Epoch: 5 cost time: 1.710585117340088
Epoch: 5, Steps: 194 | Train Loss: 1.0089209 Vali Loss: 1.0272790 Test Loss: 0.9803497
Validation loss decreased (1.028330 --> 1.027279).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0116336
	speed: 0.0089s/iter; left time: 7.7257s
Epoch: 6 cost time: 1.668916940689087
Epoch: 6, Steps: 194 | Train Loss: 1.0084810 Vali Loss: 1.0273074 Test Loss: 0.9802116
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0027239
	speed: 0.0087s/iter; left time: 5.8700s
Epoch: 7 cost time: 1.661665916442871
Epoch: 7, Steps: 194 | Train Loss: 1.0081662 Vali Loss: 1.0271266 Test Loss: 0.9800748
Validation loss decreased (1.027279 --> 1.027127).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0070654
	speed: 0.0093s/iter; left time: 4.4750s
Epoch: 8 cost time: 1.709507942199707
Epoch: 8, Steps: 194 | Train Loss: 1.0081189 Vali Loss: 1.0270792 Test Loss: 0.9800302
Validation loss decreased (1.027127 --> 1.027079).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0075390
	speed: 0.0094s/iter; left time: 2.7128s
Epoch: 9 cost time: 1.7023305892944336
Epoch: 9, Steps: 194 | Train Loss: 1.0080046 Vali Loss: 1.0270648 Test Loss: 0.9800257
Validation loss decreased (1.027079 --> 1.027065).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0039483
	speed: 0.0093s/iter; left time: 0.8862s
Epoch: 10 cost time: 1.7174997329711914
Epoch: 10, Steps: 194 | Train Loss: 1.0078760 Vali Loss: 1.0269979 Test Loss: 0.9800304
Validation loss decreased (1.027065 --> 1.026998).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9800304174423218, mae:0.7845816612243652
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0277792
	speed: 0.0094s/iter; left time: 17.2207s
Epoch: 1 cost time: 1.735548973083496
Epoch: 1, Steps: 194 | Train Loss: 1.0540362 Vali Loss: 1.0306039 Test Loss: 0.9838005
Validation loss decreased (inf --> 1.030604).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0113968
	speed: 0.0095s/iter; left time: 15.5747s
Epoch: 2 cost time: 1.73828125
Epoch: 2, Steps: 194 | Train Loss: 1.0157717 Vali Loss: 1.0305853 Test Loss: 0.9835280
Validation loss decreased (1.030604 --> 1.030585).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0077106
	speed: 0.0095s/iter; left time: 13.7475s
Epoch: 3 cost time: 1.7400875091552734
Epoch: 3, Steps: 194 | Train Loss: 1.0119559 Vali Loss: 1.0284605 Test Loss: 0.9812936
Validation loss decreased (1.030585 --> 1.028461).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0082666
	speed: 0.0094s/iter; left time: 11.7795s
Epoch: 4 cost time: 1.7343814373016357
Epoch: 4, Steps: 194 | Train Loss: 1.0097261 Vali Loss: 1.0274355 Test Loss: 0.9806929
Validation loss decreased (1.028461 --> 1.027436).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9986755
	speed: 0.0093s/iter; left time: 9.9233s
Epoch: 5 cost time: 1.7347724437713623
Epoch: 5, Steps: 194 | Train Loss: 1.0086393 Vali Loss: 1.0273412 Test Loss: 0.9803462
Validation loss decreased (1.027436 --> 1.027341).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0169842
	speed: 0.0094s/iter; left time: 8.1874s
Epoch: 6 cost time: 1.7650659084320068
Epoch: 6, Steps: 194 | Train Loss: 1.0083162 Vali Loss: 1.0270280 Test Loss: 0.9801270
Validation loss decreased (1.027341 --> 1.027028).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0034993
	speed: 0.0104s/iter; left time: 7.0738s
Epoch: 7 cost time: 1.8494775295257568
Epoch: 7, Steps: 194 | Train Loss: 1.0080605 Vali Loss: 1.0270737 Test Loss: 0.9799992
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0072777
	speed: 0.0104s/iter; left time: 5.0323s
Epoch: 8 cost time: 1.8303132057189941
Epoch: 8, Steps: 194 | Train Loss: 1.0079303 Vali Loss: 1.0269548 Test Loss: 0.9799465
Validation loss decreased (1.027028 --> 1.026955).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0021088
	speed: 0.0093s/iter; left time: 2.6887s
Epoch: 9 cost time: 1.725074052810669
Epoch: 9, Steps: 194 | Train Loss: 1.0078088 Vali Loss: 1.0268954 Test Loss: 0.9799492
Validation loss decreased (1.026955 --> 1.026895).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0089643
	speed: 0.0095s/iter; left time: 0.9022s
Epoch: 10 cost time: 1.7529358863830566
Epoch: 10, Steps: 194 | Train Loss: 1.0077627 Vali Loss: 1.0269229 Test Loss: 0.9799451
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9799492359161377, mae:0.7845263481140137
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0289578
	speed: 0.0093s/iter; left time: 17.1952s
Epoch: 1 cost time: 1.7264277935028076
Epoch: 1, Steps: 194 | Train Loss: 1.0526458 Vali Loss: 1.0305156 Test Loss: 0.9834682
Validation loss decreased (inf --> 1.030516).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0256346
	speed: 0.0097s/iter; left time: 15.9360s
Epoch: 2 cost time: 1.77449369430542
Epoch: 2, Steps: 194 | Train Loss: 1.0160743 Vali Loss: 1.0292585 Test Loss: 0.9829127
Validation loss decreased (1.030516 --> 1.029258).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0198401
	speed: 0.0094s/iter; left time: 13.6020s
Epoch: 3 cost time: 1.7251806259155273
Epoch: 3, Steps: 194 | Train Loss: 1.0117165 Vali Loss: 1.0282273 Test Loss: 0.9814515
Validation loss decreased (1.029258 --> 1.028227).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0081406
	speed: 0.0094s/iter; left time: 11.7888s
Epoch: 4 cost time: 1.7288768291473389
Epoch: 4, Steps: 194 | Train Loss: 1.0097574 Vali Loss: 1.0271647 Test Loss: 0.9806696
Validation loss decreased (1.028227 --> 1.027165).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0131085
	speed: 0.0094s/iter; left time: 10.0046s
Epoch: 5 cost time: 1.7308158874511719
Epoch: 5, Steps: 194 | Train Loss: 1.0088778 Vali Loss: 1.0267549 Test Loss: 0.9799194
Validation loss decreased (1.027165 --> 1.026755).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0001472
	speed: 0.0080s/iter; left time: 6.9826s
Epoch: 6 cost time: 1.5085132122039795
Epoch: 6, Steps: 194 | Train Loss: 1.0084502 Vali Loss: 1.0270301 Test Loss: 0.9800056
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0087745
	speed: 0.0084s/iter; left time: 5.6705s
Epoch: 7 cost time: 1.5134992599487305
Epoch: 7, Steps: 194 | Train Loss: 1.0080391 Vali Loss: 1.0268989 Test Loss: 0.9798850
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0113554
	speed: 0.0092s/iter; left time: 4.4603s
Epoch: 8 cost time: 1.7177906036376953
Epoch: 8, Steps: 194 | Train Loss: 1.0078571 Vali Loss: 1.0269065 Test Loss: 0.9798183
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0127339
	speed: 0.0092s/iter; left time: 2.6671s
Epoch: 9 cost time: 1.7080585956573486
Epoch: 9, Steps: 194 | Train Loss: 1.0077109 Vali Loss: 1.0269550 Test Loss: 0.9798054
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0045397
	speed: 0.0084s/iter; left time: 0.7983s
Epoch: 10 cost time: 1.531409740447998
Epoch: 10, Steps: 194 | Train Loss: 1.0077573 Vali Loss: 1.0268431 Test Loss: 0.9798065
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9799193739891052, mae:0.7845840454101562
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9934819
	speed: 0.0117s/iter; left time: 23.8115s
	iters: 200, epoch: 1 | loss: 1.0402248
	speed: 0.0082s/iter; left time: 15.8251s
Epoch: 1 cost time: 1.7346422672271729
Epoch: 1, Steps: 213 | Train Loss: 1.0540571 Vali Loss: 1.0255842 Test Loss: 0.9917802
Validation loss decreased (inf --> 1.025584).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9989963
	speed: 0.0068s/iter; left time: 12.2977s
	iters: 200, epoch: 2 | loss: 1.0172905
	speed: 0.0057s/iter; left time: 9.8653s
Epoch: 2 cost time: 1.2542204856872559
Epoch: 2, Steps: 213 | Train Loss: 1.0135900 Vali Loss: 1.0280799 Test Loss: 0.9921580
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9902934
	speed: 0.0064s/iter; left time: 10.2007s
	iters: 200, epoch: 3 | loss: 1.0181401
	speed: 0.0058s/iter; left time: 8.6906s
Epoch: 3 cost time: 1.265045404434204
Epoch: 3, Steps: 213 | Train Loss: 1.0059308 Vali Loss: 1.0254943 Test Loss: 0.9892851
Validation loss decreased (1.025584 --> 1.025494).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0168847
	speed: 0.0078s/iter; left time: 10.8148s
	iters: 200, epoch: 4 | loss: 0.9737568
	speed: 0.0071s/iter; left time: 9.1681s
Epoch: 4 cost time: 1.55079984664917
Epoch: 4, Steps: 213 | Train Loss: 1.0022134 Vali Loss: 1.0257516 Test Loss: 0.9893146
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0169597
	speed: 0.0072s/iter; left time: 8.4851s
	iters: 200, epoch: 5 | loss: 1.0054634
	speed: 0.0065s/iter; left time: 7.0546s
Epoch: 5 cost time: 1.437258243560791
Epoch: 5, Steps: 213 | Train Loss: 1.0002894 Vali Loss: 1.0259490 Test Loss: 0.9890234
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0289336
	speed: 0.0077s/iter; left time: 7.4046s
	iters: 200, epoch: 6 | loss: 1.0097065
	speed: 0.0071s/iter; left time: 6.1449s
Epoch: 6 cost time: 1.579702615737915
Epoch: 6, Steps: 213 | Train Loss: 0.9992333 Vali Loss: 1.0252187 Test Loss: 0.9888338
Validation loss decreased (1.025494 --> 1.025219).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9821267
	speed: 0.0079s/iter; left time: 5.9678s
	iters: 200, epoch: 7 | loss: 1.0019711
	speed: 0.0078s/iter; left time: 5.0823s
Epoch: 7 cost time: 1.715294361114502
Epoch: 7, Steps: 213 | Train Loss: 0.9982681 Vali Loss: 1.0259240 Test Loss: 0.9889254
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9982696
	speed: 0.0082s/iter; left time: 4.4228s
	iters: 200, epoch: 8 | loss: 1.0019910
	speed: 0.0073s/iter; left time: 3.1917s
Epoch: 8 cost time: 1.6005403995513916
Epoch: 8, Steps: 213 | Train Loss: 0.9979306 Vali Loss: 1.0251987 Test Loss: 0.9888621
Validation loss decreased (1.025219 --> 1.025199).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9872994
	speed: 0.0079s/iter; left time: 2.5706s
	iters: 200, epoch: 9 | loss: 0.9902009
	speed: 0.0070s/iter; left time: 1.5887s
Epoch: 9 cost time: 1.5093801021575928
Epoch: 9, Steps: 213 | Train Loss: 0.9976614 Vali Loss: 1.0253694 Test Loss: 0.9888355
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0358007
	speed: 0.0058s/iter; left time: 0.6562s
	iters: 200, epoch: 10 | loss: 0.9975841
	speed: 0.0052s/iter; left time: 0.0730s
Epoch: 10 cost time: 1.1509661674499512
Epoch: 10, Steps: 213 | Train Loss: 0.9977774 Vali Loss: 1.0257649 Test Loss: 0.9888465
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9888622760772705, mae:0.7903433442115784
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9958644
	speed: 0.0059s/iter; left time: 12.0318s
	iters: 200, epoch: 1 | loss: 1.0144346
	speed: 0.0053s/iter; left time: 10.2751s
Epoch: 1 cost time: 1.1722662448883057
Epoch: 1, Steps: 213 | Train Loss: 1.0542090 Vali Loss: 1.0285481 Test Loss: 0.9936002
Validation loss decreased (inf --> 1.028548).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9961390
	speed: 0.0067s/iter; left time: 12.2631s
	iters: 200, epoch: 2 | loss: 1.0254457
	speed: 0.0063s/iter; left time: 10.7816s
Epoch: 2 cost time: 1.379866600036621
Epoch: 2, Steps: 213 | Train Loss: 1.0127895 Vali Loss: 1.0257479 Test Loss: 0.9906967
Validation loss decreased (1.028548 --> 1.025748).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0042006
	speed: 0.0070s/iter; left time: 11.2590s
	iters: 200, epoch: 3 | loss: 0.9874943
	speed: 0.0064s/iter; left time: 9.5977s
Epoch: 3 cost time: 1.3967909812927246
Epoch: 3, Steps: 213 | Train Loss: 1.0056144 Vali Loss: 1.0244482 Test Loss: 0.9891005
Validation loss decreased (1.025748 --> 1.024448).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0184276
	speed: 0.0075s/iter; left time: 10.4568s
	iters: 200, epoch: 4 | loss: 0.9943075
	speed: 0.0067s/iter; left time: 8.7045s
Epoch: 4 cost time: 1.4752490520477295
Epoch: 4, Steps: 213 | Train Loss: 1.0019287 Vali Loss: 1.0257365 Test Loss: 0.9890662
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9622892
	speed: 0.0103s/iter; left time: 12.1791s
	iters: 200, epoch: 5 | loss: 0.9815702
	speed: 0.0088s/iter; left time: 9.4446s
Epoch: 5 cost time: 1.900477647781372
Epoch: 5, Steps: 213 | Train Loss: 0.9991558 Vali Loss: 1.0268451 Test Loss: 0.9896470
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0019629
	speed: 0.0083s/iter; left time: 7.9745s
	iters: 200, epoch: 6 | loss: 1.0052127
	speed: 0.0074s/iter; left time: 6.4346s
Epoch: 6 cost time: 1.646681785583496
Epoch: 6, Steps: 213 | Train Loss: 0.9985535 Vali Loss: 1.0264704 Test Loss: 0.9892946
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0016278
	speed: 0.0075s/iter; left time: 5.6384s
	iters: 200, epoch: 7 | loss: 0.9972295
	speed: 0.0069s/iter; left time: 4.5047s
Epoch: 7 cost time: 1.5370123386383057
Epoch: 7, Steps: 213 | Train Loss: 0.9977130 Vali Loss: 1.0252193 Test Loss: 0.9890946
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9860660
	speed: 0.0082s/iter; left time: 4.4461s
	iters: 200, epoch: 8 | loss: 1.0252600
	speed: 0.0072s/iter; left time: 3.1802s
Epoch: 8 cost time: 1.5752036571502686
Epoch: 8, Steps: 213 | Train Loss: 0.9967981 Vali Loss: 1.0254321 Test Loss: 0.9890220
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9891006350517273, mae:0.7903778553009033
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0369825
	speed: 0.0097s/iter; left time: 19.7758s
	iters: 200, epoch: 1 | loss: 1.0375396
	speed: 0.0087s/iter; left time: 16.8646s
Epoch: 1 cost time: 1.90556001663208
Epoch: 1, Steps: 213 | Train Loss: 1.0535717 Vali Loss: 1.0270535 Test Loss: 0.9926186
Validation loss decreased (inf --> 1.027053).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0293105
	speed: 0.0090s/iter; left time: 16.3711s
	iters: 200, epoch: 2 | loss: 1.0101600
	speed: 0.0079s/iter; left time: 13.5631s
Epoch: 2 cost time: 1.735238790512085
Epoch: 2, Steps: 213 | Train Loss: 1.0125876 Vali Loss: 1.0266168 Test Loss: 0.9907302
Validation loss decreased (1.027053 --> 1.026617).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0097296
	speed: 0.0084s/iter; left time: 13.5420s
	iters: 200, epoch: 3 | loss: 0.9809569
	speed: 0.0082s/iter; left time: 12.3070s
Epoch: 3 cost time: 1.799208164215088
Epoch: 3, Steps: 213 | Train Loss: 1.0058570 Vali Loss: 1.0251125 Test Loss: 0.9899203
Validation loss decreased (1.026617 --> 1.025113).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0344182
	speed: 0.0091s/iter; left time: 12.6755s
	iters: 200, epoch: 4 | loss: 1.0295061
	speed: 0.0080s/iter; left time: 10.3073s
Epoch: 4 cost time: 1.7652406692504883
Epoch: 4, Steps: 213 | Train Loss: 1.0019167 Vali Loss: 1.0246102 Test Loss: 0.9889418
Validation loss decreased (1.025113 --> 1.024610).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9929888
	speed: 0.0072s/iter; left time: 8.5038s
	iters: 200, epoch: 5 | loss: 0.9911804
	speed: 0.0069s/iter; left time: 7.4202s
Epoch: 5 cost time: 1.5125446319580078
Epoch: 5, Steps: 213 | Train Loss: 0.9998020 Vali Loss: 1.0251282 Test Loss: 0.9889552
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0008390
	speed: 0.0073s/iter; left time: 7.0822s
	iters: 200, epoch: 6 | loss: 1.0230784
	speed: 0.0067s/iter; left time: 5.7765s
Epoch: 6 cost time: 1.4744882583618164
Epoch: 6, Steps: 213 | Train Loss: 0.9981702 Vali Loss: 1.0248735 Test Loss: 0.9886974
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0011771
	speed: 0.0081s/iter; left time: 6.1194s
	iters: 200, epoch: 7 | loss: 0.9928905
	speed: 0.0073s/iter; left time: 4.7852s
Epoch: 7 cost time: 1.587977647781372
Epoch: 7, Steps: 213 | Train Loss: 0.9974837 Vali Loss: 1.0244323 Test Loss: 0.9888089
Validation loss decreased (1.024610 --> 1.024432).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0232673
	speed: 0.0089s/iter; left time: 4.8173s
	iters: 200, epoch: 8 | loss: 0.9854025
	speed: 0.0083s/iter; left time: 3.6457s
Epoch: 8 cost time: 1.8238892555236816
Epoch: 8, Steps: 213 | Train Loss: 0.9971365 Vali Loss: 1.0241047 Test Loss: 0.9887326
Validation loss decreased (1.024432 --> 1.024105).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9838939
	speed: 0.0093s/iter; left time: 3.0329s
	iters: 200, epoch: 9 | loss: 0.9933037
	speed: 0.0084s/iter; left time: 1.9042s
Epoch: 9 cost time: 1.8448171615600586
Epoch: 9, Steps: 213 | Train Loss: 0.9973092 Vali Loss: 1.0239308 Test Loss: 0.9887198
Validation loss decreased (1.024105 --> 1.023931).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0239284
	speed: 0.0095s/iter; left time: 1.0788s
	iters: 200, epoch: 10 | loss: 0.9912547
	speed: 0.0086s/iter; left time: 0.1200s
Epoch: 10 cost time: 1.8719573020935059
Epoch: 10, Steps: 213 | Train Loss: 0.9968748 Vali Loss: 1.0239999 Test Loss: 0.9887263
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9887199997901917, mae:0.7901713252067566
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0401138
	speed: 0.0163s/iter; left time: 32.6979s
	iters: 200, epoch: 1 | loss: 1.0107139
	speed: 0.0110s/iter; left time: 20.8173s
Epoch: 1 cost time: 2.2768542766571045
Epoch: 1, Steps: 210 | Train Loss: 1.0512581 Vali Loss: 1.0292830 Test Loss: 0.9893075
Validation loss decreased (inf --> 1.029283).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0362988
	speed: 0.0073s/iter; left time: 13.0383s
	iters: 200, epoch: 2 | loss: 1.0028480
	speed: 0.0065s/iter; left time: 11.0733s
Epoch: 2 cost time: 1.422750473022461
Epoch: 2, Steps: 210 | Train Loss: 1.0145151 Vali Loss: 1.0279572 Test Loss: 0.9881963
Validation loss decreased (1.029283 --> 1.027957).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9980778
	speed: 0.0088s/iter; left time: 13.8863s
	iters: 200, epoch: 3 | loss: 1.0226662
	speed: 0.0077s/iter; left time: 11.3743s
Epoch: 3 cost time: 1.6498873233795166
Epoch: 3, Steps: 210 | Train Loss: 1.0087925 Vali Loss: 1.0258473 Test Loss: 0.9862255
Validation loss decreased (1.027957 --> 1.025847).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9919508
	speed: 0.0071s/iter; left time: 9.7663s
	iters: 200, epoch: 4 | loss: 0.9897754
	speed: 0.0064s/iter; left time: 8.0715s
Epoch: 4 cost time: 1.381209373474121
Epoch: 4, Steps: 210 | Train Loss: 1.0056347 Vali Loss: 1.0272752 Test Loss: 0.9856166
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9961911
	speed: 0.0079s/iter; left time: 9.2055s
	iters: 200, epoch: 5 | loss: 0.9962510
	speed: 0.0072s/iter; left time: 7.6205s
Epoch: 5 cost time: 1.5514347553253174
Epoch: 5, Steps: 210 | Train Loss: 1.0038742 Vali Loss: 1.0258279 Test Loss: 0.9851983
Validation loss decreased (1.025847 --> 1.025828).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0235565
	speed: 0.0077s/iter; left time: 7.2976s
	iters: 200, epoch: 6 | loss: 1.0000336
	speed: 0.0070s/iter; left time: 5.9910s
Epoch: 6 cost time: 1.5198328495025635
Epoch: 6, Steps: 210 | Train Loss: 1.0030382 Vali Loss: 1.0250003 Test Loss: 0.9849627
Validation loss decreased (1.025828 --> 1.025000).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0014800
	speed: 0.0065s/iter; left time: 4.8121s
	iters: 200, epoch: 7 | loss: 0.9794248
	speed: 0.0056s/iter; left time: 3.5800s
Epoch: 7 cost time: 1.2125318050384521
Epoch: 7, Steps: 210 | Train Loss: 1.0026191 Vali Loss: 1.0261970 Test Loss: 0.9848567
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0006483
	speed: 0.0080s/iter; left time: 4.2342s
	iters: 200, epoch: 8 | loss: 1.0211002
	speed: 0.0072s/iter; left time: 3.1074s
Epoch: 8 cost time: 1.561936616897583
Epoch: 8, Steps: 210 | Train Loss: 1.0020155 Vali Loss: 1.0253770 Test Loss: 0.9848242
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0146803
	speed: 0.0070s/iter; left time: 2.2344s
	iters: 200, epoch: 9 | loss: 1.0053527
	speed: 0.0061s/iter; left time: 1.3514s
Epoch: 9 cost time: 1.3324131965637207
Epoch: 9, Steps: 210 | Train Loss: 1.0022421 Vali Loss: 1.0269097 Test Loss: 0.9848446
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9937825
	speed: 0.0074s/iter; left time: 0.8260s
	iters: 200, epoch: 10 | loss: 0.9872825
	speed: 0.0069s/iter; left time: 0.0764s
Epoch: 10 cost time: 1.5114550590515137
Epoch: 10, Steps: 210 | Train Loss: 1.0019931 Vali Loss: 1.0261471 Test Loss: 0.9848449
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9849626421928406, mae:0.788338303565979
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0225178
	speed: 0.0069s/iter; left time: 13.8627s
	iters: 200, epoch: 1 | loss: 1.0166215
	speed: 0.0061s/iter; left time: 11.5693s
Epoch: 1 cost time: 1.3246126174926758
Epoch: 1, Steps: 210 | Train Loss: 1.0520902 Vali Loss: 1.0285701 Test Loss: 0.9878896
Validation loss decreased (inf --> 1.028570).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0212827
	speed: 0.0077s/iter; left time: 13.8330s
	iters: 200, epoch: 2 | loss: 0.9937446
	speed: 0.0070s/iter; left time: 11.8613s
Epoch: 2 cost time: 1.5110127925872803
Epoch: 2, Steps: 210 | Train Loss: 1.0139059 Vali Loss: 1.0276387 Test Loss: 0.9875758
Validation loss decreased (1.028570 --> 1.027639).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0214778
	speed: 0.0066s/iter; left time: 10.5121s
	iters: 200, epoch: 3 | loss: 0.9897985
	speed: 0.0058s/iter; left time: 8.6581s
Epoch: 3 cost time: 1.2692248821258545
Epoch: 3, Steps: 210 | Train Loss: 1.0084320 Vali Loss: 1.0261891 Test Loss: 0.9865362
Validation loss decreased (1.027639 --> 1.026189).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0183296
	speed: 0.0077s/iter; left time: 10.5632s
	iters: 200, epoch: 4 | loss: 1.0027117
	speed: 0.0070s/iter; left time: 8.9363s
Epoch: 4 cost time: 1.526982307434082
Epoch: 4, Steps: 210 | Train Loss: 1.0055038 Vali Loss: 1.0258260 Test Loss: 0.9854684
Validation loss decreased (1.026189 --> 1.025826).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0059229
	speed: 0.0093s/iter; left time: 10.7873s
	iters: 200, epoch: 5 | loss: 1.0036905
	speed: 0.0084s/iter; left time: 8.9275s
Epoch: 5 cost time: 1.8126304149627686
Epoch: 5, Steps: 210 | Train Loss: 1.0036188 Vali Loss: 1.0264971 Test Loss: 0.9850776
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0034883
	speed: 0.0083s/iter; left time: 7.9190s
	iters: 200, epoch: 6 | loss: 1.0036070
	speed: 0.0074s/iter; left time: 6.2891s
Epoch: 6 cost time: 1.603346824645996
Epoch: 6, Steps: 210 | Train Loss: 1.0028232 Vali Loss: 1.0257314 Test Loss: 0.9848635
Validation loss decreased (1.025826 --> 1.025731).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9890196
	speed: 0.0089s/iter; left time: 6.6303s
	iters: 200, epoch: 7 | loss: 1.0198408
	speed: 0.0082s/iter; left time: 5.2871s
Epoch: 7 cost time: 1.7805116176605225
Epoch: 7, Steps: 210 | Train Loss: 1.0021257 Vali Loss: 1.0256313 Test Loss: 0.9847567
Validation loss decreased (1.025731 --> 1.025631).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0018464
	speed: 0.0092s/iter; left time: 4.8850s
	iters: 200, epoch: 8 | loss: 0.9831635
	speed: 0.0084s/iter; left time: 3.6140s
Epoch: 8 cost time: 1.8188812732696533
Epoch: 8, Steps: 210 | Train Loss: 1.0019574 Vali Loss: 1.0253589 Test Loss: 0.9847494
Validation loss decreased (1.025631 --> 1.025359).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9998376
	speed: 0.0077s/iter; left time: 2.4749s
	iters: 200, epoch: 9 | loss: 0.9878957
	speed: 0.0068s/iter; left time: 1.5044s
Epoch: 9 cost time: 1.4798226356506348
Epoch: 9, Steps: 210 | Train Loss: 1.0016186 Vali Loss: 1.0250659 Test Loss: 0.9847443
Validation loss decreased (1.025359 --> 1.025066).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9779558
	speed: 0.0094s/iter; left time: 1.0482s
	iters: 200, epoch: 10 | loss: 1.0134894
	speed: 0.0085s/iter; left time: 0.0938s
Epoch: 10 cost time: 1.839829921722412
Epoch: 10, Steps: 210 | Train Loss: 1.0015821 Vali Loss: 1.0249146 Test Loss: 0.9847541
Validation loss decreased (1.025066 --> 1.024915).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9847541451454163, mae:0.7883078455924988
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0093607
	speed: 0.0075s/iter; left time: 14.9811s
	iters: 200, epoch: 1 | loss: 1.0107095
	speed: 0.0067s/iter; left time: 12.8220s
Epoch: 1 cost time: 1.4700582027435303
Epoch: 1, Steps: 210 | Train Loss: 1.0516979 Vali Loss: 1.0281881 Test Loss: 0.9887325
Validation loss decreased (inf --> 1.028188).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0319829
	speed: 0.0094s/iter; left time: 16.7624s
	iters: 200, epoch: 2 | loss: 1.0041463
	speed: 0.0085s/iter; left time: 14.3523s
Epoch: 2 cost time: 1.8389644622802734
Epoch: 2, Steps: 210 | Train Loss: 1.0143427 Vali Loss: 1.0297834 Test Loss: 0.9891027
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9898696
	speed: 0.0085s/iter; left time: 13.4179s
	iters: 200, epoch: 3 | loss: 1.0025573
	speed: 0.0080s/iter; left time: 11.8517s
Epoch: 3 cost time: 1.7330141067504883
Epoch: 3, Steps: 210 | Train Loss: 1.0085783 Vali Loss: 1.0261499 Test Loss: 0.9863745
Validation loss decreased (1.028188 --> 1.026150).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9884405
	speed: 0.0086s/iter; left time: 11.7503s
	iters: 200, epoch: 4 | loss: 1.0142380
	speed: 0.0076s/iter; left time: 9.6079s
Epoch: 4 cost time: 1.6321940422058105
Epoch: 4, Steps: 210 | Train Loss: 1.0057222 Vali Loss: 1.0266501 Test Loss: 0.9855596
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9824945
	speed: 0.0084s/iter; left time: 9.7691s
	iters: 200, epoch: 5 | loss: 1.0163401
	speed: 0.0080s/iter; left time: 8.4601s
Epoch: 5 cost time: 1.7358083724975586
Epoch: 5, Steps: 210 | Train Loss: 1.0034301 Vali Loss: 1.0256436 Test Loss: 0.9853124
Validation loss decreased (1.026150 --> 1.025644).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9872956
	speed: 0.0090s/iter; left time: 8.5535s
	iters: 200, epoch: 6 | loss: 1.0168220
	speed: 0.0083s/iter; left time: 7.0495s
Epoch: 6 cost time: 1.7836124897003174
Epoch: 6, Steps: 210 | Train Loss: 1.0028157 Vali Loss: 1.0252732 Test Loss: 0.9851478
Validation loss decreased (1.025644 --> 1.025273).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0071416
	speed: 0.0090s/iter; left time: 6.6744s
	iters: 200, epoch: 7 | loss: 0.9862189
	speed: 0.0083s/iter; left time: 5.3241s
Epoch: 7 cost time: 1.7980225086212158
Epoch: 7, Steps: 210 | Train Loss: 1.0024033 Vali Loss: 1.0259845 Test Loss: 0.9851156
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0212363
	speed: 0.0075s/iter; left time: 3.9758s
	iters: 200, epoch: 8 | loss: 0.9921423
	speed: 0.0067s/iter; left time: 2.8696s
Epoch: 8 cost time: 1.446169137954712
Epoch: 8, Steps: 210 | Train Loss: 1.0019047 Vali Loss: 1.0244814 Test Loss: 0.9850368
Validation loss decreased (1.025273 --> 1.024481).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0041590
	speed: 0.0077s/iter; left time: 2.4585s
	iters: 200, epoch: 9 | loss: 1.0203191
	speed: 0.0068s/iter; left time: 1.4923s
Epoch: 9 cost time: 1.4589195251464844
Epoch: 9, Steps: 210 | Train Loss: 1.0018877 Vali Loss: 1.0261207 Test Loss: 0.9850461
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0154119
	speed: 0.0092s/iter; left time: 1.0207s
	iters: 200, epoch: 10 | loss: 0.9928263
	speed: 0.0084s/iter; left time: 0.0922s
Epoch: 10 cost time: 1.802830457687378
Epoch: 10, Steps: 210 | Train Loss: 1.0017343 Vali Loss: 1.0254674 Test Loss: 0.9850523
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9850368499755859, mae:0.7883962988853455
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0260314
	speed: 0.0157s/iter; left time: 30.8340s
	iters: 200, epoch: 1 | loss: 1.0099242
	speed: 0.0102s/iter; left time: 18.8974s
Epoch: 1 cost time: 2.0980448722839355
Epoch: 1, Steps: 206 | Train Loss: 1.0497964 Vali Loss: 1.0315086 Test Loss: 0.9907203
Validation loss decreased (inf --> 1.031509).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9981012
	speed: 0.0061s/iter; left time: 10.6784s
	iters: 200, epoch: 2 | loss: 1.0127733
	speed: 0.0054s/iter; left time: 8.8545s
Epoch: 2 cost time: 1.163407564163208
Epoch: 2, Steps: 206 | Train Loss: 1.0149366 Vali Loss: 1.0305884 Test Loss: 0.9891857
Validation loss decreased (1.031509 --> 1.030588).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0156559
	speed: 0.0061s/iter; left time: 9.4755s
	iters: 200, epoch: 3 | loss: 1.0023266
	speed: 0.0054s/iter; left time: 7.8477s
Epoch: 3 cost time: 1.157909870147705
Epoch: 3, Steps: 206 | Train Loss: 1.0099908 Vali Loss: 1.0277529 Test Loss: 0.9873514
Validation loss decreased (1.030588 --> 1.027753).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9951815
	speed: 0.0064s/iter; left time: 8.5629s
	iters: 200, epoch: 4 | loss: 1.0163848
	speed: 0.0057s/iter; left time: 7.0781s
Epoch: 4 cost time: 1.2241168022155762
Epoch: 4, Steps: 206 | Train Loss: 1.0076536 Vali Loss: 1.0272746 Test Loss: 0.9868802
Validation loss decreased (1.027753 --> 1.027275).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0067085
	speed: 0.0064s/iter; left time: 7.2735s
	iters: 200, epoch: 5 | loss: 0.9997559
	speed: 0.0055s/iter; left time: 5.7057s
Epoch: 5 cost time: 1.1778275966644287
Epoch: 5, Steps: 206 | Train Loss: 1.0060326 Vali Loss: 1.0265781 Test Loss: 0.9863851
Validation loss decreased (1.027275 --> 1.026578).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0135249
	speed: 0.0060s/iter; left time: 5.5717s
	iters: 200, epoch: 6 | loss: 1.0076984
	speed: 0.0053s/iter; left time: 4.4427s
Epoch: 6 cost time: 1.1372706890106201
Epoch: 6, Steps: 206 | Train Loss: 1.0056606 Vali Loss: 1.0263438 Test Loss: 0.9862260
Validation loss decreased (1.026578 --> 1.026344).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0045744
	speed: 0.0059s/iter; left time: 4.3086s
	iters: 200, epoch: 7 | loss: 1.0030509
	speed: 0.0055s/iter; left time: 3.4189s
Epoch: 7 cost time: 1.1753833293914795
Epoch: 7, Steps: 206 | Train Loss: 1.0049662 Vali Loss: 1.0259759 Test Loss: 0.9861093
Validation loss decreased (1.026344 --> 1.025976).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0162672
	speed: 0.0081s/iter; left time: 4.2213s
	iters: 200, epoch: 8 | loss: 1.0143893
	speed: 0.0073s/iter; left time: 3.0737s
Epoch: 8 cost time: 1.5639817714691162
Epoch: 8, Steps: 206 | Train Loss: 1.0049166 Vali Loss: 1.0262326 Test Loss: 0.9860894
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9953558
	speed: 0.0076s/iter; left time: 2.3875s
	iters: 200, epoch: 9 | loss: 0.9983379
	speed: 0.0070s/iter; left time: 1.4968s
Epoch: 9 cost time: 1.4896368980407715
Epoch: 9, Steps: 206 | Train Loss: 1.0048957 Vali Loss: 1.0261819 Test Loss: 0.9860759
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9988523
	speed: 0.0062s/iter; left time: 0.6677s
	iters: 200, epoch: 10 | loss: 1.0043217
	speed: 0.0055s/iter; left time: 0.0383s
Epoch: 10 cost time: 1.1970834732055664
Epoch: 10, Steps: 206 | Train Loss: 1.0045041 Vali Loss: 1.0262939 Test Loss: 0.9860728
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9861093163490295, mae:0.788558304309845
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0304267
	speed: 0.0077s/iter; left time: 15.1433s
	iters: 200, epoch: 1 | loss: 1.0104313
	speed: 0.0073s/iter; left time: 13.5900s
Epoch: 1 cost time: 1.5628445148468018
Epoch: 1, Steps: 206 | Train Loss: 1.0518235 Vali Loss: 1.0296537 Test Loss: 0.9891683
Validation loss decreased (inf --> 1.029654).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9983509
	speed: 0.0077s/iter; left time: 13.4784s
	iters: 200, epoch: 2 | loss: 1.0119172
	speed: 0.0068s/iter; left time: 11.2873s
Epoch: 2 cost time: 1.464599370956421
Epoch: 2, Steps: 206 | Train Loss: 1.0143607 Vali Loss: 1.0296186 Test Loss: 0.9888455
Validation loss decreased (1.029654 --> 1.029619).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9951999
	speed: 0.0077s/iter; left time: 11.9000s
	iters: 200, epoch: 3 | loss: 1.0173845
	speed: 0.0068s/iter; left time: 9.8113s
Epoch: 3 cost time: 1.4457523822784424
Epoch: 3, Steps: 206 | Train Loss: 1.0096184 Vali Loss: 1.0276730 Test Loss: 0.9872125
Validation loss decreased (1.029619 --> 1.027673).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0122283
	speed: 0.0089s/iter; left time: 11.9130s
	iters: 200, epoch: 4 | loss: 0.9985673
	speed: 0.0082s/iter; left time: 10.2397s
Epoch: 4 cost time: 1.76007080078125
Epoch: 4, Steps: 206 | Train Loss: 1.0070583 Vali Loss: 1.0262456 Test Loss: 0.9863685
Validation loss decreased (1.027673 --> 1.026246).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0060302
	speed: 0.0087s/iter; left time: 9.9353s
	iters: 200, epoch: 5 | loss: 0.9988767
	speed: 0.0082s/iter; left time: 8.5193s
Epoch: 5 cost time: 1.7537319660186768
Epoch: 5, Steps: 206 | Train Loss: 1.0058660 Vali Loss: 1.0267925 Test Loss: 0.9861228
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0139749
	speed: 0.0089s/iter; left time: 8.2961s
	iters: 200, epoch: 6 | loss: 1.0077708
	speed: 0.0083s/iter; left time: 6.8887s
Epoch: 6 cost time: 1.7616190910339355
Epoch: 6, Steps: 206 | Train Loss: 1.0050448 Vali Loss: 1.0260625 Test Loss: 0.9858793
Validation loss decreased (1.026246 --> 1.026062).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9990653
	speed: 0.0090s/iter; left time: 6.5213s
	iters: 200, epoch: 7 | loss: 1.0037216
	speed: 0.0083s/iter; left time: 5.1907s
Epoch: 7 cost time: 1.78216552734375
Epoch: 7, Steps: 206 | Train Loss: 1.0047658 Vali Loss: 1.0259874 Test Loss: 0.9858224
Validation loss decreased (1.026062 --> 1.025987).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0017117
	speed: 0.0078s/iter; left time: 4.0598s
	iters: 200, epoch: 8 | loss: 0.9931682
	speed: 0.0069s/iter; left time: 2.8792s
Epoch: 8 cost time: 1.4669427871704102
Epoch: 8, Steps: 206 | Train Loss: 1.0045445 Vali Loss: 1.0260441 Test Loss: 0.9857749
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0018539
	speed: 0.0091s/iter; left time: 2.8597s
	iters: 200, epoch: 9 | loss: 0.9977365
	speed: 0.0084s/iter; left time: 1.7879s
Epoch: 9 cost time: 1.778026819229126
Epoch: 9, Steps: 206 | Train Loss: 1.0043508 Vali Loss: 1.0260706 Test Loss: 0.9857697
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0012031
	speed: 0.0091s/iter; left time: 0.9754s
	iters: 200, epoch: 10 | loss: 1.0001452
	speed: 0.0084s/iter; left time: 0.0586s
Epoch: 10 cost time: 1.7791862487792969
Epoch: 10, Steps: 206 | Train Loss: 1.0043581 Vali Loss: 1.0260874 Test Loss: 0.9857681
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.985822319984436, mae:0.7884521484375
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0374811
	speed: 0.0078s/iter; left time: 15.2585s
	iters: 200, epoch: 1 | loss: 1.0312681
	speed: 0.0069s/iter; left time: 12.7645s
Epoch: 1 cost time: 1.4581820964813232
Epoch: 1, Steps: 206 | Train Loss: 1.0535566 Vali Loss: 1.0310695 Test Loss: 0.9899400
Validation loss decreased (inf --> 1.031070).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0030731
	speed: 0.0094s/iter; left time: 16.5252s
	iters: 200, epoch: 2 | loss: 1.0172077
	speed: 0.0085s/iter; left time: 14.0928s
Epoch: 2 cost time: 1.8279194831848145
Epoch: 2, Steps: 206 | Train Loss: 1.0141395 Vali Loss: 1.0288856 Test Loss: 0.9887329
Validation loss decreased (1.031070 --> 1.028886).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0097176
	speed: 0.0094s/iter; left time: 14.5468s
	iters: 200, epoch: 3 | loss: 1.0001887
	speed: 0.0086s/iter; left time: 12.4098s
Epoch: 3 cost time: 1.8200676441192627
Epoch: 3, Steps: 206 | Train Loss: 1.0094479 Vali Loss: 1.0280982 Test Loss: 0.9873942
Validation loss decreased (1.028886 --> 1.028098).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0033749
	speed: 0.0093s/iter; left time: 12.5458s
	iters: 200, epoch: 4 | loss: 1.0192802
	speed: 0.0085s/iter; left time: 10.5591s
Epoch: 4 cost time: 1.8136827945709229
Epoch: 4, Steps: 206 | Train Loss: 1.0070554 Vali Loss: 1.0273781 Test Loss: 0.9868873
Validation loss decreased (1.028098 --> 1.027378).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0012957
	speed: 0.0094s/iter; left time: 10.6422s
	iters: 200, epoch: 5 | loss: 1.0160773
	speed: 0.0085s/iter; left time: 8.8552s
Epoch: 5 cost time: 1.8128657341003418
Epoch: 5, Steps: 206 | Train Loss: 1.0059527 Vali Loss: 1.0260065 Test Loss: 0.9862555
Validation loss decreased (1.027378 --> 1.026006).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9877588
	speed: 0.0094s/iter; left time: 8.7390s
	iters: 200, epoch: 6 | loss: 1.0092374
	speed: 0.0085s/iter; left time: 7.0955s
Epoch: 6 cost time: 1.8143389225006104
Epoch: 6, Steps: 206 | Train Loss: 1.0049424 Vali Loss: 1.0261858 Test Loss: 0.9862092
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0014325
	speed: 0.0092s/iter; left time: 6.6944s
	iters: 200, epoch: 7 | loss: 0.9998803
	speed: 0.0085s/iter; left time: 5.2900s
Epoch: 7 cost time: 1.8058624267578125
Epoch: 7, Steps: 206 | Train Loss: 1.0045700 Vali Loss: 1.0262420 Test Loss: 0.9861125
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0048794
	speed: 0.0093s/iter; left time: 4.8226s
	iters: 200, epoch: 8 | loss: 0.9994131
	speed: 0.0086s/iter; left time: 3.6072s
Epoch: 8 cost time: 1.8337771892547607
Epoch: 8, Steps: 206 | Train Loss: 1.0046451 Vali Loss: 1.0259460 Test Loss: 0.9860780
Validation loss decreased (1.026006 --> 1.025946).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9946812
	speed: 0.0094s/iter; left time: 2.9382s
	iters: 200, epoch: 9 | loss: 1.0134839
	speed: 0.0086s/iter; left time: 1.8223s
Epoch: 9 cost time: 1.8268051147460938
Epoch: 9, Steps: 206 | Train Loss: 1.0044674 Vali Loss: 1.0259507 Test Loss: 0.9860702
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0086573
	speed: 0.0093s/iter; left time: 0.9935s
	iters: 200, epoch: 10 | loss: 1.0004814
	speed: 0.0085s/iter; left time: 0.0596s
Epoch: 10 cost time: 1.813218593597412
Epoch: 10, Steps: 206 | Train Loss: 1.0042552 Vali Loss: 1.0259852 Test Loss: 0.9860669
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9860780239105225, mae:0.7885762453079224
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0209047
	speed: 0.0170s/iter; left time: 31.3588s
Epoch: 1 cost time: 2.2766778469085693
Epoch: 1, Steps: 194 | Train Loss: 1.0514263 Vali Loss: 1.0317068 Test Loss: 0.9846373
Validation loss decreased (inf --> 1.031707).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0145525
	speed: 0.0080s/iter; left time: 13.1699s
Epoch: 2 cost time: 1.4807953834533691
Epoch: 2, Steps: 194 | Train Loss: 1.0161176 Vali Loss: 1.0297699 Test Loss: 0.9831438
Validation loss decreased (1.031707 --> 1.029770).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0213667
	speed: 0.0085s/iter; left time: 12.3022s
Epoch: 3 cost time: 1.6468725204467773
Epoch: 3, Steps: 194 | Train Loss: 1.0120323 Vali Loss: 1.0290868 Test Loss: 0.9818317
Validation loss decreased (1.029770 --> 1.029087).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0040455
	speed: 0.0085s/iter; left time: 10.7012s
Epoch: 4 cost time: 1.5408074855804443
Epoch: 4, Steps: 194 | Train Loss: 1.0100556 Vali Loss: 1.0276008 Test Loss: 0.9808086
Validation loss decreased (1.029087 --> 1.027601).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0084894
	speed: 0.0094s/iter; left time: 9.9745s
Epoch: 5 cost time: 1.7233071327209473
Epoch: 5, Steps: 194 | Train Loss: 1.0091261 Vali Loss: 1.0270630 Test Loss: 0.9804275
Validation loss decreased (1.027601 --> 1.027063).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0037552
	speed: 0.0078s/iter; left time: 6.8325s
Epoch: 6 cost time: 1.4152987003326416
Epoch: 6, Steps: 194 | Train Loss: 1.0085003 Vali Loss: 1.0268943 Test Loss: 0.9802019
Validation loss decreased (1.027063 --> 1.026894).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0093673
	speed: 0.0095s/iter; left time: 6.4273s
Epoch: 7 cost time: 1.745314598083496
Epoch: 7, Steps: 194 | Train Loss: 1.0082727 Vali Loss: 1.0266354 Test Loss: 0.9800559
Validation loss decreased (1.026894 --> 1.026635).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0055923
	speed: 0.0092s/iter; left time: 4.4292s
Epoch: 8 cost time: 1.7153162956237793
Epoch: 8, Steps: 194 | Train Loss: 1.0082800 Vali Loss: 1.0268424 Test Loss: 0.9800764
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0067580
	speed: 0.0074s/iter; left time: 2.1394s
Epoch: 9 cost time: 1.3629794120788574
Epoch: 9, Steps: 194 | Train Loss: 1.0080803 Vali Loss: 1.0268182 Test Loss: 0.9800630
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0085652
	speed: 0.0093s/iter; left time: 0.8844s
Epoch: 10 cost time: 1.6770248413085938
Epoch: 10, Steps: 194 | Train Loss: 1.0080938 Vali Loss: 1.0267082 Test Loss: 0.9800588
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9800558686256409, mae:0.7845667004585266
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0195957
	speed: 0.0085s/iter; left time: 15.5838s
Epoch: 1 cost time: 1.6073343753814697
Epoch: 1, Steps: 194 | Train Loss: 1.0540736 Vali Loss: 1.0315051 Test Loss: 0.9839415
Validation loss decreased (inf --> 1.031505).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0097905
	speed: 0.0078s/iter; left time: 12.8512s
Epoch: 2 cost time: 1.331021785736084
Epoch: 2, Steps: 194 | Train Loss: 1.0159970 Vali Loss: 1.0314511 Test Loss: 0.9836321
Validation loss decreased (1.031505 --> 1.031451).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0035801
	speed: 0.0064s/iter; left time: 9.3483s
Epoch: 3 cost time: 1.1768262386322021
Epoch: 3, Steps: 194 | Train Loss: 1.0118494 Vali Loss: 1.0285612 Test Loss: 0.9814743
Validation loss decreased (1.031451 --> 1.028561).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0121022
	speed: 0.0086s/iter; left time: 10.8027s
Epoch: 4 cost time: 1.6242008209228516
Epoch: 4, Steps: 194 | Train Loss: 1.0098224 Vali Loss: 1.0276641 Test Loss: 0.9806831
Validation loss decreased (1.028561 --> 1.027664).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0021385
	speed: 0.0089s/iter; left time: 9.4597s
Epoch: 5 cost time: 1.597287893295288
Epoch: 5, Steps: 194 | Train Loss: 1.0088644 Vali Loss: 1.0274402 Test Loss: 0.9802667
Validation loss decreased (1.027664 --> 1.027440).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0034634
	speed: 0.0093s/iter; left time: 8.0683s
Epoch: 6 cost time: 1.7089605331420898
Epoch: 6, Steps: 194 | Train Loss: 1.0083183 Vali Loss: 1.0270872 Test Loss: 0.9800625
Validation loss decreased (1.027440 --> 1.027087).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0050077
	speed: 0.0094s/iter; left time: 6.3843s
Epoch: 7 cost time: 1.7334866523742676
Epoch: 7, Steps: 194 | Train Loss: 1.0079583 Vali Loss: 1.0270528 Test Loss: 0.9799596
Validation loss decreased (1.027087 --> 1.027053).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0024585
	speed: 0.0078s/iter; left time: 3.7816s
Epoch: 8 cost time: 1.409334659576416
Epoch: 8, Steps: 194 | Train Loss: 1.0078952 Vali Loss: 1.0270110 Test Loss: 0.9798863
Validation loss decreased (1.027053 --> 1.027011).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0041368
	speed: 0.0080s/iter; left time: 2.3066s
Epoch: 9 cost time: 1.5042014122009277
Epoch: 9, Steps: 194 | Train Loss: 1.0077652 Vali Loss: 1.0268922 Test Loss: 0.9798772
Validation loss decreased (1.027011 --> 1.026892).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0163034
	speed: 0.0075s/iter; left time: 0.7161s
Epoch: 10 cost time: 1.5570533275604248
Epoch: 10, Steps: 194 | Train Loss: 1.0077891 Vali Loss: 1.0267819 Test Loss: 0.9798710
Validation loss decreased (1.026892 --> 1.026782).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9798707365989685, mae:0.7845398187637329
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0235204
	speed: 0.0097s/iter; left time: 17.8899s
Epoch: 1 cost time: 1.780191421508789
Epoch: 1, Steps: 194 | Train Loss: 1.0531815 Vali Loss: 1.0310774 Test Loss: 0.9840680
Validation loss decreased (inf --> 1.031077).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0159955
	speed: 0.0096s/iter; left time: 15.8327s
Epoch: 2 cost time: 1.7687556743621826
Epoch: 2, Steps: 194 | Train Loss: 1.0162286 Vali Loss: 1.0295601 Test Loss: 0.9833744
Validation loss decreased (1.031077 --> 1.029560).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0128355
	speed: 0.0097s/iter; left time: 14.0293s
Epoch: 3 cost time: 1.7673547267913818
Epoch: 3, Steps: 194 | Train Loss: 1.0118779 Vali Loss: 1.0288289 Test Loss: 0.9815205
Validation loss decreased (1.029560 --> 1.028829).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0090572
	speed: 0.0096s/iter; left time: 12.1342s
Epoch: 4 cost time: 1.7773675918579102
Epoch: 4, Steps: 194 | Train Loss: 1.0097828 Vali Loss: 1.0275735 Test Loss: 0.9807598
Validation loss decreased (1.028829 --> 1.027573).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0014503
	speed: 0.0096s/iter; left time: 10.2363s
Epoch: 5 cost time: 1.7848682403564453
Epoch: 5, Steps: 194 | Train Loss: 1.0088101 Vali Loss: 1.0272274 Test Loss: 0.9803686
Validation loss decreased (1.027573 --> 1.027227).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0054722
	speed: 0.0098s/iter; left time: 8.5696s
Epoch: 6 cost time: 1.7794203758239746
Epoch: 6, Steps: 194 | Train Loss: 1.0085118 Vali Loss: 1.0268784 Test Loss: 0.9801085
Validation loss decreased (1.027227 --> 1.026878).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0066829
	speed: 0.0096s/iter; left time: 6.4803s
Epoch: 7 cost time: 1.755516767501831
Epoch: 7, Steps: 194 | Train Loss: 1.0081979 Vali Loss: 1.0269243 Test Loss: 0.9799914
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0072970
	speed: 0.0095s/iter; left time: 4.5815s
Epoch: 8 cost time: 1.754774570465088
Epoch: 8, Steps: 194 | Train Loss: 1.0080680 Vali Loss: 1.0267797 Test Loss: 0.9799719
Validation loss decreased (1.026878 --> 1.026780).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0010641
	speed: 0.0096s/iter; left time: 2.7601s
Epoch: 9 cost time: 1.7524843215942383
Epoch: 9, Steps: 194 | Train Loss: 1.0077416 Vali Loss: 1.0267853 Test Loss: 0.9799528
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0126923
	speed: 0.0095s/iter; left time: 0.9017s
Epoch: 10 cost time: 1.7517733573913574
Epoch: 10, Steps: 194 | Train Loss: 1.0078696 Vali Loss: 1.0267088 Test Loss: 0.9799514
Validation loss decreased (1.026780 --> 1.026709).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9799513220787048, mae:0.7845295667648315
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9960232
	speed: 0.0171s/iter; left time: 34.7512s
	iters: 200, epoch: 1 | loss: 1.0020763
	speed: 0.0115s/iter; left time: 22.2130s
Epoch: 1 cost time: 2.421847343444824
Epoch: 1, Steps: 213 | Train Loss: 1.0568027 Vali Loss: 1.0262119 Test Loss: 0.9923326
Validation loss decreased (inf --> 1.026212).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9966320
	speed: 0.0081s/iter; left time: 14.7010s
	iters: 200, epoch: 2 | loss: 1.0159655
	speed: 0.0072s/iter; left time: 12.4354s
Epoch: 2 cost time: 1.577897548675537
Epoch: 2, Steps: 213 | Train Loss: 1.0126658 Vali Loss: 1.0265712 Test Loss: 0.9921695
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9890489
	speed: 0.0065s/iter; left time: 10.4330s
	iters: 200, epoch: 3 | loss: 1.0080680
	speed: 0.0061s/iter; left time: 9.1708s
Epoch: 3 cost time: 1.3222391605377197
Epoch: 3, Steps: 213 | Train Loss: 1.0054234 Vali Loss: 1.0262179 Test Loss: 0.9907609
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9921117
	speed: 0.0069s/iter; left time: 9.6497s
	iters: 200, epoch: 4 | loss: 0.9896356
	speed: 0.0058s/iter; left time: 7.5357s
Epoch: 4 cost time: 1.2873563766479492
Epoch: 4, Steps: 213 | Train Loss: 1.0016295 Vali Loss: 1.0257343 Test Loss: 0.9889979
Validation loss decreased (1.026212 --> 1.025734).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9794134
	speed: 0.0071s/iter; left time: 8.3969s
	iters: 200, epoch: 5 | loss: 0.9788558
	speed: 0.0073s/iter; left time: 7.9051s
Epoch: 5 cost time: 1.6317558288574219
Epoch: 5, Steps: 213 | Train Loss: 0.9993217 Vali Loss: 1.0261544 Test Loss: 0.9894728
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0093409
	speed: 0.0091s/iter; left time: 8.8220s
	iters: 200, epoch: 6 | loss: 0.9932451
	speed: 0.0084s/iter; left time: 7.2352s
Epoch: 6 cost time: 1.8338754177093506
Epoch: 6, Steps: 213 | Train Loss: 0.9982909 Vali Loss: 1.0248919 Test Loss: 0.9890424
Validation loss decreased (1.025734 --> 1.024892).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0121968
	speed: 0.0092s/iter; left time: 6.9498s
	iters: 200, epoch: 7 | loss: 0.9860200
	speed: 0.0084s/iter; left time: 5.5025s
Epoch: 7 cost time: 1.855919361114502
Epoch: 7, Steps: 213 | Train Loss: 0.9980591 Vali Loss: 1.0248603 Test Loss: 0.9889923
Validation loss decreased (1.024892 --> 1.024860).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9922570
	speed: 0.0091s/iter; left time: 4.9368s
	iters: 200, epoch: 8 | loss: 0.9991950
	speed: 0.0083s/iter; left time: 3.6527s
Epoch: 8 cost time: 1.8216588497161865
Epoch: 8, Steps: 213 | Train Loss: 0.9969229 Vali Loss: 1.0247843 Test Loss: 0.9890422
Validation loss decreased (1.024860 --> 1.024784).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9794346
	speed: 0.0093s/iter; left time: 3.0521s
	iters: 200, epoch: 9 | loss: 0.9933864
	speed: 0.0084s/iter; left time: 1.9180s
Epoch: 9 cost time: 1.8421339988708496
Epoch: 9, Steps: 213 | Train Loss: 0.9967162 Vali Loss: 1.0246038 Test Loss: 0.9891042
Validation loss decreased (1.024784 --> 1.024604).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0088966
	speed: 0.0092s/iter; left time: 1.0457s
	iters: 200, epoch: 10 | loss: 1.0010406
	speed: 0.0083s/iter; left time: 0.1166s
Epoch: 10 cost time: 1.820688009262085
Epoch: 10, Steps: 213 | Train Loss: 0.9967932 Vali Loss: 1.0247829 Test Loss: 0.9891113
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9891042709350586, mae:0.790475070476532
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0043536
	speed: 0.0097s/iter; left time: 19.7266s
	iters: 200, epoch: 1 | loss: 1.0478758
	speed: 0.0087s/iter; left time: 16.7128s
Epoch: 1 cost time: 1.8890314102172852
Epoch: 1, Steps: 213 | Train Loss: 1.0550756 Vali Loss: 1.0273633 Test Loss: 0.9921010
Validation loss decreased (inf --> 1.027363).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0197649
	speed: 0.0095s/iter; left time: 17.2363s
	iters: 200, epoch: 2 | loss: 1.0225065
	speed: 0.0085s/iter; left time: 14.6833s
Epoch: 2 cost time: 1.8715777397155762
Epoch: 2, Steps: 213 | Train Loss: 1.0126159 Vali Loss: 1.0310545 Test Loss: 0.9944547
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9980891
	speed: 0.0091s/iter; left time: 14.6170s
	iters: 200, epoch: 3 | loss: 1.0457318
	speed: 0.0083s/iter; left time: 12.5341s
Epoch: 3 cost time: 1.8201303482055664
Epoch: 3, Steps: 213 | Train Loss: 1.0055958 Vali Loss: 1.0244598 Test Loss: 0.9893204
Validation loss decreased (1.027363 --> 1.024460).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0053471
	speed: 0.0091s/iter; left time: 12.7176s
	iters: 200, epoch: 4 | loss: 0.9777279
	speed: 0.0083s/iter; left time: 10.7677s
Epoch: 4 cost time: 1.8176751136779785
Epoch: 4, Steps: 213 | Train Loss: 1.0016694 Vali Loss: 1.0243875 Test Loss: 0.9888438
Validation loss decreased (1.024460 --> 1.024387).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9971459
	speed: 0.0077s/iter; left time: 9.0753s
	iters: 200, epoch: 5 | loss: 1.0255711
	speed: 0.0068s/iter; left time: 7.3481s
Epoch: 5 cost time: 1.4888200759887695
Epoch: 5, Steps: 213 | Train Loss: 0.9995676 Vali Loss: 1.0247267 Test Loss: 0.9888793
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0014523
	speed: 0.0068s/iter; left time: 6.5327s
	iters: 200, epoch: 6 | loss: 0.9931971
	speed: 0.0060s/iter; left time: 5.1877s
Epoch: 6 cost time: 1.3181507587432861
Epoch: 6, Steps: 213 | Train Loss: 0.9984129 Vali Loss: 1.0255044 Test Loss: 0.9889062
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0138924
	speed: 0.0086s/iter; left time: 6.4766s
	iters: 200, epoch: 7 | loss: 1.0349414
	speed: 0.0079s/iter; left time: 5.1523s
Epoch: 7 cost time: 1.7314486503601074
Epoch: 7, Steps: 213 | Train Loss: 0.9976086 Vali Loss: 1.0246310 Test Loss: 0.9890367
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0273890
	speed: 0.0078s/iter; left time: 4.2155s
	iters: 200, epoch: 8 | loss: 0.9969989
	speed: 0.0073s/iter; left time: 3.1997s
Epoch: 8 cost time: 1.5845980644226074
Epoch: 8, Steps: 213 | Train Loss: 0.9975870 Vali Loss: 1.0257298 Test Loss: 0.9889774
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9951565
	speed: 0.0073s/iter; left time: 2.3975s
	iters: 200, epoch: 9 | loss: 0.9797850
	speed: 0.0068s/iter; left time: 1.5490s
Epoch: 9 cost time: 1.5032284259796143
Epoch: 9, Steps: 213 | Train Loss: 0.9972400 Vali Loss: 1.0247928 Test Loss: 0.9889424
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9888437986373901, mae:0.7904269099235535
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0211897
	speed: 0.0082s/iter; left time: 16.7422s
	iters: 200, epoch: 1 | loss: 1.0214913
	speed: 0.0074s/iter; left time: 14.2006s
Epoch: 1 cost time: 1.6095216274261475
Epoch: 1, Steps: 213 | Train Loss: 1.0533359 Vali Loss: 1.0260469 Test Loss: 0.9914435
Validation loss decreased (inf --> 1.026047).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0059032
	speed: 0.0083s/iter; left time: 15.0325s
	iters: 200, epoch: 2 | loss: 0.9867846
	speed: 0.0074s/iter; left time: 12.6712s
Epoch: 2 cost time: 1.6097171306610107
Epoch: 2, Steps: 213 | Train Loss: 1.0125317 Vali Loss: 1.0261714 Test Loss: 0.9904579
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0006269
	speed: 0.0080s/iter; left time: 12.8146s
	iters: 200, epoch: 3 | loss: 1.0282716
	speed: 0.0072s/iter; left time: 10.9100s
Epoch: 3 cost time: 1.5981166362762451
Epoch: 3, Steps: 213 | Train Loss: 1.0054812 Vali Loss: 1.0254747 Test Loss: 0.9891379
Validation loss decreased (1.026047 --> 1.025475).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9978617
	speed: 0.0090s/iter; left time: 12.5526s
	iters: 200, epoch: 4 | loss: 1.0216449
	speed: 0.0077s/iter; left time: 9.9283s
Epoch: 4 cost time: 1.6654479503631592
Epoch: 4, Steps: 213 | Train Loss: 1.0018586 Vali Loss: 1.0258405 Test Loss: 0.9886974
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0190483
	speed: 0.0077s/iter; left time: 9.0717s
	iters: 200, epoch: 5 | loss: 0.9679495
	speed: 0.0072s/iter; left time: 7.7619s
Epoch: 5 cost time: 1.579519271850586
Epoch: 5, Steps: 213 | Train Loss: 0.9996711 Vali Loss: 1.0235173 Test Loss: 0.9883385
Validation loss decreased (1.025475 --> 1.023517).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9916368
	speed: 0.0077s/iter; left time: 7.4092s
	iters: 200, epoch: 6 | loss: 1.0035493
	speed: 0.0067s/iter; left time: 5.8208s
Epoch: 6 cost time: 1.4763052463531494
Epoch: 6, Steps: 213 | Train Loss: 0.9986077 Vali Loss: 1.0245186 Test Loss: 0.9883341
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9740223
	speed: 0.0062s/iter; left time: 4.6743s
	iters: 200, epoch: 7 | loss: 1.0080636
	speed: 0.0056s/iter; left time: 3.6590s
Epoch: 7 cost time: 1.2352981567382812
Epoch: 7, Steps: 213 | Train Loss: 0.9979607 Vali Loss: 1.0251114 Test Loss: 0.9883853
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0193970
	speed: 0.0067s/iter; left time: 3.6060s
	iters: 200, epoch: 8 | loss: 1.0029100
	speed: 0.0059s/iter; left time: 2.6056s
Epoch: 8 cost time: 1.3028690814971924
Epoch: 8, Steps: 213 | Train Loss: 0.9976080 Vali Loss: 1.0246953 Test Loss: 0.9883591
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9974315
	speed: 0.0062s/iter; left time: 2.0400s
	iters: 200, epoch: 9 | loss: 1.0047646
	speed: 0.0059s/iter; left time: 1.3500s
Epoch: 9 cost time: 1.296682596206665
Epoch: 9, Steps: 213 | Train Loss: 0.9973205 Vali Loss: 1.0257391 Test Loss: 0.9883509
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0235498
	speed: 0.0059s/iter; left time: 0.6690s
	iters: 200, epoch: 10 | loss: 1.0104972
	speed: 0.0053s/iter; left time: 0.0737s
Epoch: 10 cost time: 1.1638059616088867
Epoch: 10, Steps: 213 | Train Loss: 0.9974626 Vali Loss: 1.0255162 Test Loss: 0.9883522
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9883387088775635, mae:0.7902513742446899
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0322657
	speed: 0.0127s/iter; left time: 25.3299s
	iters: 200, epoch: 1 | loss: 1.0176105
	speed: 0.0095s/iter; left time: 18.0506s
Epoch: 1 cost time: 2.004948616027832
Epoch: 1, Steps: 210 | Train Loss: 1.0524114 Vali Loss: 1.0292523 Test Loss: 0.9890202
Validation loss decreased (inf --> 1.029252).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0287766
	speed: 0.0069s/iter; left time: 12.3164s
	iters: 200, epoch: 2 | loss: 1.0238979
	speed: 0.0061s/iter; left time: 10.2485s
Epoch: 2 cost time: 1.3053762912750244
Epoch: 2, Steps: 210 | Train Loss: 1.0137490 Vali Loss: 1.0273589 Test Loss: 0.9876879
Validation loss decreased (1.029252 --> 1.027359).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0228543
	speed: 0.0081s/iter; left time: 12.7594s
	iters: 200, epoch: 3 | loss: 1.0078666
	speed: 0.0073s/iter; left time: 10.7659s
Epoch: 3 cost time: 1.5744493007659912
Epoch: 3, Steps: 210 | Train Loss: 1.0083237 Vali Loss: 1.0268868 Test Loss: 0.9865986
Validation loss decreased (1.027359 --> 1.026887).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9932637
	speed: 0.0070s/iter; left time: 9.5928s
	iters: 200, epoch: 4 | loss: 1.0040754
	speed: 0.0063s/iter; left time: 7.9484s
Epoch: 4 cost time: 1.3775017261505127
Epoch: 4, Steps: 210 | Train Loss: 1.0054169 Vali Loss: 1.0269763 Test Loss: 0.9858912
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0085378
	speed: 0.0067s/iter; left time: 7.7471s
	iters: 200, epoch: 5 | loss: 1.0073452
	speed: 0.0060s/iter; left time: 6.3811s
Epoch: 5 cost time: 1.3127949237823486
Epoch: 5, Steps: 210 | Train Loss: 1.0035566 Vali Loss: 1.0258336 Test Loss: 0.9854408
Validation loss decreased (1.026887 --> 1.025834).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0104330
	speed: 0.0072s/iter; left time: 6.8417s
	iters: 200, epoch: 6 | loss: 0.9779715
	speed: 0.0062s/iter; left time: 5.2428s
Epoch: 6 cost time: 1.3611698150634766
Epoch: 6, Steps: 210 | Train Loss: 1.0025180 Vali Loss: 1.0264874 Test Loss: 0.9854261
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9825587
	speed: 0.0079s/iter; left time: 5.8863s
	iters: 200, epoch: 7 | loss: 0.9921982
	speed: 0.0072s/iter; left time: 4.6304s
Epoch: 7 cost time: 1.5726490020751953
Epoch: 7, Steps: 210 | Train Loss: 1.0023057 Vali Loss: 1.0243789 Test Loss: 0.9852196
Validation loss decreased (1.025834 --> 1.024379).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0027804
	speed: 0.0072s/iter; left time: 3.8049s
	iters: 200, epoch: 8 | loss: 1.0046433
	speed: 0.0064s/iter; left time: 2.7628s
Epoch: 8 cost time: 1.401061773300171
Epoch: 8, Steps: 210 | Train Loss: 1.0015928 Vali Loss: 1.0253384 Test Loss: 0.9852170
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9910035
	speed: 0.0088s/iter; left time: 2.8251s
	iters: 200, epoch: 9 | loss: 1.0009208
	speed: 0.0082s/iter; left time: 1.8096s
Epoch: 9 cost time: 1.7756237983703613
Epoch: 9, Steps: 210 | Train Loss: 1.0016360 Vali Loss: 1.0262752 Test Loss: 0.9852183
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0072453
	speed: 0.0080s/iter; left time: 0.8846s
	iters: 200, epoch: 10 | loss: 0.9730090
	speed: 0.0072s/iter; left time: 0.0789s
Epoch: 10 cost time: 1.549009084701538
Epoch: 10, Steps: 210 | Train Loss: 1.0015664 Vali Loss: 1.0260680 Test Loss: 0.9852234
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.985219419002533, mae:0.7885333299636841
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0261903
	speed: 0.0068s/iter; left time: 13.6947s
	iters: 200, epoch: 1 | loss: 1.0203059
	speed: 0.0062s/iter; left time: 11.7091s
Epoch: 1 cost time: 1.3360810279846191
Epoch: 1, Steps: 210 | Train Loss: 1.0525772 Vali Loss: 1.0292636 Test Loss: 0.9885026
Validation loss decreased (inf --> 1.029264).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0097377
	speed: 0.0080s/iter; left time: 14.3156s
	iters: 200, epoch: 2 | loss: 1.0280328
	speed: 0.0070s/iter; left time: 11.8831s
Epoch: 2 cost time: 1.5105195045471191
Epoch: 2, Steps: 210 | Train Loss: 1.0142212 Vali Loss: 1.0271360 Test Loss: 0.9881009
Validation loss decreased (1.029264 --> 1.027136).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0065830
	speed: 0.0085s/iter; left time: 13.4681s
	iters: 200, epoch: 3 | loss: 0.9827599
	speed: 0.0075s/iter; left time: 11.0537s
Epoch: 3 cost time: 1.611382246017456
Epoch: 3, Steps: 210 | Train Loss: 1.0085057 Vali Loss: 1.0250452 Test Loss: 0.9859048
Validation loss decreased (1.027136 --> 1.025045).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0131050
	speed: 0.0069s/iter; left time: 9.4657s
	iters: 200, epoch: 4 | loss: 1.0119222
	speed: 0.0063s/iter; left time: 8.0693s
Epoch: 4 cost time: 1.3794748783111572
Epoch: 4, Steps: 210 | Train Loss: 1.0053885 Vali Loss: 1.0261223 Test Loss: 0.9856146
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9826649
	speed: 0.0087s/iter; left time: 10.0783s
	iters: 200, epoch: 5 | loss: 1.0042527
	speed: 0.0081s/iter; left time: 8.6442s
Epoch: 5 cost time: 1.7666077613830566
Epoch: 5, Steps: 210 | Train Loss: 1.0037782 Vali Loss: 1.0260781 Test Loss: 0.9853098
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0215458
	speed: 0.0079s/iter; left time: 7.5003s
	iters: 200, epoch: 6 | loss: 1.0106397
	speed: 0.0072s/iter; left time: 6.1187s
Epoch: 6 cost time: 1.574533462524414
Epoch: 6, Steps: 210 | Train Loss: 1.0029492 Vali Loss: 1.0251396 Test Loss: 0.9850244
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9819107
	speed: 0.0080s/iter; left time: 5.9644s
	iters: 200, epoch: 7 | loss: 0.9925601
	speed: 0.0072s/iter; left time: 4.6217s
Epoch: 7 cost time: 1.560514211654663
Epoch: 7, Steps: 210 | Train Loss: 1.0024296 Vali Loss: 1.0265800 Test Loss: 0.9850060
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0029182
	speed: 0.0075s/iter; left time: 4.0048s
	iters: 200, epoch: 8 | loss: 0.9909298
	speed: 0.0069s/iter; left time: 2.9844s
Epoch: 8 cost time: 1.4920899868011475
Epoch: 8, Steps: 210 | Train Loss: 1.0021540 Vali Loss: 1.0254470 Test Loss: 0.9849905
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.98590487241745, mae:0.7887814044952393
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0355743
	speed: 0.0077s/iter; left time: 15.4895s
	iters: 200, epoch: 1 | loss: 1.0209428
	speed: 0.0070s/iter; left time: 13.3813s
Epoch: 1 cost time: 1.5188913345336914
Epoch: 1, Steps: 210 | Train Loss: 1.0534748 Vali Loss: 1.0285764 Test Loss: 0.9888223
Validation loss decreased (inf --> 1.028576).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0089197
	speed: 0.0081s/iter; left time: 14.5403s
	iters: 200, epoch: 2 | loss: 1.0318475
	speed: 0.0073s/iter; left time: 12.3158s
Epoch: 2 cost time: 1.564995527267456
Epoch: 2, Steps: 210 | Train Loss: 1.0141915 Vali Loss: 1.0294836 Test Loss: 0.9884365
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9975446
	speed: 0.0061s/iter; left time: 9.7060s
	iters: 200, epoch: 3 | loss: 1.0057964
	speed: 0.0055s/iter; left time: 8.2100s
Epoch: 3 cost time: 1.2142283916473389
Epoch: 3, Steps: 210 | Train Loss: 1.0083743 Vali Loss: 1.0255306 Test Loss: 0.9863351
Validation loss decreased (1.028576 --> 1.025531).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9940128
	speed: 0.0064s/iter; left time: 8.7133s
	iters: 200, epoch: 4 | loss: 0.9941375
	speed: 0.0055s/iter; left time: 6.9932s
Epoch: 4 cost time: 1.1962859630584717
Epoch: 4, Steps: 210 | Train Loss: 1.0050635 Vali Loss: 1.0269324 Test Loss: 0.9858406
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0185208
	speed: 0.0069s/iter; left time: 7.9610s
	iters: 200, epoch: 5 | loss: 1.0051612
	speed: 0.0061s/iter; left time: 6.5054s
Epoch: 5 cost time: 1.335988998413086
Epoch: 5, Steps: 210 | Train Loss: 1.0034603 Vali Loss: 1.0258244 Test Loss: 0.9852719
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0006220
	speed: 0.0068s/iter; left time: 6.4566s
	iters: 200, epoch: 6 | loss: 0.9973536
	speed: 0.0063s/iter; left time: 5.3401s
Epoch: 6 cost time: 1.3658742904663086
Epoch: 6, Steps: 210 | Train Loss: 1.0026586 Vali Loss: 1.0255955 Test Loss: 0.9852135
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0082870
	speed: 0.0060s/iter; left time: 4.4757s
	iters: 200, epoch: 7 | loss: 0.9849757
	speed: 0.0053s/iter; left time: 3.4252s
Epoch: 7 cost time: 1.161198616027832
Epoch: 7, Steps: 210 | Train Loss: 1.0020762 Vali Loss: 1.0252855 Test Loss: 0.9850411
Validation loss decreased (1.025531 --> 1.025285).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0179577
	speed: 0.0061s/iter; left time: 3.2264s
	iters: 200, epoch: 8 | loss: 1.0079958
	speed: 0.0056s/iter; left time: 2.4115s
Epoch: 8 cost time: 1.2245819568634033
Epoch: 8, Steps: 210 | Train Loss: 1.0018919 Vali Loss: 1.0253294 Test Loss: 0.9850469
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0109330
	speed: 0.0069s/iter; left time: 2.2008s
	iters: 200, epoch: 9 | loss: 1.0115150
	speed: 0.0059s/iter; left time: 1.3110s
Epoch: 9 cost time: 1.284557580947876
Epoch: 9, Steps: 210 | Train Loss: 1.0016001 Vali Loss: 1.0259935 Test Loss: 0.9850486
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9933343
	speed: 0.0080s/iter; left time: 0.8851s
	iters: 200, epoch: 10 | loss: 1.0028698
	speed: 0.0072s/iter; left time: 0.0795s
Epoch: 10 cost time: 1.5545415878295898
Epoch: 10, Steps: 210 | Train Loss: 1.0017640 Vali Loss: 1.0260291 Test Loss: 0.9850531
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9850412011146545, mae:0.7884650230407715
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0044425
	speed: 0.0141s/iter; left time: 27.6194s
	iters: 200, epoch: 1 | loss: 1.0094016
	speed: 0.0099s/iter; left time: 18.5149s
Epoch: 1 cost time: 2.067375898361206
Epoch: 1, Steps: 206 | Train Loss: 1.0517215 Vali Loss: 1.0302794 Test Loss: 0.9899173
Validation loss decreased (inf --> 1.030279).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0172182
	speed: 0.0071s/iter; left time: 12.3935s
	iters: 200, epoch: 2 | loss: 1.0011281
	speed: 0.0064s/iter; left time: 10.5991s
Epoch: 2 cost time: 1.3660869598388672
Epoch: 2, Steps: 206 | Train Loss: 1.0143522 Vali Loss: 1.0302840 Test Loss: 0.9894615
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0089247
	speed: 0.0064s/iter; left time: 9.9757s
	iters: 200, epoch: 3 | loss: 1.0037544
	speed: 0.0058s/iter; left time: 8.3838s
Epoch: 3 cost time: 1.2453351020812988
Epoch: 3, Steps: 206 | Train Loss: 1.0097067 Vali Loss: 1.0275496 Test Loss: 0.9876952
Validation loss decreased (1.030279 --> 1.027550).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0137271
	speed: 0.0087s/iter; left time: 11.6681s
	iters: 200, epoch: 4 | loss: 0.9989771
	speed: 0.0078s/iter; left time: 9.7370s
Epoch: 4 cost time: 1.6614329814910889
Epoch: 4, Steps: 206 | Train Loss: 1.0071407 Vali Loss: 1.0268087 Test Loss: 0.9867557
Validation loss decreased (1.027550 --> 1.026809).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0131558
	speed: 0.0085s/iter; left time: 9.6113s
	iters: 200, epoch: 5 | loss: 1.0144401
	speed: 0.0075s/iter; left time: 7.7972s
Epoch: 5 cost time: 1.5983507633209229
Epoch: 5, Steps: 206 | Train Loss: 1.0060450 Vali Loss: 1.0268769 Test Loss: 0.9864669
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0050311
	speed: 0.0081s/iter; left time: 7.5401s
	iters: 200, epoch: 6 | loss: 1.0136229
	speed: 0.0073s/iter; left time: 6.0649s
Epoch: 6 cost time: 1.555560827255249
Epoch: 6, Steps: 206 | Train Loss: 1.0050077 Vali Loss: 1.0262225 Test Loss: 0.9862544
Validation loss decreased (1.026809 --> 1.026222).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0140446
	speed: 0.0070s/iter; left time: 5.1085s
	iters: 200, epoch: 7 | loss: 1.0010294
	speed: 0.0065s/iter; left time: 4.0534s
Epoch: 7 cost time: 1.3925437927246094
Epoch: 7, Steps: 206 | Train Loss: 1.0046907 Vali Loss: 1.0262384 Test Loss: 0.9861583
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0067751
	speed: 0.0072s/iter; left time: 3.7400s
	iters: 200, epoch: 8 | loss: 0.9968685
	speed: 0.0065s/iter; left time: 2.7242s
Epoch: 8 cost time: 1.3857405185699463
Epoch: 8, Steps: 206 | Train Loss: 1.0047022 Vali Loss: 1.0260662 Test Loss: 0.9861833
Validation loss decreased (1.026222 --> 1.026066).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0198798
	speed: 0.0089s/iter; left time: 2.7778s
	iters: 200, epoch: 9 | loss: 0.9809348
	speed: 0.0077s/iter; left time: 1.6407s
Epoch: 9 cost time: 1.6349749565124512
Epoch: 9, Steps: 206 | Train Loss: 1.0046453 Vali Loss: 1.0260634 Test Loss: 0.9861646
Validation loss decreased (1.026066 --> 1.026063).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9883410
	speed: 0.0090s/iter; left time: 0.9579s
	iters: 200, epoch: 10 | loss: 0.9960971
	speed: 0.0079s/iter; left time: 0.0556s
Epoch: 10 cost time: 1.6978044509887695
Epoch: 10, Steps: 206 | Train Loss: 1.0044167 Vali Loss: 1.0260537 Test Loss: 0.9861633
Validation loss decreased (1.026063 --> 1.026054).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9861632585525513, mae:0.7886067628860474
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0211104
	speed: 0.0073s/iter; left time: 14.3864s
	iters: 200, epoch: 1 | loss: 1.0164961
	speed: 0.0067s/iter; left time: 12.3915s
Epoch: 1 cost time: 1.4205009937286377
Epoch: 1, Steps: 206 | Train Loss: 1.0498945 Vali Loss: 1.0304968 Test Loss: 0.9893320
Validation loss decreased (inf --> 1.030497).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0285267
	speed: 0.0094s/iter; left time: 16.4528s
	iters: 200, epoch: 2 | loss: 1.0201578
	speed: 0.0084s/iter; left time: 13.9566s
Epoch: 2 cost time: 1.7915875911712646
Epoch: 2, Steps: 206 | Train Loss: 1.0142793 Vali Loss: 1.0295265 Test Loss: 0.9886932
Validation loss decreased (1.030497 --> 1.029526).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0215683
	speed: 0.0092s/iter; left time: 14.2602s
	iters: 200, epoch: 3 | loss: 1.0131322
	speed: 0.0084s/iter; left time: 12.1190s
Epoch: 3 cost time: 1.7810633182525635
Epoch: 3, Steps: 206 | Train Loss: 1.0099956 Vali Loss: 1.0274684 Test Loss: 0.9870269
Validation loss decreased (1.029526 --> 1.027468).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0139232
	speed: 0.0077s/iter; left time: 10.3171s
	iters: 200, epoch: 4 | loss: 0.9950433
	speed: 0.0068s/iter; left time: 8.4044s
Epoch: 4 cost time: 1.4507322311401367
Epoch: 4, Steps: 206 | Train Loss: 1.0074745 Vali Loss: 1.0267633 Test Loss: 0.9867135
Validation loss decreased (1.027468 --> 1.026763).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0000579
	speed: 0.0095s/iter; left time: 10.8276s
	iters: 200, epoch: 5 | loss: 1.0022985
	speed: 0.0086s/iter; left time: 8.8875s
Epoch: 5 cost time: 1.8182494640350342
Epoch: 5, Steps: 206 | Train Loss: 1.0062148 Vali Loss: 1.0262382 Test Loss: 0.9862068
Validation loss decreased (1.026763 --> 1.026238).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0137891
	speed: 0.0091s/iter; left time: 8.5020s
	iters: 200, epoch: 6 | loss: 0.9951426
	speed: 0.0081s/iter; left time: 6.7482s
Epoch: 6 cost time: 1.739253044128418
Epoch: 6, Steps: 206 | Train Loss: 1.0055155 Vali Loss: 1.0263124 Test Loss: 0.9860466
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0118525
	speed: 0.0093s/iter; left time: 6.7640s
	iters: 200, epoch: 7 | loss: 1.0041126
	speed: 0.0085s/iter; left time: 5.2966s
Epoch: 7 cost time: 1.7990474700927734
Epoch: 7, Steps: 206 | Train Loss: 1.0047523 Vali Loss: 1.0261037 Test Loss: 0.9859709
Validation loss decreased (1.026238 --> 1.026104).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9960157
	speed: 0.0094s/iter; left time: 4.8939s
	iters: 200, epoch: 8 | loss: 1.0082806
	speed: 0.0085s/iter; left time: 3.5813s
Epoch: 8 cost time: 1.8196134567260742
Epoch: 8, Steps: 206 | Train Loss: 1.0049205 Vali Loss: 1.0258963 Test Loss: 0.9859310
Validation loss decreased (1.026104 --> 1.025896).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0096155
	speed: 0.0094s/iter; left time: 2.9425s
	iters: 200, epoch: 9 | loss: 1.0137475
	speed: 0.0086s/iter; left time: 1.8215s
Epoch: 9 cost time: 1.8141837120056152
Epoch: 9, Steps: 206 | Train Loss: 1.0042979 Vali Loss: 1.0258377 Test Loss: 0.9859303
Validation loss decreased (1.025896 --> 1.025838).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9998438
	speed: 0.0093s/iter; left time: 0.9989s
	iters: 200, epoch: 10 | loss: 1.0149218
	speed: 0.0085s/iter; left time: 0.0595s
Epoch: 10 cost time: 1.821784257888794
Epoch: 10, Steps: 206 | Train Loss: 1.0046502 Vali Loss: 1.0259016 Test Loss: 0.9859265
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9859302639961243, mae:0.7885308265686035
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0300549
	speed: 0.0094s/iter; left time: 18.5210s
	iters: 200, epoch: 1 | loss: 1.0024983
	speed: 0.0086s/iter; left time: 15.9955s
Epoch: 1 cost time: 1.8483703136444092
Epoch: 1, Steps: 206 | Train Loss: 1.0523314 Vali Loss: 1.0301926 Test Loss: 0.9893590
Validation loss decreased (inf --> 1.030193).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0126814
	speed: 0.0095s/iter; left time: 16.6169s
	iters: 200, epoch: 2 | loss: 0.9967563
	speed: 0.0086s/iter; left time: 14.1822s
Epoch: 2 cost time: 1.8239831924438477
Epoch: 2, Steps: 206 | Train Loss: 1.0144424 Vali Loss: 1.0295668 Test Loss: 0.9890845
Validation loss decreased (1.030193 --> 1.029567).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0098120
	speed: 0.0095s/iter; left time: 14.6629s
	iters: 200, epoch: 3 | loss: 1.0303695
	speed: 0.0086s/iter; left time: 12.4199s
Epoch: 3 cost time: 1.8302903175354004
Epoch: 3, Steps: 206 | Train Loss: 1.0094304 Vali Loss: 1.0274791 Test Loss: 0.9872970
Validation loss decreased (1.029567 --> 1.027479).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0085928
	speed: 0.0094s/iter; left time: 12.6309s
	iters: 200, epoch: 4 | loss: 1.0119163
	speed: 0.0086s/iter; left time: 10.6306s
Epoch: 4 cost time: 1.816725254058838
Epoch: 4, Steps: 206 | Train Loss: 1.0072618 Vali Loss: 1.0267599 Test Loss: 0.9867765
Validation loss decreased (1.027479 --> 1.026760).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0048641
	speed: 0.0094s/iter; left time: 10.6473s
	iters: 200, epoch: 5 | loss: 1.0016639
	speed: 0.0085s/iter; left time: 8.7927s
Epoch: 5 cost time: 1.8116869926452637
Epoch: 5, Steps: 206 | Train Loss: 1.0059222 Vali Loss: 1.0262369 Test Loss: 0.9862862
Validation loss decreased (1.026760 --> 1.026237).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0059012
	speed: 0.0093s/iter; left time: 8.6402s
	iters: 200, epoch: 6 | loss: 1.0290476
	speed: 0.0084s/iter; left time: 7.0187s
Epoch: 6 cost time: 1.800847053527832
Epoch: 6, Steps: 206 | Train Loss: 1.0049713 Vali Loss: 1.0262418 Test Loss: 0.9859760
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9978819
	speed: 0.0091s/iter; left time: 6.6125s
	iters: 200, epoch: 7 | loss: 1.0005425
	speed: 0.0084s/iter; left time: 5.2306s
Epoch: 7 cost time: 1.7841441631317139
Epoch: 7, Steps: 206 | Train Loss: 1.0046671 Vali Loss: 1.0261099 Test Loss: 0.9859067
Validation loss decreased (1.026237 --> 1.026110).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9934276
	speed: 0.0094s/iter; left time: 4.8927s
	iters: 200, epoch: 8 | loss: 1.0043563
	speed: 0.0085s/iter; left time: 3.5664s
Epoch: 8 cost time: 1.8113629817962646
Epoch: 8, Steps: 206 | Train Loss: 1.0043764 Vali Loss: 1.0260850 Test Loss: 0.9859127
Validation loss decreased (1.026110 --> 1.026085).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0056937
	speed: 0.0094s/iter; left time: 2.9357s
	iters: 200, epoch: 9 | loss: 1.0067600
	speed: 0.0085s/iter; left time: 1.8113s
Epoch: 9 cost time: 1.805443525314331
Epoch: 9, Steps: 206 | Train Loss: 1.0043816 Vali Loss: 1.0260676 Test Loss: 0.9858928
Validation loss decreased (1.026085 --> 1.026068).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0063488
	speed: 0.0093s/iter; left time: 0.9990s
	iters: 200, epoch: 10 | loss: 1.0093901
	speed: 0.0085s/iter; left time: 0.0593s
Epoch: 10 cost time: 1.8036401271820068
Epoch: 10, Steps: 206 | Train Loss: 1.0044355 Vali Loss: 1.0259738 Test Loss: 0.9858882
Validation loss decreased (1.026068 --> 1.025974).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9858882427215576, mae:0.7884382605552673
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0206307
	speed: 0.0172s/iter; left time: 31.6297s
Epoch: 1 cost time: 2.3933424949645996
Epoch: 1, Steps: 194 | Train Loss: 1.0534212 Vali Loss: 1.0301852 Test Loss: 0.9839734
Validation loss decreased (inf --> 1.030185).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0145671
	speed: 0.0085s/iter; left time: 13.9855s
Epoch: 2 cost time: 1.64845871925354
Epoch: 2, Steps: 194 | Train Loss: 1.0162183 Vali Loss: 1.0306323 Test Loss: 0.9831988
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0262350
	speed: 0.0086s/iter; left time: 12.5243s
Epoch: 3 cost time: 1.613375186920166
Epoch: 3, Steps: 194 | Train Loss: 1.0119698 Vali Loss: 1.0289433 Test Loss: 0.9816914
Validation loss decreased (1.030185 --> 1.028943).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0099596
	speed: 0.0096s/iter; left time: 12.0766s
Epoch: 4 cost time: 1.760847806930542
Epoch: 4, Steps: 194 | Train Loss: 1.0099572 Vali Loss: 1.0279042 Test Loss: 0.9807616
Validation loss decreased (1.028943 --> 1.027904).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0076609
	speed: 0.0085s/iter; left time: 9.0429s
Epoch: 5 cost time: 1.5505728721618652
Epoch: 5, Steps: 194 | Train Loss: 1.0088367 Vali Loss: 1.0276090 Test Loss: 0.9804369
Validation loss decreased (1.027904 --> 1.027609).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0019144
	speed: 0.0088s/iter; left time: 7.6397s
Epoch: 6 cost time: 1.575974702835083
Epoch: 6, Steps: 194 | Train Loss: 1.0084873 Vali Loss: 1.0271095 Test Loss: 0.9801379
Validation loss decreased (1.027609 --> 1.027110).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0018442
	speed: 0.0082s/iter; left time: 5.5355s
Epoch: 7 cost time: 1.5225484371185303
Epoch: 7, Steps: 194 | Train Loss: 1.0081742 Vali Loss: 1.0270514 Test Loss: 0.9800143
Validation loss decreased (1.027110 --> 1.027051).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0058901
	speed: 0.0084s/iter; left time: 4.0622s
Epoch: 8 cost time: 1.5328807830810547
Epoch: 8, Steps: 194 | Train Loss: 1.0080846 Vali Loss: 1.0269009 Test Loss: 0.9799848
Validation loss decreased (1.027051 --> 1.026901).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0100781
	speed: 0.0089s/iter; left time: 2.5666s
Epoch: 9 cost time: 1.691410779953003
Epoch: 9, Steps: 194 | Train Loss: 1.0077836 Vali Loss: 1.0268043 Test Loss: 0.9799874
Validation loss decreased (1.026901 --> 1.026804).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0038419
	speed: 0.0083s/iter; left time: 0.7849s
Epoch: 10 cost time: 1.5092377662658691
Epoch: 10, Steps: 194 | Train Loss: 1.0078088 Vali Loss: 1.0270848 Test Loss: 0.9799906
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9799873232841492, mae:0.7845644950866699
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0240756
	speed: 0.0092s/iter; left time: 17.0034s
Epoch: 1 cost time: 1.639951229095459
Epoch: 1, Steps: 194 | Train Loss: 1.0532194 Vali Loss: 1.0307505 Test Loss: 0.9838766
Validation loss decreased (inf --> 1.030751).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0133059
	speed: 0.0096s/iter; left time: 15.7417s
Epoch: 2 cost time: 1.758291244506836
Epoch: 2, Steps: 194 | Train Loss: 1.0159494 Vali Loss: 1.0302444 Test Loss: 0.9833441
Validation loss decreased (1.030751 --> 1.030244).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0149137
	speed: 0.0096s/iter; left time: 13.8843s
Epoch: 3 cost time: 1.736025094985962
Epoch: 3, Steps: 194 | Train Loss: 1.0118630 Vali Loss: 1.0277661 Test Loss: 0.9813664
Validation loss decreased (1.030244 --> 1.027766).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0070049
	speed: 0.0095s/iter; left time: 11.9609s
Epoch: 4 cost time: 1.7311789989471436
Epoch: 4, Steps: 194 | Train Loss: 1.0097845 Vali Loss: 1.0275724 Test Loss: 0.9806479
Validation loss decreased (1.027766 --> 1.027572).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0176090
	speed: 0.0087s/iter; left time: 9.2404s
Epoch: 5 cost time: 1.5526225566864014
Epoch: 5, Steps: 194 | Train Loss: 1.0088427 Vali Loss: 1.0268873 Test Loss: 0.9801748
Validation loss decreased (1.027572 --> 1.026887).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0092926
	speed: 0.0079s/iter; left time: 6.8575s
Epoch: 6 cost time: 1.407761573791504
Epoch: 6, Steps: 194 | Train Loss: 1.0083675 Vali Loss: 1.0268550 Test Loss: 0.9801118
Validation loss decreased (1.026887 --> 1.026855).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0108687
	speed: 0.0095s/iter; left time: 6.4186s
Epoch: 7 cost time: 1.7241082191467285
Epoch: 7, Steps: 194 | Train Loss: 1.0081517 Vali Loss: 1.0269388 Test Loss: 0.9800050
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0088457
	speed: 0.0093s/iter; left time: 4.4950s
Epoch: 8 cost time: 1.714665174484253
Epoch: 8, Steps: 194 | Train Loss: 1.0080276 Vali Loss: 1.0268868 Test Loss: 0.9799481
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0035523
	speed: 0.0092s/iter; left time: 2.6718s
Epoch: 9 cost time: 1.7207870483398438
Epoch: 9, Steps: 194 | Train Loss: 1.0078836 Vali Loss: 1.0269231 Test Loss: 0.9799403
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0030572
	speed: 0.0082s/iter; left time: 0.7819s
Epoch: 10 cost time: 1.5712347030639648
Epoch: 10, Steps: 194 | Train Loss: 1.0080010 Vali Loss: 1.0266840 Test Loss: 0.9799343
Validation loss decreased (1.026855 --> 1.026684).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9799342751502991, mae:0.7845252156257629
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0166645
	speed: 0.0082s/iter; left time: 15.1671s
Epoch: 1 cost time: 1.6176557540893555
Epoch: 1, Steps: 194 | Train Loss: 1.0565135 Vali Loss: 1.0309033 Test Loss: 0.9838021
Validation loss decreased (inf --> 1.030903).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0101928
	speed: 0.0075s/iter; left time: 12.3609s
Epoch: 2 cost time: 1.3973159790039062
Epoch: 2, Steps: 194 | Train Loss: 1.0158705 Vali Loss: 1.0311495 Test Loss: 0.9836022
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0099274
	speed: 0.0090s/iter; left time: 13.0201s
Epoch: 3 cost time: 1.6897263526916504
Epoch: 3, Steps: 194 | Train Loss: 1.0116575 Vali Loss: 1.0278239 Test Loss: 0.9813378
Validation loss decreased (1.030903 --> 1.027824).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0101016
	speed: 0.0092s/iter; left time: 11.5297s
Epoch: 4 cost time: 1.595932960510254
Epoch: 4, Steps: 194 | Train Loss: 1.0096354 Vali Loss: 1.0273737 Test Loss: 0.9806886
Validation loss decreased (1.027824 --> 1.027374).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0033417
	speed: 0.0078s/iter; left time: 8.2798s
Epoch: 5 cost time: 1.405341625213623
Epoch: 5, Steps: 194 | Train Loss: 1.0087280 Vali Loss: 1.0269852 Test Loss: 0.9802561
Validation loss decreased (1.027374 --> 1.026985).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0143068
	speed: 0.0097s/iter; left time: 8.4639s
Epoch: 6 cost time: 1.7584788799285889
Epoch: 6, Steps: 194 | Train Loss: 1.0083503 Vali Loss: 1.0267366 Test Loss: 0.9800725
Validation loss decreased (1.026985 --> 1.026737).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0016571
	speed: 0.0095s/iter; left time: 6.4213s
Epoch: 7 cost time: 1.7338216304779053
Epoch: 7, Steps: 194 | Train Loss: 1.0079872 Vali Loss: 1.0269089 Test Loss: 0.9800158
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0102185
	speed: 0.0088s/iter; left time: 4.2466s
Epoch: 8 cost time: 1.6147587299346924
Epoch: 8, Steps: 194 | Train Loss: 1.0079504 Vali Loss: 1.0268631 Test Loss: 0.9799792
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0132045
	speed: 0.0084s/iter; left time: 2.4405s
Epoch: 9 cost time: 1.533829689025879
Epoch: 9, Steps: 194 | Train Loss: 1.0077890 Vali Loss: 1.0268340 Test Loss: 0.9799706
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0057365
	speed: 0.0094s/iter; left time: 0.8933s
Epoch: 10 cost time: 1.747572422027588
Epoch: 10, Steps: 194 | Train Loss: 1.0077282 Vali Loss: 1.0267780 Test Loss: 0.9799705
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.980072557926178, mae:0.784645140171051
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6855268
	speed: 0.0145s/iter; left time: 29.4432s
	iters: 200, epoch: 1 | loss: 0.6992077
	speed: 0.0102s/iter; left time: 19.7009s
Epoch: 1 cost time: 2.158071279525757
Epoch: 1, Steps: 213 | Train Loss: 0.7472514 Vali Loss: 0.6907489 Test Loss: 0.6561890
Validation loss decreased (inf --> 0.690749).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6804885
	speed: 0.0076s/iter; left time: 13.7541s
	iters: 200, epoch: 2 | loss: 0.7180307
	speed: 0.0067s/iter; left time: 11.5592s
Epoch: 2 cost time: 1.47841477394104
Epoch: 2, Steps: 213 | Train Loss: 0.6815108 Vali Loss: 0.7240995 Test Loss: 0.6536095
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7072606
	speed: 0.0090s/iter; left time: 14.4769s
	iters: 200, epoch: 3 | loss: 0.6549671
	speed: 0.0083s/iter; left time: 12.5229s
Epoch: 3 cost time: 1.8134407997131348
Epoch: 3, Steps: 213 | Train Loss: 0.6618044 Vali Loss: 0.7158455 Test Loss: 0.6590241
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6809438
	speed: 0.0079s/iter; left time: 11.0350s
	iters: 200, epoch: 4 | loss: 0.6297337
	speed: 0.0072s/iter; left time: 9.2726s
Epoch: 4 cost time: 1.570617437362671
Epoch: 4, Steps: 213 | Train Loss: 0.6511144 Vali Loss: 0.7147338 Test Loss: 0.6809682
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6274075
	speed: 0.0087s/iter; left time: 10.2519s
	iters: 200, epoch: 5 | loss: 0.6099672
	speed: 0.0081s/iter; left time: 8.7889s
Epoch: 5 cost time: 1.7975995540618896
Epoch: 5, Steps: 213 | Train Loss: 0.6443787 Vali Loss: 0.7215053 Test Loss: 0.6834143
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6437324
	speed: 0.0075s/iter; left time: 7.2817s
	iters: 200, epoch: 6 | loss: 0.6149648
	speed: 0.0067s/iter; left time: 5.8054s
Epoch: 6 cost time: 1.4727237224578857
Epoch: 6, Steps: 213 | Train Loss: 0.6408338 Vali Loss: 0.7269516 Test Loss: 0.6865587
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6561891436576843, mae:0.6504737734794617
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6814015
	speed: 0.0093s/iter; left time: 18.9332s
	iters: 200, epoch: 1 | loss: 0.6571102
	speed: 0.0085s/iter; left time: 16.3323s
Epoch: 1 cost time: 1.8382596969604492
Epoch: 1, Steps: 213 | Train Loss: 0.7507743 Vali Loss: 0.6519265 Test Loss: 0.6354427
Validation loss decreased (inf --> 0.651927).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6715412
	speed: 0.0077s/iter; left time: 14.0503s
	iters: 200, epoch: 2 | loss: 0.7269117
	speed: 0.0075s/iter; left time: 12.8055s
Epoch: 2 cost time: 1.642744541168213
Epoch: 2, Steps: 213 | Train Loss: 0.6872887 Vali Loss: 0.6722547 Test Loss: 0.6310285
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6479838
	speed: 0.0075s/iter; left time: 11.9715s
	iters: 200, epoch: 3 | loss: 0.6883423
	speed: 0.0067s/iter; left time: 10.0659s
Epoch: 3 cost time: 1.484496831893921
Epoch: 3, Steps: 213 | Train Loss: 0.6710485 Vali Loss: 0.7315088 Test Loss: 0.6510330
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6670643
	speed: 0.0082s/iter; left time: 11.4792s
	iters: 200, epoch: 4 | loss: 0.6458242
	speed: 0.0072s/iter; left time: 9.2428s
Epoch: 4 cost time: 1.573326587677002
Epoch: 4, Steps: 213 | Train Loss: 0.6601921 Vali Loss: 0.7249205 Test Loss: 0.6537951
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6385645
	speed: 0.0092s/iter; left time: 10.8392s
	iters: 200, epoch: 5 | loss: 0.6887813
	speed: 0.0084s/iter; left time: 9.0430s
Epoch: 5 cost time: 1.8448853492736816
Epoch: 5, Steps: 213 | Train Loss: 0.6539158 Vali Loss: 0.7136028 Test Loss: 0.6599136
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6478602
	speed: 0.0092s/iter; left time: 8.9342s
	iters: 200, epoch: 6 | loss: 0.6358446
	speed: 0.0085s/iter; left time: 7.3258s
Epoch: 6 cost time: 1.862443208694458
Epoch: 6, Steps: 213 | Train Loss: 0.6495750 Vali Loss: 0.7064412 Test Loss: 0.6643540
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.635442852973938, mae:0.6405647993087769
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7386143
	speed: 0.0094s/iter; left time: 19.1102s
	iters: 200, epoch: 1 | loss: 0.6805092
	speed: 0.0085s/iter; left time: 16.4814s
Epoch: 1 cost time: 1.8731892108917236
Epoch: 1, Steps: 213 | Train Loss: 0.7493187 Vali Loss: 0.6694047 Test Loss: 0.6284707
Validation loss decreased (inf --> 0.669405).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6964153
	speed: 0.0093s/iter; left time: 16.9793s
	iters: 200, epoch: 2 | loss: 0.6930954
	speed: 0.0085s/iter; left time: 14.5380s
Epoch: 2 cost time: 1.8579232692718506
Epoch: 2, Steps: 213 | Train Loss: 0.6837511 Vali Loss: 0.6970040 Test Loss: 0.6463093
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6742285
	speed: 0.0092s/iter; left time: 14.7893s
	iters: 200, epoch: 3 | loss: 0.6217191
	speed: 0.0084s/iter; left time: 12.6555s
Epoch: 3 cost time: 1.841268539428711
Epoch: 3, Steps: 213 | Train Loss: 0.6640707 Vali Loss: 0.7120569 Test Loss: 0.6702643
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6406650
	speed: 0.0093s/iter; left time: 12.9910s
	iters: 200, epoch: 4 | loss: 0.6260986
	speed: 0.0085s/iter; left time: 10.9921s
Epoch: 4 cost time: 1.8681890964508057
Epoch: 4, Steps: 213 | Train Loss: 0.6530612 Vali Loss: 0.6981056 Test Loss: 0.6726868
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6323345
	speed: 0.0092s/iter; left time: 10.8316s
	iters: 200, epoch: 5 | loss: 0.6177558
	speed: 0.0084s/iter; left time: 9.0752s
Epoch: 5 cost time: 1.8462557792663574
Epoch: 5, Steps: 213 | Train Loss: 0.6454056 Vali Loss: 0.7238200 Test Loss: 0.6829115
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6599469
	speed: 0.0093s/iter; left time: 8.9650s
	iters: 200, epoch: 6 | loss: 0.6488222
	speed: 0.0085s/iter; left time: 7.3205s
Epoch: 6 cost time: 1.8477048873901367
Epoch: 6, Steps: 213 | Train Loss: 0.6416320 Vali Loss: 0.7223465 Test Loss: 0.6860002
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6284706592559814, mae:0.636967122554779
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7620153
	speed: 0.0164s/iter; left time: 32.7234s
	iters: 200, epoch: 1 | loss: 0.7869069
	speed: 0.0120s/iter; left time: 22.7600s
Epoch: 1 cost time: 2.5254170894622803
Epoch: 1, Steps: 210 | Train Loss: 0.8213950 Vali Loss: 0.7865520 Test Loss: 0.6994258
Validation loss decreased (inf --> 0.786552).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7614613
	speed: 0.0093s/iter; left time: 16.6896s
	iters: 200, epoch: 2 | loss: 0.8029780
	speed: 0.0085s/iter; left time: 14.3655s
Epoch: 2 cost time: 1.8398511409759521
Epoch: 2, Steps: 210 | Train Loss: 0.7601918 Vali Loss: 0.7823285 Test Loss: 0.7183670
Validation loss decreased (0.786552 --> 0.782328).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7497653
	speed: 0.0095s/iter; left time: 14.9498s
	iters: 200, epoch: 3 | loss: 0.7168717
	speed: 0.0086s/iter; left time: 12.6821s
Epoch: 3 cost time: 1.8474605083465576
Epoch: 3, Steps: 210 | Train Loss: 0.7331820 Vali Loss: 0.7924213 Test Loss: 0.7406803
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7015080
	speed: 0.0089s/iter; left time: 12.1603s
	iters: 200, epoch: 4 | loss: 0.7360578
	speed: 0.0083s/iter; left time: 10.4990s
Epoch: 4 cost time: 1.7876856327056885
Epoch: 4, Steps: 210 | Train Loss: 0.7154313 Vali Loss: 0.8418705 Test Loss: 0.7677273
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6815237
	speed: 0.0092s/iter; left time: 10.6722s
	iters: 200, epoch: 5 | loss: 0.6808925
	speed: 0.0084s/iter; left time: 8.9151s
Epoch: 5 cost time: 1.8122925758361816
Epoch: 5, Steps: 210 | Train Loss: 0.7049210 Vali Loss: 0.8632354 Test Loss: 0.7978563
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6895072
	speed: 0.0092s/iter; left time: 8.7603s
	iters: 200, epoch: 6 | loss: 0.7013754
	speed: 0.0083s/iter; left time: 7.0328s
Epoch: 6 cost time: 1.7679839134216309
Epoch: 6, Steps: 210 | Train Loss: 0.6984469 Vali Loss: 0.8645647 Test Loss: 0.7994810
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6862532
	speed: 0.0076s/iter; left time: 5.6126s
	iters: 200, epoch: 7 | loss: 0.7176514
	speed: 0.0070s/iter; left time: 4.5149s
Epoch: 7 cost time: 1.5345890522003174
Epoch: 7, Steps: 210 | Train Loss: 0.6962972 Vali Loss: 0.8726037 Test Loss: 0.8034277
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7183670401573181, mae:0.6813094615936279
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7882366
	speed: 0.0064s/iter; left time: 12.7660s
	iters: 200, epoch: 1 | loss: 0.7902850
	speed: 0.0056s/iter; left time: 10.6804s
Epoch: 1 cost time: 1.2528226375579834
Epoch: 1, Steps: 210 | Train Loss: 0.8237216 Vali Loss: 0.7636945 Test Loss: 0.6884568
Validation loss decreased (inf --> 0.763694).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7479018
	speed: 0.0080s/iter; left time: 14.2468s
	iters: 200, epoch: 2 | loss: 0.7286217
	speed: 0.0073s/iter; left time: 12.2642s
Epoch: 2 cost time: 1.5697381496429443
Epoch: 2, Steps: 210 | Train Loss: 0.7625905 Vali Loss: 0.7549651 Test Loss: 0.7015778
Validation loss decreased (0.763694 --> 0.754965).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7520794
	speed: 0.0074s/iter; left time: 11.7655s
	iters: 200, epoch: 3 | loss: 0.6798097
	speed: 0.0067s/iter; left time: 9.9643s
Epoch: 3 cost time: 1.4666533470153809
Epoch: 3, Steps: 210 | Train Loss: 0.7405509 Vali Loss: 0.8001629 Test Loss: 0.7512525
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7146017
	speed: 0.0090s/iter; left time: 12.3934s
	iters: 200, epoch: 4 | loss: 0.7417886
	speed: 0.0078s/iter; left time: 9.9436s
Epoch: 4 cost time: 1.704735279083252
Epoch: 4, Steps: 210 | Train Loss: 0.7215631 Vali Loss: 0.8030014 Test Loss: 0.7742956
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7345678
	speed: 0.0078s/iter; left time: 9.0232s
	iters: 200, epoch: 5 | loss: 0.7187437
	speed: 0.0077s/iter; left time: 8.1922s
Epoch: 5 cost time: 1.6878793239593506
Epoch: 5, Steps: 210 | Train Loss: 0.7093458 Vali Loss: 0.8194053 Test Loss: 0.7935956
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6596197
	speed: 0.0077s/iter; left time: 7.2897s
	iters: 200, epoch: 6 | loss: 0.7086478
	speed: 0.0068s/iter; left time: 5.7906s
Epoch: 6 cost time: 1.478285789489746
Epoch: 6, Steps: 210 | Train Loss: 0.7023799 Vali Loss: 0.8332167 Test Loss: 0.8070346
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7501497
	speed: 0.0093s/iter; left time: 6.8948s
	iters: 200, epoch: 7 | loss: 0.6843537
	speed: 0.0085s/iter; left time: 5.4488s
Epoch: 7 cost time: 1.835371732711792
Epoch: 7, Steps: 210 | Train Loss: 0.7010032 Vali Loss: 0.8353401 Test Loss: 0.8098364
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.70157790184021, mae:0.6728388071060181
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7481728
	speed: 0.0077s/iter; left time: 15.4576s
	iters: 200, epoch: 1 | loss: 0.7278194
	speed: 0.0068s/iter; left time: 13.0176s
Epoch: 1 cost time: 1.4851882457733154
Epoch: 1, Steps: 210 | Train Loss: 0.8230040 Vali Loss: 0.7609009 Test Loss: 0.6843216
Validation loss decreased (inf --> 0.760901).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7433209
	speed: 0.0094s/iter; left time: 16.8467s
	iters: 200, epoch: 2 | loss: 0.7190779
	speed: 0.0085s/iter; left time: 14.4073s
Epoch: 2 cost time: 1.8355538845062256
Epoch: 2, Steps: 210 | Train Loss: 0.7617275 Vali Loss: 0.7613951 Test Loss: 0.6978811
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7126064
	speed: 0.0072s/iter; left time: 11.4235s
	iters: 200, epoch: 3 | loss: 0.7359347
	speed: 0.0066s/iter; left time: 9.8005s
Epoch: 3 cost time: 1.436464786529541
Epoch: 3, Steps: 210 | Train Loss: 0.7346353 Vali Loss: 0.7808904 Test Loss: 0.7200302
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7135370
	speed: 0.0076s/iter; left time: 10.4227s
	iters: 200, epoch: 4 | loss: 0.7167608
	speed: 0.0067s/iter; left time: 8.5725s
Epoch: 4 cost time: 1.470219612121582
Epoch: 4, Steps: 210 | Train Loss: 0.7174268 Vali Loss: 0.8186845 Test Loss: 0.7491894
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7209234
	speed: 0.0090s/iter; left time: 10.4566s
	iters: 200, epoch: 5 | loss: 0.7294928
	speed: 0.0084s/iter; left time: 8.9160s
Epoch: 5 cost time: 1.8443801403045654
Epoch: 5, Steps: 210 | Train Loss: 0.7072781 Vali Loss: 0.8502231 Test Loss: 0.7761567
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6981334
	speed: 0.0090s/iter; left time: 8.5134s
	iters: 200, epoch: 6 | loss: 0.6910590
	speed: 0.0084s/iter; left time: 7.1072s
Epoch: 6 cost time: 1.814276933670044
Epoch: 6, Steps: 210 | Train Loss: 0.7027217 Vali Loss: 0.8467496 Test Loss: 0.7772571
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6843215823173523, mae:0.6647142767906189
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8163770
	speed: 0.0132s/iter; left time: 25.7990s
	iters: 200, epoch: 1 | loss: 0.8502722
	speed: 0.0091s/iter; left time: 16.9436s
Epoch: 1 cost time: 1.887561321258545
Epoch: 1, Steps: 206 | Train Loss: 0.8782558 Vali Loss: 0.8092452 Test Loss: 0.7533836
Validation loss decreased (inf --> 0.809245).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7973442
	speed: 0.0071s/iter; left time: 12.4949s
	iters: 200, epoch: 2 | loss: 0.7982077
	speed: 0.0063s/iter; left time: 10.4233s
Epoch: 2 cost time: 1.3392844200134277
Epoch: 2, Steps: 206 | Train Loss: 0.7999265 Vali Loss: 0.8397477 Test Loss: 0.8603210
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7775123
	speed: 0.0076s/iter; left time: 11.8195s
	iters: 200, epoch: 3 | loss: 0.7458051
	speed: 0.0066s/iter; left time: 9.5279s
Epoch: 3 cost time: 1.4034671783447266
Epoch: 3, Steps: 206 | Train Loss: 0.7533643 Vali Loss: 0.8141902 Test Loss: 0.8535977
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7079725
	speed: 0.0081s/iter; left time: 10.8487s
	iters: 200, epoch: 4 | loss: 0.7727287
	speed: 0.0075s/iter; left time: 9.2922s
Epoch: 4 cost time: 1.5955674648284912
Epoch: 4, Steps: 206 | Train Loss: 0.7341033 Vali Loss: 0.8205901 Test Loss: 0.8659263
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7651780
	speed: 0.0093s/iter; left time: 10.5177s
	iters: 200, epoch: 5 | loss: 0.7027425
	speed: 0.0082s/iter; left time: 8.5049s
Epoch: 5 cost time: 1.7383999824523926
Epoch: 5, Steps: 206 | Train Loss: 0.7243577 Vali Loss: 0.8266053 Test Loss: 0.8758993
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7525216
	speed: 0.0091s/iter; left time: 8.4766s
	iters: 200, epoch: 6 | loss: 0.7353433
	speed: 0.0077s/iter; left time: 6.3627s
Epoch: 6 cost time: 1.61802339553833
Epoch: 6, Steps: 206 | Train Loss: 0.7190388 Vali Loss: 0.8283536 Test Loss: 0.8749840
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7533838152885437, mae:0.6975658535957336
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8658741
	speed: 0.0076s/iter; left time: 14.8918s
	iters: 200, epoch: 1 | loss: 0.8370481
	speed: 0.0062s/iter; left time: 11.5225s
Epoch: 1 cost time: 1.3142163753509521
Epoch: 1, Steps: 206 | Train Loss: 0.8807298 Vali Loss: 0.7888240 Test Loss: 0.7413226
Validation loss decreased (inf --> 0.788824).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7600624
	speed: 0.0071s/iter; left time: 12.4310s
	iters: 200, epoch: 2 | loss: 0.8501804
	speed: 0.0063s/iter; left time: 10.4653s
Epoch: 2 cost time: 1.3571958541870117
Epoch: 2, Steps: 206 | Train Loss: 0.8031134 Vali Loss: 0.8430772 Test Loss: 0.8373160
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7384326
	speed: 0.0086s/iter; left time: 13.2978s
	iters: 200, epoch: 3 | loss: 0.7326318
	speed: 0.0076s/iter; left time: 11.0323s
Epoch: 3 cost time: 1.6165270805358887
Epoch: 3, Steps: 206 | Train Loss: 0.7551484 Vali Loss: 0.8299968 Test Loss: 0.8314511
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7079685
	speed: 0.0077s/iter; left time: 10.3427s
	iters: 200, epoch: 4 | loss: 0.7806665
	speed: 0.0071s/iter; left time: 8.8708s
Epoch: 4 cost time: 1.5220496654510498
Epoch: 4, Steps: 206 | Train Loss: 0.7340692 Vali Loss: 0.8002419 Test Loss: 0.8369196
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7905657
	speed: 0.0080s/iter; left time: 9.1082s
	iters: 200, epoch: 5 | loss: 0.7374071
	speed: 0.0073s/iter; left time: 7.5644s
Epoch: 5 cost time: 1.5529825687408447
Epoch: 5, Steps: 206 | Train Loss: 0.7237932 Vali Loss: 0.8205776 Test Loss: 0.8423715
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7058744
	speed: 0.0065s/iter; left time: 6.0142s
	iters: 200, epoch: 6 | loss: 0.6741695
	speed: 0.0056s/iter; left time: 4.6654s
Epoch: 6 cost time: 1.2004902362823486
Epoch: 6, Steps: 206 | Train Loss: 0.7162450 Vali Loss: 0.8279428 Test Loss: 0.8435437
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7413225769996643, mae:0.6921430230140686
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8393981
	speed: 0.0076s/iter; left time: 14.9751s
	iters: 200, epoch: 1 | loss: 0.8425667
	speed: 0.0066s/iter; left time: 12.3302s
Epoch: 1 cost time: 1.4111213684082031
Epoch: 1, Steps: 206 | Train Loss: 0.8813416 Vali Loss: 0.7950719 Test Loss: 0.7435696
Validation loss decreased (inf --> 0.795072).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8261058
	speed: 0.0069s/iter; left time: 12.0541s
	iters: 200, epoch: 2 | loss: 0.8158283
	speed: 0.0062s/iter; left time: 10.2263s
Epoch: 2 cost time: 1.318329095840454
Epoch: 2, Steps: 206 | Train Loss: 0.8177266 Vali Loss: 0.8027705 Test Loss: 0.7697185
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7695728
	speed: 0.0086s/iter; left time: 13.3209s
	iters: 200, epoch: 3 | loss: 0.7760912
	speed: 0.0080s/iter; left time: 11.6562s
Epoch: 3 cost time: 1.7034697532653809
Epoch: 3, Steps: 206 | Train Loss: 0.7827456 Vali Loss: 0.8310275 Test Loss: 0.8187237
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7478464
	speed: 0.0071s/iter; left time: 9.4840s
	iters: 200, epoch: 4 | loss: 0.7846035
	speed: 0.0064s/iter; left time: 7.9162s
Epoch: 4 cost time: 1.3541436195373535
Epoch: 4, Steps: 206 | Train Loss: 0.7594379 Vali Loss: 0.8428807 Test Loss: 0.8065699
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7264646
	speed: 0.0071s/iter; left time: 8.1050s
	iters: 200, epoch: 5 | loss: 0.7845962
	speed: 0.0066s/iter; left time: 6.8382s
Epoch: 5 cost time: 1.4370882511138916
Epoch: 5, Steps: 206 | Train Loss: 0.7476802 Vali Loss: 0.8441616 Test Loss: 0.8193330
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7078620
	speed: 0.0093s/iter; left time: 8.6374s
	iters: 200, epoch: 6 | loss: 0.7366461
	speed: 0.0084s/iter; left time: 7.0122s
Epoch: 6 cost time: 1.787189245223999
Epoch: 6, Steps: 206 | Train Loss: 0.7404771 Vali Loss: 0.8529323 Test Loss: 0.8239226
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7435694932937622, mae:0.6929859519004822
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9387001
	speed: 0.0138s/iter; left time: 25.4432s
Epoch: 1 cost time: 1.9802615642547607
Epoch: 1, Steps: 194 | Train Loss: 0.9539892 Vali Loss: 0.7332867 Test Loss: 0.8352025
Validation loss decreased (inf --> 0.733287).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8743980
	speed: 0.0083s/iter; left time: 13.7458s
Epoch: 2 cost time: 1.5143568515777588
Epoch: 2, Steps: 194 | Train Loss: 0.8938404 Vali Loss: 0.7428728 Test Loss: 0.8579381
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8359983
	speed: 0.0093s/iter; left time: 13.5313s
Epoch: 3 cost time: 1.693899154663086
Epoch: 3, Steps: 194 | Train Loss: 0.8487635 Vali Loss: 0.7253966 Test Loss: 0.9574295
Validation loss decreased (0.733287 --> 0.725397).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8267093
	speed: 0.0093s/iter; left time: 11.7223s
Epoch: 4 cost time: 1.7202787399291992
Epoch: 4, Steps: 194 | Train Loss: 0.8238555 Vali Loss: 0.7704413 Test Loss: 1.0174379
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8121444
	speed: 0.0077s/iter; left time: 8.2218s
Epoch: 5 cost time: 1.3978102207183838
Epoch: 5, Steps: 194 | Train Loss: 0.8112055 Vali Loss: 0.7652608 Test Loss: 0.9874669
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7813985
	speed: 0.0092s/iter; left time: 7.9742s
Epoch: 6 cost time: 1.6583645343780518
Epoch: 6, Steps: 194 | Train Loss: 0.8051918 Vali Loss: 0.7673400 Test Loss: 1.0079497
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8017527
	speed: 0.0079s/iter; left time: 5.3207s
Epoch: 7 cost time: 1.4521353244781494
Epoch: 7, Steps: 194 | Train Loss: 0.8024516 Vali Loss: 0.7700467 Test Loss: 1.0029447
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8097224
	speed: 0.0086s/iter; left time: 4.1382s
Epoch: 8 cost time: 1.5381641387939453
Epoch: 8, Steps: 194 | Train Loss: 0.7994501 Vali Loss: 0.7736609 Test Loss: 0.9925743
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9574293494224548, mae:0.7884788513183594
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9459166
	speed: 0.0086s/iter; left time: 15.8265s
Epoch: 1 cost time: 1.5396978855133057
Epoch: 1, Steps: 194 | Train Loss: 0.9556667 Vali Loss: 0.7328840 Test Loss: 0.8461176
Validation loss decreased (inf --> 0.732884).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8915815
	speed: 0.0095s/iter; left time: 15.6318s
Epoch: 2 cost time: 1.731980800628662
Epoch: 2, Steps: 194 | Train Loss: 0.8994467 Vali Loss: 0.7684872 Test Loss: 0.8719557
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9078295
	speed: 0.0094s/iter; left time: 13.7147s
Epoch: 3 cost time: 1.7376723289489746
Epoch: 3, Steps: 194 | Train Loss: 0.8557763 Vali Loss: 0.7810581 Test Loss: 0.8966627
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8548626
	speed: 0.0094s/iter; left time: 11.8858s
Epoch: 4 cost time: 1.7336106300354004
Epoch: 4, Steps: 194 | Train Loss: 0.8228297 Vali Loss: 0.7800702 Test Loss: 0.9438999
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8081919
	speed: 0.0087s/iter; left time: 9.2593s
Epoch: 5 cost time: 1.5636637210845947
Epoch: 5, Steps: 194 | Train Loss: 0.8033719 Vali Loss: 0.7770428 Test Loss: 0.9498615
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7943860
	speed: 0.0089s/iter; left time: 7.7816s
Epoch: 6 cost time: 1.6843934059143066
Epoch: 6, Steps: 194 | Train Loss: 0.7957443 Vali Loss: 0.7687986 Test Loss: 0.9554083
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8461174964904785, mae:0.7395272850990295
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9114933
	speed: 0.0098s/iter; left time: 17.9852s
Epoch: 1 cost time: 1.799539566040039
Epoch: 1, Steps: 194 | Train Loss: 0.9568342 Vali Loss: 0.7341387 Test Loss: 0.8177720
Validation loss decreased (inf --> 0.734139).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8837814
	speed: 0.0097s/iter; left time: 16.0077s
Epoch: 2 cost time: 1.778599739074707
Epoch: 2, Steps: 194 | Train Loss: 0.8999930 Vali Loss: 0.7395832 Test Loss: 0.8632952
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8951233
	speed: 0.0094s/iter; left time: 13.7190s
Epoch: 3 cost time: 1.749450445175171
Epoch: 3, Steps: 194 | Train Loss: 0.8537807 Vali Loss: 0.7521653 Test Loss: 0.9063834
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8416392
	speed: 0.0095s/iter; left time: 11.9528s
Epoch: 4 cost time: 1.7748453617095947
Epoch: 4, Steps: 194 | Train Loss: 0.8265270 Vali Loss: 0.7550137 Test Loss: 0.9245257
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8122052
	speed: 0.0095s/iter; left time: 10.1427s
Epoch: 5 cost time: 1.759584903717041
Epoch: 5, Steps: 194 | Train Loss: 0.8156009 Vali Loss: 0.7633420 Test Loss: 0.9570006
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7809089
	speed: 0.0096s/iter; left time: 8.3785s
Epoch: 6 cost time: 1.768986463546753
Epoch: 6, Steps: 194 | Train Loss: 0.8093893 Vali Loss: 0.7491170 Test Loss: 0.9581077
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8177717924118042, mae:0.726783037185669
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6836494
	speed: 0.0190s/iter; left time: 38.5847s
	iters: 200, epoch: 1 | loss: 0.7116095
	speed: 0.0135s/iter; left time: 26.0498s
Epoch: 1 cost time: 2.8494694232940674
Epoch: 1, Steps: 213 | Train Loss: 0.7448010 Vali Loss: 0.6533294 Test Loss: 0.6336603
Validation loss decreased (inf --> 0.653329).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7028639
	speed: 0.0094s/iter; left time: 17.0905s
	iters: 200, epoch: 2 | loss: 0.6760638
	speed: 0.0087s/iter; left time: 14.9016s
Epoch: 2 cost time: 1.9251623153686523
Epoch: 2, Steps: 213 | Train Loss: 0.6869032 Vali Loss: 0.7050082 Test Loss: 0.6427329
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6719979
	speed: 0.0093s/iter; left time: 14.9708s
	iters: 200, epoch: 3 | loss: 0.7137977
	speed: 0.0085s/iter; left time: 12.8218s
Epoch: 3 cost time: 1.8553340435028076
Epoch: 3, Steps: 213 | Train Loss: 0.6686549 Vali Loss: 0.7098366 Test Loss: 0.6504222
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7073490
	speed: 0.0093s/iter; left time: 13.0132s
	iters: 200, epoch: 4 | loss: 0.6368748
	speed: 0.0085s/iter; left time: 10.9995s
Epoch: 4 cost time: 1.8592135906219482
Epoch: 4, Steps: 213 | Train Loss: 0.6588954 Vali Loss: 0.7028077 Test Loss: 0.6612637
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6124605
	speed: 0.0094s/iter; left time: 11.1136s
	iters: 200, epoch: 5 | loss: 0.6681678
	speed: 0.0086s/iter; left time: 9.2586s
Epoch: 5 cost time: 1.8832752704620361
Epoch: 5, Steps: 213 | Train Loss: 0.6525237 Vali Loss: 0.7325605 Test Loss: 0.6702747
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5912956
	speed: 0.0091s/iter; left time: 8.8336s
	iters: 200, epoch: 6 | loss: 0.6557446
	speed: 0.0084s/iter; left time: 7.2646s
Epoch: 6 cost time: 1.8382618427276611
Epoch: 6, Steps: 213 | Train Loss: 0.6480381 Vali Loss: 0.7210472 Test Loss: 0.6725367
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6336602568626404, mae:0.639636754989624
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7244635
	speed: 0.0094s/iter; left time: 18.9917s
	iters: 200, epoch: 1 | loss: 0.6960258
	speed: 0.0084s/iter; left time: 16.2614s
Epoch: 1 cost time: 1.8366317749023438
Epoch: 1, Steps: 213 | Train Loss: 0.7498909 Vali Loss: 0.6755962 Test Loss: 0.6379945
Validation loss decreased (inf --> 0.675596).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6847676
	speed: 0.0094s/iter; left time: 17.1487s
	iters: 200, epoch: 2 | loss: 0.6434233
	speed: 0.0086s/iter; left time: 14.7199s
Epoch: 2 cost time: 1.8712832927703857
Epoch: 2, Steps: 213 | Train Loss: 0.6850639 Vali Loss: 0.6967723 Test Loss: 0.6395840
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6610039
	speed: 0.0092s/iter; left time: 14.8370s
	iters: 200, epoch: 3 | loss: 0.6300968
	speed: 0.0085s/iter; left time: 12.7527s
Epoch: 3 cost time: 1.8577542304992676
Epoch: 3, Steps: 213 | Train Loss: 0.6645775 Vali Loss: 0.6937314 Test Loss: 0.6568310
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6507829
	speed: 0.0092s/iter; left time: 12.8720s
	iters: 200, epoch: 4 | loss: 0.6777209
	speed: 0.0084s/iter; left time: 10.8453s
Epoch: 4 cost time: 1.8439319133758545
Epoch: 4, Steps: 213 | Train Loss: 0.6510216 Vali Loss: 0.7077686 Test Loss: 0.6708548
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6397354
	speed: 0.0093s/iter; left time: 10.9731s
	iters: 200, epoch: 5 | loss: 0.6549296
	speed: 0.0085s/iter; left time: 9.1664s
Epoch: 5 cost time: 1.8618323802947998
Epoch: 5, Steps: 213 | Train Loss: 0.6440168 Vali Loss: 0.7160342 Test Loss: 0.6837978
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6399741
	speed: 0.0080s/iter; left time: 7.7630s
	iters: 200, epoch: 6 | loss: 0.6062548
	speed: 0.0070s/iter; left time: 6.0498s
Epoch: 6 cost time: 1.5254204273223877
Epoch: 6, Steps: 213 | Train Loss: 0.6391791 Vali Loss: 0.7072784 Test Loss: 0.6827660
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6379944682121277, mae:0.6415228247642517
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7090370
	speed: 0.0094s/iter; left time: 19.0583s
	iters: 200, epoch: 1 | loss: 0.6288875
	speed: 0.0085s/iter; left time: 16.4214s
Epoch: 1 cost time: 1.8822083473205566
Epoch: 1, Steps: 213 | Train Loss: 0.7458858 Vali Loss: 0.6695318 Test Loss: 0.6294832
Validation loss decreased (inf --> 0.669532).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7122003
	speed: 0.0077s/iter; left time: 13.9985s
	iters: 200, epoch: 2 | loss: 0.6592457
	speed: 0.0073s/iter; left time: 12.5211s
Epoch: 2 cost time: 1.615149974822998
Epoch: 2, Steps: 213 | Train Loss: 0.6835389 Vali Loss: 0.7037253 Test Loss: 0.6524966
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6413062
	speed: 0.0091s/iter; left time: 14.6163s
	iters: 200, epoch: 3 | loss: 0.6815830
	speed: 0.0083s/iter; left time: 12.4868s
Epoch: 3 cost time: 1.8211688995361328
Epoch: 3, Steps: 213 | Train Loss: 0.6637709 Vali Loss: 0.7012672 Test Loss: 0.6591794
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6695079
	speed: 0.0094s/iter; left time: 13.0784s
	iters: 200, epoch: 4 | loss: 0.6853493
	speed: 0.0087s/iter; left time: 11.2311s
Epoch: 4 cost time: 1.925797939300537
Epoch: 4, Steps: 213 | Train Loss: 0.6530857 Vali Loss: 0.7280719 Test Loss: 0.6708063
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6333055
	speed: 0.0093s/iter; left time: 10.9538s
	iters: 200, epoch: 5 | loss: 0.6271113
	speed: 0.0084s/iter; left time: 9.1145s
Epoch: 5 cost time: 1.8461685180664062
Epoch: 5, Steps: 213 | Train Loss: 0.6466231 Vali Loss: 0.7131677 Test Loss: 0.6752731
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6259055
	speed: 0.0093s/iter; left time: 8.9811s
	iters: 200, epoch: 6 | loss: 0.6326615
	speed: 0.0082s/iter; left time: 7.1033s
Epoch: 6 cost time: 1.7688336372375488
Epoch: 6, Steps: 213 | Train Loss: 0.6424781 Vali Loss: 0.7161244 Test Loss: 0.6818693
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.629483163356781, mae:0.636995255947113
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8549349
	speed: 0.0121s/iter; left time: 24.1310s
	iters: 200, epoch: 1 | loss: 0.7396777
	speed: 0.0085s/iter; left time: 16.1720s
Epoch: 1 cost time: 1.7970139980316162
Epoch: 1, Steps: 210 | Train Loss: 0.8192956 Vali Loss: 0.7542897 Test Loss: 0.6819135
Validation loss decreased (inf --> 0.754290).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7678126
	speed: 0.0075s/iter; left time: 13.4357s
	iters: 200, epoch: 2 | loss: 0.7756199
	speed: 0.0066s/iter; left time: 11.1012s
Epoch: 2 cost time: 1.4219415187835693
Epoch: 2, Steps: 210 | Train Loss: 0.7645046 Vali Loss: 0.7744750 Test Loss: 0.6995385
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7496428
	speed: 0.0073s/iter; left time: 11.5838s
	iters: 200, epoch: 3 | loss: 0.6616083
	speed: 0.0072s/iter; left time: 10.6679s
Epoch: 3 cost time: 1.5677447319030762
Epoch: 3, Steps: 210 | Train Loss: 0.7385581 Vali Loss: 0.8188586 Test Loss: 0.7487878
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7295893
	speed: 0.0087s/iter; left time: 11.9873s
	iters: 200, epoch: 4 | loss: 0.7218474
	speed: 0.0082s/iter; left time: 10.4463s
Epoch: 4 cost time: 1.7899818420410156
Epoch: 4, Steps: 210 | Train Loss: 0.7208909 Vali Loss: 0.8314822 Test Loss: 0.7623550
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7249112
	speed: 0.0077s/iter; left time: 8.9567s
	iters: 200, epoch: 5 | loss: 0.6938423
	speed: 0.0073s/iter; left time: 7.7671s
Epoch: 5 cost time: 1.582383394241333
Epoch: 5, Steps: 210 | Train Loss: 0.7116966 Vali Loss: 0.8036925 Test Loss: 0.7649060
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7077212
	speed: 0.0088s/iter; left time: 8.3768s
	iters: 200, epoch: 6 | loss: 0.6972927
	speed: 0.0082s/iter; left time: 6.9493s
Epoch: 6 cost time: 1.7676572799682617
Epoch: 6, Steps: 210 | Train Loss: 0.7071270 Vali Loss: 0.8132210 Test Loss: 0.7671390
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6819136142730713, mae:0.6638700366020203
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8281345
	speed: 0.0089s/iter; left time: 17.8655s
	iters: 200, epoch: 1 | loss: 0.7875861
	speed: 0.0080s/iter; left time: 15.2581s
Epoch: 1 cost time: 1.7410526275634766
Epoch: 1, Steps: 210 | Train Loss: 0.8227224 Vali Loss: 0.7436079 Test Loss: 0.6872293
Validation loss decreased (inf --> 0.743608).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7946353
	speed: 0.0094s/iter; left time: 16.9035s
	iters: 200, epoch: 2 | loss: 0.7502661
	speed: 0.0085s/iter; left time: 14.4500s
Epoch: 2 cost time: 1.8648791313171387
Epoch: 2, Steps: 210 | Train Loss: 0.7611659 Vali Loss: 0.7531909 Test Loss: 0.6967732
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7766497
	speed: 0.0093s/iter; left time: 14.6950s
	iters: 200, epoch: 3 | loss: 0.7991528
	speed: 0.0082s/iter; left time: 12.0897s
Epoch: 3 cost time: 1.747877597808838
Epoch: 3, Steps: 210 | Train Loss: 0.7373622 Vali Loss: 0.7698500 Test Loss: 0.7339871
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7305881
	speed: 0.0090s/iter; left time: 12.3048s
	iters: 200, epoch: 4 | loss: 0.7380666
	speed: 0.0075s/iter; left time: 9.5687s
Epoch: 4 cost time: 1.6185922622680664
Epoch: 4, Steps: 210 | Train Loss: 0.7213896 Vali Loss: 0.8054206 Test Loss: 0.7640538
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7922067
	speed: 0.0091s/iter; left time: 10.6130s
	iters: 200, epoch: 5 | loss: 0.7436303
	speed: 0.0081s/iter; left time: 8.5813s
Epoch: 5 cost time: 1.7407362461090088
Epoch: 5, Steps: 210 | Train Loss: 0.7112296 Vali Loss: 0.8193990 Test Loss: 0.7665598
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7163813
	speed: 0.0078s/iter; left time: 7.4277s
	iters: 200, epoch: 6 | loss: 0.7266458
	speed: 0.0072s/iter; left time: 6.1082s
Epoch: 6 cost time: 1.5519516468048096
Epoch: 6, Steps: 210 | Train Loss: 0.7067117 Vali Loss: 0.8248329 Test Loss: 0.7738376
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6872295141220093, mae:0.6665017604827881
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8074880
	speed: 0.0072s/iter; left time: 14.3946s
	iters: 200, epoch: 1 | loss: 0.7869072
	speed: 0.0066s/iter; left time: 12.4666s
Epoch: 1 cost time: 1.425260305404663
Epoch: 1, Steps: 210 | Train Loss: 0.8212310 Vali Loss: 0.7544914 Test Loss: 0.6850987
Validation loss decreased (inf --> 0.754491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7789630
	speed: 0.0071s/iter; left time: 12.7800s
	iters: 200, epoch: 2 | loss: 0.7484740
	speed: 0.0059s/iter; left time: 10.0323s
Epoch: 2 cost time: 1.2836756706237793
Epoch: 2, Steps: 210 | Train Loss: 0.7628798 Vali Loss: 0.7614542 Test Loss: 0.6970907
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7534282
	speed: 0.0080s/iter; left time: 12.6084s
	iters: 200, epoch: 3 | loss: 0.7621523
	speed: 0.0072s/iter; left time: 10.6711s
Epoch: 3 cost time: 1.5612869262695312
Epoch: 3, Steps: 210 | Train Loss: 0.7376666 Vali Loss: 0.8221197 Test Loss: 0.7572227
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7278260
	speed: 0.0071s/iter; left time: 9.7690s
	iters: 200, epoch: 4 | loss: 0.7188506
	speed: 0.0068s/iter; left time: 8.7029s
Epoch: 4 cost time: 1.502570390701294
Epoch: 4, Steps: 210 | Train Loss: 0.7214026 Vali Loss: 0.7796533 Test Loss: 0.7528348
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7094322
	speed: 0.0092s/iter; left time: 10.6513s
	iters: 200, epoch: 5 | loss: 0.7184987
	speed: 0.0084s/iter; left time: 8.8895s
Epoch: 5 cost time: 1.8050994873046875
Epoch: 5, Steps: 210 | Train Loss: 0.7130351 Vali Loss: 0.8232020 Test Loss: 0.7765439
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7024764
	speed: 0.0091s/iter; left time: 8.6324s
	iters: 200, epoch: 6 | loss: 0.7331424
	speed: 0.0083s/iter; left time: 7.0509s
Epoch: 6 cost time: 1.7849469184875488
Epoch: 6, Steps: 210 | Train Loss: 0.7079018 Vali Loss: 0.8227447 Test Loss: 0.7859092
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6850987076759338, mae:0.6652830243110657
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8957720
	speed: 0.0156s/iter; left time: 30.5050s
	iters: 200, epoch: 1 | loss: 0.8598629
	speed: 0.0116s/iter; left time: 21.6432s
Epoch: 1 cost time: 2.433324098587036
Epoch: 1, Steps: 206 | Train Loss: 0.8791969 Vali Loss: 0.7912937 Test Loss: 0.7471451
Validation loss decreased (inf --> 0.791294).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8067120
	speed: 0.0083s/iter; left time: 14.6535s
	iters: 200, epoch: 2 | loss: 0.8117230
	speed: 0.0075s/iter; left time: 12.4164s
Epoch: 2 cost time: 1.5935208797454834
Epoch: 2, Steps: 206 | Train Loss: 0.8070445 Vali Loss: 0.7992414 Test Loss: 0.8076265
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7439561
	speed: 0.0072s/iter; left time: 11.2185s
	iters: 200, epoch: 3 | loss: 0.7023454
	speed: 0.0066s/iter; left time: 9.5930s
Epoch: 3 cost time: 1.4279072284698486
Epoch: 3, Steps: 206 | Train Loss: 0.7633933 Vali Loss: 0.8224584 Test Loss: 0.8591534
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7314249
	speed: 0.0092s/iter; left time: 12.3541s
	iters: 200, epoch: 4 | loss: 0.6823357
	speed: 0.0085s/iter; left time: 10.5077s
Epoch: 4 cost time: 1.7931630611419678
Epoch: 4, Steps: 206 | Train Loss: 0.7415056 Vali Loss: 0.8183389 Test Loss: 0.8786733
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7326429
	speed: 0.0088s/iter; left time: 10.0231s
	iters: 200, epoch: 5 | loss: 0.7472590
	speed: 0.0083s/iter; left time: 8.5554s
Epoch: 5 cost time: 1.7538824081420898
Epoch: 5, Steps: 206 | Train Loss: 0.7335641 Vali Loss: 0.8145011 Test Loss: 0.8815663
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7386414
	speed: 0.0077s/iter; left time: 7.2144s
	iters: 200, epoch: 6 | loss: 0.7109051
	speed: 0.0073s/iter; left time: 6.0897s
Epoch: 6 cost time: 1.571681022644043
Epoch: 6, Steps: 206 | Train Loss: 0.7277368 Vali Loss: 0.8251675 Test Loss: 0.8755738
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7471451163291931, mae:0.6944025754928589
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8631026
	speed: 0.0083s/iter; left time: 16.3426s
	iters: 200, epoch: 1 | loss: 0.9142367
	speed: 0.0080s/iter; left time: 14.8334s
Epoch: 1 cost time: 1.6936373710632324
Epoch: 1, Steps: 206 | Train Loss: 0.8848277 Vali Loss: 0.7775602 Test Loss: 0.7494254
Validation loss decreased (inf --> 0.777560).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8088735
	speed: 0.0079s/iter; left time: 13.8188s
	iters: 200, epoch: 2 | loss: 0.8026038
	speed: 0.0069s/iter; left time: 11.4525s
Epoch: 2 cost time: 1.494215726852417
Epoch: 2, Steps: 206 | Train Loss: 0.8129715 Vali Loss: 0.8008417 Test Loss: 0.7969052
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7838783
	speed: 0.0087s/iter; left time: 13.4167s
	iters: 200, epoch: 3 | loss: 0.7623350
	speed: 0.0082s/iter; left time: 11.8177s
Epoch: 3 cost time: 1.733719825744629
Epoch: 3, Steps: 206 | Train Loss: 0.7649835 Vali Loss: 0.7898005 Test Loss: 0.8461679
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7298083
	speed: 0.0092s/iter; left time: 12.4073s
	iters: 200, epoch: 4 | loss: 0.7311943
	speed: 0.0085s/iter; left time: 10.5107s
Epoch: 4 cost time: 1.793515682220459
Epoch: 4, Steps: 206 | Train Loss: 0.7413149 Vali Loss: 0.8352636 Test Loss: 0.8469484
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7684392
	speed: 0.0072s/iter; left time: 8.1552s
	iters: 200, epoch: 5 | loss: 0.7515863
	speed: 0.0066s/iter; left time: 6.8246s
Epoch: 5 cost time: 1.4163246154785156
Epoch: 5, Steps: 206 | Train Loss: 0.7300000 Vali Loss: 0.8227611 Test Loss: 0.8497369
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7338201
	speed: 0.0073s/iter; left time: 6.8052s
	iters: 200, epoch: 6 | loss: 0.7034649
	speed: 0.0066s/iter; left time: 5.5125s
Epoch: 6 cost time: 1.4155092239379883
Epoch: 6, Steps: 206 | Train Loss: 0.7227172 Vali Loss: 0.8333144 Test Loss: 0.8413659
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7494254112243652, mae:0.6955344080924988
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8732612
	speed: 0.0090s/iter; left time: 17.6597s
	iters: 200, epoch: 1 | loss: 0.8024283
	speed: 0.0084s/iter; left time: 15.5402s
Epoch: 1 cost time: 1.7678675651550293
Epoch: 1, Steps: 206 | Train Loss: 0.8822391 Vali Loss: 0.7668478 Test Loss: 0.7468787
Validation loss decreased (inf --> 0.766848).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8801880
	speed: 0.0085s/iter; left time: 14.9362s
	iters: 200, epoch: 2 | loss: 0.7645018
	speed: 0.0075s/iter; left time: 12.4533s
Epoch: 2 cost time: 1.603363037109375
Epoch: 2, Steps: 206 | Train Loss: 0.8162577 Vali Loss: 0.7944995 Test Loss: 0.7687284
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7410205
	speed: 0.0077s/iter; left time: 11.8723s
	iters: 200, epoch: 3 | loss: 0.7228134
	speed: 0.0070s/iter; left time: 10.2070s
Epoch: 3 cost time: 1.5167911052703857
Epoch: 3, Steps: 206 | Train Loss: 0.7667702 Vali Loss: 0.7969155 Test Loss: 0.7899783
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6980143
	speed: 0.0070s/iter; left time: 9.3895s
	iters: 200, epoch: 4 | loss: 0.7598996
	speed: 0.0061s/iter; left time: 7.6274s
Epoch: 4 cost time: 1.3146920204162598
Epoch: 4, Steps: 206 | Train Loss: 0.7444374 Vali Loss: 0.8299893 Test Loss: 0.7894948
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7838226
	speed: 0.0076s/iter; left time: 8.6113s
	iters: 200, epoch: 5 | loss: 0.7047136
	speed: 0.0070s/iter; left time: 7.2990s
Epoch: 5 cost time: 1.4997122287750244
Epoch: 5, Steps: 206 | Train Loss: 0.7320952 Vali Loss: 0.8207788 Test Loss: 0.8115306
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7270454
	speed: 0.0073s/iter; left time: 6.7932s
	iters: 200, epoch: 6 | loss: 0.7089040
	speed: 0.0069s/iter; left time: 5.7605s
Epoch: 6 cost time: 1.4871799945831299
Epoch: 6, Steps: 206 | Train Loss: 0.7268953 Vali Loss: 0.8142844 Test Loss: 0.8148828
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7468787431716919, mae:0.6950100660324097
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9332873
	speed: 0.0157s/iter; left time: 28.9689s
Epoch: 1 cost time: 2.194256067276001
Epoch: 1, Steps: 194 | Train Loss: 0.9547248 Vali Loss: 0.7342489 Test Loss: 0.8360533
Validation loss decreased (inf --> 0.734249).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9008835
	speed: 0.0093s/iter; left time: 15.2544s
Epoch: 2 cost time: 1.7318804264068604
Epoch: 2, Steps: 194 | Train Loss: 0.9070843 Vali Loss: 0.7178859 Test Loss: 0.8319333
Validation loss decreased (0.734249 --> 0.717886).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9019199
	speed: 0.0079s/iter; left time: 11.5279s
Epoch: 3 cost time: 1.4261581897735596
Epoch: 3, Steps: 194 | Train Loss: 0.8742638 Vali Loss: 0.7253582 Test Loss: 0.8555452
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8606461
	speed: 0.0094s/iter; left time: 11.8404s
Epoch: 4 cost time: 1.7776079177856445
Epoch: 4, Steps: 194 | Train Loss: 0.8489538 Vali Loss: 0.7175631 Test Loss: 0.9000906
Validation loss decreased (0.717886 --> 0.717563).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8623391
	speed: 0.0095s/iter; left time: 10.1648s
Epoch: 5 cost time: 1.7106091976165771
Epoch: 5, Steps: 194 | Train Loss: 0.8342340 Vali Loss: 0.7334418 Test Loss: 0.9118788
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8172442
	speed: 0.0096s/iter; left time: 8.3260s
Epoch: 6 cost time: 1.755979061126709
Epoch: 6, Steps: 194 | Train Loss: 0.8263780 Vali Loss: 0.7302310 Test Loss: 0.9123355
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8367825
	speed: 0.0076s/iter; left time: 5.1766s
Epoch: 7 cost time: 1.392317295074463
Epoch: 7, Steps: 194 | Train Loss: 0.8243816 Vali Loss: 0.7366866 Test Loss: 0.9118959
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7645261
	speed: 0.0095s/iter; left time: 4.5771s
Epoch: 8 cost time: 1.7437732219696045
Epoch: 8, Steps: 194 | Train Loss: 0.8219344 Vali Loss: 0.7372188 Test Loss: 0.9129146
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8043751
	speed: 0.0095s/iter; left time: 2.7497s
Epoch: 9 cost time: 1.750732421875
Epoch: 9, Steps: 194 | Train Loss: 0.8216398 Vali Loss: 0.7362468 Test Loss: 0.9120198
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9000906944274902, mae:0.7630492448806763
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9235506
	speed: 0.0084s/iter; left time: 15.5019s
Epoch: 1 cost time: 1.5490899085998535
Epoch: 1, Steps: 194 | Train Loss: 0.9564184 Vali Loss: 0.7377432 Test Loss: 0.8422304
Validation loss decreased (inf --> 0.737743).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9331419
	speed: 0.0082s/iter; left time: 13.4851s
Epoch: 2 cost time: 1.605241298675537
Epoch: 2, Steps: 194 | Train Loss: 0.9022850 Vali Loss: 0.7279952 Test Loss: 0.8605230
Validation loss decreased (0.737743 --> 0.727995).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8325868
	speed: 0.0091s/iter; left time: 13.2430s
Epoch: 3 cost time: 1.6077759265899658
Epoch: 3, Steps: 194 | Train Loss: 0.8649902 Vali Loss: 0.7291287 Test Loss: 0.9111492
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8595349
	speed: 0.0085s/iter; left time: 10.6422s
Epoch: 4 cost time: 1.5804550647735596
Epoch: 4, Steps: 194 | Train Loss: 0.8344283 Vali Loss: 0.7375562 Test Loss: 0.8979154
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8170224
	speed: 0.0083s/iter; left time: 8.8621s
Epoch: 5 cost time: 1.5170392990112305
Epoch: 5, Steps: 194 | Train Loss: 0.8196736 Vali Loss: 0.7632477 Test Loss: 0.8964688
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7878849
	speed: 0.0077s/iter; left time: 6.6986s
Epoch: 6 cost time: 1.405588150024414
Epoch: 6, Steps: 194 | Train Loss: 0.8134122 Vali Loss: 0.7578012 Test Loss: 0.9117998
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8361467
	speed: 0.0094s/iter; left time: 6.3340s
Epoch: 7 cost time: 1.577805519104004
Epoch: 7, Steps: 194 | Train Loss: 0.8096729 Vali Loss: 0.7662000 Test Loss: 0.9270097
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8605229258537292, mae:0.7462947964668274
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9829338
	speed: 0.0096s/iter; left time: 17.5830s
Epoch: 1 cost time: 1.758275032043457
Epoch: 1, Steps: 194 | Train Loss: 0.9603845 Vali Loss: 0.7396192 Test Loss: 0.8324205
Validation loss decreased (inf --> 0.739619).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8845144
	speed: 0.0085s/iter; left time: 14.0088s
Epoch: 2 cost time: 1.5381033420562744
Epoch: 2, Steps: 194 | Train Loss: 0.9154075 Vali Loss: 0.7018146 Test Loss: 0.8059397
Validation loss decreased (0.739619 --> 0.701815).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8704151
	speed: 0.0095s/iter; left time: 13.7417s
Epoch: 3 cost time: 1.7350263595581055
Epoch: 3, Steps: 194 | Train Loss: 0.8984867 Vali Loss: 0.7092229 Test Loss: 0.8441259
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9287498
	speed: 0.0077s/iter; left time: 9.7267s
Epoch: 4 cost time: 1.398061752319336
Epoch: 4, Steps: 194 | Train Loss: 0.8868760 Vali Loss: 0.7069914 Test Loss: 0.8362231
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8712104
	speed: 0.0094s/iter; left time: 9.9994s
Epoch: 5 cost time: 1.7267467975616455
Epoch: 5, Steps: 194 | Train Loss: 0.8776953 Vali Loss: 0.7096603 Test Loss: 0.8460844
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8677714
	speed: 0.0093s/iter; left time: 8.0985s
Epoch: 6 cost time: 1.713538646697998
Epoch: 6, Steps: 194 | Train Loss: 0.8730285 Vali Loss: 0.7150295 Test Loss: 0.8452709
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8932792
	speed: 0.0086s/iter; left time: 5.8171s
Epoch: 7 cost time: 1.6576707363128662
Epoch: 7, Steps: 194 | Train Loss: 0.8704234 Vali Loss: 0.7147806 Test Loss: 0.8509213
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8059397339820862, mae:0.7217015027999878
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7382290
	speed: 0.0144s/iter; left time: 29.3339s
	iters: 200, epoch: 1 | loss: 0.6837444
	speed: 0.0100s/iter; left time: 19.2931s
Epoch: 1 cost time: 2.1072018146514893
Epoch: 1, Steps: 213 | Train Loss: 0.7506250 Vali Loss: 0.6995127 Test Loss: 0.6413675
Validation loss decreased (inf --> 0.699513).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7004111
	speed: 0.0094s/iter; left time: 17.0277s
	iters: 200, epoch: 2 | loss: 0.6704449
	speed: 0.0085s/iter; left time: 14.6108s
Epoch: 2 cost time: 1.8649499416351318
Epoch: 2, Steps: 213 | Train Loss: 0.6831006 Vali Loss: 0.6953344 Test Loss: 0.6516343
Validation loss decreased (0.699513 --> 0.695334).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6208235
	speed: 0.0089s/iter; left time: 14.3288s
	iters: 200, epoch: 3 | loss: 0.6808019
	speed: 0.0083s/iter; left time: 12.4593s
Epoch: 3 cost time: 1.8268523216247559
Epoch: 3, Steps: 213 | Train Loss: 0.6662319 Vali Loss: 0.7287445 Test Loss: 0.6656389
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6494204
	speed: 0.0092s/iter; left time: 12.7604s
	iters: 200, epoch: 4 | loss: 0.6548445
	speed: 0.0084s/iter; left time: 10.8439s
Epoch: 4 cost time: 1.837285041809082
Epoch: 4, Steps: 213 | Train Loss: 0.6563880 Vali Loss: 0.7239137 Test Loss: 0.6758793
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6737624
	speed: 0.0081s/iter; left time: 9.4922s
	iters: 200, epoch: 5 | loss: 0.6258492
	speed: 0.0071s/iter; left time: 7.6140s
Epoch: 5 cost time: 1.5372405052185059
Epoch: 5, Steps: 213 | Train Loss: 0.6499830 Vali Loss: 0.7305923 Test Loss: 0.6780055
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6484746
	speed: 0.0087s/iter; left time: 8.4266s
	iters: 200, epoch: 6 | loss: 0.6304111
	speed: 0.0081s/iter; left time: 7.0431s
Epoch: 6 cost time: 1.7863914966583252
Epoch: 6, Steps: 213 | Train Loss: 0.6467893 Vali Loss: 0.7310338 Test Loss: 0.6810578
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6382804
	speed: 0.0091s/iter; left time: 6.8600s
	iters: 200, epoch: 7 | loss: 0.6581322
	speed: 0.0084s/iter; left time: 5.4732s
Epoch: 7 cost time: 1.8330047130584717
Epoch: 7, Steps: 213 | Train Loss: 0.6452838 Vali Loss: 0.7464824 Test Loss: 0.6840142
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6516344547271729, mae:0.648037314414978
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7001172
	speed: 0.0094s/iter; left time: 19.0036s
	iters: 200, epoch: 1 | loss: 0.7108611
	speed: 0.0085s/iter; left time: 16.3382s
Epoch: 1 cost time: 1.844313144683838
Epoch: 1, Steps: 213 | Train Loss: 0.7492230 Vali Loss: 0.6926988 Test Loss: 0.6396562
Validation loss decreased (inf --> 0.692699).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6981012
	speed: 0.0095s/iter; left time: 17.1992s
	iters: 200, epoch: 2 | loss: 0.6717535
	speed: 0.0085s/iter; left time: 14.6388s
Epoch: 2 cost time: 1.8663451671600342
Epoch: 2, Steps: 213 | Train Loss: 0.6840579 Vali Loss: 0.7319297 Test Loss: 0.6543583
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6823168
	speed: 0.0092s/iter; left time: 14.7906s
	iters: 200, epoch: 3 | loss: 0.6832455
	speed: 0.0084s/iter; left time: 12.6529s
Epoch: 3 cost time: 1.843719482421875
Epoch: 3, Steps: 213 | Train Loss: 0.6648434 Vali Loss: 0.7223499 Test Loss: 0.6579292
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6686932
	speed: 0.0093s/iter; left time: 12.9110s
	iters: 200, epoch: 4 | loss: 0.6907520
	speed: 0.0085s/iter; left time: 10.9252s
Epoch: 4 cost time: 1.854773759841919
Epoch: 4, Steps: 213 | Train Loss: 0.6534331 Vali Loss: 0.7301174 Test Loss: 0.6760067
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6418616
	speed: 0.0092s/iter; left time: 10.8227s
	iters: 200, epoch: 5 | loss: 0.6200049
	speed: 0.0085s/iter; left time: 9.1812s
Epoch: 5 cost time: 1.8758230209350586
Epoch: 5, Steps: 213 | Train Loss: 0.6467867 Vali Loss: 0.7274998 Test Loss: 0.6809613
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6279899
	speed: 0.0092s/iter; left time: 8.8558s
	iters: 200, epoch: 6 | loss: 0.6263985
	speed: 0.0084s/iter; left time: 7.2416s
Epoch: 6 cost time: 1.8259074687957764
Epoch: 6, Steps: 213 | Train Loss: 0.6413874 Vali Loss: 0.7348392 Test Loss: 0.6868269
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6396563053131104, mae:0.6420871019363403
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6998958
	speed: 0.0095s/iter; left time: 19.1984s
	iters: 200, epoch: 1 | loss: 0.6654633
	speed: 0.0085s/iter; left time: 16.4176s
Epoch: 1 cost time: 1.8592493534088135
Epoch: 1, Steps: 213 | Train Loss: 0.7493333 Vali Loss: 0.6545150 Test Loss: 0.6377668
Validation loss decreased (inf --> 0.654515).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6504058
	speed: 0.0094s/iter; left time: 17.1145s
	iters: 200, epoch: 2 | loss: 0.6579529
	speed: 0.0085s/iter; left time: 14.6721s
Epoch: 2 cost time: 1.8618111610412598
Epoch: 2, Steps: 213 | Train Loss: 0.6849865 Vali Loss: 0.6862921 Test Loss: 0.6480653
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6789588
	speed: 0.0092s/iter; left time: 14.7792s
	iters: 200, epoch: 3 | loss: 0.6651270
	speed: 0.0081s/iter; left time: 12.1696s
Epoch: 3 cost time: 1.7595112323760986
Epoch: 3, Steps: 213 | Train Loss: 0.6659766 Vali Loss: 0.7230971 Test Loss: 0.6569994
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6226401
	speed: 0.0091s/iter; left time: 12.6766s
	iters: 200, epoch: 4 | loss: 0.6388975
	speed: 0.0083s/iter; left time: 10.7296s
Epoch: 4 cost time: 1.8163681030273438
Epoch: 4, Steps: 213 | Train Loss: 0.6550504 Vali Loss: 0.7193900 Test Loss: 0.6706346
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6677907
	speed: 0.0092s/iter; left time: 10.8536s
	iters: 200, epoch: 5 | loss: 0.6059687
	speed: 0.0084s/iter; left time: 9.0581s
Epoch: 5 cost time: 1.8352077007293701
Epoch: 5, Steps: 213 | Train Loss: 0.6485092 Vali Loss: 0.7217177 Test Loss: 0.6751953
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6666894
	speed: 0.0086s/iter; left time: 8.3492s
	iters: 200, epoch: 6 | loss: 0.6449029
	speed: 0.0081s/iter; left time: 7.0115s
Epoch: 6 cost time: 1.7847175598144531
Epoch: 6, Steps: 213 | Train Loss: 0.6454829 Vali Loss: 0.7143251 Test Loss: 0.6774929
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.63776695728302, mae:0.6416855454444885
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8467574
	speed: 0.0165s/iter; left time: 32.9413s
	iters: 200, epoch: 1 | loss: 0.8046880
	speed: 0.0111s/iter; left time: 21.0280s
Epoch: 1 cost time: 2.3017542362213135
Epoch: 1, Steps: 210 | Train Loss: 0.8239839 Vali Loss: 0.7796289 Test Loss: 0.6889502
Validation loss decreased (inf --> 0.779629).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7298303
	speed: 0.0066s/iter; left time: 11.7850s
	iters: 200, epoch: 2 | loss: 0.7691833
	speed: 0.0059s/iter; left time: 9.9958s
Epoch: 2 cost time: 1.2772471904754639
Epoch: 2, Steps: 210 | Train Loss: 0.7627886 Vali Loss: 0.7750143 Test Loss: 0.6965775
Validation loss decreased (0.779629 --> 0.775014).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7277572
	speed: 0.0070s/iter; left time: 11.0556s
	iters: 200, epoch: 3 | loss: 0.7370853
	speed: 0.0062s/iter; left time: 9.1613s
Epoch: 3 cost time: 1.3406062126159668
Epoch: 3, Steps: 210 | Train Loss: 0.7362728 Vali Loss: 0.7920513 Test Loss: 0.7404517
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7118737
	speed: 0.0064s/iter; left time: 8.7761s
	iters: 200, epoch: 4 | loss: 0.7376760
	speed: 0.0059s/iter; left time: 7.5176s
Epoch: 4 cost time: 1.3000280857086182
Epoch: 4, Steps: 210 | Train Loss: 0.7210322 Vali Loss: 0.8329669 Test Loss: 0.7712239
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7517530
	speed: 0.0076s/iter; left time: 8.7988s
	iters: 200, epoch: 5 | loss: 0.7066348
	speed: 0.0070s/iter; left time: 7.4455s
Epoch: 5 cost time: 1.5155589580535889
Epoch: 5, Steps: 210 | Train Loss: 0.7104411 Vali Loss: 0.8144876 Test Loss: 0.7761586
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7285427
	speed: 0.0081s/iter; left time: 7.7268s
	iters: 200, epoch: 6 | loss: 0.7666032
	speed: 0.0078s/iter; left time: 6.6722s
Epoch: 6 cost time: 1.6948473453521729
Epoch: 6, Steps: 210 | Train Loss: 0.7077922 Vali Loss: 0.8214291 Test Loss: 0.7784523
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7279778
	speed: 0.0076s/iter; left time: 5.6443s
	iters: 200, epoch: 7 | loss: 0.6767356
	speed: 0.0072s/iter; left time: 4.6167s
Epoch: 7 cost time: 1.5575733184814453
Epoch: 7, Steps: 210 | Train Loss: 0.7025963 Vali Loss: 0.8230022 Test Loss: 0.7815340
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6965776681900024, mae:0.6704376935958862
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7736065
	speed: 0.0082s/iter; left time: 16.4210s
	iters: 200, epoch: 1 | loss: 0.8001865
	speed: 0.0073s/iter; left time: 13.9547s
Epoch: 1 cost time: 1.5833251476287842
Epoch: 1, Steps: 210 | Train Loss: 0.8227021 Vali Loss: 0.7538445 Test Loss: 0.6844721
Validation loss decreased (inf --> 0.753844).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7341163
	speed: 0.0079s/iter; left time: 14.1515s
	iters: 200, epoch: 2 | loss: 0.7190161
	speed: 0.0077s/iter; left time: 12.9546s
Epoch: 2 cost time: 1.6596872806549072
Epoch: 2, Steps: 210 | Train Loss: 0.7590833 Vali Loss: 0.7503055 Test Loss: 0.7062882
Validation loss decreased (0.753844 --> 0.750306).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7414536
	speed: 0.0092s/iter; left time: 14.5167s
	iters: 200, epoch: 3 | loss: 0.7849907
	speed: 0.0080s/iter; left time: 11.8921s
Epoch: 3 cost time: 1.73874831199646
Epoch: 3, Steps: 210 | Train Loss: 0.7371632 Vali Loss: 0.7709996 Test Loss: 0.7525176
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7347550
	speed: 0.0080s/iter; left time: 10.9193s
	iters: 200, epoch: 4 | loss: 0.7202731
	speed: 0.0069s/iter; left time: 8.8107s
Epoch: 4 cost time: 1.493006944656372
Epoch: 4, Steps: 210 | Train Loss: 0.7200679 Vali Loss: 0.8020157 Test Loss: 0.7902346
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7002887
	speed: 0.0084s/iter; left time: 9.7538s
	iters: 200, epoch: 5 | loss: 0.6795037
	speed: 0.0071s/iter; left time: 7.5762s
Epoch: 5 cost time: 1.5384783744812012
Epoch: 5, Steps: 210 | Train Loss: 0.7077370 Vali Loss: 0.8152805 Test Loss: 0.7936255
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6512504
	speed: 0.0091s/iter; left time: 8.6971s
	iters: 200, epoch: 6 | loss: 0.7134725
	speed: 0.0078s/iter; left time: 6.6609s
Epoch: 6 cost time: 1.7009034156799316
Epoch: 6, Steps: 210 | Train Loss: 0.7018428 Vali Loss: 0.8290185 Test Loss: 0.8121255
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6673345
	speed: 0.0075s/iter; left time: 5.5762s
	iters: 200, epoch: 7 | loss: 0.6553788
	speed: 0.0067s/iter; left time: 4.3075s
Epoch: 7 cost time: 1.4601411819458008
Epoch: 7, Steps: 210 | Train Loss: 0.6987392 Vali Loss: 0.8315907 Test Loss: 0.8127825
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.70628821849823, mae:0.6755031943321228
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7991128
	speed: 0.0091s/iter; left time: 18.1220s
	iters: 200, epoch: 1 | loss: 0.7603825
	speed: 0.0077s/iter; left time: 14.7227s
Epoch: 1 cost time: 1.669938325881958
Epoch: 1, Steps: 210 | Train Loss: 0.8237067 Vali Loss: 0.7591035 Test Loss: 0.6872608
Validation loss decreased (inf --> 0.759104).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7439691
	speed: 0.0078s/iter; left time: 13.9655s
	iters: 200, epoch: 2 | loss: 0.7256449
	speed: 0.0069s/iter; left time: 11.6363s
Epoch: 2 cost time: 1.4933054447174072
Epoch: 2, Steps: 210 | Train Loss: 0.7644899 Vali Loss: 0.7586555 Test Loss: 0.6989018
Validation loss decreased (0.759104 --> 0.758656).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7305030
	speed: 0.0081s/iter; left time: 12.8814s
	iters: 200, epoch: 3 | loss: 0.8127917
	speed: 0.0073s/iter; left time: 10.8518s
Epoch: 3 cost time: 1.594245195388794
Epoch: 3, Steps: 210 | Train Loss: 0.7409182 Vali Loss: 0.7765388 Test Loss: 0.7162264
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6930603
	speed: 0.0073s/iter; left time: 9.9474s
	iters: 200, epoch: 4 | loss: 0.7605593
	speed: 0.0064s/iter; left time: 8.1410s
Epoch: 4 cost time: 1.3917901515960693
Epoch: 4, Steps: 210 | Train Loss: 0.7225446 Vali Loss: 0.8524314 Test Loss: 0.7720445
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7420483
	speed: 0.0086s/iter; left time: 10.0286s
	iters: 200, epoch: 5 | loss: 0.7272166
	speed: 0.0081s/iter; left time: 8.5790s
Epoch: 5 cost time: 1.7564184665679932
Epoch: 5, Steps: 210 | Train Loss: 0.7136971 Vali Loss: 0.8138773 Test Loss: 0.7581462
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7419056
	speed: 0.0080s/iter; left time: 7.6029s
	iters: 200, epoch: 6 | loss: 0.7060393
	speed: 0.0073s/iter; left time: 6.1761s
Epoch: 6 cost time: 1.5743732452392578
Epoch: 6, Steps: 210 | Train Loss: 0.7089136 Vali Loss: 0.8266186 Test Loss: 0.7612251
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6988117
	speed: 0.0072s/iter; left time: 5.3070s
	iters: 200, epoch: 7 | loss: 0.7363037
	speed: 0.0068s/iter; left time: 4.3540s
Epoch: 7 cost time: 1.4908127784729004
Epoch: 7, Steps: 210 | Train Loss: 0.7071853 Vali Loss: 0.8312883 Test Loss: 0.7703478
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6989016532897949, mae:0.6728125214576721
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8124951
	speed: 0.0112s/iter; left time: 22.0497s
	iters: 200, epoch: 1 | loss: 0.8088287
	speed: 0.0080s/iter; left time: 14.8358s
Epoch: 1 cost time: 1.6652686595916748
Epoch: 1, Steps: 206 | Train Loss: 0.8825328 Vali Loss: 0.7954176 Test Loss: 0.7513233
Validation loss decreased (inf --> 0.795418).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8228866
	speed: 0.0079s/iter; left time: 13.8124s
	iters: 200, epoch: 2 | loss: 0.7870700
	speed: 0.0072s/iter; left time: 11.9137s
Epoch: 2 cost time: 1.531916618347168
Epoch: 2, Steps: 206 | Train Loss: 0.8097668 Vali Loss: 0.7792376 Test Loss: 0.7949328
Validation loss decreased (0.795418 --> 0.779238).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7700002
	speed: 0.0080s/iter; left time: 12.3723s
	iters: 200, epoch: 3 | loss: 0.7658690
	speed: 0.0078s/iter; left time: 11.3064s
Epoch: 3 cost time: 1.6634669303894043
Epoch: 3, Steps: 206 | Train Loss: 0.7615029 Vali Loss: 0.8160467 Test Loss: 0.8329570
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7148536
	speed: 0.0068s/iter; left time: 9.1336s
	iters: 200, epoch: 4 | loss: 0.7029948
	speed: 0.0065s/iter; left time: 8.0736s
Epoch: 4 cost time: 1.3988029956817627
Epoch: 4, Steps: 206 | Train Loss: 0.7382825 Vali Loss: 0.8081270 Test Loss: 0.8258581
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7403345
	speed: 0.0069s/iter; left time: 7.7909s
	iters: 200, epoch: 5 | loss: 0.7324609
	speed: 0.0063s/iter; left time: 6.5456s
Epoch: 5 cost time: 1.346515417098999
Epoch: 5, Steps: 206 | Train Loss: 0.7257835 Vali Loss: 0.7938839 Test Loss: 0.8380738
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6838440
	speed: 0.0091s/iter; left time: 8.4443s
	iters: 200, epoch: 6 | loss: 0.7139240
	speed: 0.0084s/iter; left time: 6.9461s
Epoch: 6 cost time: 1.765953540802002
Epoch: 6, Steps: 206 | Train Loss: 0.7204652 Vali Loss: 0.8011009 Test Loss: 0.8470017
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7057943
	speed: 0.0072s/iter; left time: 5.2329s
	iters: 200, epoch: 7 | loss: 0.7212688
	speed: 0.0063s/iter; left time: 3.9339s
Epoch: 7 cost time: 1.3364930152893066
Epoch: 7, Steps: 206 | Train Loss: 0.7168417 Vali Loss: 0.7961745 Test Loss: 0.8475536
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7949329018592834, mae:0.7161930203437805
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8786173
	speed: 0.0073s/iter; left time: 14.3949s
	iters: 200, epoch: 1 | loss: 0.9177237
	speed: 0.0061s/iter; left time: 11.3969s
Epoch: 1 cost time: 1.3152906894683838
Epoch: 1, Steps: 206 | Train Loss: 0.8836248 Vali Loss: 0.7621819 Test Loss: 0.7341822
Validation loss decreased (inf --> 0.762182).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7911168
	speed: 0.0088s/iter; left time: 15.5109s
	iters: 200, epoch: 2 | loss: 0.7961071
	speed: 0.0082s/iter; left time: 13.5718s
Epoch: 2 cost time: 1.7442536354064941
Epoch: 2, Steps: 206 | Train Loss: 0.8176626 Vali Loss: 0.7915123 Test Loss: 0.7797136
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8027616
	speed: 0.0090s/iter; left time: 13.9087s
	iters: 200, epoch: 3 | loss: 0.7124323
	speed: 0.0083s/iter; left time: 11.9906s
Epoch: 3 cost time: 1.7598249912261963
Epoch: 3, Steps: 206 | Train Loss: 0.7729296 Vali Loss: 0.7969879 Test Loss: 0.8102719
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7397557
	speed: 0.0076s/iter; left time: 10.1560s
	iters: 200, epoch: 4 | loss: 0.7229404
	speed: 0.0070s/iter; left time: 8.7251s
Epoch: 4 cost time: 1.4956061840057373
Epoch: 4, Steps: 206 | Train Loss: 0.7466817 Vali Loss: 0.8027127 Test Loss: 0.8261755
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7539468
	speed: 0.0070s/iter; left time: 7.9380s
	iters: 200, epoch: 5 | loss: 0.7265362
	speed: 0.0064s/iter; left time: 6.6472s
Epoch: 5 cost time: 1.3689460754394531
Epoch: 5, Steps: 206 | Train Loss: 0.7367344 Vali Loss: 0.8304443 Test Loss: 0.8366374
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7126233
	speed: 0.0077s/iter; left time: 7.1685s
	iters: 200, epoch: 6 | loss: 0.7537636
	speed: 0.0072s/iter; left time: 6.0119s
Epoch: 6 cost time: 1.5478508472442627
Epoch: 6, Steps: 206 | Train Loss: 0.7292497 Vali Loss: 0.8246205 Test Loss: 0.8394218
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7341822385787964, mae:0.6883963346481323
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8442067
	speed: 0.0068s/iter; left time: 13.3462s
	iters: 200, epoch: 1 | loss: 0.8293788
	speed: 0.0066s/iter; left time: 12.3750s
Epoch: 1 cost time: 1.4167282581329346
Epoch: 1, Steps: 206 | Train Loss: 0.8853992 Vali Loss: 0.7683586 Test Loss: 0.7548527
Validation loss decreased (inf --> 0.768359).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8385007
	speed: 0.0079s/iter; left time: 13.7935s
	iters: 200, epoch: 2 | loss: 0.8349621
	speed: 0.0070s/iter; left time: 11.5863s
Epoch: 2 cost time: 1.4904074668884277
Epoch: 2, Steps: 206 | Train Loss: 0.8221803 Vali Loss: 0.8287936 Test Loss: 0.7849879
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7981028
	speed: 0.0074s/iter; left time: 11.5266s
	iters: 200, epoch: 3 | loss: 0.7807964
	speed: 0.0067s/iter; left time: 9.6570s
Epoch: 3 cost time: 1.4253716468811035
Epoch: 3, Steps: 206 | Train Loss: 0.7846158 Vali Loss: 0.8508874 Test Loss: 0.8341939
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7837340
	speed: 0.0092s/iter; left time: 12.3051s
	iters: 200, epoch: 4 | loss: 0.7531400
	speed: 0.0084s/iter; left time: 10.4099s
Epoch: 4 cost time: 1.7803268432617188
Epoch: 4, Steps: 206 | Train Loss: 0.7583217 Vali Loss: 0.8932754 Test Loss: 0.8588989
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7657520
	speed: 0.0074s/iter; left time: 8.4275s
	iters: 200, epoch: 5 | loss: 0.7953569
	speed: 0.0075s/iter; left time: 7.7447s
Epoch: 5 cost time: 1.5963022708892822
Epoch: 5, Steps: 206 | Train Loss: 0.7494957 Vali Loss: 0.9039770 Test Loss: 0.8552478
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7197285
	speed: 0.0075s/iter; left time: 6.9367s
	iters: 200, epoch: 6 | loss: 0.7656371
	speed: 0.0067s/iter; left time: 5.5424s
Epoch: 6 cost time: 1.4332983493804932
Epoch: 6, Steps: 206 | Train Loss: 0.7432487 Vali Loss: 0.9038333 Test Loss: 0.8713085
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7548527121543884, mae:0.6979998350143433
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9719067
	speed: 0.0134s/iter; left time: 24.6422s
Epoch: 1 cost time: 2.030853748321533
Epoch: 1, Steps: 194 | Train Loss: 0.9558210 Vali Loss: 0.7482414 Test Loss: 0.8415758
Validation loss decreased (inf --> 0.748241).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8711433
	speed: 0.0067s/iter; left time: 10.9718s
Epoch: 2 cost time: 1.3573315143585205
Epoch: 2, Steps: 194 | Train Loss: 0.9050061 Vali Loss: 0.7362162 Test Loss: 0.8619800
Validation loss decreased (0.748241 --> 0.736216).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8651827
	speed: 0.0070s/iter; left time: 10.1005s
Epoch: 3 cost time: 1.2823247909545898
Epoch: 3, Steps: 194 | Train Loss: 0.8595578 Vali Loss: 0.7485310 Test Loss: 0.9071120
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8800651
	speed: 0.0070s/iter; left time: 8.7639s
Epoch: 4 cost time: 1.2602355480194092
Epoch: 4, Steps: 194 | Train Loss: 0.8221332 Vali Loss: 0.7687424 Test Loss: 0.9107336
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7930951
	speed: 0.0064s/iter; left time: 6.8506s
Epoch: 5 cost time: 1.1704721450805664
Epoch: 5, Steps: 194 | Train Loss: 0.8069998 Vali Loss: 0.7487772 Test Loss: 0.9132006
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7918389
	speed: 0.0082s/iter; left time: 7.1103s
Epoch: 6 cost time: 1.4888243675231934
Epoch: 6, Steps: 194 | Train Loss: 0.8005320 Vali Loss: 0.7466695 Test Loss: 0.9556911
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8065706
	speed: 0.0069s/iter; left time: 4.6518s
Epoch: 7 cost time: 1.1977033615112305
Epoch: 7, Steps: 194 | Train Loss: 0.7960911 Vali Loss: 0.7463433 Test Loss: 0.9400423
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8619799613952637, mae:0.746605396270752
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9188846
	speed: 0.0091s/iter; left time: 16.6814s
Epoch: 1 cost time: 1.6974222660064697
Epoch: 1, Steps: 194 | Train Loss: 0.9551744 Vali Loss: 0.7393414 Test Loss: 0.8340889
Validation loss decreased (inf --> 0.739341).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9191693
	speed: 0.0095s/iter; left time: 15.6790s
Epoch: 2 cost time: 1.7538752555847168
Epoch: 2, Steps: 194 | Train Loss: 0.8970415 Vali Loss: 0.7428378 Test Loss: 0.8472347
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8248391
	speed: 0.0086s/iter; left time: 12.5010s
Epoch: 3 cost time: 1.544039011001587
Epoch: 3, Steps: 194 | Train Loss: 0.8515448 Vali Loss: 0.7391369 Test Loss: 0.8960485
Validation loss decreased (0.739341 --> 0.739137).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8418173
	speed: 0.0080s/iter; left time: 10.0354s
Epoch: 4 cost time: 1.495434045791626
Epoch: 4, Steps: 194 | Train Loss: 0.8221017 Vali Loss: 0.7344792 Test Loss: 0.8931621
Validation loss decreased (0.739137 --> 0.734479).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8041723
	speed: 0.0093s/iter; left time: 9.9477s
Epoch: 5 cost time: 1.7168066501617432
Epoch: 5, Steps: 194 | Train Loss: 0.8081489 Vali Loss: 0.7462109 Test Loss: 0.9350032
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8146968
	speed: 0.0083s/iter; left time: 7.1950s
Epoch: 6 cost time: 1.5711631774902344
Epoch: 6, Steps: 194 | Train Loss: 0.8014312 Vali Loss: 0.7331409 Test Loss: 0.9433448
Validation loss decreased (0.734479 --> 0.733141).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7723862
	speed: 0.0096s/iter; left time: 6.5153s
Epoch: 7 cost time: 1.7462787628173828
Epoch: 7, Steps: 194 | Train Loss: 0.7994496 Vali Loss: 0.7337083 Test Loss: 0.9343790
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7898264
	speed: 0.0095s/iter; left time: 4.5886s
Epoch: 8 cost time: 1.754499912261963
Epoch: 8, Steps: 194 | Train Loss: 0.7969281 Vali Loss: 0.7334099 Test Loss: 0.9349254
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7714524
	speed: 0.0098s/iter; left time: 2.8268s
Epoch: 9 cost time: 1.82188081741333
Epoch: 9, Steps: 194 | Train Loss: 0.7959857 Vali Loss: 0.7331828 Test Loss: 0.9370366
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7981991
	speed: 0.0094s/iter; left time: 0.8945s
Epoch: 10 cost time: 1.7455742359161377
Epoch: 10, Steps: 194 | Train Loss: 0.7957114 Vali Loss: 0.7330772 Test Loss: 0.9355139
Validation loss decreased (0.733141 --> 0.733077).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.935513973236084, mae:0.7788193225860596
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9078435
	speed: 0.0097s/iter; left time: 17.9056s
Epoch: 1 cost time: 1.7806944847106934
Epoch: 1, Steps: 194 | Train Loss: 0.9570123 Vali Loss: 0.7333642 Test Loss: 0.8313177
Validation loss decreased (inf --> 0.733364).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8949051
	speed: 0.0096s/iter; left time: 15.8466s
Epoch: 2 cost time: 1.762824296951294
Epoch: 2, Steps: 194 | Train Loss: 0.9015235 Vali Loss: 0.7344701 Test Loss: 0.8854830
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8677167
	speed: 0.0094s/iter; left time: 13.6199s
Epoch: 3 cost time: 1.734473466873169
Epoch: 3, Steps: 194 | Train Loss: 0.8630505 Vali Loss: 0.7258271 Test Loss: 0.9245965
Validation loss decreased (0.733364 --> 0.725827).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8496584
	speed: 0.0096s/iter; left time: 12.0862s
Epoch: 4 cost time: 1.7643258571624756
Epoch: 4, Steps: 194 | Train Loss: 0.8384730 Vali Loss: 0.7206805 Test Loss: 0.9496622
Validation loss decreased (0.725827 --> 0.720680).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8521748
	speed: 0.0098s/iter; left time: 10.4117s
Epoch: 5 cost time: 1.7832520008087158
Epoch: 5, Steps: 194 | Train Loss: 0.8241909 Vali Loss: 0.7227863 Test Loss: 0.9563409
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7890666
	speed: 0.0094s/iter; left time: 8.2145s
Epoch: 6 cost time: 1.73988676071167
Epoch: 6, Steps: 194 | Train Loss: 0.8176680 Vali Loss: 0.7290438 Test Loss: 0.9618766
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8168011
	speed: 0.0094s/iter; left time: 6.3879s
Epoch: 7 cost time: 1.7483978271484375
Epoch: 7, Steps: 194 | Train Loss: 0.8150484 Vali Loss: 0.7259453 Test Loss: 0.9688364
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8019664
	speed: 0.0095s/iter; left time: 4.5868s
Epoch: 8 cost time: 1.7630209922790527
Epoch: 8, Steps: 194 | Train Loss: 0.8121281 Vali Loss: 0.7248579 Test Loss: 0.9693320
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8234780
	speed: 0.0094s/iter; left time: 2.7278s
Epoch: 9 cost time: 1.770214557647705
Epoch: 9, Steps: 194 | Train Loss: 0.8134293 Vali Loss: 0.7252490 Test Loss: 0.9669571
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9496623277664185, mae:0.7829040884971619
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0208232
	speed: 0.0187s/iter; left time: 38.0194s
	iters: 200, epoch: 1 | loss: 1.0066295
	speed: 0.0133s/iter; left time: 25.6195s
Epoch: 1 cost time: 2.818345546722412
Epoch: 1, Steps: 213 | Train Loss: 1.0642763 Vali Loss: 1.0344892 Test Loss: 1.0174836
Validation loss decreased (inf --> 1.034489).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0079948
	speed: 0.0083s/iter; left time: 15.0642s
	iters: 200, epoch: 2 | loss: 0.9883973
	speed: 0.0071s/iter; left time: 12.2403s
Epoch: 2 cost time: 1.5719599723815918
Epoch: 2, Steps: 213 | Train Loss: 1.0092820 Vali Loss: 1.0304013 Test Loss: 1.0169070
Validation loss decreased (1.034489 --> 1.030401).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9959790
	speed: 0.0097s/iter; left time: 15.5024s
	iters: 200, epoch: 3 | loss: 0.9858190
	speed: 0.0086s/iter; left time: 13.0151s
Epoch: 3 cost time: 1.8935410976409912
Epoch: 3, Steps: 213 | Train Loss: 1.0006306 Vali Loss: 1.0283405 Test Loss: 1.0163269
Validation loss decreased (1.030401 --> 1.028340).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0165061
	speed: 0.0094s/iter; left time: 13.0717s
	iters: 200, epoch: 4 | loss: 1.0053548
	speed: 0.0085s/iter; left time: 11.0349s
Epoch: 4 cost time: 1.8707566261291504
Epoch: 4, Steps: 213 | Train Loss: 0.9956051 Vali Loss: 1.0269414 Test Loss: 1.0151817
Validation loss decreased (1.028340 --> 1.026941).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9741794
	speed: 0.0094s/iter; left time: 11.0649s
	iters: 200, epoch: 5 | loss: 0.9907609
	speed: 0.0085s/iter; left time: 9.2049s
Epoch: 5 cost time: 1.8764398097991943
Epoch: 5, Steps: 213 | Train Loss: 0.9930157 Vali Loss: 1.0274432 Test Loss: 1.0160489
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9977889
	speed: 0.0092s/iter; left time: 8.9231s
	iters: 200, epoch: 6 | loss: 0.9720076
	speed: 0.0085s/iter; left time: 7.3245s
Epoch: 6 cost time: 1.8515255451202393
Epoch: 6, Steps: 213 | Train Loss: 0.9906645 Vali Loss: 1.0264940 Test Loss: 1.0157962
Validation loss decreased (1.026941 --> 1.026494).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9739865
	speed: 0.0094s/iter; left time: 7.0629s
	iters: 200, epoch: 7 | loss: 0.9954786
	speed: 0.0085s/iter; left time: 5.5531s
Epoch: 7 cost time: 1.8590123653411865
Epoch: 7, Steps: 213 | Train Loss: 0.9896451 Vali Loss: 1.0270264 Test Loss: 1.0158582
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0454972
	speed: 0.0091s/iter; left time: 4.9401s
	iters: 200, epoch: 8 | loss: 0.9762802
	speed: 0.0084s/iter; left time: 3.6980s
Epoch: 8 cost time: 1.8404242992401123
Epoch: 8, Steps: 213 | Train Loss: 0.9892174 Vali Loss: 1.0266991 Test Loss: 1.0159602
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9827603
	speed: 0.0093s/iter; left time: 3.0337s
	iters: 200, epoch: 9 | loss: 0.9696825
	speed: 0.0085s/iter; left time: 1.9256s
Epoch: 9 cost time: 1.8561303615570068
Epoch: 9, Steps: 213 | Train Loss: 0.9892179 Vali Loss: 1.0286088 Test Loss: 1.0158843
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0023062
	speed: 0.0092s/iter; left time: 1.0475s
	iters: 200, epoch: 10 | loss: 0.9573783
	speed: 0.0084s/iter; left time: 0.1177s
Epoch: 10 cost time: 1.8404505252838135
Epoch: 10, Steps: 213 | Train Loss: 0.9887888 Vali Loss: 1.0272610 Test Loss: 1.0159103
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0157960653305054, mae:0.8085481524467468
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0348930
	speed: 0.0094s/iter; left time: 19.0982s
	iters: 200, epoch: 1 | loss: 1.0260329
	speed: 0.0085s/iter; left time: 16.4122s
Epoch: 1 cost time: 1.86149263381958
Epoch: 1, Steps: 213 | Train Loss: 1.0616493 Vali Loss: 1.0377752 Test Loss: 1.0196297
Validation loss decreased (inf --> 1.037775).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9900588
	speed: 0.0094s/iter; left time: 17.0342s
	iters: 200, epoch: 2 | loss: 1.0431762
	speed: 0.0085s/iter; left time: 14.6103s
Epoch: 2 cost time: 1.8654255867004395
Epoch: 2, Steps: 213 | Train Loss: 1.0096005 Vali Loss: 1.0327953 Test Loss: 1.0188487
Validation loss decreased (1.037775 --> 1.032795).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9938310
	speed: 0.0094s/iter; left time: 15.0864s
	iters: 200, epoch: 3 | loss: 1.0369158
	speed: 0.0085s/iter; left time: 12.8168s
Epoch: 3 cost time: 1.867828607559204
Epoch: 3, Steps: 213 | Train Loss: 1.0008197 Vali Loss: 1.0286694 Test Loss: 1.0148604
Validation loss decreased (1.032795 --> 1.028669).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9907143
	speed: 0.0094s/iter; left time: 13.0513s
	iters: 200, epoch: 4 | loss: 0.9552312
	speed: 0.0085s/iter; left time: 10.9892s
Epoch: 4 cost time: 1.868506669998169
Epoch: 4, Steps: 213 | Train Loss: 0.9956245 Vali Loss: 1.0285814 Test Loss: 1.0154996
Validation loss decreased (1.028669 --> 1.028581).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0099902
	speed: 0.0093s/iter; left time: 11.0195s
	iters: 200, epoch: 5 | loss: 1.0276617
	speed: 0.0085s/iter; left time: 9.1195s
Epoch: 5 cost time: 1.8479344844818115
Epoch: 5, Steps: 213 | Train Loss: 0.9928954 Vali Loss: 1.0265244 Test Loss: 1.0152396
Validation loss decreased (1.028581 --> 1.026524).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0077001
	speed: 0.0094s/iter; left time: 9.0864s
	iters: 200, epoch: 6 | loss: 1.0032305
	speed: 0.0085s/iter; left time: 7.3587s
Epoch: 6 cost time: 1.8600833415985107
Epoch: 6, Steps: 213 | Train Loss: 0.9909320 Vali Loss: 1.0281917 Test Loss: 1.0160309
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9806280
	speed: 0.0092s/iter; left time: 6.8926s
	iters: 200, epoch: 7 | loss: 0.9742030
	speed: 0.0084s/iter; left time: 5.4845s
Epoch: 7 cost time: 1.8480825424194336
Epoch: 7, Steps: 213 | Train Loss: 0.9900199 Vali Loss: 1.0280231 Test Loss: 1.0157347
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9797914
	speed: 0.0093s/iter; left time: 5.0410s
	iters: 200, epoch: 8 | loss: 0.9926276
	speed: 0.0085s/iter; left time: 3.7383s
Epoch: 8 cost time: 1.8604848384857178
Epoch: 8, Steps: 213 | Train Loss: 0.9896824 Vali Loss: 1.0287958 Test Loss: 1.0156653
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9681681
	speed: 0.0092s/iter; left time: 3.0184s
	iters: 200, epoch: 9 | loss: 0.9426696
	speed: 0.0085s/iter; left time: 1.9200s
Epoch: 9 cost time: 1.8664522171020508
Epoch: 9, Steps: 213 | Train Loss: 0.9891898 Vali Loss: 1.0291616 Test Loss: 1.0156419
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9645643
	speed: 0.0094s/iter; left time: 1.0762s
	iters: 200, epoch: 10 | loss: 0.9980825
	speed: 0.0087s/iter; left time: 0.1213s
Epoch: 10 cost time: 1.900022268295288
Epoch: 10, Steps: 213 | Train Loss: 0.9890257 Vali Loss: 1.0279644 Test Loss: 1.0157025
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0152394771575928, mae:0.8082914352416992
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9924523
	speed: 0.0095s/iter; left time: 19.2157s
	iters: 200, epoch: 1 | loss: 1.0156933
	speed: 0.0086s/iter; left time: 16.5733s
Epoch: 1 cost time: 1.8673577308654785
Epoch: 1, Steps: 213 | Train Loss: 1.0623359 Vali Loss: 1.0375024 Test Loss: 1.0174612
Validation loss decreased (inf --> 1.037502).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9843346
	speed: 0.0094s/iter; left time: 17.0323s
	iters: 200, epoch: 2 | loss: 1.0003637
	speed: 0.0085s/iter; left time: 14.6039s
Epoch: 2 cost time: 1.8582966327667236
Epoch: 2, Steps: 213 | Train Loss: 1.0096691 Vali Loss: 1.0328600 Test Loss: 1.0170184
Validation loss decreased (1.037502 --> 1.032860).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0324011
	speed: 0.0088s/iter; left time: 14.1686s
	iters: 200, epoch: 3 | loss: 1.0020549
	speed: 0.0076s/iter; left time: 11.4694s
Epoch: 3 cost time: 1.6689774990081787
Epoch: 3, Steps: 213 | Train Loss: 1.0003993 Vali Loss: 1.0277903 Test Loss: 1.0145935
Validation loss decreased (1.032860 --> 1.027790).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0192536
	speed: 0.0090s/iter; left time: 12.5926s
	iters: 200, epoch: 4 | loss: 1.0142074
	speed: 0.0083s/iter; left time: 10.7750s
Epoch: 4 cost time: 1.8269720077514648
Epoch: 4, Steps: 213 | Train Loss: 0.9954000 Vali Loss: 1.0246503 Test Loss: 1.0141754
Validation loss decreased (1.027790 --> 1.024650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0281447
	speed: 0.0091s/iter; left time: 10.6796s
	iters: 200, epoch: 5 | loss: 0.9493048
	speed: 0.0083s/iter; left time: 9.0061s
Epoch: 5 cost time: 1.8289220333099365
Epoch: 5, Steps: 213 | Train Loss: 0.9923661 Vali Loss: 1.0279238 Test Loss: 1.0150862
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9902449
	speed: 0.0088s/iter; left time: 8.5403s
	iters: 200, epoch: 6 | loss: 0.9745799
	speed: 0.0083s/iter; left time: 7.1538s
Epoch: 6 cost time: 1.8116247653961182
Epoch: 6, Steps: 213 | Train Loss: 0.9905239 Vali Loss: 1.0296911 Test Loss: 1.0149840
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0001502
	speed: 0.0079s/iter; left time: 5.9335s
	iters: 200, epoch: 7 | loss: 1.0346936
	speed: 0.0072s/iter; left time: 4.7052s
Epoch: 7 cost time: 1.5877876281738281
Epoch: 7, Steps: 213 | Train Loss: 0.9902039 Vali Loss: 1.0272781 Test Loss: 1.0149415
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9721695
	speed: 0.0082s/iter; left time: 4.4300s
	iters: 200, epoch: 8 | loss: 0.9938668
	speed: 0.0074s/iter; left time: 3.2574s
Epoch: 8 cost time: 1.6198937892913818
Epoch: 8, Steps: 213 | Train Loss: 0.9892238 Vali Loss: 1.0289245 Test Loss: 1.0151185
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9950212
	speed: 0.0076s/iter; left time: 2.5009s
	iters: 200, epoch: 9 | loss: 1.0045662
	speed: 0.0068s/iter; left time: 1.5477s
Epoch: 9 cost time: 1.4883205890655518
Epoch: 9, Steps: 213 | Train Loss: 0.9893198 Vali Loss: 1.0260350 Test Loss: 1.0151223
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0141756534576416, mae:0.8078493475914001
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0242950
	speed: 0.0170s/iter; left time: 34.0030s
	iters: 200, epoch: 1 | loss: 1.0244355
	speed: 0.0114s/iter; left time: 21.6817s
Epoch: 1 cost time: 2.366563081741333
Epoch: 1, Steps: 210 | Train Loss: 1.0598690 Vali Loss: 1.0285743 Test Loss: 1.0172551
Validation loss decreased (inf --> 1.028574).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9930527
	speed: 0.0071s/iter; left time: 12.7857s
	iters: 200, epoch: 2 | loss: 1.0019201
	speed: 0.0060s/iter; left time: 10.0783s
Epoch: 2 cost time: 1.285994291305542
Epoch: 2, Steps: 210 | Train Loss: 1.0122239 Vali Loss: 1.0239860 Test Loss: 1.0161568
Validation loss decreased (1.028574 --> 1.023986).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0270706
	speed: 0.0079s/iter; left time: 12.4289s
	iters: 200, epoch: 3 | loss: 1.0255630
	speed: 0.0071s/iter; left time: 10.5722s
Epoch: 3 cost time: 1.5497326850891113
Epoch: 3, Steps: 210 | Train Loss: 1.0051414 Vali Loss: 1.0223439 Test Loss: 1.0150090
Validation loss decreased (1.023986 --> 1.022344).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9740230
	speed: 0.0072s/iter; left time: 9.8323s
	iters: 200, epoch: 4 | loss: 1.0170822
	speed: 0.0065s/iter; left time: 8.2604s
Epoch: 4 cost time: 1.4120664596557617
Epoch: 4, Steps: 210 | Train Loss: 1.0010476 Vali Loss: 1.0228931 Test Loss: 1.0147425
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9718987
	speed: 0.0083s/iter; left time: 9.6644s
	iters: 200, epoch: 5 | loss: 1.0093850
	speed: 0.0069s/iter; left time: 7.3281s
Epoch: 5 cost time: 1.4811375141143799
Epoch: 5, Steps: 210 | Train Loss: 0.9987257 Vali Loss: 1.0189153 Test Loss: 1.0140566
Validation loss decreased (1.022344 --> 1.018915).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0018283
	speed: 0.0067s/iter; left time: 6.3906s
	iters: 200, epoch: 6 | loss: 0.9841248
	speed: 0.0061s/iter; left time: 5.1808s
Epoch: 6 cost time: 1.3215217590332031
Epoch: 6, Steps: 210 | Train Loss: 0.9972777 Vali Loss: 1.0194955 Test Loss: 1.0138166
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0194987
	speed: 0.0080s/iter; left time: 5.9280s
	iters: 200, epoch: 7 | loss: 0.9782681
	speed: 0.0077s/iter; left time: 4.9199s
Epoch: 7 cost time: 1.6578071117401123
Epoch: 7, Steps: 210 | Train Loss: 0.9971027 Vali Loss: 1.0177387 Test Loss: 1.0138850
Validation loss decreased (1.018915 --> 1.017739).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9902231
	speed: 0.0078s/iter; left time: 4.1411s
	iters: 200, epoch: 8 | loss: 1.0010936
	speed: 0.0071s/iter; left time: 3.0620s
Epoch: 8 cost time: 1.5365476608276367
Epoch: 8, Steps: 210 | Train Loss: 0.9963113 Vali Loss: 1.0186719 Test Loss: 1.0138528
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0106734
	speed: 0.0080s/iter; left time: 2.5573s
	iters: 200, epoch: 9 | loss: 1.0136206
	speed: 0.0072s/iter; left time: 1.5961s
Epoch: 9 cost time: 1.5692245960235596
Epoch: 9, Steps: 210 | Train Loss: 0.9964854 Vali Loss: 1.0184878 Test Loss: 1.0138744
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0186961
	speed: 0.0069s/iter; left time: 0.7696s
	iters: 200, epoch: 10 | loss: 1.0039974
	speed: 0.0062s/iter; left time: 0.0685s
Epoch: 10 cost time: 1.3485729694366455
Epoch: 10, Steps: 210 | Train Loss: 0.9963191 Vali Loss: 1.0185699 Test Loss: 1.0138954
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0138847827911377, mae:0.8072676062583923
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0473303
	speed: 0.0081s/iter; left time: 16.2010s
	iters: 200, epoch: 1 | loss: 1.0330251
	speed: 0.0073s/iter; left time: 13.9153s
Epoch: 1 cost time: 1.5895545482635498
Epoch: 1, Steps: 210 | Train Loss: 1.0600811 Vali Loss: 1.0249933 Test Loss: 1.0162312
Validation loss decreased (inf --> 1.024993).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9573528
	speed: 0.0093s/iter; left time: 16.6198s
	iters: 200, epoch: 2 | loss: 1.0330343
	speed: 0.0084s/iter; left time: 14.1875s
Epoch: 2 cost time: 1.8091588020324707
Epoch: 2, Steps: 210 | Train Loss: 1.0123780 Vali Loss: 1.0228492 Test Loss: 1.0162824
Validation loss decreased (1.024993 --> 1.022849).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9900941
	speed: 0.0068s/iter; left time: 10.6921s
	iters: 200, epoch: 3 | loss: 1.0023764
	speed: 0.0060s/iter; left time: 8.8426s
Epoch: 3 cost time: 1.303025245666504
Epoch: 3, Steps: 210 | Train Loss: 1.0051935 Vali Loss: 1.0209913 Test Loss: 1.0144944
Validation loss decreased (1.022849 --> 1.020991).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0275013
	speed: 0.0068s/iter; left time: 9.3485s
	iters: 200, epoch: 4 | loss: 1.0053295
	speed: 0.0063s/iter; left time: 8.0045s
Epoch: 4 cost time: 1.366304874420166
Epoch: 4, Steps: 210 | Train Loss: 1.0010564 Vali Loss: 1.0216271 Test Loss: 1.0144582
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9842960
	speed: 0.0085s/iter; left time: 9.9106s
	iters: 200, epoch: 5 | loss: 1.0068204
	speed: 0.0080s/iter; left time: 8.4756s
Epoch: 5 cost time: 1.724177360534668
Epoch: 5, Steps: 210 | Train Loss: 0.9988920 Vali Loss: 1.0191547 Test Loss: 1.0137551
Validation loss decreased (1.020991 --> 1.019155).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9961640
	speed: 0.0090s/iter; left time: 8.5781s
	iters: 200, epoch: 6 | loss: 0.9869589
	speed: 0.0083s/iter; left time: 7.0351s
Epoch: 6 cost time: 1.7866899967193604
Epoch: 6, Steps: 210 | Train Loss: 0.9976147 Vali Loss: 1.0203331 Test Loss: 1.0137712
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9757853
	speed: 0.0065s/iter; left time: 4.7885s
	iters: 200, epoch: 7 | loss: 0.9989461
	speed: 0.0059s/iter; left time: 3.7766s
Epoch: 7 cost time: 1.2815299034118652
Epoch: 7, Steps: 210 | Train Loss: 0.9968910 Vali Loss: 1.0190384 Test Loss: 1.0137507
Validation loss decreased (1.019155 --> 1.019038).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0124141
	speed: 0.0071s/iter; left time: 3.7522s
	iters: 200, epoch: 8 | loss: 0.9996285
	speed: 0.0060s/iter; left time: 2.5937s
Epoch: 8 cost time: 1.3240535259246826
Epoch: 8, Steps: 210 | Train Loss: 0.9967321 Vali Loss: 1.0196221 Test Loss: 1.0138332
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0040007
	speed: 0.0080s/iter; left time: 2.5705s
	iters: 200, epoch: 9 | loss: 0.9783067
	speed: 0.0072s/iter; left time: 1.5894s
Epoch: 9 cost time: 1.5489869117736816
Epoch: 9, Steps: 210 | Train Loss: 0.9961935 Vali Loss: 1.0192196 Test Loss: 1.0138522
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9920756
	speed: 0.0066s/iter; left time: 0.7364s
	iters: 200, epoch: 10 | loss: 0.9908215
	speed: 0.0063s/iter; left time: 0.0688s
Epoch: 10 cost time: 1.3575851917266846
Epoch: 10, Steps: 210 | Train Loss: 0.9964318 Vali Loss: 1.0191238 Test Loss: 1.0138384
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0137505531311035, mae:0.8072739839553833
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0177305
	speed: 0.0092s/iter; left time: 18.4645s
	iters: 200, epoch: 1 | loss: 1.0287673
	speed: 0.0079s/iter; left time: 15.0745s
Epoch: 1 cost time: 1.7064273357391357
Epoch: 1, Steps: 210 | Train Loss: 1.0582183 Vali Loss: 1.0246003 Test Loss: 1.0161859
Validation loss decreased (inf --> 1.024600).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0384979
	speed: 0.0082s/iter; left time: 14.7421s
	iters: 200, epoch: 2 | loss: 1.0116431
	speed: 0.0073s/iter; left time: 12.4044s
Epoch: 2 cost time: 1.590867280960083
Epoch: 2, Steps: 210 | Train Loss: 1.0128629 Vali Loss: 1.0247266 Test Loss: 1.0162276
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0292003
	speed: 0.0071s/iter; left time: 11.2606s
	iters: 200, epoch: 3 | loss: 1.0128396
	speed: 0.0065s/iter; left time: 9.5972s
Epoch: 3 cost time: 1.4069483280181885
Epoch: 3, Steps: 210 | Train Loss: 1.0055765 Vali Loss: 1.0225637 Test Loss: 1.0156269
Validation loss decreased (1.024600 --> 1.022564).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0184029
	speed: 0.0093s/iter; left time: 12.6868s
	iters: 200, epoch: 4 | loss: 1.0211473
	speed: 0.0084s/iter; left time: 10.6135s
Epoch: 4 cost time: 1.7922451496124268
Epoch: 4, Steps: 210 | Train Loss: 1.0013228 Vali Loss: 1.0193328 Test Loss: 1.0139068
Validation loss decreased (1.022564 --> 1.019333).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0179121
	speed: 0.0093s/iter; left time: 10.8413s
	iters: 200, epoch: 5 | loss: 1.0086505
	speed: 0.0085s/iter; left time: 8.9892s
Epoch: 5 cost time: 1.832298755645752
Epoch: 5, Steps: 210 | Train Loss: 0.9993363 Vali Loss: 1.0204530 Test Loss: 1.0138521
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9966869
	speed: 0.0092s/iter; left time: 8.7265s
	iters: 200, epoch: 6 | loss: 0.9931310
	speed: 0.0084s/iter; left time: 7.1077s
Epoch: 6 cost time: 1.8170020580291748
Epoch: 6, Steps: 210 | Train Loss: 0.9979489 Vali Loss: 1.0198795 Test Loss: 1.0139834
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9824115
	speed: 0.0076s/iter; left time: 5.6421s
	iters: 200, epoch: 7 | loss: 0.9782245
	speed: 0.0071s/iter; left time: 4.5289s
Epoch: 7 cost time: 1.5337486267089844
Epoch: 7, Steps: 210 | Train Loss: 0.9971167 Vali Loss: 1.0190116 Test Loss: 1.0137538
Validation loss decreased (1.019333 --> 1.019012).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0142888
	speed: 0.0081s/iter; left time: 4.2813s
	iters: 200, epoch: 8 | loss: 0.9484038
	speed: 0.0072s/iter; left time: 3.0937s
Epoch: 8 cost time: 1.5573680400848389
Epoch: 8, Steps: 210 | Train Loss: 0.9969527 Vali Loss: 1.0191127 Test Loss: 1.0137818
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0166953
	speed: 0.0079s/iter; left time: 2.5241s
	iters: 200, epoch: 9 | loss: 0.9806253
	speed: 0.0071s/iter; left time: 1.5724s
Epoch: 9 cost time: 1.53495454788208
Epoch: 9, Steps: 210 | Train Loss: 0.9966422 Vali Loss: 1.0195930 Test Loss: 1.0138215
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0095005
	speed: 0.0077s/iter; left time: 0.8515s
	iters: 200, epoch: 10 | loss: 1.0082612
	speed: 0.0071s/iter; left time: 0.0782s
Epoch: 10 cost time: 1.54903244972229
Epoch: 10, Steps: 210 | Train Loss: 0.9964945 Vali Loss: 1.0194408 Test Loss: 1.0138630
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0137537717819214, mae:0.8072580695152283
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0340171
	speed: 0.0125s/iter; left time: 24.4922s
	iters: 200, epoch: 1 | loss: 1.0148898
	speed: 0.0089s/iter; left time: 16.5398s
Epoch: 1 cost time: 1.8600916862487793
Epoch: 1, Steps: 206 | Train Loss: 1.0571973 Vali Loss: 1.0202886 Test Loss: 1.0076090
Validation loss decreased (inf --> 1.020289).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0215704
	speed: 0.0071s/iter; left time: 12.5284s
	iters: 200, epoch: 2 | loss: 1.0027277
	speed: 0.0065s/iter; left time: 10.7128s
Epoch: 2 cost time: 1.3827009201049805
Epoch: 2, Steps: 206 | Train Loss: 1.0121075 Vali Loss: 1.0190961 Test Loss: 1.0069234
Validation loss decreased (1.020289 --> 1.019096).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0291190
	speed: 0.0078s/iter; left time: 12.0495s
	iters: 200, epoch: 3 | loss: 1.0011514
	speed: 0.0071s/iter; left time: 10.3282s
Epoch: 3 cost time: 1.513728141784668
Epoch: 3, Steps: 206 | Train Loss: 1.0064791 Vali Loss: 1.0179098 Test Loss: 1.0047002
Validation loss decreased (1.019096 --> 1.017910).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0029441
	speed: 0.0073s/iter; left time: 9.8439s
	iters: 200, epoch: 4 | loss: 1.0019923
	speed: 0.0066s/iter; left time: 8.2231s
Epoch: 4 cost time: 1.4082667827606201
Epoch: 4, Steps: 206 | Train Loss: 1.0032887 Vali Loss: 1.0168089 Test Loss: 1.0034660
Validation loss decreased (1.017910 --> 1.016809).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0065299
	speed: 0.0091s/iter; left time: 10.2947s
	iters: 200, epoch: 5 | loss: 1.0082587
	speed: 0.0084s/iter; left time: 8.6856s
Epoch: 5 cost time: 1.7885921001434326
Epoch: 5, Steps: 206 | Train Loss: 1.0012527 Vali Loss: 1.0160155 Test Loss: 1.0032873
Validation loss decreased (1.016809 --> 1.016016).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9917626
	speed: 0.0094s/iter; left time: 8.7423s
	iters: 200, epoch: 6 | loss: 1.0202913
	speed: 0.0086s/iter; left time: 7.1301s
Epoch: 6 cost time: 1.823648452758789
Epoch: 6, Steps: 206 | Train Loss: 1.0006161 Vali Loss: 1.0159364 Test Loss: 1.0029817
Validation loss decreased (1.016016 --> 1.015936).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0014120
	speed: 0.0075s/iter; left time: 5.4585s
	iters: 200, epoch: 7 | loss: 1.0166796
	speed: 0.0067s/iter; left time: 4.1773s
Epoch: 7 cost time: 1.445573091506958
Epoch: 7, Steps: 206 | Train Loss: 0.9999549 Vali Loss: 1.0161048 Test Loss: 1.0029655
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0132346
	speed: 0.0076s/iter; left time: 3.9658s
	iters: 200, epoch: 8 | loss: 0.9895220
	speed: 0.0070s/iter; left time: 2.9508s
Epoch: 8 cost time: 1.5043630599975586
Epoch: 8, Steps: 206 | Train Loss: 0.9996457 Vali Loss: 1.0157840 Test Loss: 1.0028840
Validation loss decreased (1.015936 --> 1.015784).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9985014
	speed: 0.0080s/iter; left time: 2.5125s
	iters: 200, epoch: 9 | loss: 0.9813102
	speed: 0.0073s/iter; left time: 1.5456s
Epoch: 9 cost time: 1.539736032485962
Epoch: 9, Steps: 206 | Train Loss: 0.9997740 Vali Loss: 1.0158815 Test Loss: 1.0028933
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0034690
	speed: 0.0067s/iter; left time: 0.7147s
	iters: 200, epoch: 10 | loss: 1.0100807
	speed: 0.0061s/iter; left time: 0.0430s
Epoch: 10 cost time: 1.322805643081665
Epoch: 10, Steps: 206 | Train Loss: 0.9996679 Vali Loss: 1.0158724 Test Loss: 1.0029063
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0028839111328125, mae:0.803121030330658
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0142332
	speed: 0.0073s/iter; left time: 14.2770s
	iters: 200, epoch: 1 | loss: 1.0233059
	speed: 0.0063s/iter; left time: 11.7176s
Epoch: 1 cost time: 1.340550422668457
Epoch: 1, Steps: 206 | Train Loss: 1.0582277 Vali Loss: 1.0214131 Test Loss: 1.0076212
Validation loss decreased (inf --> 1.021413).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0073491
	speed: 0.0079s/iter; left time: 13.8623s
	iters: 200, epoch: 2 | loss: 1.0242635
	speed: 0.0072s/iter; left time: 11.9319s
Epoch: 2 cost time: 1.5392861366271973
Epoch: 2, Steps: 206 | Train Loss: 1.0121383 Vali Loss: 1.0213895 Test Loss: 1.0074793
Validation loss decreased (1.021413 --> 1.021389).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0145686
	speed: 0.0092s/iter; left time: 14.1781s
	iters: 200, epoch: 3 | loss: 1.0022045
	speed: 0.0084s/iter; left time: 12.1696s
Epoch: 3 cost time: 1.7822794914245605
Epoch: 3, Steps: 206 | Train Loss: 1.0060482 Vali Loss: 1.0211146 Test Loss: 1.0052147
Validation loss decreased (1.021389 --> 1.021115).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0076903
	speed: 0.0083s/iter; left time: 11.1498s
	iters: 200, epoch: 4 | loss: 1.0119680
	speed: 0.0075s/iter; left time: 9.2923s
Epoch: 4 cost time: 1.5967726707458496
Epoch: 4, Steps: 206 | Train Loss: 1.0030873 Vali Loss: 1.0159316 Test Loss: 1.0033517
Validation loss decreased (1.021115 --> 1.015932).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0133326
	speed: 0.0083s/iter; left time: 9.4828s
	iters: 200, epoch: 5 | loss: 1.0014266
	speed: 0.0081s/iter; left time: 8.3485s
Epoch: 5 cost time: 1.7142345905303955
Epoch: 5, Steps: 206 | Train Loss: 1.0011650 Vali Loss: 1.0161959 Test Loss: 1.0031323
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0022808
	speed: 0.0089s/iter; left time: 8.2664s
	iters: 200, epoch: 6 | loss: 1.0158482
	speed: 0.0083s/iter; left time: 6.8652s
Epoch: 6 cost time: 1.750258445739746
Epoch: 6, Steps: 206 | Train Loss: 1.0003119 Vali Loss: 1.0160002 Test Loss: 1.0029323
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9834428
	speed: 0.0082s/iter; left time: 5.9386s
	iters: 200, epoch: 7 | loss: 0.9899516
	speed: 0.0074s/iter; left time: 4.5978s
Epoch: 7 cost time: 1.5683507919311523
Epoch: 7, Steps: 206 | Train Loss: 0.9998024 Vali Loss: 1.0157903 Test Loss: 1.0028635
Validation loss decreased (1.015932 --> 1.015790).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9992029
	speed: 0.0088s/iter; left time: 4.5813s
	iters: 200, epoch: 8 | loss: 0.9835968
	speed: 0.0074s/iter; left time: 3.0840s
Epoch: 8 cost time: 1.5751879215240479
Epoch: 8, Steps: 206 | Train Loss: 0.9993878 Vali Loss: 1.0156561 Test Loss: 1.0028119
Validation loss decreased (1.015790 --> 1.015656).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0199033
	speed: 0.0087s/iter; left time: 2.7270s
	iters: 200, epoch: 9 | loss: 1.0135424
	speed: 0.0076s/iter; left time: 1.6175s
Epoch: 9 cost time: 1.6107549667358398
Epoch: 9, Steps: 206 | Train Loss: 0.9991929 Vali Loss: 1.0158206 Test Loss: 1.0028210
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9763360
	speed: 0.0076s/iter; left time: 0.8175s
	iters: 200, epoch: 10 | loss: 0.9820600
	speed: 0.0066s/iter; left time: 0.0464s
Epoch: 10 cost time: 1.4094340801239014
Epoch: 10, Steps: 206 | Train Loss: 0.9991890 Vali Loss: 1.0158353 Test Loss: 1.0028262
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0028119087219238, mae:0.803161084651947
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9881721
	speed: 0.0074s/iter; left time: 14.4722s
	iters: 200, epoch: 1 | loss: 1.0277625
	speed: 0.0066s/iter; left time: 12.3307s
Epoch: 1 cost time: 1.4115569591522217
Epoch: 1, Steps: 206 | Train Loss: 1.0568110 Vali Loss: 1.0233893 Test Loss: 1.0075450
Validation loss decreased (inf --> 1.023389).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0309209
	speed: 0.0074s/iter; left time: 12.9353s
	iters: 200, epoch: 2 | loss: 1.0322725
	speed: 0.0065s/iter; left time: 10.8219s
Epoch: 2 cost time: 1.401341438293457
Epoch: 2, Steps: 206 | Train Loss: 1.0121690 Vali Loss: 1.0222497 Test Loss: 1.0065448
Validation loss decreased (1.023389 --> 1.022250).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9997517
	speed: 0.0083s/iter; left time: 12.7827s
	iters: 200, epoch: 3 | loss: 1.0200258
	speed: 0.0080s/iter; left time: 11.5314s
Epoch: 3 cost time: 1.6968677043914795
Epoch: 3, Steps: 206 | Train Loss: 1.0062353 Vali Loss: 1.0201606 Test Loss: 1.0051273
Validation loss decreased (1.022250 --> 1.020161).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0293952
	speed: 0.0094s/iter; left time: 12.6783s
	iters: 200, epoch: 4 | loss: 0.9902057
	speed: 0.0086s/iter; left time: 10.6625s
Epoch: 4 cost time: 1.8255398273468018
Epoch: 4, Steps: 206 | Train Loss: 1.0030630 Vali Loss: 1.0177127 Test Loss: 1.0034598
Validation loss decreased (1.020161 --> 1.017713).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9966815
	speed: 0.0096s/iter; left time: 10.8909s
	iters: 200, epoch: 5 | loss: 1.0113318
	speed: 0.0087s/iter; left time: 9.0011s
Epoch: 5 cost time: 1.8442251682281494
Epoch: 5, Steps: 206 | Train Loss: 1.0012466 Vali Loss: 1.0173028 Test Loss: 1.0033060
Validation loss decreased (1.017713 --> 1.017303).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9874260
	speed: 0.0075s/iter; left time: 6.9614s
	iters: 200, epoch: 6 | loss: 0.9973390
	speed: 0.0067s/iter; left time: 5.5782s
Epoch: 6 cost time: 1.4297351837158203
Epoch: 6, Steps: 206 | Train Loss: 1.0004226 Vali Loss: 1.0168446 Test Loss: 1.0031649
Validation loss decreased (1.017303 --> 1.016845).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9971323
	speed: 0.0088s/iter; left time: 6.3963s
	iters: 200, epoch: 7 | loss: 1.0125597
	speed: 0.0082s/iter; left time: 5.1505s
Epoch: 7 cost time: 1.7690913677215576
Epoch: 7, Steps: 206 | Train Loss: 0.9996123 Vali Loss: 1.0160582 Test Loss: 1.0029390
Validation loss decreased (1.016845 --> 1.016058).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0072639
	speed: 0.0078s/iter; left time: 4.0521s
	iters: 200, epoch: 8 | loss: 0.9987345
	speed: 0.0069s/iter; left time: 2.8931s
Epoch: 8 cost time: 1.4774930477142334
Epoch: 8, Steps: 206 | Train Loss: 0.9994719 Vali Loss: 1.0161320 Test Loss: 1.0029594
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0187753
	speed: 0.0086s/iter; left time: 2.6893s
	iters: 200, epoch: 9 | loss: 1.0088848
	speed: 0.0082s/iter; left time: 1.7383s
Epoch: 9 cost time: 1.7377820014953613
Epoch: 9, Steps: 206 | Train Loss: 0.9994432 Vali Loss: 1.0161448 Test Loss: 1.0029531
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0070800
	speed: 0.0079s/iter; left time: 0.8400s
	iters: 200, epoch: 10 | loss: 1.0126433
	speed: 0.0070s/iter; left time: 0.0491s
Epoch: 10 cost time: 1.4928092956542969
Epoch: 10, Steps: 206 | Train Loss: 0.9994601 Vali Loss: 1.0161951 Test Loss: 1.0029505
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.002938985824585, mae:0.8031164407730103
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0161738
	speed: 0.0207s/iter; left time: 38.0555s
Epoch: 1 cost time: 2.8339242935180664
Epoch: 1, Steps: 194 | Train Loss: 1.0568346 Vali Loss: 1.0221819 Test Loss: 0.9963175
Validation loss decreased (inf --> 1.022182).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0101887
	speed: 0.0092s/iter; left time: 15.1695s
Epoch: 2 cost time: 1.7282488346099854
Epoch: 2, Steps: 194 | Train Loss: 1.0129047 Vali Loss: 1.0205529 Test Loss: 0.9961405
Validation loss decreased (1.022182 --> 1.020553).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9978792
	speed: 0.0087s/iter; left time: 12.5826s
Epoch: 3 cost time: 1.5803320407867432
Epoch: 3, Steps: 194 | Train Loss: 1.0080417 Vali Loss: 1.0187131 Test Loss: 0.9924912
Validation loss decreased (1.020553 --> 1.018713).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0144031
	speed: 0.0091s/iter; left time: 11.5026s
Epoch: 4 cost time: 1.6657757759094238
Epoch: 4, Steps: 194 | Train Loss: 1.0052940 Vali Loss: 1.0171429 Test Loss: 0.9926743
Validation loss decreased (1.018713 --> 1.017143).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0029144
	speed: 0.0091s/iter; left time: 9.7314s
Epoch: 5 cost time: 1.7202370166778564
Epoch: 5, Steps: 194 | Train Loss: 1.0040640 Vali Loss: 1.0168850 Test Loss: 0.9920443
Validation loss decreased (1.017143 --> 1.016885).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0018058
	speed: 0.0096s/iter; left time: 8.3355s
Epoch: 6 cost time: 1.7113795280456543
Epoch: 6, Steps: 194 | Train Loss: 1.0032045 Vali Loss: 1.0169618 Test Loss: 0.9919410
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0063632
	speed: 0.0061s/iter; left time: 4.1128s
Epoch: 7 cost time: 1.0985116958618164
Epoch: 7, Steps: 194 | Train Loss: 1.0028074 Vali Loss: 1.0169917 Test Loss: 0.9916805
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0057302
	speed: 0.0078s/iter; left time: 3.7604s
Epoch: 8 cost time: 1.4515454769134521
Epoch: 8, Steps: 194 | Train Loss: 1.0026227 Vali Loss: 1.0169096 Test Loss: 0.9917440
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0017340
	speed: 0.0079s/iter; left time: 2.2820s
Epoch: 9 cost time: 1.4857075214385986
Epoch: 9, Steps: 194 | Train Loss: 1.0024184 Vali Loss: 1.0168343 Test Loss: 0.9917272
Validation loss decreased (1.016885 --> 1.016834).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0004046
	speed: 0.0094s/iter; left time: 0.8925s
Epoch: 10 cost time: 1.7326087951660156
Epoch: 10, Steps: 194 | Train Loss: 1.0023695 Vali Loss: 1.0168111 Test Loss: 0.9917168
Validation loss decreased (1.016834 --> 1.016811).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9917168617248535, mae:0.799128532409668
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0268483
	speed: 0.0096s/iter; left time: 17.7524s
Epoch: 1 cost time: 1.7591378688812256
Epoch: 1, Steps: 194 | Train Loss: 1.0572158 Vali Loss: 1.0247844 Test Loss: 0.9964831
Validation loss decreased (inf --> 1.024784).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0140859
	speed: 0.0092s/iter; left time: 15.1751s
Epoch: 2 cost time: 1.6189618110656738
Epoch: 2, Steps: 194 | Train Loss: 1.0127394 Vali Loss: 1.0209091 Test Loss: 0.9954990
Validation loss decreased (1.024784 --> 1.020909).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0147599
	speed: 0.0085s/iter; left time: 12.3401s
Epoch: 3 cost time: 1.50115966796875
Epoch: 3, Steps: 194 | Train Loss: 1.0079382 Vali Loss: 1.0195071 Test Loss: 0.9936232
Validation loss decreased (1.020909 --> 1.019507).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9957556
	speed: 0.0085s/iter; left time: 10.7184s
Epoch: 4 cost time: 1.5441436767578125
Epoch: 4, Steps: 194 | Train Loss: 1.0051081 Vali Loss: 1.0167016 Test Loss: 0.9921717
Validation loss decreased (1.019507 --> 1.016702).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0095121
	speed: 0.0085s/iter; left time: 9.0974s
Epoch: 5 cost time: 1.5742108821868896
Epoch: 5, Steps: 194 | Train Loss: 1.0039539 Vali Loss: 1.0170442 Test Loss: 0.9922063
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9911363
	speed: 0.0082s/iter; left time: 7.1473s
Epoch: 6 cost time: 1.585829734802246
Epoch: 6, Steps: 194 | Train Loss: 1.0030785 Vali Loss: 1.0162779 Test Loss: 0.9915743
Validation loss decreased (1.016702 --> 1.016278).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0112070
	speed: 0.0087s/iter; left time: 5.8925s
Epoch: 7 cost time: 1.5510494709014893
Epoch: 7, Steps: 194 | Train Loss: 1.0027658 Vali Loss: 1.0170161 Test Loss: 0.9916967
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0110117
	speed: 0.0075s/iter; left time: 3.6172s
Epoch: 8 cost time: 1.3659694194793701
Epoch: 8, Steps: 194 | Train Loss: 1.0025230 Vali Loss: 1.0168716 Test Loss: 0.9916410
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9970887
	speed: 0.0077s/iter; left time: 2.2295s
Epoch: 9 cost time: 1.3863210678100586
Epoch: 9, Steps: 194 | Train Loss: 1.0024032 Vali Loss: 1.0168359 Test Loss: 0.9916126
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0004480
	speed: 0.0093s/iter; left time: 0.8860s
Epoch: 10 cost time: 1.6792409420013428
Epoch: 10, Steps: 194 | Train Loss: 1.0021904 Vali Loss: 1.0169083 Test Loss: 0.9916109
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9915743470191956, mae:0.7990575432777405
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0152777
	speed: 0.0066s/iter; left time: 12.1299s
Epoch: 1 cost time: 1.1643733978271484
Epoch: 1, Steps: 194 | Train Loss: 1.0558434 Vali Loss: 1.0220462 Test Loss: 0.9970310
Validation loss decreased (inf --> 1.022046).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0174407
	speed: 0.0069s/iter; left time: 11.4201s
Epoch: 2 cost time: 1.2226486206054688
Epoch: 2, Steps: 194 | Train Loss: 1.0128639 Vali Loss: 1.0208488 Test Loss: 0.9956720
Validation loss decreased (1.022046 --> 1.020849).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0093664
	speed: 0.0066s/iter; left time: 9.6182s
Epoch: 3 cost time: 1.1598706245422363
Epoch: 3, Steps: 194 | Train Loss: 1.0078350 Vali Loss: 1.0193940 Test Loss: 0.9937507
Validation loss decreased (1.020849 --> 1.019394).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9904985
	speed: 0.0083s/iter; left time: 10.4496s
Epoch: 4 cost time: 1.5170233249664307
Epoch: 4, Steps: 194 | Train Loss: 1.0052883 Vali Loss: 1.0185536 Test Loss: 0.9926733
Validation loss decreased (1.019394 --> 1.018554).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9936802
	speed: 0.0066s/iter; left time: 7.0249s
Epoch: 5 cost time: 1.235753059387207
Epoch: 5, Steps: 194 | Train Loss: 1.0038054 Vali Loss: 1.0172504 Test Loss: 0.9919385
Validation loss decreased (1.018554 --> 1.017250).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9966829
	speed: 0.0082s/iter; left time: 7.1547s
Epoch: 6 cost time: 1.394733190536499
Epoch: 6, Steps: 194 | Train Loss: 1.0029589 Vali Loss: 1.0176734 Test Loss: 0.9917372
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9948125
	speed: 0.0089s/iter; left time: 6.0412s
Epoch: 7 cost time: 1.6958255767822266
Epoch: 7, Steps: 194 | Train Loss: 1.0025727 Vali Loss: 1.0169901 Test Loss: 0.9916719
Validation loss decreased (1.017250 --> 1.016990).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0042877
	speed: 0.0092s/iter; left time: 4.4235s
Epoch: 8 cost time: 1.7129015922546387
Epoch: 8, Steps: 194 | Train Loss: 1.0023587 Vali Loss: 1.0168604 Test Loss: 0.9916077
Validation loss decreased (1.016990 --> 1.016860).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9848413
	speed: 0.0096s/iter; left time: 2.7789s
Epoch: 9 cost time: 1.7652347087860107
Epoch: 9, Steps: 194 | Train Loss: 1.0022993 Vali Loss: 1.0168343 Test Loss: 0.9916021
Validation loss decreased (1.016860 --> 1.016834).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0114317
	speed: 0.0095s/iter; left time: 0.9018s
Epoch: 10 cost time: 1.7469727993011475
Epoch: 10, Steps: 194 | Train Loss: 1.0022150 Vali Loss: 1.0167929 Test Loss: 0.9916002
Validation loss decreased (1.016834 --> 1.016793).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9916000962257385, mae:0.7990716099739075
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0359070
	speed: 0.0186s/iter; left time: 37.6960s
	iters: 200, epoch: 1 | loss: 0.9923338
	speed: 0.0131s/iter; left time: 25.3108s
Epoch: 1 cost time: 2.770536422729492
Epoch: 1, Steps: 213 | Train Loss: 1.0602145 Vali Loss: 1.0378730 Test Loss: 1.0203127
Validation loss decreased (inf --> 1.037873).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0438175
	speed: 0.0093s/iter; left time: 16.9415s
	iters: 200, epoch: 2 | loss: 1.0055654
	speed: 0.0084s/iter; left time: 14.5122s
Epoch: 2 cost time: 1.8393521308898926
Epoch: 2, Steps: 213 | Train Loss: 1.0103154 Vali Loss: 1.0330316 Test Loss: 1.0169052
Validation loss decreased (1.037873 --> 1.033032).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0206426
	speed: 0.0090s/iter; left time: 14.4105s
	iters: 200, epoch: 3 | loss: 1.0003986
	speed: 0.0083s/iter; left time: 12.4805s
Epoch: 3 cost time: 1.8144638538360596
Epoch: 3, Steps: 213 | Train Loss: 1.0013095 Vali Loss: 1.0354670 Test Loss: 1.0194002
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9444062
	speed: 0.0092s/iter; left time: 12.7478s
	iters: 200, epoch: 4 | loss: 1.0270214
	speed: 0.0084s/iter; left time: 10.8306s
Epoch: 4 cost time: 1.8351213932037354
Epoch: 4, Steps: 213 | Train Loss: 0.9962649 Vali Loss: 1.0267951 Test Loss: 1.0151844
Validation loss decreased (1.033032 --> 1.026795).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9949190
	speed: 0.0076s/iter; left time: 8.9419s
	iters: 200, epoch: 5 | loss: 1.0033133
	speed: 0.0067s/iter; left time: 7.2492s
Epoch: 5 cost time: 1.4725275039672852
Epoch: 5, Steps: 213 | Train Loss: 0.9936768 Vali Loss: 1.0313258 Test Loss: 1.0160238
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9502831
	speed: 0.0074s/iter; left time: 7.1051s
	iters: 200, epoch: 6 | loss: 1.0552585
	speed: 0.0066s/iter; left time: 5.7233s
Epoch: 6 cost time: 1.4501781463623047
Epoch: 6, Steps: 213 | Train Loss: 0.9915567 Vali Loss: 1.0272787 Test Loss: 1.0153098
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9531879
	speed: 0.0091s/iter; left time: 6.8790s
	iters: 200, epoch: 7 | loss: 1.0133908
	speed: 0.0083s/iter; left time: 5.4443s
Epoch: 7 cost time: 1.826134443283081
Epoch: 7, Steps: 213 | Train Loss: 0.9906708 Vali Loss: 1.0271599 Test Loss: 1.0151439
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9900259
	speed: 0.0075s/iter; left time: 4.0577s
	iters: 200, epoch: 8 | loss: 0.9850163
	speed: 0.0067s/iter; left time: 2.9583s
Epoch: 8 cost time: 1.475278377532959
Epoch: 8, Steps: 213 | Train Loss: 0.9901488 Vali Loss: 1.0276706 Test Loss: 1.0152125
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0157069
	speed: 0.0088s/iter; left time: 2.8751s
	iters: 200, epoch: 9 | loss: 1.0357654
	speed: 0.0082s/iter; left time: 1.8606s
Epoch: 9 cost time: 1.7856943607330322
Epoch: 9, Steps: 213 | Train Loss: 0.9902149 Vali Loss: 1.0278044 Test Loss: 1.0153100
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0151845216751099, mae:0.8082503080368042
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0519150
	speed: 0.0083s/iter; left time: 16.8722s
	iters: 200, epoch: 1 | loss: 1.0185629
	speed: 0.0074s/iter; left time: 14.2418s
Epoch: 1 cost time: 1.6367087364196777
Epoch: 1, Steps: 213 | Train Loss: 1.0644155 Vali Loss: 1.0293574 Test Loss: 1.0168904
Validation loss decreased (inf --> 1.029357).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9807544
	speed: 0.0095s/iter; left time: 17.2379s
	iters: 200, epoch: 2 | loss: 0.9765396
	speed: 0.0086s/iter; left time: 14.7379s
Epoch: 2 cost time: 1.8703393936157227
Epoch: 2, Steps: 213 | Train Loss: 1.0096403 Vali Loss: 1.0334903 Test Loss: 1.0181404
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0211592
	speed: 0.0092s/iter; left time: 14.8066s
	iters: 200, epoch: 3 | loss: 1.0181170
	speed: 0.0084s/iter; left time: 12.6877s
Epoch: 3 cost time: 1.8747470378875732
Epoch: 3, Steps: 213 | Train Loss: 1.0003121 Vali Loss: 1.0333968 Test Loss: 1.0165719
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9656760
	speed: 0.0093s/iter; left time: 12.9824s
	iters: 200, epoch: 4 | loss: 0.9948518
	speed: 0.0085s/iter; left time: 10.9535s
Epoch: 4 cost time: 1.8587045669555664
Epoch: 4, Steps: 213 | Train Loss: 0.9953147 Vali Loss: 1.0296674 Test Loss: 1.0158592
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9947995
	speed: 0.0091s/iter; left time: 10.7348s
	iters: 200, epoch: 5 | loss: 1.0098550
	speed: 0.0084s/iter; left time: 9.0120s
Epoch: 5 cost time: 1.8303675651550293
Epoch: 5, Steps: 213 | Train Loss: 0.9922007 Vali Loss: 1.0285501 Test Loss: 1.0155184
Validation loss decreased (1.029357 --> 1.028550).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9767715
	speed: 0.0094s/iter; left time: 9.0638s
	iters: 200, epoch: 6 | loss: 1.0275178
	speed: 0.0085s/iter; left time: 7.3506s
Epoch: 6 cost time: 1.8550753593444824
Epoch: 6, Steps: 213 | Train Loss: 0.9911397 Vali Loss: 1.0270951 Test Loss: 1.0151944
Validation loss decreased (1.028550 --> 1.027095).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9913414
	speed: 0.0094s/iter; left time: 7.0562s
	iters: 200, epoch: 7 | loss: 0.9501165
	speed: 0.0084s/iter; left time: 5.5132s
Epoch: 7 cost time: 1.8462793827056885
Epoch: 7, Steps: 213 | Train Loss: 0.9896323 Vali Loss: 1.0271608 Test Loss: 1.0152390
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9811594
	speed: 0.0094s/iter; left time: 5.0961s
	iters: 200, epoch: 8 | loss: 0.9727786
	speed: 0.0087s/iter; left time: 3.8469s
Epoch: 8 cost time: 1.9410548210144043
Epoch: 8, Steps: 213 | Train Loss: 0.9891025 Vali Loss: 1.0272048 Test Loss: 1.0152336
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9950309
	speed: 0.0092s/iter; left time: 3.0207s
	iters: 200, epoch: 9 | loss: 0.9823031
	speed: 0.0085s/iter; left time: 1.9202s
Epoch: 9 cost time: 1.8528549671173096
Epoch: 9, Steps: 213 | Train Loss: 0.9887605 Vali Loss: 1.0277065 Test Loss: 1.0152453
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9821483
	speed: 0.0092s/iter; left time: 1.0534s
	iters: 200, epoch: 10 | loss: 0.9928125
	speed: 0.0084s/iter; left time: 0.1183s
Epoch: 10 cost time: 1.8478631973266602
Epoch: 10, Steps: 213 | Train Loss: 0.9885935 Vali Loss: 1.0278538 Test Loss: 1.0152687
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0151945352554321, mae:0.8082491159439087
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0537446
	speed: 0.0094s/iter; left time: 19.1472s
	iters: 200, epoch: 1 | loss: 1.0183454
	speed: 0.0085s/iter; left time: 16.4138s
Epoch: 1 cost time: 1.858867883682251
Epoch: 1, Steps: 213 | Train Loss: 1.0635512 Vali Loss: 1.0348986 Test Loss: 1.0185483
Validation loss decreased (inf --> 1.034899).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0109953
	speed: 0.0098s/iter; left time: 17.8491s
	iters: 200, epoch: 2 | loss: 1.0256016
	speed: 0.0088s/iter; left time: 15.1762s
Epoch: 2 cost time: 1.9228284358978271
Epoch: 2, Steps: 213 | Train Loss: 1.0095185 Vali Loss: 1.0374397 Test Loss: 1.0190302
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9561965
	speed: 0.0088s/iter; left time: 14.0962s
	iters: 200, epoch: 3 | loss: 1.0217173
	speed: 0.0076s/iter; left time: 11.4937s
Epoch: 3 cost time: 1.668186902999878
Epoch: 3, Steps: 213 | Train Loss: 1.0008242 Vali Loss: 1.0314547 Test Loss: 1.0167531
Validation loss decreased (1.034899 --> 1.031455).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9757203
	speed: 0.0083s/iter; left time: 11.5190s
	iters: 200, epoch: 4 | loss: 0.9569701
	speed: 0.0074s/iter; left time: 9.5386s
Epoch: 4 cost time: 1.6286699771881104
Epoch: 4, Steps: 213 | Train Loss: 0.9953126 Vali Loss: 1.0301648 Test Loss: 1.0159371
Validation loss decreased (1.031455 --> 1.030165).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0256299
	speed: 0.0088s/iter; left time: 10.3496s
	iters: 200, epoch: 5 | loss: 0.9921147
	speed: 0.0082s/iter; left time: 8.8809s
Epoch: 5 cost time: 1.8051693439483643
Epoch: 5, Steps: 213 | Train Loss: 0.9920529 Vali Loss: 1.0280410 Test Loss: 1.0159372
Validation loss decreased (1.030165 --> 1.028041).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0351045
	speed: 0.0093s/iter; left time: 9.0281s
	iters: 200, epoch: 6 | loss: 0.9973757
	speed: 0.0085s/iter; left time: 7.3262s
Epoch: 6 cost time: 1.8585541248321533
Epoch: 6, Steps: 213 | Train Loss: 0.9902600 Vali Loss: 1.0286862 Test Loss: 1.0159900
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9753954
	speed: 0.0064s/iter; left time: 4.8357s
	iters: 200, epoch: 7 | loss: 1.0369625
	speed: 0.0056s/iter; left time: 3.6555s
Epoch: 7 cost time: 1.234722375869751
Epoch: 7, Steps: 213 | Train Loss: 0.9897550 Vali Loss: 1.0286605 Test Loss: 1.0159180
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9878590
	speed: 0.0068s/iter; left time: 3.6838s
	iters: 200, epoch: 8 | loss: 0.9423189
	speed: 0.0062s/iter; left time: 2.7375s
Epoch: 8 cost time: 1.3691468238830566
Epoch: 8, Steps: 213 | Train Loss: 0.9893068 Vali Loss: 1.0292087 Test Loss: 1.0161128
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0087188
	speed: 0.0088s/iter; left time: 2.8840s
	iters: 200, epoch: 9 | loss: 0.9854625
	speed: 0.0082s/iter; left time: 1.8657s
Epoch: 9 cost time: 1.809957504272461
Epoch: 9, Steps: 213 | Train Loss: 0.9883576 Vali Loss: 1.0281678 Test Loss: 1.0161139
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9904785
	speed: 0.0089s/iter; left time: 1.0117s
	iters: 200, epoch: 10 | loss: 1.0104426
	speed: 0.0082s/iter; left time: 0.1149s
Epoch: 10 cost time: 1.7930192947387695
Epoch: 10, Steps: 213 | Train Loss: 0.9884928 Vali Loss: 1.0273590 Test Loss: 1.0161307
Validation loss decreased (1.028041 --> 1.027359).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.016130805015564, mae:0.8087813258171082
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0153375
	speed: 0.0183s/iter; left time: 36.6921s
	iters: 200, epoch: 1 | loss: 1.0294721
	speed: 0.0121s/iter; left time: 22.9751s
Epoch: 1 cost time: 2.5296056270599365
Epoch: 1, Steps: 210 | Train Loss: 1.0562849 Vali Loss: 1.0295658 Test Loss: 1.0180489
Validation loss decreased (inf --> 1.029566).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0110600
	speed: 0.0088s/iter; left time: 15.7703s
	iters: 200, epoch: 2 | loss: 1.0029438
	speed: 0.0074s/iter; left time: 12.4616s
Epoch: 2 cost time: 1.5801868438720703
Epoch: 2, Steps: 210 | Train Loss: 1.0126319 Vali Loss: 1.0223501 Test Loss: 1.0167136
Validation loss decreased (1.029566 --> 1.022350).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9977338
	speed: 0.0087s/iter; left time: 13.7497s
	iters: 200, epoch: 3 | loss: 1.0274662
	speed: 0.0082s/iter; left time: 12.1248s
Epoch: 3 cost time: 1.7586324214935303
Epoch: 3, Steps: 210 | Train Loss: 1.0056385 Vali Loss: 1.0267367 Test Loss: 1.0165855
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0434055
	speed: 0.0091s/iter; left time: 12.4990s
	iters: 200, epoch: 4 | loss: 1.0018333
	speed: 0.0084s/iter; left time: 10.6518s
Epoch: 4 cost time: 1.8113598823547363
Epoch: 4, Steps: 210 | Train Loss: 1.0015212 Vali Loss: 1.0225921 Test Loss: 1.0143062
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0108147
	speed: 0.0092s/iter; left time: 10.6323s
	iters: 200, epoch: 5 | loss: 0.9847913
	speed: 0.0084s/iter; left time: 8.9156s
Epoch: 5 cost time: 1.8151204586029053
Epoch: 5, Steps: 210 | Train Loss: 0.9994398 Vali Loss: 1.0185040 Test Loss: 1.0135489
Validation loss decreased (1.022350 --> 1.018504).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0126760
	speed: 0.0076s/iter; left time: 7.2747s
	iters: 200, epoch: 6 | loss: 0.9965130
	speed: 0.0068s/iter; left time: 5.7596s
Epoch: 6 cost time: 1.470970630645752
Epoch: 6, Steps: 210 | Train Loss: 0.9980126 Vali Loss: 1.0190932 Test Loss: 1.0136751
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9773218
	speed: 0.0088s/iter; left time: 6.4965s
	iters: 200, epoch: 7 | loss: 1.0053921
	speed: 0.0082s/iter; left time: 5.2387s
Epoch: 7 cost time: 1.7706797122955322
Epoch: 7, Steps: 210 | Train Loss: 0.9972333 Vali Loss: 1.0186869 Test Loss: 1.0136236
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0010109
	speed: 0.0075s/iter; left time: 3.9898s
	iters: 200, epoch: 8 | loss: 0.9738082
	speed: 0.0075s/iter; left time: 3.2232s
Epoch: 8 cost time: 1.6251616477966309
Epoch: 8, Steps: 210 | Train Loss: 0.9970466 Vali Loss: 1.0188751 Test Loss: 1.0137728
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9883036
	speed: 0.0091s/iter; left time: 2.9187s
	iters: 200, epoch: 9 | loss: 1.0157875
	speed: 0.0083s/iter; left time: 1.8439s
Epoch: 9 cost time: 1.8066926002502441
Epoch: 9, Steps: 210 | Train Loss: 0.9968255 Vali Loss: 1.0189985 Test Loss: 1.0137917
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0225151
	speed: 0.0074s/iter; left time: 0.8234s
	iters: 200, epoch: 10 | loss: 0.9985447
	speed: 0.0067s/iter; left time: 0.0732s
Epoch: 10 cost time: 1.4497032165527344
Epoch: 10, Steps: 210 | Train Loss: 0.9967612 Vali Loss: 1.0194148 Test Loss: 1.0138173
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.013548731803894, mae:0.8072046637535095
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0199816
	speed: 0.0093s/iter; left time: 18.6592s
	iters: 200, epoch: 1 | loss: 1.0333610
	speed: 0.0084s/iter; left time: 16.0448s
Epoch: 1 cost time: 1.8317413330078125
Epoch: 1, Steps: 210 | Train Loss: 1.0586510 Vali Loss: 1.0252808 Test Loss: 1.0156106
Validation loss decreased (inf --> 1.025281).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9994105
	speed: 0.0091s/iter; left time: 16.2563s
	iters: 200, epoch: 2 | loss: 1.0096134
	speed: 0.0084s/iter; left time: 14.1700s
Epoch: 2 cost time: 1.8151934146881104
Epoch: 2, Steps: 210 | Train Loss: 1.0120152 Vali Loss: 1.0246565 Test Loss: 1.0162461
Validation loss decreased (1.025281 --> 1.024657).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0121881
	speed: 0.0093s/iter; left time: 14.6545s
	iters: 200, epoch: 3 | loss: 1.0000952
	speed: 0.0085s/iter; left time: 12.5287s
Epoch: 3 cost time: 1.827185869216919
Epoch: 3, Steps: 210 | Train Loss: 1.0046901 Vali Loss: 1.0259844 Test Loss: 1.0160842
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0040684
	speed: 0.0092s/iter; left time: 12.6812s
	iters: 200, epoch: 4 | loss: 1.0365937
	speed: 0.0084s/iter; left time: 10.7138s
Epoch: 4 cost time: 1.8283665180206299
Epoch: 4, Steps: 210 | Train Loss: 1.0010960 Vali Loss: 1.0230759 Test Loss: 1.0148684
Validation loss decreased (1.024657 --> 1.023076).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0213981
	speed: 0.0094s/iter; left time: 10.8651s
	iters: 200, epoch: 5 | loss: 0.9897507
	speed: 0.0085s/iter; left time: 9.0291s
Epoch: 5 cost time: 1.8479816913604736
Epoch: 5, Steps: 210 | Train Loss: 0.9986504 Vali Loss: 1.0201440 Test Loss: 1.0137458
Validation loss decreased (1.023076 --> 1.020144).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9924030
	speed: 0.0094s/iter; left time: 8.9760s
	iters: 200, epoch: 6 | loss: 1.0218804
	speed: 0.0087s/iter; left time: 7.4364s
Epoch: 6 cost time: 1.9129252433776855
Epoch: 6, Steps: 210 | Train Loss: 0.9970728 Vali Loss: 1.0198649 Test Loss: 1.0137730
Validation loss decreased (1.020144 --> 1.019865).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9989074
	speed: 0.0093s/iter; left time: 6.9146s
	iters: 200, epoch: 7 | loss: 0.9990117
	speed: 0.0085s/iter; left time: 5.4606s
Epoch: 7 cost time: 1.854194164276123
Epoch: 7, Steps: 210 | Train Loss: 0.9965003 Vali Loss: 1.0194721 Test Loss: 1.0137353
Validation loss decreased (1.019865 --> 1.019472).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9936349
	speed: 0.0094s/iter; left time: 4.9832s
	iters: 200, epoch: 8 | loss: 1.0021880
	speed: 0.0085s/iter; left time: 3.6724s
Epoch: 8 cost time: 1.8493828773498535
Epoch: 8, Steps: 210 | Train Loss: 0.9961660 Vali Loss: 1.0190114 Test Loss: 1.0137473
Validation loss decreased (1.019472 --> 1.019011).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9860439
	speed: 0.0094s/iter; left time: 3.0029s
	iters: 200, epoch: 9 | loss: 1.0142715
	speed: 0.0079s/iter; left time: 1.7382s
Epoch: 9 cost time: 1.6994743347167969
Epoch: 9, Steps: 210 | Train Loss: 0.9958641 Vali Loss: 1.0188771 Test Loss: 1.0136852
Validation loss decreased (1.019011 --> 1.018877).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0185378
	speed: 0.0093s/iter; left time: 1.0336s
	iters: 200, epoch: 10 | loss: 0.9950177
	speed: 0.0085s/iter; left time: 0.0933s
Epoch: 10 cost time: 1.8383636474609375
Epoch: 10, Steps: 210 | Train Loss: 0.9957768 Vali Loss: 1.0182657 Test Loss: 1.0136827
Validation loss decreased (1.018877 --> 1.018266).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0136827230453491, mae:0.8072492480278015
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0073211
	speed: 0.0093s/iter; left time: 18.7000s
	iters: 200, epoch: 1 | loss: 1.0254632
	speed: 0.0085s/iter; left time: 16.1243s
Epoch: 1 cost time: 1.8337223529815674
Epoch: 1, Steps: 210 | Train Loss: 1.0580927 Vali Loss: 1.0256990 Test Loss: 1.0170681
Validation loss decreased (inf --> 1.025699).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0248656
	speed: 0.0094s/iter; left time: 16.8839s
	iters: 200, epoch: 2 | loss: 0.9843645
	speed: 0.0085s/iter; left time: 14.3974s
Epoch: 2 cost time: 1.8460667133331299
Epoch: 2, Steps: 210 | Train Loss: 1.0120434 Vali Loss: 1.0270820 Test Loss: 1.0171429
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0037128
	speed: 0.0093s/iter; left time: 14.6515s
	iters: 200, epoch: 3 | loss: 1.0076592
	speed: 0.0084s/iter; left time: 12.4983s
Epoch: 3 cost time: 1.832465648651123
Epoch: 3, Steps: 210 | Train Loss: 1.0050084 Vali Loss: 1.0231345 Test Loss: 1.0152426
Validation loss decreased (1.025699 --> 1.023134).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9908460
	speed: 0.0094s/iter; left time: 12.9427s
	iters: 200, epoch: 4 | loss: 1.0190824
	speed: 0.0086s/iter; left time: 10.8841s
Epoch: 4 cost time: 1.850445032119751
Epoch: 4, Steps: 210 | Train Loss: 1.0011708 Vali Loss: 1.0172766 Test Loss: 1.0138575
Validation loss decreased (1.023134 --> 1.017277).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9973245
	speed: 0.0094s/iter; left time: 10.8890s
	iters: 200, epoch: 5 | loss: 0.9773197
	speed: 0.0085s/iter; left time: 9.0038s
Epoch: 5 cost time: 1.8316600322723389
Epoch: 5, Steps: 210 | Train Loss: 0.9987618 Vali Loss: 1.0190078 Test Loss: 1.0141227
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9796247
	speed: 0.0093s/iter; left time: 8.8158s
	iters: 200, epoch: 6 | loss: 1.0169804
	speed: 0.0086s/iter; left time: 7.3292s
Epoch: 6 cost time: 1.8670322895050049
Epoch: 6, Steps: 210 | Train Loss: 0.9976999 Vali Loss: 1.0194211 Test Loss: 1.0140271
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9741712
	speed: 0.0093s/iter; left time: 6.8642s
	iters: 200, epoch: 7 | loss: 0.9939883
	speed: 0.0084s/iter; left time: 5.4066s
Epoch: 7 cost time: 1.82279634475708
Epoch: 7, Steps: 210 | Train Loss: 0.9966474 Vali Loss: 1.0170782 Test Loss: 1.0137417
Validation loss decreased (1.017277 --> 1.017078).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9826835
	speed: 0.0093s/iter; left time: 4.9398s
	iters: 200, epoch: 8 | loss: 0.9792914
	speed: 0.0084s/iter; left time: 3.6391s
Epoch: 8 cost time: 1.8279035091400146
Epoch: 8, Steps: 210 | Train Loss: 0.9964898 Vali Loss: 1.0189435 Test Loss: 1.0138558
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9743013
	speed: 0.0093s/iter; left time: 2.9903s
	iters: 200, epoch: 9 | loss: 1.0246384
	speed: 0.0085s/iter; left time: 1.8739s
Epoch: 9 cost time: 1.8307507038116455
Epoch: 9, Steps: 210 | Train Loss: 0.9959808 Vali Loss: 1.0186218 Test Loss: 1.0139161
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9885339
	speed: 0.0092s/iter; left time: 1.0241s
	iters: 200, epoch: 10 | loss: 0.9810581
	speed: 0.0082s/iter; left time: 0.0898s
Epoch: 10 cost time: 1.7503490447998047
Epoch: 10, Steps: 210 | Train Loss: 0.9962455 Vali Loss: 1.0192387 Test Loss: 1.0139376
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0137419700622559, mae:0.8072801232337952
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0272789
	speed: 0.0168s/iter; left time: 33.0358s
	iters: 200, epoch: 1 | loss: 1.0102633
	speed: 0.0123s/iter; left time: 22.8782s
Epoch: 1 cost time: 2.556293249130249
Epoch: 1, Steps: 206 | Train Loss: 1.0540372 Vali Loss: 1.0216626 Test Loss: 1.0076705
Validation loss decreased (inf --> 1.021663).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0132514
	speed: 0.0093s/iter; left time: 16.3944s
	iters: 200, epoch: 2 | loss: 1.0075530
	speed: 0.0085s/iter; left time: 14.1031s
Epoch: 2 cost time: 1.8104112148284912
Epoch: 2, Steps: 206 | Train Loss: 1.0127237 Vali Loss: 1.0198466 Test Loss: 1.0066302
Validation loss decreased (1.021663 --> 1.019847).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0071445
	speed: 0.0094s/iter; left time: 14.5156s
	iters: 200, epoch: 3 | loss: 1.0215316
	speed: 0.0085s/iter; left time: 12.3764s
Epoch: 3 cost time: 1.818277359008789
Epoch: 3, Steps: 206 | Train Loss: 1.0066174 Vali Loss: 1.0183804 Test Loss: 1.0049829
Validation loss decreased (1.019847 --> 1.018380).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0259929
	speed: 0.0094s/iter; left time: 12.5956s
	iters: 200, epoch: 4 | loss: 0.9885485
	speed: 0.0081s/iter; left time: 10.1256s
Epoch: 4 cost time: 1.7343876361846924
Epoch: 4, Steps: 206 | Train Loss: 1.0038273 Vali Loss: 1.0169890 Test Loss: 1.0038284
Validation loss decreased (1.018380 --> 1.016989).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0072500
	speed: 0.0094s/iter; left time: 10.6674s
	iters: 200, epoch: 5 | loss: 0.9976792
	speed: 0.0086s/iter; left time: 8.8721s
Epoch: 5 cost time: 1.826941728591919
Epoch: 5, Steps: 206 | Train Loss: 1.0020106 Vali Loss: 1.0176138 Test Loss: 1.0034742
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0048280
	speed: 0.0072s/iter; left time: 6.6718s
	iters: 200, epoch: 6 | loss: 1.0089219
	speed: 0.0066s/iter; left time: 5.4668s
Epoch: 6 cost time: 1.4065141677856445
Epoch: 6, Steps: 206 | Train Loss: 1.0010087 Vali Loss: 1.0164628 Test Loss: 1.0029635
Validation loss decreased (1.016989 --> 1.016463).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0127215
	speed: 0.0091s/iter; left time: 6.5922s
	iters: 200, epoch: 7 | loss: 0.9862144
	speed: 0.0084s/iter; left time: 5.2404s
Epoch: 7 cost time: 1.7764172554016113
Epoch: 7, Steps: 206 | Train Loss: 1.0003479 Vali Loss: 1.0164229 Test Loss: 1.0028844
Validation loss decreased (1.016463 --> 1.016423).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9746515
	speed: 0.0079s/iter; left time: 4.1188s
	iters: 200, epoch: 8 | loss: 0.9890177
	speed: 0.0076s/iter; left time: 3.2007s
Epoch: 8 cost time: 1.6353836059570312
Epoch: 8, Steps: 206 | Train Loss: 1.0003038 Vali Loss: 1.0162119 Test Loss: 1.0028301
Validation loss decreased (1.016423 --> 1.016212).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0047354
	speed: 0.0083s/iter; left time: 2.6016s
	iters: 200, epoch: 9 | loss: 1.0074340
	speed: 0.0077s/iter; left time: 1.6418s
Epoch: 9 cost time: 1.642460584640503
Epoch: 9, Steps: 206 | Train Loss: 0.9999910 Vali Loss: 1.0162917 Test Loss: 1.0028564
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0090890
	speed: 0.0078s/iter; left time: 0.8295s
	iters: 200, epoch: 10 | loss: 1.0163761
	speed: 0.0069s/iter; left time: 0.0480s
Epoch: 10 cost time: 1.4609315395355225
Epoch: 10, Steps: 206 | Train Loss: 1.0001510 Vali Loss: 1.0163981 Test Loss: 1.0028635
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.002830147743225, mae:0.8031484484672546
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0364366
	speed: 0.0077s/iter; left time: 15.1196s
	iters: 200, epoch: 1 | loss: 1.0344769
	speed: 0.0068s/iter; left time: 12.6905s
Epoch: 1 cost time: 1.4618113040924072
Epoch: 1, Steps: 206 | Train Loss: 1.0571290 Vali Loss: 1.0209005 Test Loss: 1.0072912
Validation loss decreased (inf --> 1.020900).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0293658
	speed: 0.0084s/iter; left time: 14.6696s
	iters: 200, epoch: 2 | loss: 1.0252047
	speed: 0.0080s/iter; left time: 13.2888s
Epoch: 2 cost time: 1.7173302173614502
Epoch: 2, Steps: 206 | Train Loss: 1.0120375 Vali Loss: 1.0216990 Test Loss: 1.0068361
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0116340
	speed: 0.0086s/iter; left time: 13.2527s
	iters: 200, epoch: 3 | loss: 1.0131333
	speed: 0.0081s/iter; left time: 11.7721s
Epoch: 3 cost time: 1.7506182193756104
Epoch: 3, Steps: 206 | Train Loss: 1.0062300 Vali Loss: 1.0194776 Test Loss: 1.0047405
Validation loss decreased (1.020900 --> 1.019478).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0043471
	speed: 0.0091s/iter; left time: 12.2277s
	iters: 200, epoch: 4 | loss: 1.0089968
	speed: 0.0079s/iter; left time: 9.7980s
Epoch: 4 cost time: 1.673649549484253
Epoch: 4, Steps: 206 | Train Loss: 1.0033274 Vali Loss: 1.0184118 Test Loss: 1.0041499
Validation loss decreased (1.019478 --> 1.018412).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0240359
	speed: 0.0083s/iter; left time: 9.4090s
	iters: 200, epoch: 5 | loss: 0.9983969
	speed: 0.0074s/iter; left time: 7.6930s
Epoch: 5 cost time: 1.5760486125946045
Epoch: 5, Steps: 206 | Train Loss: 1.0012362 Vali Loss: 1.0157003 Test Loss: 1.0029117
Validation loss decreased (1.018412 --> 1.015700).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9831051
	speed: 0.0089s/iter; left time: 8.2952s
	iters: 200, epoch: 6 | loss: 0.9893866
	speed: 0.0080s/iter; left time: 6.6667s
Epoch: 6 cost time: 1.6985201835632324
Epoch: 6, Steps: 206 | Train Loss: 1.0004149 Vali Loss: 1.0162146 Test Loss: 1.0027820
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9828482
	speed: 0.0088s/iter; left time: 6.3489s
	iters: 200, epoch: 7 | loss: 1.0010939
	speed: 0.0081s/iter; left time: 5.0697s
Epoch: 7 cost time: 1.7184109687805176
Epoch: 7, Steps: 206 | Train Loss: 1.0000854 Vali Loss: 1.0158668 Test Loss: 1.0026484
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0080192
	speed: 0.0075s/iter; left time: 3.8948s
	iters: 200, epoch: 8 | loss: 1.0010821
	speed: 0.0067s/iter; left time: 2.8039s
Epoch: 8 cost time: 1.4318854808807373
Epoch: 8, Steps: 206 | Train Loss: 0.9997138 Vali Loss: 1.0157468 Test Loss: 1.0026177
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9956592
	speed: 0.0082s/iter; left time: 2.5595s
	iters: 200, epoch: 9 | loss: 1.0048013
	speed: 0.0074s/iter; left time: 1.5695s
Epoch: 9 cost time: 1.5640108585357666
Epoch: 9, Steps: 206 | Train Loss: 0.9998019 Vali Loss: 1.0159639 Test Loss: 1.0026571
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0110618
	speed: 0.0089s/iter; left time: 0.9480s
	iters: 200, epoch: 10 | loss: 0.9846643
	speed: 0.0080s/iter; left time: 0.0563s
Epoch: 10 cost time: 1.71034836769104
Epoch: 10, Steps: 206 | Train Loss: 0.9995205 Vali Loss: 1.0159218 Test Loss: 1.0026830
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0029118061065674, mae:0.8031060695648193
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9997177
	speed: 0.0086s/iter; left time: 16.8546s
	iters: 200, epoch: 1 | loss: 1.0112416
	speed: 0.0081s/iter; left time: 15.1016s
Epoch: 1 cost time: 1.7383413314819336
Epoch: 1, Steps: 206 | Train Loss: 1.0583738 Vali Loss: 1.0215327 Test Loss: 1.0082897
Validation loss decreased (inf --> 1.021533).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0318691
	speed: 0.0078s/iter; left time: 13.6375s
	iters: 200, epoch: 2 | loss: 1.0144234
	speed: 0.0069s/iter; left time: 11.3665s
Epoch: 2 cost time: 1.4771320819854736
Epoch: 2, Steps: 206 | Train Loss: 1.0118041 Vali Loss: 1.0236667 Test Loss: 1.0076813
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0018739
	speed: 0.0093s/iter; left time: 14.3398s
	iters: 200, epoch: 3 | loss: 1.0094192
	speed: 0.0085s/iter; left time: 12.2575s
Epoch: 3 cost time: 1.7971642017364502
Epoch: 3, Steps: 206 | Train Loss: 1.0060165 Vali Loss: 1.0171976 Test Loss: 1.0041147
Validation loss decreased (1.021533 --> 1.017198).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0134095
	speed: 0.0095s/iter; left time: 12.7637s
	iters: 200, epoch: 4 | loss: 0.9866513
	speed: 0.0086s/iter; left time: 10.6373s
Epoch: 4 cost time: 1.82757568359375
Epoch: 4, Steps: 206 | Train Loss: 1.0032232 Vali Loss: 1.0180376 Test Loss: 1.0035465
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9851418
	speed: 0.0091s/iter; left time: 10.3397s
	iters: 200, epoch: 5 | loss: 1.0047367
	speed: 0.0084s/iter; left time: 8.6682s
Epoch: 5 cost time: 1.7870500087738037
Epoch: 5, Steps: 206 | Train Loss: 1.0010449 Vali Loss: 1.0180724 Test Loss: 1.0038267
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0193381
	speed: 0.0093s/iter; left time: 8.6631s
	iters: 200, epoch: 6 | loss: 0.9968667
	speed: 0.0085s/iter; left time: 7.0778s
Epoch: 6 cost time: 1.814157247543335
Epoch: 6, Steps: 206 | Train Loss: 1.0001622 Vali Loss: 1.0168482 Test Loss: 1.0031916
Validation loss decreased (1.017198 --> 1.016848).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0036160
	speed: 0.0095s/iter; left time: 6.8595s
	iters: 200, epoch: 7 | loss: 0.9911999
	speed: 0.0086s/iter; left time: 5.3773s
Epoch: 7 cost time: 1.8276400566101074
Epoch: 7, Steps: 206 | Train Loss: 0.9997619 Vali Loss: 1.0165715 Test Loss: 1.0030863
Validation loss decreased (1.016848 --> 1.016572).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9963549
	speed: 0.0095s/iter; left time: 4.9226s
	iters: 200, epoch: 8 | loss: 1.0189921
	speed: 0.0086s/iter; left time: 3.6021s
Epoch: 8 cost time: 1.8329112529754639
Epoch: 8, Steps: 206 | Train Loss: 0.9989244 Vali Loss: 1.0162582 Test Loss: 1.0030417
Validation loss decreased (1.016572 --> 1.016258).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0367786
	speed: 0.0096s/iter; left time: 2.9901s
	iters: 200, epoch: 9 | loss: 0.9959030
	speed: 0.0086s/iter; left time: 1.8422s
Epoch: 9 cost time: 1.849123477935791
Epoch: 9, Steps: 206 | Train Loss: 0.9992628 Vali Loss: 1.0162469 Test Loss: 1.0030531
Validation loss decreased (1.016258 --> 1.016247).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0139903
	speed: 0.0095s/iter; left time: 1.0194s
	iters: 200, epoch: 10 | loss: 0.9963388
	speed: 0.0086s/iter; left time: 0.0603s
Epoch: 10 cost time: 1.8292112350463867
Epoch: 10, Steps: 206 | Train Loss: 0.9991641 Vali Loss: 1.0162441 Test Loss: 1.0030689
Validation loss decreased (1.016247 --> 1.016244).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0030690431594849, mae:0.8032407164573669
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0148808
	speed: 0.0173s/iter; left time: 31.7620s
Epoch: 1 cost time: 2.25107741355896
Epoch: 1, Steps: 194 | Train Loss: 1.0540239 Vali Loss: 1.0231715 Test Loss: 0.9966714
Validation loss decreased (inf --> 1.023172).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0277897
	speed: 0.0081s/iter; left time: 13.3949s
Epoch: 2 cost time: 1.5039565563201904
Epoch: 2, Steps: 194 | Train Loss: 1.0132697 Vali Loss: 1.0230873 Test Loss: 0.9962488
Validation loss decreased (1.023172 --> 1.023087).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0038714
	speed: 0.0081s/iter; left time: 11.7336s
Epoch: 3 cost time: 1.5148413181304932
Epoch: 3, Steps: 194 | Train Loss: 1.0084176 Vali Loss: 1.0190686 Test Loss: 0.9939541
Validation loss decreased (1.023087 --> 1.019069).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0122648
	speed: 0.0081s/iter; left time: 10.1772s
Epoch: 4 cost time: 1.468834400177002
Epoch: 4, Steps: 194 | Train Loss: 1.0055693 Vali Loss: 1.0182874 Test Loss: 0.9927977
Validation loss decreased (1.019069 --> 1.018287).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0045793
	speed: 0.0067s/iter; left time: 7.1401s
Epoch: 5 cost time: 1.260979413986206
Epoch: 5, Steps: 194 | Train Loss: 1.0040643 Vali Loss: 1.0179368 Test Loss: 0.9919485
Validation loss decreased (1.018287 --> 1.017937).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9909013
	speed: 0.0069s/iter; left time: 5.9845s
Epoch: 6 cost time: 1.2293126583099365
Epoch: 6, Steps: 194 | Train Loss: 1.0036262 Vali Loss: 1.0176508 Test Loss: 0.9918646
Validation loss decreased (1.017937 --> 1.017651).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0046929
	speed: 0.0086s/iter; left time: 5.8506s
Epoch: 7 cost time: 1.4377052783966064
Epoch: 7, Steps: 194 | Train Loss: 1.0031175 Vali Loss: 1.0172219 Test Loss: 0.9916279
Validation loss decreased (1.017651 --> 1.017222).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0029838
	speed: 0.0078s/iter; left time: 3.7848s
Epoch: 8 cost time: 1.352562427520752
Epoch: 8, Steps: 194 | Train Loss: 1.0029290 Vali Loss: 1.0173793 Test Loss: 0.9916117
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9788334
	speed: 0.0089s/iter; left time: 2.5607s
Epoch: 9 cost time: 1.7131195068359375
Epoch: 9, Steps: 194 | Train Loss: 1.0028826 Vali Loss: 1.0173888 Test Loss: 0.9916189
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0018271
	speed: 0.0093s/iter; left time: 0.8797s
Epoch: 10 cost time: 1.7123067378997803
Epoch: 10, Steps: 194 | Train Loss: 1.0026597 Vali Loss: 1.0172987 Test Loss: 0.9916198
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9916279911994934, mae:0.7990961670875549
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0044190
	speed: 0.0079s/iter; left time: 14.6242s
Epoch: 1 cost time: 1.441819190979004
Epoch: 1, Steps: 194 | Train Loss: 1.0572024 Vali Loss: 1.0246205 Test Loss: 0.9975702
Validation loss decreased (inf --> 1.024621).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0188944
	speed: 0.0097s/iter; left time: 15.9683s
Epoch: 2 cost time: 1.7731249332427979
Epoch: 2, Steps: 194 | Train Loss: 1.0127958 Vali Loss: 1.0214623 Test Loss: 0.9962496
Validation loss decreased (1.024621 --> 1.021462).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0256852
	speed: 0.0092s/iter; left time: 13.4379s
Epoch: 3 cost time: 1.7281463146209717
Epoch: 3, Steps: 194 | Train Loss: 1.0077223 Vali Loss: 1.0182196 Test Loss: 0.9937343
Validation loss decreased (1.021462 --> 1.018220).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0199937
	speed: 0.0093s/iter; left time: 11.6505s
Epoch: 4 cost time: 1.723900318145752
Epoch: 4, Steps: 194 | Train Loss: 1.0052772 Vali Loss: 1.0183107 Test Loss: 0.9926475
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9950983
	speed: 0.0073s/iter; left time: 7.7596s
Epoch: 5 cost time: 1.3597488403320312
Epoch: 5, Steps: 194 | Train Loss: 1.0036912 Vali Loss: 1.0172002 Test Loss: 0.9918244
Validation loss decreased (1.018220 --> 1.017200).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0122724
	speed: 0.0084s/iter; left time: 7.3012s
Epoch: 6 cost time: 1.5283541679382324
Epoch: 6, Steps: 194 | Train Loss: 1.0029518 Vali Loss: 1.0175581 Test Loss: 0.9917942
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0051847
	speed: 0.0090s/iter; left time: 6.0731s
Epoch: 7 cost time: 1.6986031532287598
Epoch: 7, Steps: 194 | Train Loss: 1.0026305 Vali Loss: 1.0171545 Test Loss: 0.9917156
Validation loss decreased (1.017200 --> 1.017154).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0035188
	speed: 0.0075s/iter; left time: 3.6459s
Epoch: 8 cost time: 1.3777337074279785
Epoch: 8, Steps: 194 | Train Loss: 1.0025028 Vali Loss: 1.0169380 Test Loss: 0.9916279
Validation loss decreased (1.017154 --> 1.016938).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0046449
	speed: 0.0077s/iter; left time: 2.2326s
Epoch: 9 cost time: 1.3811061382293701
Epoch: 9, Steps: 194 | Train Loss: 1.0021749 Vali Loss: 1.0170058 Test Loss: 0.9916152
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9920770
	speed: 0.0094s/iter; left time: 0.8916s
Epoch: 10 cost time: 1.7175545692443848
Epoch: 10, Steps: 194 | Train Loss: 1.0022725 Vali Loss: 1.0169442 Test Loss: 0.9916133
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9916278123855591, mae:0.7991133332252502
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0068078
	speed: 0.0096s/iter; left time: 17.7266s
Epoch: 1 cost time: 1.7578599452972412
Epoch: 1, Steps: 194 | Train Loss: 1.0568087 Vali Loss: 1.0255213 Test Loss: 0.9972609
Validation loss decreased (inf --> 1.025521).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0053846
	speed: 0.0078s/iter; left time: 12.8566s
Epoch: 2 cost time: 1.4040555953979492
Epoch: 2, Steps: 194 | Train Loss: 1.0128132 Vali Loss: 1.0198325 Test Loss: 0.9951711
Validation loss decreased (1.025521 --> 1.019832).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0009243
	speed: 0.0079s/iter; left time: 11.4824s
Epoch: 3 cost time: 1.40903639793396
Epoch: 3, Steps: 194 | Train Loss: 1.0077219 Vali Loss: 1.0187461 Test Loss: 0.9941946
Validation loss decreased (1.019832 --> 1.018746).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0318611
	speed: 0.0093s/iter; left time: 11.6754s
Epoch: 4 cost time: 1.7386868000030518
Epoch: 4, Steps: 194 | Train Loss: 1.0054391 Vali Loss: 1.0162072 Test Loss: 0.9924690
Validation loss decreased (1.018746 --> 1.016207).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0012090
	speed: 0.0096s/iter; left time: 10.2662s
Epoch: 5 cost time: 1.7611057758331299
Epoch: 5, Steps: 194 | Train Loss: 1.0036933 Vali Loss: 1.0169344 Test Loss: 0.9920613
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0010550
	speed: 0.0094s/iter; left time: 8.1778s
Epoch: 6 cost time: 1.7247035503387451
Epoch: 6, Steps: 194 | Train Loss: 1.0031849 Vali Loss: 1.0171964 Test Loss: 0.9919153
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0100815
	speed: 0.0095s/iter; left time: 6.4362s
Epoch: 7 cost time: 1.7552077770233154
Epoch: 7, Steps: 194 | Train Loss: 1.0026827 Vali Loss: 1.0166587 Test Loss: 0.9918657
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9971478
	speed: 0.0095s/iter; left time: 4.5807s
Epoch: 8 cost time: 1.7492761611938477
Epoch: 8, Steps: 194 | Train Loss: 1.0023291 Vali Loss: 1.0169191 Test Loss: 0.9918140
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0119411
	speed: 0.0099s/iter; left time: 2.8470s
Epoch: 9 cost time: 1.8150150775909424
Epoch: 9, Steps: 194 | Train Loss: 1.0023643 Vali Loss: 1.0167396 Test Loss: 0.9918023
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9924688339233398, mae:0.7994328737258911
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0350012
	speed: 0.0154s/iter; left time: 31.2603s
	iters: 200, epoch: 1 | loss: 1.0090060
	speed: 0.0109s/iter; left time: 21.1205s
Epoch: 1 cost time: 2.307856321334839
Epoch: 1, Steps: 213 | Train Loss: 1.0646314 Vali Loss: 1.0313795 Test Loss: 1.0171643
Validation loss decreased (inf --> 1.031379).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0047791
	speed: 0.0066s/iter; left time: 11.9375s
	iters: 200, epoch: 2 | loss: 1.0262259
	speed: 0.0056s/iter; left time: 9.6212s
Epoch: 2 cost time: 1.2330422401428223
Epoch: 2, Steps: 213 | Train Loss: 1.0099596 Vali Loss: 1.0348407 Test Loss: 1.0189354
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0046290
	speed: 0.0056s/iter; left time: 8.9386s
	iters: 200, epoch: 3 | loss: 1.0336951
	speed: 0.0051s/iter; left time: 7.6212s
Epoch: 3 cost time: 1.1281771659851074
Epoch: 3, Steps: 213 | Train Loss: 1.0005960 Vali Loss: 1.0277309 Test Loss: 1.0157373
Validation loss decreased (1.031379 --> 1.027731).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9792217
	speed: 0.0080s/iter; left time: 11.2037s
	iters: 200, epoch: 4 | loss: 1.0304556
	speed: 0.0072s/iter; left time: 9.3384s
Epoch: 4 cost time: 1.5842807292938232
Epoch: 4, Steps: 213 | Train Loss: 0.9953753 Vali Loss: 1.0311450 Test Loss: 1.0169088
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0282904
	speed: 0.0063s/iter; left time: 7.4714s
	iters: 200, epoch: 5 | loss: 0.9438639
	speed: 0.0055s/iter; left time: 5.9665s
Epoch: 5 cost time: 1.218721866607666
Epoch: 5, Steps: 213 | Train Loss: 0.9925223 Vali Loss: 1.0285406 Test Loss: 1.0155911
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0144072
	speed: 0.0068s/iter; left time: 6.5353s
	iters: 200, epoch: 6 | loss: 0.9844477
	speed: 0.0062s/iter; left time: 5.3822s
Epoch: 6 cost time: 1.349243402481079
Epoch: 6, Steps: 213 | Train Loss: 0.9906350 Vali Loss: 1.0273117 Test Loss: 1.0154319
Validation loss decreased (1.027731 --> 1.027312).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9994191
	speed: 0.0070s/iter; left time: 5.2475s
	iters: 200, epoch: 7 | loss: 1.0209587
	speed: 0.0063s/iter; left time: 4.0892s
Epoch: 7 cost time: 1.3913249969482422
Epoch: 7, Steps: 213 | Train Loss: 0.9895910 Vali Loss: 1.0292908 Test Loss: 1.0157297
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0080926
	speed: 0.0069s/iter; left time: 3.7102s
	iters: 200, epoch: 8 | loss: 0.9668179
	speed: 0.0064s/iter; left time: 2.8323s
Epoch: 8 cost time: 1.4148988723754883
Epoch: 8, Steps: 213 | Train Loss: 0.9894462 Vali Loss: 1.0270118 Test Loss: 1.0156491
Validation loss decreased (1.027312 --> 1.027012).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9668564
	speed: 0.0090s/iter; left time: 2.9498s
	iters: 200, epoch: 9 | loss: 0.9468082
	speed: 0.0077s/iter; left time: 1.7589s
Epoch: 9 cost time: 1.6883223056793213
Epoch: 9, Steps: 213 | Train Loss: 0.9894012 Vali Loss: 1.0289032 Test Loss: 1.0157293
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9746010
	speed: 0.0061s/iter; left time: 0.6978s
	iters: 200, epoch: 10 | loss: 1.0690699
	speed: 0.0055s/iter; left time: 0.0777s
Epoch: 10 cost time: 1.2324299812316895
Epoch: 10, Steps: 213 | Train Loss: 0.9886629 Vali Loss: 1.0291921 Test Loss: 1.0157470
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0156490802764893, mae:0.808510422706604
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0662514
	speed: 0.0093s/iter; left time: 18.8180s
	iters: 200, epoch: 1 | loss: 0.9996943
	speed: 0.0083s/iter; left time: 16.0936s
Epoch: 1 cost time: 1.8228561878204346
Epoch: 1, Steps: 213 | Train Loss: 1.0637838 Vali Loss: 1.0339411 Test Loss: 1.0171201
Validation loss decreased (inf --> 1.033941).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0053968
	speed: 0.0083s/iter; left time: 15.0775s
	iters: 200, epoch: 2 | loss: 1.0355544
	speed: 0.0074s/iter; left time: 12.6577s
Epoch: 2 cost time: 1.6053810119628906
Epoch: 2, Steps: 213 | Train Loss: 1.0098301 Vali Loss: 1.0374265 Test Loss: 1.0211186
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0150230
	speed: 0.0079s/iter; left time: 12.6497s
	iters: 200, epoch: 3 | loss: 1.0421233
	speed: 0.0071s/iter; left time: 10.6733s
Epoch: 3 cost time: 1.5538251399993896
Epoch: 3, Steps: 213 | Train Loss: 1.0002427 Vali Loss: 1.0368991 Test Loss: 1.0189202
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0169463
	speed: 0.0057s/iter; left time: 7.9200s
	iters: 200, epoch: 4 | loss: 1.0077255
	speed: 0.0057s/iter; left time: 7.3611s
Epoch: 4 cost time: 1.2639708518981934
Epoch: 4, Steps: 213 | Train Loss: 0.9952968 Vali Loss: 1.0288178 Test Loss: 1.0157962
Validation loss decreased (1.033941 --> 1.028818).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0083632
	speed: 0.0066s/iter; left time: 7.7929s
	iters: 200, epoch: 5 | loss: 0.9926581
	speed: 0.0060s/iter; left time: 6.4204s
Epoch: 5 cost time: 1.3133463859558105
Epoch: 5, Steps: 213 | Train Loss: 0.9920663 Vali Loss: 1.0256146 Test Loss: 1.0149994
Validation loss decreased (1.028818 --> 1.025615).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9863281
	speed: 0.0077s/iter; left time: 7.3961s
	iters: 200, epoch: 6 | loss: 0.9558107
	speed: 0.0069s/iter; left time: 6.0103s
Epoch: 6 cost time: 1.5193710327148438
Epoch: 6, Steps: 213 | Train Loss: 0.9904430 Vali Loss: 1.0271089 Test Loss: 1.0153974
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9720888
	speed: 0.0074s/iter; left time: 5.5810s
	iters: 200, epoch: 7 | loss: 0.9523364
	speed: 0.0068s/iter; left time: 4.4659s
Epoch: 7 cost time: 1.505356788635254
Epoch: 7, Steps: 213 | Train Loss: 0.9897520 Vali Loss: 1.0274022 Test Loss: 1.0152532
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9717917
	speed: 0.0065s/iter; left time: 3.4880s
	iters: 200, epoch: 8 | loss: 0.9796740
	speed: 0.0056s/iter; left time: 2.4661s
Epoch: 8 cost time: 1.2313199043273926
Epoch: 8, Steps: 213 | Train Loss: 0.9887848 Vali Loss: 1.0293807 Test Loss: 1.0155187
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9840497
	speed: 0.0059s/iter; left time: 1.9391s
	iters: 200, epoch: 9 | loss: 0.9922036
	speed: 0.0053s/iter; left time: 1.2102s
Epoch: 9 cost time: 1.180243730545044
Epoch: 9, Steps: 213 | Train Loss: 0.9885072 Vali Loss: 1.0267929 Test Loss: 1.0156337
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0306543
	speed: 0.0066s/iter; left time: 0.7510s
	iters: 200, epoch: 10 | loss: 0.9613080
	speed: 0.0061s/iter; left time: 0.0853s
Epoch: 10 cost time: 1.3572192192077637
Epoch: 10, Steps: 213 | Train Loss: 0.9884367 Vali Loss: 1.0281231 Test Loss: 1.0156496
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.014999270439148, mae:0.8081233501434326
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0451374
	speed: 0.0086s/iter; left time: 17.4175s
	iters: 200, epoch: 1 | loss: 1.0366055
	speed: 0.0081s/iter; left time: 15.5647s
Epoch: 1 cost time: 1.7716617584228516
Epoch: 1, Steps: 213 | Train Loss: 1.0636811 Vali Loss: 1.0387508 Test Loss: 1.0201792
Validation loss decreased (inf --> 1.038751).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0288711
	speed: 0.0094s/iter; left time: 17.0405s
	iters: 200, epoch: 2 | loss: 1.0291984
	speed: 0.0084s/iter; left time: 14.5160s
Epoch: 2 cost time: 1.8544394969940186
Epoch: 2, Steps: 213 | Train Loss: 1.0091776 Vali Loss: 1.0358402 Test Loss: 1.0196903
Validation loss decreased (1.038751 --> 1.035840).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0023842
	speed: 0.0091s/iter; left time: 14.5782s
	iters: 200, epoch: 3 | loss: 0.9969354
	speed: 0.0081s/iter; left time: 12.1441s
Epoch: 3 cost time: 1.7675485610961914
Epoch: 3, Steps: 213 | Train Loss: 1.0003425 Vali Loss: 1.0328480 Test Loss: 1.0171456
Validation loss decreased (1.035840 --> 1.032848).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9721195
	speed: 0.0069s/iter; left time: 9.6734s
	iters: 200, epoch: 4 | loss: 1.0087640
	speed: 0.0064s/iter; left time: 8.2063s
Epoch: 4 cost time: 1.4069690704345703
Epoch: 4, Steps: 213 | Train Loss: 0.9950824 Vali Loss: 1.0306163 Test Loss: 1.0161694
Validation loss decreased (1.032848 --> 1.030616).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0283116
	speed: 0.0086s/iter; left time: 10.1637s
	iters: 200, epoch: 5 | loss: 0.9859638
	speed: 0.0075s/iter; left time: 8.1095s
Epoch: 5 cost time: 1.6319663524627686
Epoch: 5, Steps: 213 | Train Loss: 0.9920349 Vali Loss: 1.0269054 Test Loss: 1.0149833
Validation loss decreased (1.030616 --> 1.026905).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9804257
	speed: 0.0094s/iter; left time: 9.0335s
	iters: 200, epoch: 6 | loss: 0.9980018
	speed: 0.0084s/iter; left time: 7.2903s
Epoch: 6 cost time: 1.8200232982635498
Epoch: 6, Steps: 213 | Train Loss: 0.9905536 Vali Loss: 1.0264874 Test Loss: 1.0150942
Validation loss decreased (1.026905 --> 1.026487).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9440908
	speed: 0.0093s/iter; left time: 7.0330s
	iters: 200, epoch: 7 | loss: 0.9709660
	speed: 0.0084s/iter; left time: 5.5066s
Epoch: 7 cost time: 1.8432414531707764
Epoch: 7, Steps: 213 | Train Loss: 0.9894479 Vali Loss: 1.0286918 Test Loss: 1.0152099
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0314138
	speed: 0.0085s/iter; left time: 4.6037s
	iters: 200, epoch: 8 | loss: 0.9901513
	speed: 0.0073s/iter; left time: 3.2123s
Epoch: 8 cost time: 1.5946998596191406
Epoch: 8, Steps: 213 | Train Loss: 0.9887950 Vali Loss: 1.0272989 Test Loss: 1.0153522
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9820464
	speed: 0.0091s/iter; left time: 2.9758s
	iters: 200, epoch: 9 | loss: 0.9919493
	speed: 0.0084s/iter; left time: 1.8955s
Epoch: 9 cost time: 1.8438634872436523
Epoch: 9, Steps: 213 | Train Loss: 0.9886840 Vali Loss: 1.0282241 Test Loss: 1.0154359
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9615731
	speed: 0.0076s/iter; left time: 0.8633s
	iters: 200, epoch: 10 | loss: 0.9524376
	speed: 0.0067s/iter; left time: 0.0942s
Epoch: 10 cost time: 1.4816696643829346
Epoch: 10, Steps: 213 | Train Loss: 0.9884957 Vali Loss: 1.0268430 Test Loss: 1.0154651
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0150941610336304, mae:0.8082689642906189
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0364494
	speed: 0.0144s/iter; left time: 28.7219s
	iters: 200, epoch: 1 | loss: 0.9979649
	speed: 0.0097s/iter; left time: 18.4842s
Epoch: 1 cost time: 2.0448477268218994
Epoch: 1, Steps: 210 | Train Loss: 1.0599701 Vali Loss: 1.0250694 Test Loss: 1.0172931
Validation loss decreased (inf --> 1.025069).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0217052
	speed: 0.0077s/iter; left time: 13.7936s
	iters: 200, epoch: 2 | loss: 1.0060570
	speed: 0.0070s/iter; left time: 11.8926s
Epoch: 2 cost time: 1.5339345932006836
Epoch: 2, Steps: 210 | Train Loss: 1.0122036 Vali Loss: 1.0233489 Test Loss: 1.0162278
Validation loss decreased (1.025069 --> 1.023349).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9772940
	speed: 0.0070s/iter; left time: 11.1101s
	iters: 200, epoch: 3 | loss: 0.9928777
	speed: 0.0067s/iter; left time: 9.9058s
Epoch: 3 cost time: 1.4440131187438965
Epoch: 3, Steps: 210 | Train Loss: 1.0051564 Vali Loss: 1.0225700 Test Loss: 1.0148742
Validation loss decreased (1.023349 --> 1.022570).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0162157
	speed: 0.0075s/iter; left time: 10.3114s
	iters: 200, epoch: 4 | loss: 0.9960612
	speed: 0.0065s/iter; left time: 8.2374s
Epoch: 4 cost time: 1.3901617527008057
Epoch: 4, Steps: 210 | Train Loss: 1.0012363 Vali Loss: 1.0196435 Test Loss: 1.0133352
Validation loss decreased (1.022570 --> 1.019644).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9914932
	speed: 0.0074s/iter; left time: 8.5848s
	iters: 200, epoch: 5 | loss: 1.0007365
	speed: 0.0065s/iter; left time: 6.9273s
Epoch: 5 cost time: 1.4215972423553467
Epoch: 5, Steps: 210 | Train Loss: 0.9987774 Vali Loss: 1.0204457 Test Loss: 1.0141152
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9895042
	speed: 0.0060s/iter; left time: 5.6855s
	iters: 200, epoch: 6 | loss: 1.0017575
	speed: 0.0053s/iter; left time: 4.5451s
Epoch: 6 cost time: 1.1603362560272217
Epoch: 6, Steps: 210 | Train Loss: 0.9975996 Vali Loss: 1.0192846 Test Loss: 1.0136954
Validation loss decreased (1.019644 --> 1.019285).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0039833
	speed: 0.0064s/iter; left time: 4.7227s
	iters: 200, epoch: 7 | loss: 1.0190085
	speed: 0.0055s/iter; left time: 3.5205s
Epoch: 7 cost time: 1.1936922073364258
Epoch: 7, Steps: 210 | Train Loss: 0.9967472 Vali Loss: 1.0199020 Test Loss: 1.0136772
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9706404
	speed: 0.0074s/iter; left time: 3.9546s
	iters: 200, epoch: 8 | loss: 0.9555451
	speed: 0.0072s/iter; left time: 3.1130s
Epoch: 8 cost time: 1.5743389129638672
Epoch: 8, Steps: 210 | Train Loss: 0.9961769 Vali Loss: 1.0181309 Test Loss: 1.0136728
Validation loss decreased (1.019285 --> 1.018131).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0043693
	speed: 0.0077s/iter; left time: 2.4651s
	iters: 200, epoch: 9 | loss: 1.0094852
	speed: 0.0062s/iter; left time: 1.3729s
Epoch: 9 cost time: 1.3484320640563965
Epoch: 9, Steps: 210 | Train Loss: 0.9962783 Vali Loss: 1.0195359 Test Loss: 1.0136957
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0108784
	speed: 0.0075s/iter; left time: 0.8275s
	iters: 200, epoch: 10 | loss: 0.9974513
	speed: 0.0067s/iter; left time: 0.0739s
Epoch: 10 cost time: 1.449836015701294
Epoch: 10, Steps: 210 | Train Loss: 0.9962123 Vali Loss: 1.0195647 Test Loss: 1.0137247
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0136725902557373, mae:0.8072089552879333
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0345072
	speed: 0.0070s/iter; left time: 13.9506s
	iters: 200, epoch: 1 | loss: 1.0101240
	speed: 0.0063s/iter; left time: 11.8980s
Epoch: 1 cost time: 1.3567626476287842
Epoch: 1, Steps: 210 | Train Loss: 1.0588851 Vali Loss: 1.0280060 Test Loss: 1.0177214
Validation loss decreased (inf --> 1.028006).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0232139
	speed: 0.0075s/iter; left time: 13.3720s
	iters: 200, epoch: 2 | loss: 1.0039170
	speed: 0.0066s/iter; left time: 11.1567s
Epoch: 2 cost time: 1.4250710010528564
Epoch: 2, Steps: 210 | Train Loss: 1.0127103 Vali Loss: 1.0226266 Test Loss: 1.0155444
Validation loss decreased (1.028006 --> 1.022627).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0207745
	speed: 0.0088s/iter; left time: 13.8497s
	iters: 200, epoch: 3 | loss: 1.0213032
	speed: 0.0076s/iter; left time: 11.2514s
Epoch: 3 cost time: 1.6359224319458008
Epoch: 3, Steps: 210 | Train Loss: 1.0048119 Vali Loss: 1.0225098 Test Loss: 1.0151399
Validation loss decreased (1.022627 --> 1.022510).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9731439
	speed: 0.0084s/iter; left time: 11.5787s
	iters: 200, epoch: 4 | loss: 1.0163245
	speed: 0.0080s/iter; left time: 10.2039s
Epoch: 4 cost time: 1.7499198913574219
Epoch: 4, Steps: 210 | Train Loss: 1.0011439 Vali Loss: 1.0192618 Test Loss: 1.0138665
Validation loss decreased (1.022510 --> 1.019262).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9769365
	speed: 0.0094s/iter; left time: 10.9031s
	iters: 200, epoch: 5 | loss: 1.0011585
	speed: 0.0085s/iter; left time: 9.0202s
Epoch: 5 cost time: 1.842470407485962
Epoch: 5, Steps: 210 | Train Loss: 0.9989560 Vali Loss: 1.0199306 Test Loss: 1.0141101
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9921330
	speed: 0.0092s/iter; left time: 8.7723s
	iters: 200, epoch: 6 | loss: 0.9892747
	speed: 0.0084s/iter; left time: 7.1419s
Epoch: 6 cost time: 1.8213324546813965
Epoch: 6, Steps: 210 | Train Loss: 0.9973790 Vali Loss: 1.0194615 Test Loss: 1.0140854
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9929931
	speed: 0.0092s/iter; left time: 6.7807s
	iters: 200, epoch: 7 | loss: 1.0044937
	speed: 0.0084s/iter; left time: 5.3583s
Epoch: 7 cost time: 1.8019218444824219
Epoch: 7, Steps: 210 | Train Loss: 0.9968579 Vali Loss: 1.0205714 Test Loss: 1.0141315
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9997025
	speed: 0.0092s/iter; left time: 4.8641s
	iters: 200, epoch: 8 | loss: 0.9862790
	speed: 0.0084s/iter; left time: 3.6159s
Epoch: 8 cost time: 1.8195421695709229
Epoch: 8, Steps: 210 | Train Loss: 0.9962254 Vali Loss: 1.0201132 Test Loss: 1.0140920
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9773706
	speed: 0.0092s/iter; left time: 2.9575s
	iters: 200, epoch: 9 | loss: 0.9990630
	speed: 0.0084s/iter; left time: 1.8581s
Epoch: 9 cost time: 1.8362505435943604
Epoch: 9, Steps: 210 | Train Loss: 0.9959899 Vali Loss: 1.0190854 Test Loss: 1.0141295
Validation loss decreased (1.019262 --> 1.019085).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0008205
	speed: 0.0093s/iter; left time: 1.0367s
	iters: 200, epoch: 10 | loss: 1.0065374
	speed: 0.0084s/iter; left time: 0.0929s
Epoch: 10 cost time: 1.8334686756134033
Epoch: 10, Steps: 210 | Train Loss: 0.9957580 Vali Loss: 1.0196118 Test Loss: 1.0141553
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.014129638671875, mae:0.8073880672454834
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0198168
	speed: 0.0094s/iter; left time: 18.8060s
	iters: 200, epoch: 1 | loss: 1.0116291
	speed: 0.0085s/iter; left time: 16.1955s
Epoch: 1 cost time: 1.8569588661193848
Epoch: 1, Steps: 210 | Train Loss: 1.0571190 Vali Loss: 1.0260917 Test Loss: 1.0176783
Validation loss decreased (inf --> 1.026092).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9940729
	speed: 0.0095s/iter; left time: 17.0518s
	iters: 200, epoch: 2 | loss: 1.0323408
	speed: 0.0086s/iter; left time: 14.4863s
Epoch: 2 cost time: 1.8500659465789795
Epoch: 2, Steps: 210 | Train Loss: 1.0120840 Vali Loss: 1.0228486 Test Loss: 1.0159297
Validation loss decreased (1.026092 --> 1.022849).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9642745
	speed: 0.0091s/iter; left time: 14.4661s
	iters: 200, epoch: 3 | loss: 0.9927664
	speed: 0.0078s/iter; left time: 11.5245s
Epoch: 3 cost time: 1.6718430519104004
Epoch: 3, Steps: 210 | Train Loss: 1.0052692 Vali Loss: 1.0208369 Test Loss: 1.0145167
Validation loss decreased (1.022849 --> 1.020837).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0057817
	speed: 0.0086s/iter; left time: 11.7801s
	iters: 200, epoch: 4 | loss: 0.9976341
	speed: 0.0080s/iter; left time: 10.2214s
Epoch: 4 cost time: 1.7432191371917725
Epoch: 4, Steps: 210 | Train Loss: 1.0010385 Vali Loss: 1.0201974 Test Loss: 1.0142741
Validation loss decreased (1.020837 --> 1.020197).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0080549
	speed: 0.0088s/iter; left time: 10.2027s
	iters: 200, epoch: 5 | loss: 1.0022029
	speed: 0.0076s/iter; left time: 8.1080s
Epoch: 5 cost time: 1.6718945503234863
Epoch: 5, Steps: 210 | Train Loss: 0.9988077 Vali Loss: 1.0182128 Test Loss: 1.0136597
Validation loss decreased (1.020197 --> 1.018213).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0171663
	speed: 0.0078s/iter; left time: 7.4419s
	iters: 200, epoch: 6 | loss: 0.9881765
	speed: 0.0072s/iter; left time: 6.1138s
Epoch: 6 cost time: 1.5775115489959717
Epoch: 6, Steps: 210 | Train Loss: 0.9975357 Vali Loss: 1.0192374 Test Loss: 1.0138310
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9901578
	speed: 0.0075s/iter; left time: 5.5408s
	iters: 200, epoch: 7 | loss: 0.9735462
	speed: 0.0067s/iter; left time: 4.2749s
Epoch: 7 cost time: 1.4471402168273926
Epoch: 7, Steps: 210 | Train Loss: 0.9968377 Vali Loss: 1.0185298 Test Loss: 1.0137693
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9706838
	speed: 0.0091s/iter; left time: 4.8471s
	iters: 200, epoch: 8 | loss: 0.9890431
	speed: 0.0083s/iter; left time: 3.5826s
Epoch: 8 cost time: 1.7997651100158691
Epoch: 8, Steps: 210 | Train Loss: 0.9967407 Vali Loss: 1.0191138 Test Loss: 1.0137461
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0150678
	speed: 0.0076s/iter; left time: 2.4380s
	iters: 200, epoch: 9 | loss: 0.9948255
	speed: 0.0067s/iter; left time: 1.4891s
Epoch: 9 cost time: 1.4568281173706055
Epoch: 9, Steps: 210 | Train Loss: 0.9963138 Vali Loss: 1.0199336 Test Loss: 1.0137877
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9912884
	speed: 0.0082s/iter; left time: 0.9156s
	iters: 200, epoch: 10 | loss: 0.9914510
	speed: 0.0068s/iter; left time: 0.0747s
Epoch: 10 cost time: 1.4524178504943848
Epoch: 10, Steps: 210 | Train Loss: 0.9961360 Vali Loss: 1.0197217 Test Loss: 1.0138202
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0136597156524658, mae:0.8071942925453186
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0355772
	speed: 0.0143s/iter; left time: 27.9931s
	iters: 200, epoch: 1 | loss: 1.0375136
	speed: 0.0102s/iter; left time: 18.9675s
Epoch: 1 cost time: 2.124526023864746
Epoch: 1, Steps: 206 | Train Loss: 1.0566925 Vali Loss: 1.0241644 Test Loss: 1.0075259
Validation loss decreased (inf --> 1.024164).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0218568
	speed: 0.0083s/iter; left time: 14.5650s
	iters: 200, epoch: 2 | loss: 1.0197407
	speed: 0.0080s/iter; left time: 13.1651s
Epoch: 2 cost time: 1.6962461471557617
Epoch: 2, Steps: 206 | Train Loss: 1.0123514 Vali Loss: 1.0213666 Test Loss: 1.0063020
Validation loss decreased (1.024164 --> 1.021367).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0081115
	speed: 0.0089s/iter; left time: 13.7443s
	iters: 200, epoch: 3 | loss: 1.0330607
	speed: 0.0082s/iter; left time: 11.9524s
Epoch: 3 cost time: 1.7573754787445068
Epoch: 3, Steps: 206 | Train Loss: 1.0064136 Vali Loss: 1.0194371 Test Loss: 1.0047441
Validation loss decreased (1.021367 --> 1.019437).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0070987
	speed: 0.0077s/iter; left time: 10.3719s
	iters: 200, epoch: 4 | loss: 0.9936792
	speed: 0.0068s/iter; left time: 8.5121s
Epoch: 4 cost time: 1.458390235900879
Epoch: 4, Steps: 206 | Train Loss: 1.0036286 Vali Loss: 1.0181067 Test Loss: 1.0032660
Validation loss decreased (1.019437 --> 1.018107).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0041498
	speed: 0.0089s/iter; left time: 10.1609s
	iters: 200, epoch: 5 | loss: 1.0012704
	speed: 0.0083s/iter; left time: 8.5869s
Epoch: 5 cost time: 1.7518551349639893
Epoch: 5, Steps: 206 | Train Loss: 1.0016202 Vali Loss: 1.0161269 Test Loss: 1.0027742
Validation loss decreased (1.018107 --> 1.016127).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9900960
	speed: 0.0094s/iter; left time: 8.7617s
	iters: 200, epoch: 6 | loss: 1.0021799
	speed: 0.0085s/iter; left time: 7.0553s
Epoch: 6 cost time: 1.791515588760376
Epoch: 6, Steps: 206 | Train Loss: 1.0003362 Vali Loss: 1.0167656 Test Loss: 1.0027993
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0112147
	speed: 0.0094s/iter; left time: 6.7794s
	iters: 200, epoch: 7 | loss: 0.9977123
	speed: 0.0085s/iter; left time: 5.3211s
Epoch: 7 cost time: 1.8199410438537598
Epoch: 7, Steps: 206 | Train Loss: 1.0000912 Vali Loss: 1.0161192 Test Loss: 1.0025847
Validation loss decreased (1.016127 --> 1.016119).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9954035
	speed: 0.0076s/iter; left time: 3.9599s
	iters: 200, epoch: 8 | loss: 0.9917426
	speed: 0.0071s/iter; left time: 2.9568s
Epoch: 8 cost time: 1.5162146091461182
Epoch: 8, Steps: 206 | Train Loss: 0.9996652 Vali Loss: 1.0162466 Test Loss: 1.0026120
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0027753
	speed: 0.0074s/iter; left time: 2.3217s
	iters: 200, epoch: 9 | loss: 1.0122428
	speed: 0.0067s/iter; left time: 1.4271s
Epoch: 9 cost time: 1.43681001663208
Epoch: 9, Steps: 206 | Train Loss: 0.9996524 Vali Loss: 1.0163034 Test Loss: 1.0025983
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0088047
	speed: 0.0079s/iter; left time: 0.8470s
	iters: 200, epoch: 10 | loss: 0.9940603
	speed: 0.0069s/iter; left time: 0.0484s
Epoch: 10 cost time: 1.4667456150054932
Epoch: 10, Steps: 206 | Train Loss: 0.9994641 Vali Loss: 1.0161867 Test Loss: 1.0026067
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0025849342346191, mae:0.8030402660369873
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0300326
	speed: 0.0091s/iter; left time: 17.7581s
	iters: 200, epoch: 1 | loss: 1.0204340
	speed: 0.0083s/iter; left time: 15.5058s
Epoch: 1 cost time: 1.783738613128662
Epoch: 1, Steps: 206 | Train Loss: 1.0542634 Vali Loss: 1.0203015 Test Loss: 1.0072920
Validation loss decreased (inf --> 1.020301).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0150833
	speed: 0.0094s/iter; left time: 16.4946s
	iters: 200, epoch: 2 | loss: 1.0240935
	speed: 0.0085s/iter; left time: 14.0185s
Epoch: 2 cost time: 1.7953495979309082
Epoch: 2, Steps: 206 | Train Loss: 1.0122894 Vali Loss: 1.0193373 Test Loss: 1.0053974
Validation loss decreased (1.020301 --> 1.019337).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9975879
	speed: 0.0093s/iter; left time: 14.4236s
	iters: 200, epoch: 3 | loss: 1.0065596
	speed: 0.0085s/iter; left time: 12.2601s
Epoch: 3 cost time: 1.7955529689788818
Epoch: 3, Steps: 206 | Train Loss: 1.0064686 Vali Loss: 1.0178894 Test Loss: 1.0041726
Validation loss decreased (1.019337 --> 1.017889).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9885479
	speed: 0.0094s/iter; left time: 12.6844s
	iters: 200, epoch: 4 | loss: 1.0328680
	speed: 0.0086s/iter; left time: 10.6278s
Epoch: 4 cost time: 1.8229217529296875
Epoch: 4, Steps: 206 | Train Loss: 1.0032903 Vali Loss: 1.0184580 Test Loss: 1.0038666
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9997078
	speed: 0.0095s/iter; left time: 10.7937s
	iters: 200, epoch: 5 | loss: 1.0011995
	speed: 0.0086s/iter; left time: 8.8993s
Epoch: 5 cost time: 1.8226966857910156
Epoch: 5, Steps: 206 | Train Loss: 1.0015667 Vali Loss: 1.0171584 Test Loss: 1.0031661
Validation loss decreased (1.017889 --> 1.017158).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9967523
	speed: 0.0095s/iter; left time: 8.8125s
	iters: 200, epoch: 6 | loss: 1.0012412
	speed: 0.0086s/iter; left time: 7.1315s
Epoch: 6 cost time: 1.843925952911377
Epoch: 6, Steps: 206 | Train Loss: 1.0006160 Vali Loss: 1.0162141 Test Loss: 1.0027797
Validation loss decreased (1.017158 --> 1.016214).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9936920
	speed: 0.0094s/iter; left time: 6.8413s
	iters: 200, epoch: 7 | loss: 1.0163920
	speed: 0.0087s/iter; left time: 5.4168s
Epoch: 7 cost time: 1.8508765697479248
Epoch: 7, Steps: 206 | Train Loss: 1.0003108 Vali Loss: 1.0167477 Test Loss: 1.0028067
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9989395
	speed: 0.0094s/iter; left time: 4.8936s
	iters: 200, epoch: 8 | loss: 0.9827858
	speed: 0.0086s/iter; left time: 3.5830s
Epoch: 8 cost time: 1.8140466213226318
Epoch: 8, Steps: 206 | Train Loss: 0.9999480 Vali Loss: 1.0164039 Test Loss: 1.0027803
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9934389
	speed: 0.0093s/iter; left time: 2.9094s
	iters: 200, epoch: 9 | loss: 1.0010562
	speed: 0.0085s/iter; left time: 1.8068s
Epoch: 9 cost time: 1.8130097389221191
Epoch: 9, Steps: 206 | Train Loss: 0.9995136 Vali Loss: 1.0163580 Test Loss: 1.0027746
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9856431
	speed: 0.0093s/iter; left time: 0.9901s
	iters: 200, epoch: 10 | loss: 0.9919572
	speed: 0.0085s/iter; left time: 0.0592s
Epoch: 10 cost time: 1.8023135662078857
Epoch: 10, Steps: 206 | Train Loss: 0.9997500 Vali Loss: 1.0164752 Test Loss: 1.0027821
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0027797222137451, mae:0.8031109571456909
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0367632
	speed: 0.0095s/iter; left time: 18.6631s
	iters: 200, epoch: 1 | loss: 1.0059439
	speed: 0.0086s/iter; left time: 15.9309s
Epoch: 1 cost time: 1.8134713172912598
Epoch: 1, Steps: 206 | Train Loss: 1.0581497 Vali Loss: 1.0225915 Test Loss: 1.0077212
Validation loss decreased (inf --> 1.022591).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0226855
	speed: 0.0081s/iter; left time: 14.1736s
	iters: 200, epoch: 2 | loss: 1.0276200
	speed: 0.0079s/iter; left time: 13.0280s
Epoch: 2 cost time: 1.686774730682373
Epoch: 2, Steps: 206 | Train Loss: 1.0123637 Vali Loss: 1.0231860 Test Loss: 1.0074217
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9966598
	speed: 0.0092s/iter; left time: 14.2541s
	iters: 200, epoch: 3 | loss: 1.0055716
	speed: 0.0084s/iter; left time: 12.1950s
Epoch: 3 cost time: 1.7874646186828613
Epoch: 3, Steps: 206 | Train Loss: 1.0061698 Vali Loss: 1.0181925 Test Loss: 1.0045134
Validation loss decreased (1.022591 --> 1.018193).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0009503
	speed: 0.0094s/iter; left time: 12.6328s
	iters: 200, epoch: 4 | loss: 1.0024333
	speed: 0.0085s/iter; left time: 10.5793s
Epoch: 4 cost time: 1.8114547729492188
Epoch: 4, Steps: 206 | Train Loss: 1.0031142 Vali Loss: 1.0165427 Test Loss: 1.0037174
Validation loss decreased (1.018193 --> 1.016543).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9960583
	speed: 0.0071s/iter; left time: 8.0742s
	iters: 200, epoch: 5 | loss: 1.0177407
	speed: 0.0070s/iter; left time: 7.2628s
Epoch: 5 cost time: 1.4973962306976318
Epoch: 5, Steps: 206 | Train Loss: 1.0012098 Vali Loss: 1.0162429 Test Loss: 1.0030149
Validation loss decreased (1.016543 --> 1.016243).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0102147
	speed: 0.0092s/iter; left time: 8.5991s
	iters: 200, epoch: 6 | loss: 1.0206686
	speed: 0.0084s/iter; left time: 6.9579s
Epoch: 6 cost time: 1.7695355415344238
Epoch: 6, Steps: 206 | Train Loss: 1.0002361 Vali Loss: 1.0168679 Test Loss: 1.0030328
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0065587
	speed: 0.0094s/iter; left time: 6.7986s
	iters: 200, epoch: 7 | loss: 0.9822538
	speed: 0.0085s/iter; left time: 5.3211s
Epoch: 7 cost time: 1.8176963329315186
Epoch: 7, Steps: 206 | Train Loss: 0.9998154 Vali Loss: 1.0165148 Test Loss: 1.0029314
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0081446
	speed: 0.0093s/iter; left time: 4.8017s
	iters: 200, epoch: 8 | loss: 0.9922530
	speed: 0.0085s/iter; left time: 3.5523s
Epoch: 8 cost time: 1.8010380268096924
Epoch: 8, Steps: 206 | Train Loss: 0.9993628 Vali Loss: 1.0163643 Test Loss: 1.0028770
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9852170
	speed: 0.0083s/iter; left time: 2.6063s
	iters: 200, epoch: 9 | loss: 0.9922700
	speed: 0.0075s/iter; left time: 1.5874s
Epoch: 9 cost time: 1.5907399654388428
Epoch: 9, Steps: 206 | Train Loss: 0.9994738 Vali Loss: 1.0164354 Test Loss: 1.0029119
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0163262
	speed: 0.0081s/iter; left time: 0.8650s
	iters: 200, epoch: 10 | loss: 0.9530590
	speed: 0.0069s/iter; left time: 0.0481s
Epoch: 10 cost time: 1.4572129249572754
Epoch: 10, Steps: 206 | Train Loss: 0.9994467 Vali Loss: 1.0163748 Test Loss: 1.0029172
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0030148029327393, mae:0.8031463623046875
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0307798
	speed: 0.0127s/iter; left time: 23.4175s
Epoch: 1 cost time: 1.774972915649414
Epoch: 1, Steps: 194 | Train Loss: 1.0571746 Vali Loss: 1.0223479 Test Loss: 0.9969388
Validation loss decreased (inf --> 1.022348).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0032786
	speed: 0.0066s/iter; left time: 10.9052s
Epoch: 2 cost time: 1.169990062713623
Epoch: 2, Steps: 194 | Train Loss: 1.0129347 Vali Loss: 1.0213858 Test Loss: 0.9954451
Validation loss decreased (1.022348 --> 1.021386).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0248022
	speed: 0.0068s/iter; left time: 9.8469s
Epoch: 3 cost time: 1.2186195850372314
Epoch: 3, Steps: 194 | Train Loss: 1.0078719 Vali Loss: 1.0203897 Test Loss: 0.9936550
Validation loss decreased (1.021386 --> 1.020390).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9997308
	speed: 0.0067s/iter; left time: 8.4650s
Epoch: 4 cost time: 1.2333934307098389
Epoch: 4, Steps: 194 | Train Loss: 1.0054116 Vali Loss: 1.0181980 Test Loss: 0.9922900
Validation loss decreased (1.020390 --> 1.018198).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9986445
	speed: 0.0072s/iter; left time: 7.6570s
Epoch: 5 cost time: 1.3086626529693604
Epoch: 5, Steps: 194 | Train Loss: 1.0041248 Vali Loss: 1.0175271 Test Loss: 0.9919765
Validation loss decreased (1.018198 --> 1.017527).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0041269
	speed: 0.0095s/iter; left time: 8.2897s
Epoch: 6 cost time: 1.763777732849121
Epoch: 6, Steps: 194 | Train Loss: 1.0031877 Vali Loss: 1.0174491 Test Loss: 0.9918516
Validation loss decreased (1.017527 --> 1.017449).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0040725
	speed: 0.0093s/iter; left time: 6.2656s
Epoch: 7 cost time: 1.7275187969207764
Epoch: 7, Steps: 194 | Train Loss: 1.0028436 Vali Loss: 1.0173411 Test Loss: 0.9916589
Validation loss decreased (1.017449 --> 1.017341).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9984462
	speed: 0.0081s/iter; left time: 3.9101s
Epoch: 8 cost time: 1.5047070980072021
Epoch: 8, Steps: 194 | Train Loss: 1.0027393 Vali Loss: 1.0174373 Test Loss: 0.9915960
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0145304
	speed: 0.0090s/iter; left time: 2.5981s
Epoch: 9 cost time: 1.731900930404663
Epoch: 9, Steps: 194 | Train Loss: 1.0025854 Vali Loss: 1.0174476 Test Loss: 0.9916036
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0065162
	speed: 0.0083s/iter; left time: 0.7888s
Epoch: 10 cost time: 1.53322434425354
Epoch: 10, Steps: 194 | Train Loss: 1.0024871 Vali Loss: 1.0174888 Test Loss: 0.9916065
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9916585087776184, mae:0.7991190552711487
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0293722
	speed: 0.0074s/iter; left time: 13.6684s
Epoch: 1 cost time: 1.372267723083496
Epoch: 1, Steps: 194 | Train Loss: 1.0553759 Vali Loss: 1.0257944 Test Loss: 0.9967266
Validation loss decreased (inf --> 1.025794).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0081182
	speed: 0.0096s/iter; left time: 15.7849s
Epoch: 2 cost time: 1.7576689720153809
Epoch: 2, Steps: 194 | Train Loss: 1.0129286 Vali Loss: 1.0203223 Test Loss: 0.9952563
Validation loss decreased (1.025794 --> 1.020322).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0187782
	speed: 0.0094s/iter; left time: 13.6905s
Epoch: 3 cost time: 1.6339788436889648
Epoch: 3, Steps: 194 | Train Loss: 1.0078760 Vali Loss: 1.0191407 Test Loss: 0.9934377
Validation loss decreased (1.020322 --> 1.019141).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0011517
	speed: 0.0097s/iter; left time: 12.2172s
Epoch: 4 cost time: 1.7791624069213867
Epoch: 4, Steps: 194 | Train Loss: 1.0054336 Vali Loss: 1.0195355 Test Loss: 0.9931451
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0196530
	speed: 0.0096s/iter; left time: 10.2147s
Epoch: 5 cost time: 1.769883394241333
Epoch: 5, Steps: 194 | Train Loss: 1.0039743 Vali Loss: 1.0162020 Test Loss: 0.9917856
Validation loss decreased (1.019141 --> 1.016202).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0159400
	speed: 0.0092s/iter; left time: 8.0338s
Epoch: 6 cost time: 1.7301647663116455
Epoch: 6, Steps: 194 | Train Loss: 1.0030645 Vali Loss: 1.0165292 Test Loss: 0.9916717
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0269804
	speed: 0.0077s/iter; left time: 5.1866s
Epoch: 7 cost time: 1.522226095199585
Epoch: 7, Steps: 194 | Train Loss: 1.0028333 Vali Loss: 1.0170224 Test Loss: 0.9917754
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0029572
	speed: 0.0096s/iter; left time: 4.6552s
Epoch: 8 cost time: 1.7665903568267822
Epoch: 8, Steps: 194 | Train Loss: 1.0025819 Vali Loss: 1.0169600 Test Loss: 0.9917614
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0036007
	speed: 0.0096s/iter; left time: 2.7805s
Epoch: 9 cost time: 1.7735865116119385
Epoch: 9, Steps: 194 | Train Loss: 1.0025171 Vali Loss: 1.0169920 Test Loss: 0.9917437
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0019796
	speed: 0.0096s/iter; left time: 0.9083s
Epoch: 10 cost time: 1.7657344341278076
Epoch: 10, Steps: 194 | Train Loss: 1.0020325 Vali Loss: 1.0168837 Test Loss: 0.9917367
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9917854070663452, mae:0.7991652488708496
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0247884
	speed: 0.0097s/iter; left time: 17.8580s
Epoch: 1 cost time: 1.7871453762054443
Epoch: 1, Steps: 194 | Train Loss: 1.0602572 Vali Loss: 1.0248753 Test Loss: 0.9979478
Validation loss decreased (inf --> 1.024875).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9890566
	speed: 0.0097s/iter; left time: 16.0520s
Epoch: 2 cost time: 1.7927496433258057
Epoch: 2, Steps: 194 | Train Loss: 1.0127471 Vali Loss: 1.0203389 Test Loss: 0.9958096
Validation loss decreased (1.024875 --> 1.020339).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0174609
	speed: 0.0097s/iter; left time: 14.1205s
Epoch: 3 cost time: 1.781999111175537
Epoch: 3, Steps: 194 | Train Loss: 1.0076779 Vali Loss: 1.0208174 Test Loss: 0.9939604
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0176573
	speed: 0.0095s/iter; left time: 12.0010s
Epoch: 4 cost time: 1.7088532447814941
Epoch: 4, Steps: 194 | Train Loss: 1.0051153 Vali Loss: 1.0183877 Test Loss: 0.9926335
Validation loss decreased (1.020339 --> 1.018388).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0180634
	speed: 0.0093s/iter; left time: 9.8571s
Epoch: 5 cost time: 1.636986494064331
Epoch: 5, Steps: 194 | Train Loss: 1.0037483 Vali Loss: 1.0183829 Test Loss: 0.9921905
Validation loss decreased (1.018388 --> 1.018383).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0098852
	speed: 0.0078s/iter; left time: 6.7585s
Epoch: 6 cost time: 1.3433327674865723
Epoch: 6, Steps: 194 | Train Loss: 1.0028632 Vali Loss: 1.0178759 Test Loss: 0.9920111
Validation loss decreased (1.018383 --> 1.017876).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0009419
	speed: 0.0084s/iter; left time: 5.7141s
Epoch: 7 cost time: 1.5236186981201172
Epoch: 7, Steps: 194 | Train Loss: 1.0024802 Vali Loss: 1.0171152 Test Loss: 0.9917775
Validation loss decreased (1.017876 --> 1.017115).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0116357
	speed: 0.0063s/iter; left time: 3.0503s
Epoch: 8 cost time: 1.1433963775634766
Epoch: 8, Steps: 194 | Train Loss: 1.0024246 Vali Loss: 1.0168542 Test Loss: 0.9917029
Validation loss decreased (1.017115 --> 1.016854).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9861845
	speed: 0.0083s/iter; left time: 2.4104s
Epoch: 9 cost time: 1.5386292934417725
Epoch: 9, Steps: 194 | Train Loss: 1.0022027 Vali Loss: 1.0168670 Test Loss: 0.9916433
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0003759
	speed: 0.0077s/iter; left time: 0.7285s
Epoch: 10 cost time: 1.3908185958862305
Epoch: 10, Steps: 194 | Train Loss: 1.0022697 Vali Loss: 1.0168201 Test Loss: 0.9916345
Validation loss decreased (1.016854 --> 1.016820).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9916346073150635, mae:0.7991374731063843
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5858797
	speed: 0.0140s/iter; left time: 28.5349s
	iters: 200, epoch: 1 | loss: 0.5458144
	speed: 0.0108s/iter; left time: 20.8214s
Epoch: 1 cost time: 2.301480293273926
Epoch: 1, Steps: 213 | Train Loss: 0.5708970 Vali Loss: 0.4855776 Test Loss: 0.5733792
Validation loss decreased (inf --> 0.485578).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5030825
	speed: 0.0081s/iter; left time: 14.8051s
	iters: 200, epoch: 2 | loss: 0.5100256
	speed: 0.0079s/iter; left time: 13.5706s
Epoch: 2 cost time: 1.747544288635254
Epoch: 2, Steps: 213 | Train Loss: 0.4905525 Vali Loss: 0.5177446 Test Loss: 0.5717217
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4281001
	speed: 0.0080s/iter; left time: 12.7834s
	iters: 200, epoch: 3 | loss: 0.4503944
	speed: 0.0078s/iter; left time: 11.7456s
Epoch: 3 cost time: 1.7154207229614258
Epoch: 3, Steps: 213 | Train Loss: 0.4573761 Vali Loss: 0.5395836 Test Loss: 0.5796536
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4406956
	speed: 0.0093s/iter; left time: 12.9242s
	iters: 200, epoch: 4 | loss: 0.3967898
	speed: 0.0084s/iter; left time: 10.9121s
Epoch: 4 cost time: 1.8494341373443604
Epoch: 4, Steps: 213 | Train Loss: 0.4395688 Vali Loss: 0.5123897 Test Loss: 0.5593069
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4613612
	speed: 0.0092s/iter; left time: 10.8359s
	iters: 200, epoch: 5 | loss: 0.4518811
	speed: 0.0084s/iter; left time: 9.0817s
Epoch: 5 cost time: 1.8483312129974365
Epoch: 5, Steps: 213 | Train Loss: 0.4312962 Vali Loss: 0.5519645 Test Loss: 0.5773870
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4235561
	speed: 0.0095s/iter; left time: 9.1429s
	iters: 200, epoch: 6 | loss: 0.4320408
	speed: 0.0087s/iter; left time: 7.5250s
Epoch: 6 cost time: 1.9275014400482178
Epoch: 6, Steps: 213 | Train Loss: 0.4267403 Vali Loss: 0.5479642 Test Loss: 0.5733807
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5733792185783386, mae:0.598937451839447
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6103581
	speed: 0.0096s/iter; left time: 19.4208s
	iters: 200, epoch: 1 | loss: 0.5054185
	speed: 0.0086s/iter; left time: 16.6879s
Epoch: 1 cost time: 1.8939497470855713
Epoch: 1, Steps: 213 | Train Loss: 0.5782628 Vali Loss: 0.4818398 Test Loss: 0.5616116
Validation loss decreased (inf --> 0.481840).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5297719
	speed: 0.0096s/iter; left time: 17.4100s
	iters: 200, epoch: 2 | loss: 0.4894395
	speed: 0.0086s/iter; left time: 14.8571s
Epoch: 2 cost time: 1.8851537704467773
Epoch: 2, Steps: 213 | Train Loss: 0.5060787 Vali Loss: 0.5276326 Test Loss: 0.5744522
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4988443
	speed: 0.0077s/iter; left time: 12.2808s
	iters: 200, epoch: 3 | loss: 0.4611154
	speed: 0.0069s/iter; left time: 10.3668s
Epoch: 3 cost time: 1.5429186820983887
Epoch: 3, Steps: 213 | Train Loss: 0.4777997 Vali Loss: 0.5190769 Test Loss: 0.5799448
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4797844
	speed: 0.0088s/iter; left time: 12.1888s
	iters: 200, epoch: 4 | loss: 0.4289351
	speed: 0.0082s/iter; left time: 10.5785s
Epoch: 4 cost time: 1.8151719570159912
Epoch: 4, Steps: 213 | Train Loss: 0.4593756 Vali Loss: 0.5064558 Test Loss: 0.5590898
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4705535
	speed: 0.0093s/iter; left time: 10.9613s
	iters: 200, epoch: 5 | loss: 0.5016369
	speed: 0.0084s/iter; left time: 9.0920s
Epoch: 5 cost time: 1.8481950759887695
Epoch: 5, Steps: 213 | Train Loss: 0.4503870 Vali Loss: 0.5031493 Test Loss: 0.5608599
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3985376
	speed: 0.0092s/iter; left time: 8.9242s
	iters: 200, epoch: 6 | loss: 0.4296257
	speed: 0.0084s/iter; left time: 7.2710s
Epoch: 6 cost time: 1.832911729812622
Epoch: 6, Steps: 213 | Train Loss: 0.4454408 Vali Loss: 0.5085559 Test Loss: 0.5653025
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5616115927696228, mae:0.5938849449157715
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5487232
	speed: 0.0079s/iter; left time: 15.9927s
	iters: 200, epoch: 1 | loss: 0.5426433
	speed: 0.0069s/iter; left time: 13.3813s
Epoch: 1 cost time: 1.5275695323944092
Epoch: 1, Steps: 213 | Train Loss: 0.5789807 Vali Loss: 0.5266733 Test Loss: 0.6280034
Validation loss decreased (inf --> 0.526673).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4880450
	speed: 0.0091s/iter; left time: 16.4661s
	iters: 200, epoch: 2 | loss: 0.4417263
	speed: 0.0076s/iter; left time: 13.0725s
Epoch: 2 cost time: 1.662261724472046
Epoch: 2, Steps: 213 | Train Loss: 0.5025986 Vali Loss: 0.4982644 Test Loss: 0.5703748
Validation loss decreased (0.526673 --> 0.498264).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4520440
	speed: 0.0090s/iter; left time: 14.3680s
	iters: 200, epoch: 3 | loss: 0.5080520
	speed: 0.0078s/iter; left time: 11.7438s
Epoch: 3 cost time: 1.7181603908538818
Epoch: 3, Steps: 213 | Train Loss: 0.4715246 Vali Loss: 0.4994542 Test Loss: 0.5769262
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4354685
	speed: 0.0072s/iter; left time: 10.0725s
	iters: 200, epoch: 4 | loss: 0.5391806
	speed: 0.0066s/iter; left time: 8.5898s
Epoch: 4 cost time: 1.4826931953430176
Epoch: 4, Steps: 213 | Train Loss: 0.4529800 Vali Loss: 0.5014272 Test Loss: 0.5720569
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4311915
	speed: 0.0088s/iter; left time: 10.3262s
	iters: 200, epoch: 5 | loss: 0.4443735
	speed: 0.0077s/iter; left time: 8.2640s
Epoch: 5 cost time: 1.6820497512817383
Epoch: 5, Steps: 213 | Train Loss: 0.4422339 Vali Loss: 0.5193487 Test Loss: 0.5707589
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4070528
	speed: 0.0082s/iter; left time: 7.9167s
	iters: 200, epoch: 6 | loss: 0.4446188
	speed: 0.0071s/iter; left time: 6.1603s
Epoch: 6 cost time: 1.5656418800354004
Epoch: 6, Steps: 213 | Train Loss: 0.4370713 Vali Loss: 0.5157059 Test Loss: 0.5723315
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4603349
	speed: 0.0077s/iter; left time: 5.8092s
	iters: 200, epoch: 7 | loss: 0.4295453
	speed: 0.0068s/iter; left time: 4.4667s
Epoch: 7 cost time: 1.5009541511535645
Epoch: 7, Steps: 213 | Train Loss: 0.4353967 Vali Loss: 0.5140903 Test Loss: 0.5763332
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5703748464584351, mae:0.5980803370475769
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7326347
	speed: 0.0177s/iter; left time: 35.4033s
	iters: 200, epoch: 1 | loss: 0.6835009
	speed: 0.0118s/iter; left time: 22.3705s
Epoch: 1 cost time: 2.4653425216674805
Epoch: 1, Steps: 210 | Train Loss: 0.6698629 Vali Loss: 0.5801967 Test Loss: 0.8362132
Validation loss decreased (inf --> 0.580197).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5939245
	speed: 0.0069s/iter; left time: 12.3500s
	iters: 200, epoch: 2 | loss: 0.6251583
	speed: 0.0063s/iter; left time: 10.6927s
Epoch: 2 cost time: 1.3785734176635742
Epoch: 2, Steps: 210 | Train Loss: 0.5661069 Vali Loss: 0.5610971 Test Loss: 0.7329725
Validation loss decreased (0.580197 --> 0.561097).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5294360
	speed: 0.0084s/iter; left time: 13.2417s
	iters: 200, epoch: 3 | loss: 0.5140709
	speed: 0.0080s/iter; left time: 11.8028s
Epoch: 3 cost time: 1.7146058082580566
Epoch: 3, Steps: 210 | Train Loss: 0.5152694 Vali Loss: 0.6124179 Test Loss: 0.7761776
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4822148
	speed: 0.0079s/iter; left time: 10.7747s
	iters: 200, epoch: 4 | loss: 0.4566410
	speed: 0.0068s/iter; left time: 8.6153s
Epoch: 4 cost time: 1.466501235961914
Epoch: 4, Steps: 210 | Train Loss: 0.4901915 Vali Loss: 0.6166423 Test Loss: 0.7522093
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4421813
	speed: 0.0080s/iter; left time: 9.3171s
	iters: 200, epoch: 5 | loss: 0.4783132
	speed: 0.0071s/iter; left time: 7.5123s
Epoch: 5 cost time: 1.5294320583343506
Epoch: 5, Steps: 210 | Train Loss: 0.4786351 Vali Loss: 0.6145900 Test Loss: 0.7498903
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4535532
	speed: 0.0075s/iter; left time: 7.1350s
	iters: 200, epoch: 6 | loss: 0.4677513
	speed: 0.0070s/iter; left time: 5.9516s
Epoch: 6 cost time: 1.5195584297180176
Epoch: 6, Steps: 210 | Train Loss: 0.4731747 Vali Loss: 0.6139454 Test Loss: 0.7357287
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4869547
	speed: 0.0064s/iter; left time: 4.7770s
	iters: 200, epoch: 7 | loss: 0.4571548
	speed: 0.0058s/iter; left time: 3.7444s
Epoch: 7 cost time: 1.2716495990753174
Epoch: 7, Steps: 210 | Train Loss: 0.4696946 Vali Loss: 0.6245407 Test Loss: 0.7413068
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7329724431037903, mae:0.6751684546470642
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6680385
	speed: 0.0065s/iter; left time: 12.9531s
	iters: 200, epoch: 1 | loss: 0.5932233
	speed: 0.0056s/iter; left time: 10.6703s
Epoch: 1 cost time: 1.2249839305877686
Epoch: 1, Steps: 210 | Train Loss: 0.6682694 Vali Loss: 0.6308044 Test Loss: 0.8994821
Validation loss decreased (inf --> 0.630804).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5649914
	speed: 0.0083s/iter; left time: 14.8945s
	iters: 200, epoch: 2 | loss: 0.5693415
	speed: 0.0080s/iter; left time: 13.4757s
Epoch: 2 cost time: 1.728778600692749
Epoch: 2, Steps: 210 | Train Loss: 0.5746577 Vali Loss: 0.5910633 Test Loss: 0.7686567
Validation loss decreased (0.630804 --> 0.591063).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5255205
	speed: 0.0069s/iter; left time: 10.9477s
	iters: 200, epoch: 3 | loss: 0.5068623
	speed: 0.0066s/iter; left time: 9.7433s
Epoch: 3 cost time: 1.4466986656188965
Epoch: 3, Steps: 210 | Train Loss: 0.5224423 Vali Loss: 0.5875180 Test Loss: 0.7347159
Validation loss decreased (0.591063 --> 0.587518).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5026652
	speed: 0.0090s/iter; left time: 12.3643s
	iters: 200, epoch: 4 | loss: 0.4702989
	speed: 0.0078s/iter; left time: 9.8941s
Epoch: 4 cost time: 1.6688265800476074
Epoch: 4, Steps: 210 | Train Loss: 0.4961126 Vali Loss: 0.6080028 Test Loss: 0.7575482
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5032925
	speed: 0.0073s/iter; left time: 8.4609s
	iters: 200, epoch: 5 | loss: 0.4414750
	speed: 0.0069s/iter; left time: 7.3370s
Epoch: 5 cost time: 1.5003888607025146
Epoch: 5, Steps: 210 | Train Loss: 0.4856256 Vali Loss: 0.5982035 Test Loss: 0.7617418
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4656032
	speed: 0.0072s/iter; left time: 6.8491s
	iters: 200, epoch: 6 | loss: 0.5021609
	speed: 0.0062s/iter; left time: 5.2435s
Epoch: 6 cost time: 1.3478412628173828
Epoch: 6, Steps: 210 | Train Loss: 0.4793183 Vali Loss: 0.6108533 Test Loss: 0.7384261
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4675329
	speed: 0.0069s/iter; left time: 5.0791s
	iters: 200, epoch: 7 | loss: 0.4464433
	speed: 0.0061s/iter; left time: 3.9110s
Epoch: 7 cost time: 1.3223536014556885
Epoch: 7, Steps: 210 | Train Loss: 0.4765682 Vali Loss: 0.6125082 Test Loss: 0.7460912
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4606578
	speed: 0.0070s/iter; left time: 3.7166s
	iters: 200, epoch: 8 | loss: 0.4501641
	speed: 0.0064s/iter; left time: 2.7603s
Epoch: 8 cost time: 1.387761116027832
Epoch: 8, Steps: 210 | Train Loss: 0.4749644 Vali Loss: 0.6119450 Test Loss: 0.7564298
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.73471599817276, mae:0.6784402132034302
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6447273
	speed: 0.0083s/iter; left time: 16.5144s
	iters: 200, epoch: 1 | loss: 0.5916458
	speed: 0.0073s/iter; left time: 13.9398s
Epoch: 1 cost time: 1.58976149559021
Epoch: 1, Steps: 210 | Train Loss: 0.6700025 Vali Loss: 0.5976304 Test Loss: 0.7733493
Validation loss decreased (inf --> 0.597630).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6810314
	speed: 0.0078s/iter; left time: 13.9304s
	iters: 200, epoch: 2 | loss: 0.4550719
	speed: 0.0071s/iter; left time: 12.0493s
Epoch: 2 cost time: 1.5446314811706543
Epoch: 2, Steps: 210 | Train Loss: 0.5702654 Vali Loss: 0.5783966 Test Loss: 0.7234061
Validation loss decreased (0.597630 --> 0.578397).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4964345
	speed: 0.0073s/iter; left time: 11.4992s
	iters: 200, epoch: 3 | loss: 0.4957039
	speed: 0.0066s/iter; left time: 9.8124s
Epoch: 3 cost time: 1.4490714073181152
Epoch: 3, Steps: 210 | Train Loss: 0.5226973 Vali Loss: 0.5929642 Test Loss: 0.7660652
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4723264
	speed: 0.0078s/iter; left time: 10.7180s
	iters: 200, epoch: 4 | loss: 0.4562415
	speed: 0.0072s/iter; left time: 9.1296s
Epoch: 4 cost time: 1.5563685894012451
Epoch: 4, Steps: 210 | Train Loss: 0.5014855 Vali Loss: 0.6130413 Test Loss: 0.7381266
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5015285
	speed: 0.0075s/iter; left time: 8.7457s
	iters: 200, epoch: 5 | loss: 0.4655969
	speed: 0.0067s/iter; left time: 7.1365s
Epoch: 5 cost time: 1.454859733581543
Epoch: 5, Steps: 210 | Train Loss: 0.4877464 Vali Loss: 0.6024633 Test Loss: 0.7311934
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4866289
	speed: 0.0088s/iter; left time: 8.3816s
	iters: 200, epoch: 6 | loss: 0.4745930
	speed: 0.0082s/iter; left time: 6.9879s
Epoch: 6 cost time: 1.7735052108764648
Epoch: 6, Steps: 210 | Train Loss: 0.4829558 Vali Loss: 0.6215405 Test Loss: 0.7560976
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4891980
	speed: 0.0075s/iter; left time: 5.5910s
	iters: 200, epoch: 7 | loss: 0.4450049
	speed: 0.0067s/iter; left time: 4.3159s
Epoch: 7 cost time: 1.4756309986114502
Epoch: 7, Steps: 210 | Train Loss: 0.4794862 Vali Loss: 0.6230252 Test Loss: 0.7558352
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7234062552452087, mae:0.6733391284942627
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7300658
	speed: 0.0148s/iter; left time: 29.0478s
	iters: 200, epoch: 1 | loss: 0.6680133
	speed: 0.0099s/iter; left time: 18.4442s
Epoch: 1 cost time: 2.058826446533203
Epoch: 1, Steps: 206 | Train Loss: 0.7567333 Vali Loss: 0.6687317 Test Loss: 1.1129608
Validation loss decreased (inf --> 0.668732).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5675710
	speed: 0.0082s/iter; left time: 14.4518s
	iters: 200, epoch: 2 | loss: 0.5301237
	speed: 0.0074s/iter; left time: 12.2806s
Epoch: 2 cost time: 1.5813977718353271
Epoch: 2, Steps: 206 | Train Loss: 0.6097639 Vali Loss: 0.6513861 Test Loss: 1.0564220
Validation loss decreased (0.668732 --> 0.651386).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5752733
	speed: 0.0084s/iter; left time: 12.9627s
	iters: 200, epoch: 3 | loss: 0.5270929
	speed: 0.0076s/iter; left time: 10.9425s
Epoch: 3 cost time: 1.6078925132751465
Epoch: 3, Steps: 206 | Train Loss: 0.5430450 Vali Loss: 0.6850295 Test Loss: 1.0207781
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5543273
	speed: 0.0081s/iter; left time: 10.8127s
	iters: 200, epoch: 4 | loss: 0.5468174
	speed: 0.0076s/iter; left time: 9.5088s
Epoch: 4 cost time: 1.628622055053711
Epoch: 4, Steps: 206 | Train Loss: 0.5180200 Vali Loss: 0.7217766 Test Loss: 0.9761443
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4965197
	speed: 0.0084s/iter; left time: 9.5485s
	iters: 200, epoch: 5 | loss: 0.4954311
	speed: 0.0081s/iter; left time: 8.3632s
Epoch: 5 cost time: 1.713754653930664
Epoch: 5, Steps: 206 | Train Loss: 0.5039475 Vali Loss: 0.7091495 Test Loss: 0.9723259
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5054170
	speed: 0.0088s/iter; left time: 8.1737s
	iters: 200, epoch: 6 | loss: 0.4904521
	speed: 0.0082s/iter; left time: 6.8131s
Epoch: 6 cost time: 1.7382636070251465
Epoch: 6, Steps: 206 | Train Loss: 0.4985973 Vali Loss: 0.7113668 Test Loss: 0.9563653
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4870746
	speed: 0.0084s/iter; left time: 6.1237s
	iters: 200, epoch: 7 | loss: 0.4795550
	speed: 0.0079s/iter; left time: 4.9559s
Epoch: 7 cost time: 1.7010612487792969
Epoch: 7, Steps: 206 | Train Loss: 0.4951731 Vali Loss: 0.7143038 Test Loss: 0.9418321
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0564219951629639, mae:0.8098952174186707
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7536274
	speed: 0.0076s/iter; left time: 14.9953s
	iters: 200, epoch: 1 | loss: 0.6581458
	speed: 0.0068s/iter; left time: 12.6733s
Epoch: 1 cost time: 1.4433395862579346
Epoch: 1, Steps: 206 | Train Loss: 0.7738611 Vali Loss: 0.7468199 Test Loss: 1.1571119
Validation loss decreased (inf --> 0.746820).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6307306
	speed: 0.0085s/iter; left time: 14.8745s
	iters: 200, epoch: 2 | loss: 0.5833015
	speed: 0.0080s/iter; left time: 13.2403s
Epoch: 2 cost time: 1.7031736373901367
Epoch: 2, Steps: 206 | Train Loss: 0.6316479 Vali Loss: 0.6237394 Test Loss: 0.8810123
Validation loss decreased (0.746820 --> 0.623739).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6106706
	speed: 0.0094s/iter; left time: 14.5908s
	iters: 200, epoch: 3 | loss: 0.5150242
	speed: 0.0085s/iter; left time: 12.3626s
Epoch: 3 cost time: 1.817553997039795
Epoch: 3, Steps: 206 | Train Loss: 0.5577181 Vali Loss: 0.8019711 Test Loss: 0.9526583
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4820576
	speed: 0.0094s/iter; left time: 12.5650s
	iters: 200, epoch: 4 | loss: 0.5159935
	speed: 0.0085s/iter; left time: 10.6218s
Epoch: 4 cost time: 1.8183786869049072
Epoch: 4, Steps: 206 | Train Loss: 0.5265331 Vali Loss: 0.7796457 Test Loss: 0.9619130
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5077716
	speed: 0.0095s/iter; left time: 10.7999s
	iters: 200, epoch: 5 | loss: 0.5383115
	speed: 0.0086s/iter; left time: 8.9231s
Epoch: 5 cost time: 1.8294758796691895
Epoch: 5, Steps: 206 | Train Loss: 0.5124674 Vali Loss: 0.7759103 Test Loss: 0.9547368
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4963519
	speed: 0.0093s/iter; left time: 8.6215s
	iters: 200, epoch: 6 | loss: 0.5241991
	speed: 0.0085s/iter; left time: 7.0544s
Epoch: 6 cost time: 1.8058011531829834
Epoch: 6, Steps: 206 | Train Loss: 0.5062747 Vali Loss: 0.7783376 Test Loss: 0.9558663
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4850637
	speed: 0.0093s/iter; left time: 6.7237s
	iters: 200, epoch: 7 | loss: 0.4754429
	speed: 0.0085s/iter; left time: 5.2988s
Epoch: 7 cost time: 1.8069016933441162
Epoch: 7, Steps: 206 | Train Loss: 0.5027080 Vali Loss: 0.7868041 Test Loss: 0.9506653
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8810122609138489, mae:0.7415895462036133
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8240864
	speed: 0.0095s/iter; left time: 18.5579s
	iters: 200, epoch: 1 | loss: 0.6150743
	speed: 0.0085s/iter; left time: 15.8785s
Epoch: 1 cost time: 1.8136305809020996
Epoch: 1, Steps: 206 | Train Loss: 0.7568507 Vali Loss: 0.6306942 Test Loss: 1.0560651
Validation loss decreased (inf --> 0.630694).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6287755
	speed: 0.0095s/iter; left time: 16.6431s
	iters: 200, epoch: 2 | loss: 0.5200450
	speed: 0.0086s/iter; left time: 14.1619s
Epoch: 2 cost time: 1.8191032409667969
Epoch: 2, Steps: 206 | Train Loss: 0.6188989 Vali Loss: 0.6183233 Test Loss: 0.8866288
Validation loss decreased (0.630694 --> 0.618323).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5768147
	speed: 0.0095s/iter; left time: 14.6502s
	iters: 200, epoch: 3 | loss: 0.5500549
	speed: 0.0085s/iter; left time: 12.3809s
Epoch: 3 cost time: 1.8121895790100098
Epoch: 3, Steps: 206 | Train Loss: 0.5583573 Vali Loss: 0.6424907 Test Loss: 0.9709430
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5293562
	speed: 0.0093s/iter; left time: 12.5434s
	iters: 200, epoch: 4 | loss: 0.5381029
	speed: 0.0085s/iter; left time: 10.5698s
Epoch: 4 cost time: 1.8308236598968506
Epoch: 4, Steps: 206 | Train Loss: 0.5283921 Vali Loss: 0.6736402 Test Loss: 0.9497520
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4972293
	speed: 0.0092s/iter; left time: 10.4838s
	iters: 200, epoch: 5 | loss: 0.5257492
	speed: 0.0084s/iter; left time: 8.7607s
Epoch: 5 cost time: 1.8054890632629395
Epoch: 5, Steps: 206 | Train Loss: 0.5175028 Vali Loss: 0.6830466 Test Loss: 0.9979605
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5174503
	speed: 0.0093s/iter; left time: 8.6904s
	iters: 200, epoch: 6 | loss: 0.5265893
	speed: 0.0085s/iter; left time: 7.0590s
Epoch: 6 cost time: 1.8159160614013672
Epoch: 6, Steps: 206 | Train Loss: 0.5133771 Vali Loss: 0.6630052 Test Loss: 0.9831840
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5286497
	speed: 0.0094s/iter; left time: 6.8138s
	iters: 200, epoch: 7 | loss: 0.5150738
	speed: 0.0086s/iter; left time: 5.3511s
Epoch: 7 cost time: 1.8253390789031982
Epoch: 7, Steps: 206 | Train Loss: 0.5091436 Vali Loss: 0.6734969 Test Loss: 0.9786079
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8866287469863892, mae:0.7473508715629578
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9483914
	speed: 0.0174s/iter; left time: 32.0512s
Epoch: 1 cost time: 2.5145468711853027
Epoch: 1, Steps: 194 | Train Loss: 0.9200655 Vali Loss: 0.6337471 Test Loss: 1.1742160
Validation loss decreased (inf --> 0.633747).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8586609
	speed: 0.0097s/iter; left time: 15.9892s
Epoch: 2 cost time: 1.7594785690307617
Epoch: 2, Steps: 194 | Train Loss: 0.7592248 Vali Loss: 0.6136634 Test Loss: 1.1793786
Validation loss decreased (0.633747 --> 0.613663).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6211435
	speed: 0.0098s/iter; left time: 14.2479s
Epoch: 3 cost time: 1.7983925342559814
Epoch: 3, Steps: 194 | Train Loss: 0.6207798 Vali Loss: 0.6649917 Test Loss: 1.1521626
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5425608
	speed: 0.0096s/iter; left time: 12.0595s
Epoch: 4 cost time: 1.7693743705749512
Epoch: 4, Steps: 194 | Train Loss: 0.5795443 Vali Loss: 0.6736192 Test Loss: 1.1213186
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5293313
	speed: 0.0096s/iter; left time: 10.1806s
Epoch: 5 cost time: 1.7846872806549072
Epoch: 5, Steps: 194 | Train Loss: 0.5664520 Vali Loss: 0.6693484 Test Loss: 1.1432904
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6172866
	speed: 0.0095s/iter; left time: 8.2587s
Epoch: 6 cost time: 1.7475428581237793
Epoch: 6, Steps: 194 | Train Loss: 0.5619014 Vali Loss: 0.6643249 Test Loss: 1.1446517
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5381023
	speed: 0.0095s/iter; left time: 6.4079s
Epoch: 7 cost time: 1.7471375465393066
Epoch: 7, Steps: 194 | Train Loss: 0.5587784 Vali Loss: 0.6658177 Test Loss: 1.1451579
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.1793785095214844, mae:0.8614922165870667
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8988310
	speed: 0.0097s/iter; left time: 17.7722s
Epoch: 1 cost time: 1.831693172454834
Epoch: 1, Steps: 194 | Train Loss: 0.9219101 Vali Loss: 0.6703446 Test Loss: 1.0215338
Validation loss decreased (inf --> 0.670345).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7693361
	speed: 0.0096s/iter; left time: 15.8408s
Epoch: 2 cost time: 1.7622613906860352
Epoch: 2, Steps: 194 | Train Loss: 0.7388502 Vali Loss: 0.5929567 Test Loss: 1.2565929
Validation loss decreased (0.670345 --> 0.592957).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6339746
	speed: 0.0096s/iter; left time: 13.9648s
Epoch: 3 cost time: 1.7664589881896973
Epoch: 3, Steps: 194 | Train Loss: 0.6104689 Vali Loss: 0.6202287 Test Loss: 1.1185265
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5703806
	speed: 0.0094s/iter; left time: 11.8782s
Epoch: 4 cost time: 1.74442720413208
Epoch: 4, Steps: 194 | Train Loss: 0.5821676 Vali Loss: 0.6264079 Test Loss: 1.1654476
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5725798
	speed: 0.0096s/iter; left time: 10.1728s
Epoch: 5 cost time: 1.747441053390503
Epoch: 5, Steps: 194 | Train Loss: 0.5672100 Vali Loss: 0.6404538 Test Loss: 1.1910801
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5835516
	speed: 0.0095s/iter; left time: 8.2706s
Epoch: 6 cost time: 1.7605745792388916
Epoch: 6, Steps: 194 | Train Loss: 0.5616496 Vali Loss: 0.6407111 Test Loss: 1.1715720
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5397543
	speed: 0.0095s/iter; left time: 6.4104s
Epoch: 7 cost time: 1.7640578746795654
Epoch: 7, Steps: 194 | Train Loss: 0.5593247 Vali Loss: 0.6397488 Test Loss: 1.1698215
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.256592869758606, mae:0.8778806328773499
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8896669
	speed: 0.0098s/iter; left time: 18.0002s
Epoch: 1 cost time: 1.7934534549713135
Epoch: 1, Steps: 194 | Train Loss: 0.9207785 Vali Loss: 0.6117184 Test Loss: 1.1664753
Validation loss decreased (inf --> 0.611718).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6624241
	speed: 0.0097s/iter; left time: 16.0200s
Epoch: 2 cost time: 1.7875096797943115
Epoch: 2, Steps: 194 | Train Loss: 0.7616364 Vali Loss: 0.6100864 Test Loss: 1.1773801
Validation loss decreased (0.611718 --> 0.610086).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6432686
	speed: 0.0097s/iter; left time: 14.0953s
Epoch: 3 cost time: 1.5870428085327148
Epoch: 3, Steps: 194 | Train Loss: 0.6158877 Vali Loss: 0.6177418 Test Loss: 1.1902212
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5619695
	speed: 0.0095s/iter; left time: 11.9805s
Epoch: 4 cost time: 1.711972713470459
Epoch: 4, Steps: 194 | Train Loss: 0.5820164 Vali Loss: 0.6546936 Test Loss: 1.1357340
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5719959
	speed: 0.0088s/iter; left time: 9.3957s
Epoch: 5 cost time: 1.6858100891113281
Epoch: 5, Steps: 194 | Train Loss: 0.5687115 Vali Loss: 0.6274500 Test Loss: 1.1676370
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5463675
	speed: 0.0077s/iter; left time: 6.6963s
Epoch: 6 cost time: 1.4001331329345703
Epoch: 6, Steps: 194 | Train Loss: 0.5641342 Vali Loss: 0.6401242 Test Loss: 1.1620622
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5465939
	speed: 0.0095s/iter; left time: 6.4127s
Epoch: 7 cost time: 1.7699263095855713
Epoch: 7, Steps: 194 | Train Loss: 0.5608536 Vali Loss: 0.6377736 Test Loss: 1.1651517
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.177380084991455, mae:0.8512476086616516
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5250213
	speed: 0.0136s/iter; left time: 27.6703s
	iters: 200, epoch: 1 | loss: 0.5223879
	speed: 0.0098s/iter; left time: 18.9655s
Epoch: 1 cost time: 2.0984108448028564
Epoch: 1, Steps: 213 | Train Loss: 0.5713012 Vali Loss: 0.4854475 Test Loss: 0.5709398
Validation loss decreased (inf --> 0.485447).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5333121
	speed: 0.0079s/iter; left time: 14.2937s
	iters: 200, epoch: 2 | loss: 0.5407347
	speed: 0.0069s/iter; left time: 11.8334s
Epoch: 2 cost time: 1.5084927082061768
Epoch: 2, Steps: 213 | Train Loss: 0.4955951 Vali Loss: 0.5176428 Test Loss: 0.5816161
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4340334
	speed: 0.0076s/iter; left time: 12.2082s
	iters: 200, epoch: 3 | loss: 0.4040697
	speed: 0.0068s/iter; left time: 10.1679s
Epoch: 3 cost time: 1.4984121322631836
Epoch: 3, Steps: 213 | Train Loss: 0.4609503 Vali Loss: 0.5172361 Test Loss: 0.5768372
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4233491
	speed: 0.0092s/iter; left time: 12.7599s
	iters: 200, epoch: 4 | loss: 0.4029878
	speed: 0.0084s/iter; left time: 10.8789s
Epoch: 4 cost time: 1.8455774784088135
Epoch: 4, Steps: 213 | Train Loss: 0.4451597 Vali Loss: 0.5076538 Test Loss: 0.5836099
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4310513
	speed: 0.0072s/iter; left time: 8.4977s
	iters: 200, epoch: 5 | loss: 0.4399728
	speed: 0.0066s/iter; left time: 7.0790s
Epoch: 5 cost time: 1.4595232009887695
Epoch: 5, Steps: 213 | Train Loss: 0.4358300 Vali Loss: 0.5367884 Test Loss: 0.6042282
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4494525
	speed: 0.0070s/iter; left time: 6.7383s
	iters: 200, epoch: 6 | loss: 0.4452897
	speed: 0.0064s/iter; left time: 5.5828s
Epoch: 6 cost time: 1.4185080528259277
Epoch: 6, Steps: 213 | Train Loss: 0.4316547 Vali Loss: 0.5274360 Test Loss: 0.5994171
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5709397196769714, mae:0.5993626713752747
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5758086
	speed: 0.0085s/iter; left time: 17.1879s
	iters: 200, epoch: 1 | loss: 0.5746051
	speed: 0.0074s/iter; left time: 14.3657s
Epoch: 1 cost time: 1.6282463073730469
Epoch: 1, Steps: 213 | Train Loss: 0.5748945 Vali Loss: 0.4638230 Test Loss: 0.5550543
Validation loss decreased (inf --> 0.463823).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5376058
	speed: 0.0089s/iter; left time: 16.1743s
	iters: 200, epoch: 2 | loss: 0.5323814
	speed: 0.0082s/iter; left time: 14.1657s
Epoch: 2 cost time: 1.7962074279785156
Epoch: 2, Steps: 213 | Train Loss: 0.4996824 Vali Loss: 0.4782627 Test Loss: 0.5568581
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4831241
	speed: 0.0092s/iter; left time: 14.8371s
	iters: 200, epoch: 3 | loss: 0.5517553
	speed: 0.0084s/iter; left time: 12.6783s
Epoch: 3 cost time: 1.8393609523773193
Epoch: 3, Steps: 213 | Train Loss: 0.4732148 Vali Loss: 0.4809884 Test Loss: 0.5543789
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4063980
	speed: 0.0093s/iter; left time: 12.9110s
	iters: 200, epoch: 4 | loss: 0.4773833
	speed: 0.0093s/iter; left time: 11.9909s
Epoch: 4 cost time: 2.0453498363494873
Epoch: 4, Steps: 213 | Train Loss: 0.4573938 Vali Loss: 0.5073619 Test Loss: 0.5611134
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4801638
	speed: 0.0092s/iter; left time: 10.8369s
	iters: 200, epoch: 5 | loss: 0.4872256
	speed: 0.0084s/iter; left time: 9.1043s
Epoch: 5 cost time: 1.8607704639434814
Epoch: 5, Steps: 213 | Train Loss: 0.4485571 Vali Loss: 0.5016407 Test Loss: 0.5617953
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4313196
	speed: 0.0091s/iter; left time: 8.8329s
	iters: 200, epoch: 6 | loss: 0.4187415
	speed: 0.0084s/iter; left time: 7.2434s
Epoch: 6 cost time: 1.855675220489502
Epoch: 6, Steps: 213 | Train Loss: 0.4438709 Vali Loss: 0.5108348 Test Loss: 0.5650198
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5550543069839478, mae:0.5904197096824646
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5906656
	speed: 0.0095s/iter; left time: 19.2716s
	iters: 200, epoch: 1 | loss: 0.5352449
	speed: 0.0086s/iter; left time: 16.5264s
Epoch: 1 cost time: 1.8928117752075195
Epoch: 1, Steps: 213 | Train Loss: 0.5745391 Vali Loss: 0.4961289 Test Loss: 0.5802640
Validation loss decreased (inf --> 0.496129).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4991319
	speed: 0.0094s/iter; left time: 17.1501s
	iters: 200, epoch: 2 | loss: 0.4877876
	speed: 0.0085s/iter; left time: 14.6840s
Epoch: 2 cost time: 1.8722810745239258
Epoch: 2, Steps: 213 | Train Loss: 0.5016111 Vali Loss: 0.4637661 Test Loss: 0.5574749
Validation loss decreased (0.496129 --> 0.463766).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4161717
	speed: 0.0094s/iter; left time: 15.1141s
	iters: 200, epoch: 3 | loss: 0.4496729
	speed: 0.0085s/iter; left time: 12.8052s
Epoch: 3 cost time: 1.874847650527954
Epoch: 3, Steps: 213 | Train Loss: 0.4682286 Vali Loss: 0.4888589 Test Loss: 0.5567434
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5148247
	speed: 0.0093s/iter; left time: 12.9560s
	iters: 200, epoch: 4 | loss: 0.4530706
	speed: 0.0085s/iter; left time: 10.9322s
Epoch: 4 cost time: 1.8562452793121338
Epoch: 4, Steps: 213 | Train Loss: 0.4502796 Vali Loss: 0.4864390 Test Loss: 0.5744151
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4203772
	speed: 0.0092s/iter; left time: 10.8654s
	iters: 200, epoch: 5 | loss: 0.4690431
	speed: 0.0084s/iter; left time: 9.0461s
Epoch: 5 cost time: 1.8396177291870117
Epoch: 5, Steps: 213 | Train Loss: 0.4404871 Vali Loss: 0.4956078 Test Loss: 0.5828349
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4139788
	speed: 0.0093s/iter; left time: 9.0303s
	iters: 200, epoch: 6 | loss: 0.4303900
	speed: 0.0085s/iter; left time: 7.3230s
Epoch: 6 cost time: 1.8590402603149414
Epoch: 6, Steps: 213 | Train Loss: 0.4362811 Vali Loss: 0.5005603 Test Loss: 0.5789709
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4565741
	speed: 0.0092s/iter; left time: 6.9227s
	iters: 200, epoch: 7 | loss: 0.4132316
	speed: 0.0084s/iter; left time: 5.4870s
Epoch: 7 cost time: 1.8409571647644043
Epoch: 7, Steps: 213 | Train Loss: 0.4334643 Vali Loss: 0.5023392 Test Loss: 0.5833009
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5574749708175659, mae:0.589997410774231
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7423100
	speed: 0.0168s/iter; left time: 33.5635s
	iters: 200, epoch: 1 | loss: 0.5986211
	speed: 0.0111s/iter; left time: 21.1279s
Epoch: 1 cost time: 2.3159961700439453
Epoch: 1, Steps: 210 | Train Loss: 0.6695230 Vali Loss: 0.5715109 Test Loss: 0.7907410
Validation loss decreased (inf --> 0.571511).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5944438
	speed: 0.0059s/iter; left time: 10.6394s
	iters: 200, epoch: 2 | loss: 0.5391102
	speed: 0.0053s/iter; left time: 8.9593s
Epoch: 2 cost time: 1.1449854373931885
Epoch: 2, Steps: 210 | Train Loss: 0.5805791 Vali Loss: 0.5463032 Test Loss: 0.7950825
Validation loss decreased (0.571511 --> 0.546303).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5750861
	speed: 0.0060s/iter; left time: 9.5354s
	iters: 200, epoch: 3 | loss: 0.5215082
	speed: 0.0054s/iter; left time: 7.9546s
Epoch: 3 cost time: 1.1817958354949951
Epoch: 3, Steps: 210 | Train Loss: 0.5272963 Vali Loss: 0.6000402 Test Loss: 0.7943789
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4583021
	speed: 0.0061s/iter; left time: 8.4083s
	iters: 200, epoch: 4 | loss: 0.5276878
	speed: 0.0056s/iter; left time: 7.1276s
Epoch: 4 cost time: 1.242180347442627
Epoch: 4, Steps: 210 | Train Loss: 0.5041489 Vali Loss: 0.5956354 Test Loss: 0.7476310
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4851590
	speed: 0.0088s/iter; left time: 10.2413s
	iters: 200, epoch: 5 | loss: 0.5039463
	speed: 0.0077s/iter; left time: 8.1704s
Epoch: 5 cost time: 1.6595337390899658
Epoch: 5, Steps: 210 | Train Loss: 0.4928268 Vali Loss: 0.5917721 Test Loss: 0.7586819
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5109667
	speed: 0.0084s/iter; left time: 7.9926s
	iters: 200, epoch: 6 | loss: 0.4732856
	speed: 0.0075s/iter; left time: 6.3551s
Epoch: 6 cost time: 1.614227533340454
Epoch: 6, Steps: 210 | Train Loss: 0.4882505 Vali Loss: 0.5936998 Test Loss: 0.7531223
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5006784
	speed: 0.0076s/iter; left time: 5.6556s
	iters: 200, epoch: 7 | loss: 0.5081737
	speed: 0.0075s/iter; left time: 4.7758s
Epoch: 7 cost time: 1.6194050312042236
Epoch: 7, Steps: 210 | Train Loss: 0.4838521 Vali Loss: 0.6043839 Test Loss: 0.7526473
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7950824499130249, mae:0.7019158005714417
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6466982
	speed: 0.0073s/iter; left time: 14.5417s
	iters: 200, epoch: 1 | loss: 0.5773968
	speed: 0.0064s/iter; left time: 12.2510s
Epoch: 1 cost time: 1.38716459274292
Epoch: 1, Steps: 210 | Train Loss: 0.6757667 Vali Loss: 0.5615310 Test Loss: 0.7612102
Validation loss decreased (inf --> 0.561531).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6944126
	speed: 0.0080s/iter; left time: 14.3055s
	iters: 200, epoch: 2 | loss: 0.5022584
	speed: 0.0075s/iter; left time: 12.6985s
Epoch: 2 cost time: 1.6145970821380615
Epoch: 2, Steps: 210 | Train Loss: 0.5923544 Vali Loss: 0.5685868 Test Loss: 0.7400091
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5309372
	speed: 0.0087s/iter; left time: 13.8287s
	iters: 200, epoch: 3 | loss: 0.5216244
	speed: 0.0082s/iter; left time: 12.0872s
Epoch: 3 cost time: 1.7761116027832031
Epoch: 3, Steps: 210 | Train Loss: 0.5513901 Vali Loss: 0.6056420 Test Loss: 0.7759410
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5079120
	speed: 0.0066s/iter; left time: 9.0818s
	iters: 200, epoch: 4 | loss: 0.4688448
	speed: 0.0059s/iter; left time: 7.5051s
Epoch: 4 cost time: 1.2759180068969727
Epoch: 4, Steps: 210 | Train Loss: 0.5241455 Vali Loss: 0.6608968 Test Loss: 0.7501586
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4817383
	speed: 0.0082s/iter; left time: 9.5558s
	iters: 200, epoch: 5 | loss: 0.5402604
	speed: 0.0074s/iter; left time: 7.8093s
Epoch: 5 cost time: 1.5874030590057373
Epoch: 5, Steps: 210 | Train Loss: 0.5122556 Vali Loss: 0.6629693 Test Loss: 0.7164717
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4779797
	speed: 0.0073s/iter; left time: 6.8955s
	iters: 200, epoch: 6 | loss: 0.4806740
	speed: 0.0065s/iter; left time: 5.5515s
Epoch: 6 cost time: 1.4179985523223877
Epoch: 6, Steps: 210 | Train Loss: 0.5034572 Vali Loss: 0.6707148 Test Loss: 0.7139135
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.761210024356842, mae:0.6892819404602051
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6200693
	speed: 0.0079s/iter; left time: 15.9034s
	iters: 200, epoch: 1 | loss: 0.6306270
	speed: 0.0072s/iter; left time: 13.7560s
Epoch: 1 cost time: 1.5640738010406494
Epoch: 1, Steps: 210 | Train Loss: 0.6636378 Vali Loss: 0.5976979 Test Loss: 0.8400972
Validation loss decreased (inf --> 0.597698).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5879436
	speed: 0.0074s/iter; left time: 13.2821s
	iters: 200, epoch: 2 | loss: 0.4980950
	speed: 0.0066s/iter; left time: 11.1027s
Epoch: 2 cost time: 1.4085466861724854
Epoch: 2, Steps: 210 | Train Loss: 0.5724141 Vali Loss: 0.5875503 Test Loss: 0.7357301
Validation loss decreased (0.597698 --> 0.587550).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5410833
	speed: 0.0066s/iter; left time: 10.4356s
	iters: 200, epoch: 3 | loss: 0.4858588
	speed: 0.0061s/iter; left time: 9.0394s
Epoch: 3 cost time: 1.3354196548461914
Epoch: 3, Steps: 210 | Train Loss: 0.5250158 Vali Loss: 0.5950466 Test Loss: 0.8304502
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5178207
	speed: 0.0068s/iter; left time: 9.3043s
	iters: 200, epoch: 4 | loss: 0.4682590
	speed: 0.0061s/iter; left time: 7.7273s
Epoch: 4 cost time: 1.330073595046997
Epoch: 4, Steps: 210 | Train Loss: 0.5004572 Vali Loss: 0.6255851 Test Loss: 0.7838265
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4794446
	speed: 0.0074s/iter; left time: 8.6168s
	iters: 200, epoch: 5 | loss: 0.4758899
	speed: 0.0067s/iter; left time: 7.0811s
Epoch: 5 cost time: 1.4433166980743408
Epoch: 5, Steps: 210 | Train Loss: 0.4878417 Vali Loss: 0.6199881 Test Loss: 0.7702988
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4671298
	speed: 0.0080s/iter; left time: 7.6104s
	iters: 200, epoch: 6 | loss: 0.5148387
	speed: 0.0072s/iter; left time: 6.1543s
Epoch: 6 cost time: 1.5707414150238037
Epoch: 6, Steps: 210 | Train Loss: 0.4807640 Vali Loss: 0.6405851 Test Loss: 0.7982579
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4944992
	speed: 0.0087s/iter; left time: 6.4333s
	iters: 200, epoch: 7 | loss: 0.4949399
	speed: 0.0082s/iter; left time: 5.2250s
Epoch: 7 cost time: 1.7350711822509766
Epoch: 7, Steps: 210 | Train Loss: 0.4782639 Vali Loss: 0.6343058 Test Loss: 0.7883950
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7357299327850342, mae:0.6799154877662659
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7442909
	speed: 0.0133s/iter; left time: 26.1424s
	iters: 200, epoch: 1 | loss: 0.6324955
	speed: 0.0094s/iter; left time: 17.4457s
Epoch: 1 cost time: 1.9621107578277588
Epoch: 1, Steps: 206 | Train Loss: 0.7666648 Vali Loss: 0.6693265 Test Loss: 1.0966562
Validation loss decreased (inf --> 0.669326).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5621575
	speed: 0.0073s/iter; left time: 12.8541s
	iters: 200, epoch: 2 | loss: 0.6521961
	speed: 0.0066s/iter; left time: 10.8954s
Epoch: 2 cost time: 1.4094088077545166
Epoch: 2, Steps: 206 | Train Loss: 0.6300885 Vali Loss: 0.6512715 Test Loss: 0.9722640
Validation loss decreased (0.669326 --> 0.651272).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6025843
	speed: 0.0091s/iter; left time: 14.0492s
	iters: 200, epoch: 3 | loss: 0.5590073
	speed: 0.0084s/iter; left time: 12.1398s
Epoch: 3 cost time: 1.7836217880249023
Epoch: 3, Steps: 206 | Train Loss: 0.5596343 Vali Loss: 0.6811700 Test Loss: 1.0111932
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4818318
	speed: 0.0089s/iter; left time: 11.9450s
	iters: 200, epoch: 4 | loss: 0.5318976
	speed: 0.0083s/iter; left time: 10.2626s
Epoch: 4 cost time: 1.7533049583435059
Epoch: 4, Steps: 206 | Train Loss: 0.5310452 Vali Loss: 0.6625291 Test Loss: 0.9446457
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5288845
	speed: 0.0094s/iter; left time: 10.6651s
	iters: 200, epoch: 5 | loss: 0.5573734
	speed: 0.0085s/iter; left time: 8.8477s
Epoch: 5 cost time: 1.8115434646606445
Epoch: 5, Steps: 206 | Train Loss: 0.5199749 Vali Loss: 0.6803878 Test Loss: 0.9505582
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5199000
	speed: 0.0078s/iter; left time: 7.2986s
	iters: 200, epoch: 6 | loss: 0.4947429
	speed: 0.0068s/iter; left time: 5.6594s
Epoch: 6 cost time: 1.4558439254760742
Epoch: 6, Steps: 206 | Train Loss: 0.5149509 Vali Loss: 0.6660832 Test Loss: 0.9329571
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4800791
	speed: 0.0082s/iter; left time: 5.9598s
	iters: 200, epoch: 7 | loss: 0.4950829
	speed: 0.0074s/iter; left time: 4.6098s
Epoch: 7 cost time: 1.5860223770141602
Epoch: 7, Steps: 206 | Train Loss: 0.5135735 Vali Loss: 0.6657828 Test Loss: 0.9428304
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9722640514373779, mae:0.7784845232963562
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8144470
	speed: 0.0067s/iter; left time: 13.0460s
	iters: 200, epoch: 1 | loss: 0.5570377
	speed: 0.0057s/iter; left time: 10.6562s
Epoch: 1 cost time: 1.245913028717041
Epoch: 1, Steps: 206 | Train Loss: 0.7631440 Vali Loss: 0.7645921 Test Loss: 1.2182109
Validation loss decreased (inf --> 0.764592).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6125252
	speed: 0.0070s/iter; left time: 12.2114s
	iters: 200, epoch: 2 | loss: 0.6281469
	speed: 0.0063s/iter; left time: 10.3953s
Epoch: 2 cost time: 1.3479137420654297
Epoch: 2, Steps: 206 | Train Loss: 0.6199047 Vali Loss: 0.7495326 Test Loss: 1.0052900
Validation loss decreased (0.764592 --> 0.749533).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5319054
	speed: 0.0071s/iter; left time: 10.9693s
	iters: 200, epoch: 3 | loss: 0.4937042
	speed: 0.0065s/iter; left time: 9.4796s
Epoch: 3 cost time: 1.4040942192077637
Epoch: 3, Steps: 206 | Train Loss: 0.5495328 Vali Loss: 0.7542996 Test Loss: 0.9362366
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5310542
	speed: 0.0079s/iter; left time: 10.6282s
	iters: 200, epoch: 4 | loss: 0.5396286
	speed: 0.0072s/iter; left time: 8.9347s
Epoch: 4 cost time: 1.5377533435821533
Epoch: 4, Steps: 206 | Train Loss: 0.5211296 Vali Loss: 0.8126304 Test Loss: 0.9787282
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5043808
	speed: 0.0074s/iter; left time: 8.4659s
	iters: 200, epoch: 5 | loss: 0.4999076
	speed: 0.0067s/iter; left time: 6.9455s
Epoch: 5 cost time: 1.431812047958374
Epoch: 5, Steps: 206 | Train Loss: 0.5097912 Vali Loss: 0.8119293 Test Loss: 0.9748824
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5012118
	speed: 0.0076s/iter; left time: 7.1071s
	iters: 200, epoch: 6 | loss: 0.4927371
	speed: 0.0068s/iter; left time: 5.6518s
Epoch: 6 cost time: 1.4540560245513916
Epoch: 6, Steps: 206 | Train Loss: 0.5049623 Vali Loss: 0.8173900 Test Loss: 0.9530500
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4800443
	speed: 0.0092s/iter; left time: 6.6867s
	iters: 200, epoch: 7 | loss: 0.4977978
	speed: 0.0084s/iter; left time: 5.2708s
Epoch: 7 cost time: 1.795165777206421
Epoch: 7, Steps: 206 | Train Loss: 0.5024717 Vali Loss: 0.8380020 Test Loss: 0.9713804
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0052900314331055, mae:0.7918254137039185
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8183075
	speed: 0.0095s/iter; left time: 18.6080s
	iters: 200, epoch: 1 | loss: 0.7249898
	speed: 0.0080s/iter; left time: 14.9729s
Epoch: 1 cost time: 1.6964597702026367
Epoch: 1, Steps: 206 | Train Loss: 0.7706092 Vali Loss: 0.7389909 Test Loss: 1.1558934
Validation loss decreased (inf --> 0.738991).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7037995
	speed: 0.0088s/iter; left time: 15.3756s
	iters: 200, epoch: 2 | loss: 0.5735393
	speed: 0.0076s/iter; left time: 12.6360s
Epoch: 2 cost time: 1.6333158016204834
Epoch: 2, Steps: 206 | Train Loss: 0.6379950 Vali Loss: 0.7388968 Test Loss: 0.9206646
Validation loss decreased (0.738991 --> 0.738897).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6253608
	speed: 0.0074s/iter; left time: 11.5324s
	iters: 200, epoch: 3 | loss: 0.5739833
	speed: 0.0066s/iter; left time: 9.5175s
Epoch: 3 cost time: 1.412818431854248
Epoch: 3, Steps: 206 | Train Loss: 0.5839387 Vali Loss: 0.7758002 Test Loss: 0.9927516
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5367889
	speed: 0.0068s/iter; left time: 9.1635s
	iters: 200, epoch: 4 | loss: 0.5938790
	speed: 0.0065s/iter; left time: 8.0575s
Epoch: 4 cost time: 1.3909294605255127
Epoch: 4, Steps: 206 | Train Loss: 0.5569782 Vali Loss: 0.8401878 Test Loss: 0.9998526
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5378178
	speed: 0.0084s/iter; left time: 9.5946s
	iters: 200, epoch: 5 | loss: 0.5393000
	speed: 0.0079s/iter; left time: 8.2161s
Epoch: 5 cost time: 1.6806108951568604
Epoch: 5, Steps: 206 | Train Loss: 0.5419248 Vali Loss: 0.8795596 Test Loss: 0.9895126
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5555196
	speed: 0.0094s/iter; left time: 8.7571s
	iters: 200, epoch: 6 | loss: 0.5672799
	speed: 0.0086s/iter; left time: 7.1165s
Epoch: 6 cost time: 1.832533836364746
Epoch: 6, Steps: 206 | Train Loss: 0.5377397 Vali Loss: 0.8463282 Test Loss: 0.9484341
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5503360
	speed: 0.0095s/iter; left time: 6.8571s
	iters: 200, epoch: 7 | loss: 0.5832687
	speed: 0.0086s/iter; left time: 5.3648s
Epoch: 7 cost time: 1.8558862209320068
Epoch: 7, Steps: 206 | Train Loss: 0.5313462 Vali Loss: 0.8688726 Test Loss: 0.9539220
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9206646084785461, mae:0.7657465934753418
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8514609
	speed: 0.0124s/iter; left time: 22.8075s
Epoch: 1 cost time: 1.7854249477386475
Epoch: 1, Steps: 194 | Train Loss: 0.9297977 Vali Loss: 0.5506523 Test Loss: 1.2909703
Validation loss decreased (inf --> 0.550652).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7802942
	speed: 0.0075s/iter; left time: 12.4066s
Epoch: 2 cost time: 1.3486759662628174
Epoch: 2, Steps: 194 | Train Loss: 0.7506751 Vali Loss: 0.5614636 Test Loss: 1.1443694
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7240847
	speed: 0.0091s/iter; left time: 13.1611s
Epoch: 3 cost time: 1.6339848041534424
Epoch: 3, Steps: 194 | Train Loss: 0.6636768 Vali Loss: 0.6098872 Test Loss: 1.1984808
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6211763
	speed: 0.0071s/iter; left time: 8.9311s
Epoch: 4 cost time: 1.332338571548462
Epoch: 4, Steps: 194 | Train Loss: 0.6280755 Vali Loss: 0.6254928 Test Loss: 1.2001553
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6240353
	speed: 0.0094s/iter; left time: 10.0487s
Epoch: 5 cost time: 1.7591426372528076
Epoch: 5, Steps: 194 | Train Loss: 0.6145435 Vali Loss: 0.6450387 Test Loss: 1.1752938
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5889336
	speed: 0.0082s/iter; left time: 7.1467s
Epoch: 6 cost time: 1.5118553638458252
Epoch: 6, Steps: 194 | Train Loss: 0.6073324 Vali Loss: 0.6475513 Test Loss: 1.1752356
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2909702062606812, mae:0.8822959661483765
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8543978
	speed: 0.0086s/iter; left time: 15.8825s
Epoch: 1 cost time: 1.5380194187164307
Epoch: 1, Steps: 194 | Train Loss: 0.9281596 Vali Loss: 0.6107780 Test Loss: 1.1506056
Validation loss decreased (inf --> 0.610778).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7506222
	speed: 0.0068s/iter; left time: 11.1360s
Epoch: 2 cost time: 1.3790695667266846
Epoch: 2, Steps: 194 | Train Loss: 0.7996635 Vali Loss: 0.6138629 Test Loss: 1.2767504
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6313833
	speed: 0.0083s/iter; left time: 12.0235s
Epoch: 3 cost time: 1.5549592971801758
Epoch: 3, Steps: 194 | Train Loss: 0.6558679 Vali Loss: 0.6491619 Test Loss: 1.1346782
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5753725
	speed: 0.0083s/iter; left time: 10.4490s
Epoch: 4 cost time: 1.5201797485351562
Epoch: 4, Steps: 194 | Train Loss: 0.6093186 Vali Loss: 0.6790907 Test Loss: 1.1833394
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5572784
	speed: 0.0084s/iter; left time: 8.9583s
Epoch: 5 cost time: 1.537379503250122
Epoch: 5, Steps: 194 | Train Loss: 0.5958339 Vali Loss: 0.6677178 Test Loss: 1.1697687
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6413499
	speed: 0.0076s/iter; left time: 6.6542s
Epoch: 6 cost time: 1.4027037620544434
Epoch: 6, Steps: 194 | Train Loss: 0.5880384 Vali Loss: 0.6676857 Test Loss: 1.1735753
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.1506054401397705, mae:0.8407752513885498
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9042137
	speed: 0.0096s/iter; left time: 17.6275s
Epoch: 1 cost time: 1.6583201885223389
Epoch: 1, Steps: 194 | Train Loss: 0.9230763 Vali Loss: 0.5798430 Test Loss: 1.1171229
Validation loss decreased (inf --> 0.579843).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7655473
	speed: 0.0096s/iter; left time: 15.7999s
Epoch: 2 cost time: 1.6380259990692139
Epoch: 2, Steps: 194 | Train Loss: 0.7520687 Vali Loss: 0.6080001 Test Loss: 1.1858438
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5828135
	speed: 0.0079s/iter; left time: 11.5016s
Epoch: 3 cost time: 1.4128968715667725
Epoch: 3, Steps: 194 | Train Loss: 0.6177880 Vali Loss: 0.6156927 Test Loss: 1.1599674
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5639781
	speed: 0.0094s/iter; left time: 11.8855s
Epoch: 4 cost time: 1.7586708068847656
Epoch: 4, Steps: 194 | Train Loss: 0.5880137 Vali Loss: 0.6362133 Test Loss: 1.1717770
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5489848
	speed: 0.0095s/iter; left time: 10.1124s
Epoch: 5 cost time: 1.7617831230163574
Epoch: 5, Steps: 194 | Train Loss: 0.5750734 Vali Loss: 0.6325251 Test Loss: 1.1691848
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6069863
	speed: 0.0095s/iter; left time: 8.3000s
Epoch: 6 cost time: 1.7559056282043457
Epoch: 6, Steps: 194 | Train Loss: 0.5697332 Vali Loss: 0.6472935 Test Loss: 1.1748110
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.1171226501464844, mae:0.8267887830734253
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.4939018
	speed: 0.0174s/iter; left time: 35.3605s
	iters: 200, epoch: 1 | loss: 0.4536824
	speed: 0.0114s/iter; left time: 22.0677s
Epoch: 1 cost time: 2.395393133163452
Epoch: 1, Steps: 213 | Train Loss: 0.5720161 Vali Loss: 0.5023847 Test Loss: 0.5955924
Validation loss decreased (inf --> 0.502385).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5189493
	speed: 0.0070s/iter; left time: 12.7479s
	iters: 200, epoch: 2 | loss: 0.4720756
	speed: 0.0063s/iter; left time: 10.8464s
Epoch: 2 cost time: 1.3982264995574951
Epoch: 2, Steps: 213 | Train Loss: 0.4959107 Vali Loss: 0.5292500 Test Loss: 0.5856634
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4460081
	speed: 0.0090s/iter; left time: 14.5162s
	iters: 200, epoch: 3 | loss: 0.4725912
	speed: 0.0083s/iter; left time: 12.5203s
Epoch: 3 cost time: 1.8208017349243164
Epoch: 3, Steps: 213 | Train Loss: 0.4624705 Vali Loss: 0.5035437 Test Loss: 0.5920559
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4478277
	speed: 0.0091s/iter; left time: 12.7290s
	iters: 200, epoch: 4 | loss: 0.4443752
	speed: 0.0084s/iter; left time: 10.8390s
Epoch: 4 cost time: 1.8473422527313232
Epoch: 4, Steps: 213 | Train Loss: 0.4476057 Vali Loss: 0.5107722 Test Loss: 0.5857595
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4260747
	speed: 0.0081s/iter; left time: 9.5367s
	iters: 200, epoch: 5 | loss: 0.4482070
	speed: 0.0073s/iter; left time: 7.9034s
Epoch: 5 cost time: 1.6170005798339844
Epoch: 5, Steps: 213 | Train Loss: 0.4394685 Vali Loss: 0.5163888 Test Loss: 0.5801095
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4304577
	speed: 0.0075s/iter; left time: 7.2304s
	iters: 200, epoch: 6 | loss: 0.4334646
	speed: 0.0067s/iter; left time: 5.8174s
Epoch: 6 cost time: 1.467400074005127
Epoch: 6, Steps: 213 | Train Loss: 0.4351855 Vali Loss: 0.5140190 Test Loss: 0.5822766
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5955924391746521, mae:0.6126863360404968
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5671417
	speed: 0.0093s/iter; left time: 18.8710s
	iters: 200, epoch: 1 | loss: 0.5308827
	speed: 0.0084s/iter; left time: 16.1991s
Epoch: 1 cost time: 1.8416545391082764
Epoch: 1, Steps: 213 | Train Loss: 0.5739830 Vali Loss: 0.5002624 Test Loss: 0.5623081
Validation loss decreased (inf --> 0.500262).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5072181
	speed: 0.0089s/iter; left time: 16.2334s
	iters: 200, epoch: 2 | loss: 0.4297917
	speed: 0.0082s/iter; left time: 14.1491s
Epoch: 2 cost time: 1.8100717067718506
Epoch: 2, Steps: 213 | Train Loss: 0.4961406 Vali Loss: 0.4913066 Test Loss: 0.5495557
Validation loss decreased (0.500262 --> 0.491307).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4702428
	speed: 0.0081s/iter; left time: 13.0689s
	iters: 200, epoch: 3 | loss: 0.4388099
	speed: 0.0073s/iter; left time: 10.9196s
Epoch: 3 cost time: 1.5922107696533203
Epoch: 3, Steps: 213 | Train Loss: 0.4688209 Vali Loss: 0.5071819 Test Loss: 0.5645949
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4664450
	speed: 0.0080s/iter; left time: 11.1761s
	iters: 200, epoch: 4 | loss: 0.4254318
	speed: 0.0074s/iter; left time: 9.6025s
Epoch: 4 cost time: 1.6484858989715576
Epoch: 4, Steps: 213 | Train Loss: 0.4522790 Vali Loss: 0.5303285 Test Loss: 0.5874383
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4580402
	speed: 0.0091s/iter; left time: 10.6805s
	iters: 200, epoch: 5 | loss: 0.4159538
	speed: 0.0083s/iter; left time: 8.9385s
Epoch: 5 cost time: 1.8160860538482666
Epoch: 5, Steps: 213 | Train Loss: 0.4433230 Vali Loss: 0.5299038 Test Loss: 0.5900913
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4332941
	speed: 0.0092s/iter; left time: 8.8963s
	iters: 200, epoch: 6 | loss: 0.4362701
	speed: 0.0084s/iter; left time: 7.2660s
Epoch: 6 cost time: 1.8391578197479248
Epoch: 6, Steps: 213 | Train Loss: 0.4387151 Vali Loss: 0.5259474 Test Loss: 0.5843390
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4169683
	speed: 0.0094s/iter; left time: 7.0626s
	iters: 200, epoch: 7 | loss: 0.4130350
	speed: 0.0086s/iter; left time: 5.6020s
Epoch: 7 cost time: 1.8874907493591309
Epoch: 7, Steps: 213 | Train Loss: 0.4371789 Vali Loss: 0.5257183 Test Loss: 0.5860152
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5495556592941284, mae:0.5866796374320984
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5579094
	speed: 0.0094s/iter; left time: 19.1576s
	iters: 200, epoch: 1 | loss: 0.4960235
	speed: 0.0085s/iter; left time: 16.4640s
Epoch: 1 cost time: 1.8657257556915283
Epoch: 1, Steps: 213 | Train Loss: 0.5759024 Vali Loss: 0.4753033 Test Loss: 0.5651643
Validation loss decreased (inf --> 0.475303).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4751150
	speed: 0.0093s/iter; left time: 16.9170s
	iters: 200, epoch: 2 | loss: 0.4763674
	speed: 0.0084s/iter; left time: 14.5137s
Epoch: 2 cost time: 1.85835599899292
Epoch: 2, Steps: 213 | Train Loss: 0.5013023 Vali Loss: 0.5152032 Test Loss: 0.5783460
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4740312
	speed: 0.0092s/iter; left time: 14.7473s
	iters: 200, epoch: 3 | loss: 0.4480217
	speed: 0.0084s/iter; left time: 12.6231s
Epoch: 3 cost time: 1.84580397605896
Epoch: 3, Steps: 213 | Train Loss: 0.4681562 Vali Loss: 0.5034772 Test Loss: 0.5585927
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4483396
	speed: 0.0092s/iter; left time: 12.8665s
	iters: 200, epoch: 4 | loss: 0.4631324
	speed: 0.0084s/iter; left time: 10.8905s
Epoch: 4 cost time: 1.8479750156402588
Epoch: 4, Steps: 213 | Train Loss: 0.4511707 Vali Loss: 0.5369675 Test Loss: 0.5783408
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4521064
	speed: 0.0094s/iter; left time: 11.1043s
	iters: 200, epoch: 5 | loss: 0.4639460
	speed: 0.0086s/iter; left time: 9.2980s
Epoch: 5 cost time: 1.8919150829315186
Epoch: 5, Steps: 213 | Train Loss: 0.4410464 Vali Loss: 0.5183195 Test Loss: 0.5707096
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4407691
	speed: 0.0093s/iter; left time: 8.9554s
	iters: 200, epoch: 6 | loss: 0.4336368
	speed: 0.0084s/iter; left time: 7.3056s
Epoch: 6 cost time: 1.8476197719573975
Epoch: 6, Steps: 213 | Train Loss: 0.4365351 Vali Loss: 0.5397969 Test Loss: 0.5806455
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5651643872261047, mae:0.5953601598739624
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7493032
	speed: 0.0146s/iter; left time: 29.1624s
	iters: 200, epoch: 1 | loss: 0.5568252
	speed: 0.0099s/iter; left time: 18.7401s
Epoch: 1 cost time: 2.101423740386963
Epoch: 1, Steps: 210 | Train Loss: 0.6709921 Vali Loss: 0.5964845 Test Loss: 0.8162999
Validation loss decreased (inf --> 0.596484).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6316046
	speed: 0.0084s/iter; left time: 15.1206s
	iters: 200, epoch: 2 | loss: 0.5901785
	speed: 0.0075s/iter; left time: 12.6576s
Epoch: 2 cost time: 1.6184380054473877
Epoch: 2, Steps: 210 | Train Loss: 0.5757010 Vali Loss: 0.5987535 Test Loss: 0.8031787
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5521969
	speed: 0.0067s/iter; left time: 10.5141s
	iters: 200, epoch: 3 | loss: 0.5711910
	speed: 0.0059s/iter; left time: 8.7124s
Epoch: 3 cost time: 1.2713375091552734
Epoch: 3, Steps: 210 | Train Loss: 0.5323945 Vali Loss: 0.6110508 Test Loss: 0.7813801
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5177399
	speed: 0.0079s/iter; left time: 10.8636s
	iters: 200, epoch: 4 | loss: 0.5337582
	speed: 0.0073s/iter; left time: 9.2508s
Epoch: 4 cost time: 1.5802652835845947
Epoch: 4, Steps: 210 | Train Loss: 0.5076224 Vali Loss: 0.6515483 Test Loss: 0.8083545
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4868417
	speed: 0.0086s/iter; left time: 10.0337s
	iters: 200, epoch: 5 | loss: 0.5176808
	speed: 0.0080s/iter; left time: 8.4882s
Epoch: 5 cost time: 1.7317373752593994
Epoch: 5, Steps: 210 | Train Loss: 0.4942426 Vali Loss: 0.6497697 Test Loss: 0.8019418
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4918960
	speed: 0.0079s/iter; left time: 7.4843s
	iters: 200, epoch: 6 | loss: 0.4697301
	speed: 0.0077s/iter; left time: 6.5843s
Epoch: 6 cost time: 1.6925644874572754
Epoch: 6, Steps: 210 | Train Loss: 0.4915917 Vali Loss: 0.6513714 Test Loss: 0.7846902
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8162998557090759, mae:0.7144061923027039
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5899494
	speed: 0.0093s/iter; left time: 18.5441s
	iters: 200, epoch: 1 | loss: 0.5904212
	speed: 0.0084s/iter; left time: 15.9766s
Epoch: 1 cost time: 1.8113915920257568
Epoch: 1, Steps: 210 | Train Loss: 0.6679146 Vali Loss: 0.5549897 Test Loss: 0.7815214
Validation loss decreased (inf --> 0.554990).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5529252
	speed: 0.0095s/iter; left time: 17.0756s
	iters: 200, epoch: 2 | loss: 0.5315208
	speed: 0.0085s/iter; left time: 14.4032s
Epoch: 2 cost time: 1.8386259078979492
Epoch: 2, Steps: 210 | Train Loss: 0.5788690 Vali Loss: 0.6181555 Test Loss: 0.7875645
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5089677
	speed: 0.0087s/iter; left time: 13.8304s
	iters: 200, epoch: 3 | loss: 0.4845983
	speed: 0.0082s/iter; left time: 12.1202s
Epoch: 3 cost time: 1.7713792324066162
Epoch: 3, Steps: 210 | Train Loss: 0.5268120 Vali Loss: 0.6166123 Test Loss: 0.7765836
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4737690
	speed: 0.0091s/iter; left time: 12.4748s
	iters: 200, epoch: 4 | loss: 0.4748253
	speed: 0.0078s/iter; left time: 9.9563s
Epoch: 4 cost time: 1.6799030303955078
Epoch: 4, Steps: 210 | Train Loss: 0.5022973 Vali Loss: 0.5809432 Test Loss: 0.7255285
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4956178
	speed: 0.0075s/iter; left time: 8.7611s
	iters: 200, epoch: 5 | loss: 0.4803066
	speed: 0.0067s/iter; left time: 7.1263s
Epoch: 5 cost time: 1.4571726322174072
Epoch: 5, Steps: 210 | Train Loss: 0.4883776 Vali Loss: 0.6129814 Test Loss: 0.7343267
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4445984
	speed: 0.0092s/iter; left time: 8.7895s
	iters: 200, epoch: 6 | loss: 0.4661780
	speed: 0.0084s/iter; left time: 7.1775s
Epoch: 6 cost time: 1.8247342109680176
Epoch: 6, Steps: 210 | Train Loss: 0.4823502 Vali Loss: 0.6222464 Test Loss: 0.7495229
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7815213203430176, mae:0.6963205337524414
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6369246
	speed: 0.0095s/iter; left time: 19.0049s
	iters: 200, epoch: 1 | loss: 0.5857117
	speed: 0.0086s/iter; left time: 16.3465s
Epoch: 1 cost time: 1.86411452293396
Epoch: 1, Steps: 210 | Train Loss: 0.6686838 Vali Loss: 0.5532208 Test Loss: 0.7706707
Validation loss decreased (inf --> 0.553221).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5245191
	speed: 0.0083s/iter; left time: 14.8189s
	iters: 200, epoch: 2 | loss: 0.6135978
	speed: 0.0079s/iter; left time: 13.2879s
Epoch: 2 cost time: 1.7168240547180176
Epoch: 2, Steps: 210 | Train Loss: 0.5732645 Vali Loss: 0.5961249 Test Loss: 0.7919277
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5587825
	speed: 0.0092s/iter; left time: 14.5082s
	iters: 200, epoch: 3 | loss: 0.4949616
	speed: 0.0084s/iter; left time: 12.4141s
Epoch: 3 cost time: 1.8106048107147217
Epoch: 3, Steps: 210 | Train Loss: 0.5216480 Vali Loss: 0.6237326 Test Loss: 0.7220979
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5063642
	speed: 0.0094s/iter; left time: 12.8671s
	iters: 200, epoch: 4 | loss: 0.5087620
	speed: 0.0085s/iter; left time: 10.8058s
Epoch: 4 cost time: 1.851384162902832
Epoch: 4, Steps: 210 | Train Loss: 0.4939248 Vali Loss: 0.6078529 Test Loss: 0.7190811
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4808753
	speed: 0.0093s/iter; left time: 10.7670s
	iters: 200, epoch: 5 | loss: 0.4840526
	speed: 0.0084s/iter; left time: 8.9347s
Epoch: 5 cost time: 1.8166913986206055
Epoch: 5, Steps: 210 | Train Loss: 0.4808496 Vali Loss: 0.6174589 Test Loss: 0.7365452
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4760617
	speed: 0.0093s/iter; left time: 8.8061s
	iters: 200, epoch: 6 | loss: 0.4766934
	speed: 0.0084s/iter; left time: 7.1701s
Epoch: 6 cost time: 1.8238286972045898
Epoch: 6, Steps: 210 | Train Loss: 0.4762104 Vali Loss: 0.6116024 Test Loss: 0.7397980
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7706707715988159, mae:0.6932017207145691
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6916441
	speed: 0.0144s/iter; left time: 28.2970s
	iters: 200, epoch: 1 | loss: 0.6933053
	speed: 0.0111s/iter; left time: 20.5818s
Epoch: 1 cost time: 2.3103957176208496
Epoch: 1, Steps: 206 | Train Loss: 0.7666573 Vali Loss: 0.7034588 Test Loss: 1.1200567
Validation loss decreased (inf --> 0.703459).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5918623
	speed: 0.0086s/iter; left time: 15.1120s
	iters: 200, epoch: 2 | loss: 0.5672728
	speed: 0.0081s/iter; left time: 13.4505s
Epoch: 2 cost time: 1.7255311012268066
Epoch: 2, Steps: 206 | Train Loss: 0.6340352 Vali Loss: 0.7157443 Test Loss: 1.0848439
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5830500
	speed: 0.0087s/iter; left time: 13.4429s
	iters: 200, epoch: 3 | loss: 0.5470151
	speed: 0.0082s/iter; left time: 11.8146s
Epoch: 3 cost time: 1.7333683967590332
Epoch: 3, Steps: 206 | Train Loss: 0.5630714 Vali Loss: 0.7064961 Test Loss: 1.0096393
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5589516
	speed: 0.0091s/iter; left time: 12.2829s
	iters: 200, epoch: 4 | loss: 0.5614160
	speed: 0.0075s/iter; left time: 9.3287s
Epoch: 4 cost time: 1.5970849990844727
Epoch: 4, Steps: 206 | Train Loss: 0.5303981 Vali Loss: 0.6429691 Test Loss: 0.9328846
Validation loss decreased (0.703459 --> 0.642969).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5376422
	speed: 0.0075s/iter; left time: 8.5296s
	iters: 200, epoch: 5 | loss: 0.5119213
	speed: 0.0067s/iter; left time: 6.9430s
Epoch: 5 cost time: 1.429152250289917
Epoch: 5, Steps: 206 | Train Loss: 0.5179300 Vali Loss: 0.6673786 Test Loss: 0.9573941
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5099729
	speed: 0.0074s/iter; left time: 6.8481s
	iters: 200, epoch: 6 | loss: 0.4901314
	speed: 0.0067s/iter; left time: 5.5789s
Epoch: 6 cost time: 1.4295647144317627
Epoch: 6, Steps: 206 | Train Loss: 0.5109018 Vali Loss: 0.6628221 Test Loss: 0.9640728
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5156642
	speed: 0.0091s/iter; left time: 6.6082s
	iters: 200, epoch: 7 | loss: 0.5148523
	speed: 0.0082s/iter; left time: 5.1003s
Epoch: 7 cost time: 1.744062900543213
Epoch: 7, Steps: 206 | Train Loss: 0.5087512 Vali Loss: 0.6753828 Test Loss: 0.9774972
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5027776
	speed: 0.0086s/iter; left time: 4.4737s
	iters: 200, epoch: 8 | loss: 0.4902168
	speed: 0.0081s/iter; left time: 3.3948s
Epoch: 8 cost time: 1.720505952835083
Epoch: 8, Steps: 206 | Train Loss: 0.5061548 Vali Loss: 0.6699120 Test Loss: 0.9706637
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5227548
	speed: 0.0092s/iter; left time: 2.8708s
	iters: 200, epoch: 9 | loss: 0.5021773
	speed: 0.0076s/iter; left time: 1.6286s
Epoch: 9 cost time: 1.6107230186462402
Epoch: 9, Steps: 206 | Train Loss: 0.5049587 Vali Loss: 0.6685382 Test Loss: 0.9703102
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9328845739364624, mae:0.7707796692848206
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6280241
	speed: 0.0080s/iter; left time: 15.7111s
	iters: 200, epoch: 1 | loss: 0.6745951
	speed: 0.0070s/iter; left time: 12.9462s
Epoch: 1 cost time: 1.4792113304138184
Epoch: 1, Steps: 206 | Train Loss: 0.7584678 Vali Loss: 0.6070035 Test Loss: 0.8785637
Validation loss decreased (inf --> 0.607003).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6020154
	speed: 0.0090s/iter; left time: 15.8515s
	iters: 200, epoch: 2 | loss: 0.5854045
	speed: 0.0083s/iter; left time: 13.7463s
Epoch: 2 cost time: 1.7601711750030518
Epoch: 2, Steps: 206 | Train Loss: 0.6187847 Vali Loss: 0.6116828 Test Loss: 1.0062722
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5302857
	speed: 0.0076s/iter; left time: 11.7508s
	iters: 200, epoch: 3 | loss: 0.5206389
	speed: 0.0068s/iter; left time: 9.8227s
Epoch: 3 cost time: 1.459855079650879
Epoch: 3, Steps: 206 | Train Loss: 0.5503681 Vali Loss: 0.6296841 Test Loss: 1.0162598
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5439386
	speed: 0.0072s/iter; left time: 9.6427s
	iters: 200, epoch: 4 | loss: 0.5592617
	speed: 0.0066s/iter; left time: 8.1536s
Epoch: 4 cost time: 1.4014554023742676
Epoch: 4, Steps: 206 | Train Loss: 0.5246947 Vali Loss: 0.6288364 Test Loss: 0.9339337
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4935120
	speed: 0.0091s/iter; left time: 10.3908s
	iters: 200, epoch: 5 | loss: 0.4780121
	speed: 0.0084s/iter; left time: 8.6623s
Epoch: 5 cost time: 1.7722103595733643
Epoch: 5, Steps: 206 | Train Loss: 0.5105154 Vali Loss: 0.6409194 Test Loss: 0.9464228
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5083044
	speed: 0.0075s/iter; left time: 6.9908s
	iters: 200, epoch: 6 | loss: 0.4806506
	speed: 0.0067s/iter; left time: 5.6061s
Epoch: 6 cost time: 1.4574954509735107
Epoch: 6, Steps: 206 | Train Loss: 0.5066873 Vali Loss: 0.6499892 Test Loss: 0.9660260
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8785637617111206, mae:0.7439616918563843
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6925280
	speed: 0.0090s/iter; left time: 17.6229s
	iters: 200, epoch: 1 | loss: 0.5700065
	speed: 0.0080s/iter; left time: 14.8930s
Epoch: 1 cost time: 1.6930601596832275
Epoch: 1, Steps: 206 | Train Loss: 0.7618465 Vali Loss: 0.7171943 Test Loss: 1.1210214
Validation loss decreased (inf --> 0.717194).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5924461
	speed: 0.0089s/iter; left time: 15.6664s
	iters: 200, epoch: 2 | loss: 0.6328552
	speed: 0.0083s/iter; left time: 13.7146s
Epoch: 2 cost time: 1.7697513103485107
Epoch: 2, Steps: 206 | Train Loss: 0.6311215 Vali Loss: 0.5888046 Test Loss: 1.0042570
Validation loss decreased (0.717194 --> 0.588805).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5744258
	speed: 0.0081s/iter; left time: 12.5092s
	iters: 200, epoch: 3 | loss: 0.5811420
	speed: 0.0077s/iter; left time: 11.1538s
Epoch: 3 cost time: 1.632585048675537
Epoch: 3, Steps: 206 | Train Loss: 0.5617542 Vali Loss: 0.6208653 Test Loss: 0.9797910
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5294197
	speed: 0.0093s/iter; left time: 12.4355s
	iters: 200, epoch: 4 | loss: 0.5718632
	speed: 0.0085s/iter; left time: 10.5060s
Epoch: 4 cost time: 1.804744005203247
Epoch: 4, Steps: 206 | Train Loss: 0.5286162 Vali Loss: 0.6659799 Test Loss: 0.9870987
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4669800
	speed: 0.0092s/iter; left time: 10.4251s
	iters: 200, epoch: 5 | loss: 0.5068380
	speed: 0.0084s/iter; left time: 8.6827s
Epoch: 5 cost time: 1.7890706062316895
Epoch: 5, Steps: 206 | Train Loss: 0.5153674 Vali Loss: 0.6763154 Test Loss: 0.9805588
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4882834
	speed: 0.0093s/iter; left time: 8.6988s
	iters: 200, epoch: 6 | loss: 0.5190800
	speed: 0.0086s/iter; left time: 7.1340s
Epoch: 6 cost time: 1.8337314128875732
Epoch: 6, Steps: 206 | Train Loss: 0.5087399 Vali Loss: 0.6906600 Test Loss: 0.9777087
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5090761
	speed: 0.0092s/iter; left time: 6.6939s
	iters: 200, epoch: 7 | loss: 0.4836874
	speed: 0.0084s/iter; left time: 5.2702s
Epoch: 7 cost time: 1.791405200958252
Epoch: 7, Steps: 206 | Train Loss: 0.5049551 Vali Loss: 0.6812379 Test Loss: 0.9652780
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0042569637298584, mae:0.7941837906837463
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8282924
	speed: 0.0152s/iter; left time: 27.9613s
Epoch: 1 cost time: 2.201802968978882
Epoch: 1, Steps: 194 | Train Loss: 0.9224785 Vali Loss: 0.6264980 Test Loss: 1.0957338
Validation loss decreased (inf --> 0.626498).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7705168
	speed: 0.0094s/iter; left time: 15.5187s
Epoch: 2 cost time: 1.778118371963501
Epoch: 2, Steps: 194 | Train Loss: 0.7345128 Vali Loss: 0.5744691 Test Loss: 1.1164242
Validation loss decreased (0.626498 --> 0.574469).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6014616
	speed: 0.0094s/iter; left time: 13.6931s
Epoch: 3 cost time: 1.699282169342041
Epoch: 3, Steps: 194 | Train Loss: 0.6142195 Vali Loss: 0.5849249 Test Loss: 1.1278145
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5937111
	speed: 0.0076s/iter; left time: 9.5307s
Epoch: 4 cost time: 1.3908109664916992
Epoch: 4, Steps: 194 | Train Loss: 0.5853674 Vali Loss: 0.6107358 Test Loss: 1.1368630
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5588809
	speed: 0.0093s/iter; left time: 9.8999s
Epoch: 5 cost time: 1.6678593158721924
Epoch: 5, Steps: 194 | Train Loss: 0.5750579 Vali Loss: 0.6014864 Test Loss: 1.1397891
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5513397
	speed: 0.0084s/iter; left time: 7.3096s
Epoch: 6 cost time: 1.5580508708953857
Epoch: 6, Steps: 194 | Train Loss: 0.5704548 Vali Loss: 0.5966528 Test Loss: 1.1515081
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5454250
	speed: 0.0095s/iter; left time: 6.4103s
Epoch: 7 cost time: 1.742663860321045
Epoch: 7, Steps: 194 | Train Loss: 0.5664117 Vali Loss: 0.6053212 Test Loss: 1.1413364
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.1164240837097168, mae:0.831609845161438
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9508888
	speed: 0.0096s/iter; left time: 17.6973s
Epoch: 1 cost time: 1.7635996341705322
Epoch: 1, Steps: 194 | Train Loss: 0.9267363 Vali Loss: 0.6170410 Test Loss: 1.0805392
Validation loss decreased (inf --> 0.617041).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7264630
	speed: 0.0097s/iter; left time: 15.9434s
Epoch: 2 cost time: 1.7781896591186523
Epoch: 2, Steps: 194 | Train Loss: 0.7203944 Vali Loss: 0.6515496 Test Loss: 1.1588439
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6498427
	speed: 0.0094s/iter; left time: 13.6013s
Epoch: 3 cost time: 1.7340714931488037
Epoch: 3, Steps: 194 | Train Loss: 0.6116795 Vali Loss: 0.6015069 Test Loss: 1.1650296
Validation loss decreased (0.617041 --> 0.601507).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5558559
	speed: 0.0096s/iter; left time: 12.1441s
Epoch: 4 cost time: 1.7640745639801025
Epoch: 4, Steps: 194 | Train Loss: 0.5814220 Vali Loss: 0.6330578 Test Loss: 1.1304586
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5351045
	speed: 0.0095s/iter; left time: 10.1379s
Epoch: 5 cost time: 1.755007028579712
Epoch: 5, Steps: 194 | Train Loss: 0.5710383 Vali Loss: 0.6366029 Test Loss: 1.1267514
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5849754
	speed: 0.0095s/iter; left time: 8.2418s
Epoch: 6 cost time: 1.7468090057373047
Epoch: 6, Steps: 194 | Train Loss: 0.5656344 Vali Loss: 0.6344314 Test Loss: 1.1302795
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5584767
	speed: 0.0095s/iter; left time: 6.4238s
Epoch: 7 cost time: 1.7489802837371826
Epoch: 7, Steps: 194 | Train Loss: 0.5624762 Vali Loss: 0.6387339 Test Loss: 1.1338122
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5766059
	speed: 0.0097s/iter; left time: 4.6881s
Epoch: 8 cost time: 1.8057770729064941
Epoch: 8, Steps: 194 | Train Loss: 0.5614500 Vali Loss: 0.6408187 Test Loss: 1.1345342
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.165029764175415, mae:0.8477662801742554
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8867040
	speed: 0.0096s/iter; left time: 17.6138s
Epoch: 1 cost time: 1.7537000179290771
Epoch: 1, Steps: 194 | Train Loss: 0.9243767 Vali Loss: 0.6176521 Test Loss: 1.1037432
Validation loss decreased (inf --> 0.617652).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6828943
	speed: 0.0099s/iter; left time: 16.2521s
Epoch: 2 cost time: 1.7954673767089844
Epoch: 2, Steps: 194 | Train Loss: 0.7493957 Vali Loss: 0.5847341 Test Loss: 1.1178836
Validation loss decreased (0.617652 --> 0.584734).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5940043
	speed: 0.0098s/iter; left time: 14.2211s
Epoch: 3 cost time: 1.7877213954925537
Epoch: 3, Steps: 194 | Train Loss: 0.6142032 Vali Loss: 0.6065774 Test Loss: 1.1566066
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6031407
	speed: 0.0094s/iter; left time: 11.8772s
Epoch: 4 cost time: 1.7427027225494385
Epoch: 4, Steps: 194 | Train Loss: 0.5834128 Vali Loss: 0.6101282 Test Loss: 1.1641197
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5658923
	speed: 0.0094s/iter; left time: 10.0316s
Epoch: 5 cost time: 1.7406625747680664
Epoch: 5, Steps: 194 | Train Loss: 0.5711220 Vali Loss: 0.6236557 Test Loss: 1.1564106
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5264834
	speed: 0.0099s/iter; left time: 8.6538s
Epoch: 6 cost time: 1.803809404373169
Epoch: 6, Steps: 194 | Train Loss: 0.5639733 Vali Loss: 0.6283895 Test Loss: 1.1571263
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5759179
	speed: 0.0093s/iter; left time: 6.3058s
Epoch: 7 cost time: 1.7350640296936035
Epoch: 7, Steps: 194 | Train Loss: 0.5608833 Vali Loss: 0.6240118 Test Loss: 1.1656759
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.1178834438323975, mae:0.836571991443634
