nohup: ignoring input
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0362644
	speed: 0.0425s/iter; left time: 86.2962s
	iters: 200, epoch: 1 | loss: 1.0201324
	speed: 0.0284s/iter; left time: 54.7758s
Epoch: 1 cost time: 6.030989408493042
Epoch: 1, Steps: 213 | Train Loss: 1.0580016 Vali Loss: 1.0446702 Test Loss: 1.0270693
Validation loss decreased (inf --> 1.044670).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0559510
	speed: 0.0152s/iter; left time: 27.6916s
	iters: 200, epoch: 2 | loss: 1.0451975
	speed: 0.0133s/iter; left time: 22.9024s
Epoch: 2 cost time: 2.9436895847320557
Epoch: 2, Steps: 213 | Train Loss: 1.0427639 Vali Loss: 1.0472010 Test Loss: 1.0273337
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0033503
	speed: 0.0182s/iter; left time: 29.2681s
	iters: 200, epoch: 3 | loss: 1.0132229
	speed: 0.0168s/iter; left time: 25.2476s
Epoch: 3 cost time: 3.6272170543670654
Epoch: 3, Steps: 213 | Train Loss: 1.0374097 Vali Loss: 1.0442703 Test Loss: 1.0258495
Validation loss decreased (1.044670 --> 1.044270).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0295184
	speed: 0.0214s/iter; left time: 29.7874s
	iters: 200, epoch: 4 | loss: 1.0241741
	speed: 0.0174s/iter; left time: 22.4450s
Epoch: 4 cost time: 3.690477132797241
Epoch: 4, Steps: 213 | Train Loss: 1.0339622 Vali Loss: 1.0431031 Test Loss: 1.0259116
Validation loss decreased (1.044270 --> 1.043103).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0333915
	speed: 0.0226s/iter; left time: 26.6868s
	iters: 200, epoch: 5 | loss: 1.0796191
	speed: 0.0194s/iter; left time: 20.8904s
Epoch: 5 cost time: 4.093489170074463
Epoch: 5, Steps: 213 | Train Loss: 1.0325457 Vali Loss: 1.0427647 Test Loss: 1.0256172
Validation loss decreased (1.043103 --> 1.042765).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0353094
	speed: 0.0179s/iter; left time: 17.3326s
	iters: 200, epoch: 6 | loss: 1.0434587
	speed: 0.0152s/iter; left time: 13.1938s
Epoch: 6 cost time: 3.2396609783172607
Epoch: 6, Steps: 213 | Train Loss: 1.0312364 Vali Loss: 1.0409766 Test Loss: 1.0258800
Validation loss decreased (1.042765 --> 1.040977).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9997784
	speed: 0.0146s/iter; left time: 10.9860s
	iters: 200, epoch: 7 | loss: 1.0110239
	speed: 0.0146s/iter; left time: 9.5591s
Epoch: 7 cost time: 3.211536407470703
Epoch: 7, Steps: 213 | Train Loss: 1.0308170 Vali Loss: 1.0411729 Test Loss: 1.0259579
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0308173
	speed: 0.0154s/iter; left time: 8.2918s
	iters: 200, epoch: 8 | loss: 1.0351056
	speed: 0.0148s/iter; left time: 6.5009s
Epoch: 8 cost time: 3.226080894470215
Epoch: 8, Steps: 213 | Train Loss: 1.0303794 Vali Loss: 1.0420169 Test Loss: 1.0261769
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0646925
	speed: 0.0223s/iter; left time: 7.3076s
	iters: 200, epoch: 9 | loss: 1.0386355
	speed: 0.0202s/iter; left time: 4.5878s
Epoch: 9 cost time: 4.300549030303955
Epoch: 9, Steps: 213 | Train Loss: 1.0300255 Vali Loss: 1.0409775 Test Loss: 1.0262080
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9974135
	speed: 0.0171s/iter; left time: 1.9477s
	iters: 200, epoch: 10 | loss: 1.0390085
	speed: 0.0145s/iter; left time: 0.2033s
Epoch: 10 cost time: 3.1690125465393066
Epoch: 10, Steps: 213 | Train Loss: 1.0299992 Vali Loss: 1.0418110 Test Loss: 1.0262320
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0258800983428955, mae:0.8080206513404846
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0346415
	speed: 0.0199s/iter; left time: 40.4319s
	iters: 200, epoch: 1 | loss: 1.0439718
	speed: 0.0176s/iter; left time: 33.9705s
Epoch: 1 cost time: 3.8653109073638916
Epoch: 1, Steps: 213 | Train Loss: 1.0577655 Vali Loss: 1.0465314 Test Loss: 1.0278252
Validation loss decreased (inf --> 1.046531).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0406593
	speed: 0.0215s/iter; left time: 38.9971s
	iters: 200, epoch: 2 | loss: 1.0656176
	speed: 0.0174s/iter; left time: 29.8655s
Epoch: 2 cost time: 3.779843330383301
Epoch: 2, Steps: 213 | Train Loss: 1.0429539 Vali Loss: 1.0457075 Test Loss: 1.0265654
Validation loss decreased (1.046531 --> 1.045707).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0609332
	speed: 0.0187s/iter; left time: 30.0194s
	iters: 200, epoch: 3 | loss: 1.0077689
	speed: 0.0154s/iter; left time: 23.1267s
Epoch: 3 cost time: 3.280658483505249
Epoch: 3, Steps: 213 | Train Loss: 1.0375551 Vali Loss: 1.0436816 Test Loss: 1.0266212
Validation loss decreased (1.045707 --> 1.043682).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0157114
	speed: 0.0205s/iter; left time: 28.5715s
	iters: 200, epoch: 4 | loss: 1.0419438
	speed: 0.0152s/iter; left time: 19.6259s
Epoch: 4 cost time: 3.3075215816497803
Epoch: 4, Steps: 213 | Train Loss: 1.0341633 Vali Loss: 1.0418468 Test Loss: 1.0267955
Validation loss decreased (1.043682 --> 1.041847).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0123891
	speed: 0.0189s/iter; left time: 22.2783s
	iters: 200, epoch: 5 | loss: 1.0170730
	speed: 0.0177s/iter; left time: 19.1274s
Epoch: 5 cost time: 3.796093702316284
Epoch: 5, Steps: 213 | Train Loss: 1.0326112 Vali Loss: 1.0428395 Test Loss: 1.0260452
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0128189
	speed: 0.0174s/iter; left time: 16.8420s
	iters: 200, epoch: 6 | loss: 1.0187978
	speed: 0.0172s/iter; left time: 14.8651s
Epoch: 6 cost time: 3.704676628112793
Epoch: 6, Steps: 213 | Train Loss: 1.0315615 Vali Loss: 1.0412644 Test Loss: 1.0265716
Validation loss decreased (1.041847 --> 1.041264).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0158536
	speed: 0.0324s/iter; left time: 24.3807s
	iters: 200, epoch: 7 | loss: 1.0201567
	speed: 0.0226s/iter; left time: 14.7858s
Epoch: 7 cost time: 4.701860189437866
Epoch: 7, Steps: 213 | Train Loss: 1.0308893 Vali Loss: 1.0420884 Test Loss: 1.0265749
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0141153
	speed: 0.0178s/iter; left time: 9.6184s
	iters: 200, epoch: 8 | loss: 1.0693941
	speed: 0.0158s/iter; left time: 6.9639s
Epoch: 8 cost time: 3.411905527114868
Epoch: 8, Steps: 213 | Train Loss: 1.0305867 Vali Loss: 1.0417571 Test Loss: 1.0265988
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0081387
	speed: 0.0244s/iter; left time: 7.9840s
	iters: 200, epoch: 9 | loss: 1.0283570
	speed: 0.0203s/iter; left time: 4.5992s
Epoch: 9 cost time: 4.463903427124023
Epoch: 9, Steps: 213 | Train Loss: 1.0301413 Vali Loss: 1.0416389 Test Loss: 1.0266880
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0332563
	speed: 0.0176s/iter; left time: 2.0076s
	iters: 200, epoch: 10 | loss: 1.0236611
	speed: 0.0169s/iter; left time: 0.2365s
Epoch: 10 cost time: 3.7159290313720703
Epoch: 10, Steps: 213 | Train Loss: 1.0303976 Vali Loss: 1.0428451 Test Loss: 1.0267400
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0265716314315796, mae:0.8082616329193115
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0861058
	speed: 0.0170s/iter; left time: 34.5178s
	iters: 200, epoch: 1 | loss: 1.0177481
	speed: 0.0149s/iter; left time: 28.7788s
Epoch: 1 cost time: 3.194287061691284
Epoch: 1, Steps: 213 | Train Loss: 1.0578398 Vali Loss: 1.0427803 Test Loss: 1.0273910
Validation loss decreased (inf --> 1.042780).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0665250
	speed: 0.0189s/iter; left time: 34.3559s
	iters: 200, epoch: 2 | loss: 1.0392323
	speed: 0.0188s/iter; left time: 32.2171s
Epoch: 2 cost time: 4.044416427612305
Epoch: 2, Steps: 213 | Train Loss: 1.0428392 Vali Loss: 1.0457431 Test Loss: 1.0283633
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0527484
	speed: 0.0159s/iter; left time: 25.5818s
	iters: 200, epoch: 3 | loss: 1.0099199
	speed: 0.0151s/iter; left time: 22.6542s
Epoch: 3 cost time: 3.3635952472686768
Epoch: 3, Steps: 213 | Train Loss: 1.0370266 Vali Loss: 1.0433708 Test Loss: 1.0267193
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0405093
	speed: 0.0202s/iter; left time: 28.1872s
	iters: 200, epoch: 4 | loss: 1.0590072
	speed: 0.0198s/iter; left time: 25.6055s
Epoch: 4 cost time: 4.2968971729278564
Epoch: 4, Steps: 213 | Train Loss: 1.0337906 Vali Loss: 1.0423787 Test Loss: 1.0258310
Validation loss decreased (1.042780 --> 1.042379).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0380642
	speed: 0.0187s/iter; left time: 22.0975s
	iters: 200, epoch: 5 | loss: 1.0082016
	speed: 0.0152s/iter; left time: 16.4045s
Epoch: 5 cost time: 3.3472275733947754
Epoch: 5, Steps: 213 | Train Loss: 1.0322208 Vali Loss: 1.0432059 Test Loss: 1.0263164
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0549506
	speed: 0.0185s/iter; left time: 17.9077s
	iters: 200, epoch: 6 | loss: 1.0413969
	speed: 0.0160s/iter; left time: 13.8469s
Epoch: 6 cost time: 3.6168644428253174
Epoch: 6, Steps: 213 | Train Loss: 1.0308588 Vali Loss: 1.0420920 Test Loss: 1.0265404
Validation loss decreased (1.042379 --> 1.042092).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0311918
	speed: 0.0160s/iter; left time: 12.0820s
	iters: 200, epoch: 7 | loss: 1.0369673
	speed: 0.0139s/iter; left time: 9.0662s
Epoch: 7 cost time: 2.962352752685547
Epoch: 7, Steps: 213 | Train Loss: 1.0302417 Vali Loss: 1.0425986 Test Loss: 1.0265230
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0125450
	speed: 0.0111s/iter; left time: 5.9880s
	iters: 200, epoch: 8 | loss: 1.0205510
	speed: 0.0103s/iter; left time: 4.5395s
Epoch: 8 cost time: 2.29500675201416
Epoch: 8, Steps: 213 | Train Loss: 1.0297693 Vali Loss: 1.0405209 Test Loss: 1.0266010
Validation loss decreased (1.042092 --> 1.040521).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0124009
	speed: 0.0131s/iter; left time: 4.2950s
	iters: 200, epoch: 9 | loss: 1.0375419
	speed: 0.0104s/iter; left time: 2.3714s
Epoch: 9 cost time: 2.278146505355835
Epoch: 9, Steps: 213 | Train Loss: 1.0299214 Vali Loss: 1.0420083 Test Loss: 1.0266711
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0049191
	speed: 0.0093s/iter; left time: 1.0604s
	iters: 200, epoch: 10 | loss: 1.0524852
	speed: 0.0092s/iter; left time: 0.1289s
Epoch: 10 cost time: 2.015439987182617
Epoch: 10, Steps: 213 | Train Loss: 1.0300114 Vali Loss: 1.0419888 Test Loss: 1.0266703
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0266010761260986, mae:0.8082926869392395
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0412464
	speed: 0.0262s/iter; left time: 52.4098s
	iters: 200, epoch: 1 | loss: 1.0516766
	speed: 0.0182s/iter; left time: 34.6676s
Epoch: 1 cost time: 3.8079633712768555
Epoch: 1, Steps: 210 | Train Loss: 1.0606238 Vali Loss: 1.0499548 Test Loss: 1.0255283
Validation loss decreased (inf --> 1.049955).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0560899
	speed: 0.0176s/iter; left time: 31.4558s
	iters: 200, epoch: 2 | loss: 1.0386417
	speed: 0.0176s/iter; left time: 29.7435s
Epoch: 2 cost time: 3.7752835750579834
Epoch: 2, Steps: 210 | Train Loss: 1.0476036 Vali Loss: 1.0511458 Test Loss: 1.0259930
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0453973
	speed: 0.0202s/iter; left time: 31.8595s
	iters: 200, epoch: 3 | loss: 1.0386685
	speed: 0.0185s/iter; left time: 27.4174s
Epoch: 3 cost time: 3.972473382949829
Epoch: 3, Steps: 210 | Train Loss: 1.0429846 Vali Loss: 1.0487592 Test Loss: 1.0231175
Validation loss decreased (1.049955 --> 1.048759).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0562546
	speed: 0.0171s/iter; left time: 23.4255s
	iters: 200, epoch: 4 | loss: 1.0403687
	speed: 0.0139s/iter; left time: 17.6535s
Epoch: 4 cost time: 2.95957088470459
Epoch: 4, Steps: 210 | Train Loss: 1.0407613 Vali Loss: 1.0477391 Test Loss: 1.0230513
Validation loss decreased (1.048759 --> 1.047739).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0254881
	speed: 0.0217s/iter; left time: 25.1708s
	iters: 200, epoch: 5 | loss: 1.0270574
	speed: 0.0158s/iter; left time: 16.7170s
Epoch: 5 cost time: 3.285689115524292
Epoch: 5, Steps: 210 | Train Loss: 1.0390092 Vali Loss: 1.0474198 Test Loss: 1.0224911
Validation loss decreased (1.047739 --> 1.047420).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0473369
	speed: 0.0171s/iter; left time: 16.2872s
	iters: 200, epoch: 6 | loss: 1.0318049
	speed: 0.0172s/iter; left time: 14.6082s
Epoch: 6 cost time: 3.761526584625244
Epoch: 6, Steps: 210 | Train Loss: 1.0383628 Vali Loss: 1.0490549 Test Loss: 1.0221955
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0421808
	speed: 0.0246s/iter; left time: 18.2528s
	iters: 200, epoch: 7 | loss: 1.0229883
	speed: 0.0203s/iter; left time: 12.9842s
Epoch: 7 cost time: 4.298730373382568
Epoch: 7, Steps: 210 | Train Loss: 1.0377290 Vali Loss: 1.0470011 Test Loss: 1.0224794
Validation loss decreased (1.047420 --> 1.047001).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0664967
	speed: 0.0239s/iter; left time: 12.6965s
	iters: 200, epoch: 8 | loss: 1.0387834
	speed: 0.0222s/iter; left time: 9.5868s
Epoch: 8 cost time: 4.766272306442261
Epoch: 8, Steps: 210 | Train Loss: 1.0377131 Vali Loss: 1.0471919 Test Loss: 1.0223063
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0458182
	speed: 0.0175s/iter; left time: 5.6276s
	iters: 200, epoch: 9 | loss: 1.0616684
	speed: 0.0135s/iter; left time: 2.9909s
Epoch: 9 cost time: 2.90651273727417
Epoch: 9, Steps: 210 | Train Loss: 1.0376533 Vali Loss: 1.0485370 Test Loss: 1.0223194
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0650988
	speed: 0.0220s/iter; left time: 2.4396s
	iters: 200, epoch: 10 | loss: 1.0320499
	speed: 0.0166s/iter; left time: 0.1823s
Epoch: 10 cost time: 3.5360300540924072
Epoch: 10, Steps: 210 | Train Loss: 1.0373586 Vali Loss: 1.0480564 Test Loss: 1.0223511
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0224794149398804, mae:0.805912435054779
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0557890
	speed: 0.0214s/iter; left time: 42.8831s
	iters: 200, epoch: 1 | loss: 1.0254006
	speed: 0.0166s/iter; left time: 31.5339s
Epoch: 1 cost time: 3.565650463104248
Epoch: 1, Steps: 210 | Train Loss: 1.0601747 Vali Loss: 1.0538330 Test Loss: 1.0262057
Validation loss decreased (inf --> 1.053833).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0468841
	speed: 0.0171s/iter; left time: 30.6753s
	iters: 200, epoch: 2 | loss: 1.0174545
	speed: 0.0124s/iter; left time: 20.9405s
Epoch: 2 cost time: 2.63568115234375
Epoch: 2, Steps: 210 | Train Loss: 1.0476924 Vali Loss: 1.0485711 Test Loss: 1.0252445
Validation loss decreased (1.053833 --> 1.048571).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0601962
	speed: 0.0213s/iter; left time: 33.6670s
	iters: 200, epoch: 3 | loss: 1.0390673
	speed: 0.0173s/iter; left time: 25.6601s
Epoch: 3 cost time: 3.660527467727661
Epoch: 3, Steps: 210 | Train Loss: 1.0430138 Vali Loss: 1.0512092 Test Loss: 1.0233090
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0254437
	speed: 0.0244s/iter; left time: 33.4296s
	iters: 200, epoch: 4 | loss: 1.0528529
	speed: 0.0196s/iter; left time: 24.8889s
Epoch: 4 cost time: 4.155205488204956
Epoch: 4, Steps: 210 | Train Loss: 1.0404487 Vali Loss: 1.0481886 Test Loss: 1.0229430
Validation loss decreased (1.048571 --> 1.048189).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0266078
	speed: 0.0197s/iter; left time: 22.9191s
	iters: 200, epoch: 5 | loss: 1.0738711
	speed: 0.0185s/iter; left time: 19.5966s
Epoch: 5 cost time: 3.93290376663208
Epoch: 5, Steps: 210 | Train Loss: 1.0391240 Vali Loss: 1.0496939 Test Loss: 1.0225464
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0530969
	speed: 0.0136s/iter; left time: 12.9022s
	iters: 200, epoch: 6 | loss: 1.0401410
	speed: 0.0116s/iter; left time: 9.8481s
Epoch: 6 cost time: 2.5033257007598877
Epoch: 6, Steps: 210 | Train Loss: 1.0382218 Vali Loss: 1.0480781 Test Loss: 1.0226122
Validation loss decreased (1.048189 --> 1.048078).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0242181
	speed: 0.0197s/iter; left time: 14.6276s
	iters: 200, epoch: 7 | loss: 1.0219400
	speed: 0.0156s/iter; left time: 10.0123s
Epoch: 7 cost time: 3.359951972961426
Epoch: 7, Steps: 210 | Train Loss: 1.0375258 Vali Loss: 1.0480574 Test Loss: 1.0224949
Validation loss decreased (1.048078 --> 1.048057).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0617414
	speed: 0.0275s/iter; left time: 14.6066s
	iters: 200, epoch: 8 | loss: 1.0325742
	speed: 0.0213s/iter; left time: 9.1997s
Epoch: 8 cost time: 4.463104248046875
Epoch: 8, Steps: 210 | Train Loss: 1.0377659 Vali Loss: 1.0474020 Test Loss: 1.0226797
Validation loss decreased (1.048057 --> 1.047402).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0444119
	speed: 0.0231s/iter; left time: 7.4154s
	iters: 200, epoch: 9 | loss: 1.0456362
	speed: 0.0191s/iter; left time: 4.2255s
Epoch: 9 cost time: 4.058410406112671
Epoch: 9, Steps: 210 | Train Loss: 1.0372812 Vali Loss: 1.0473210 Test Loss: 1.0226486
Validation loss decreased (1.047402 --> 1.047321).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0298531
	speed: 0.0170s/iter; left time: 1.8833s
	iters: 200, epoch: 10 | loss: 1.0574121
	speed: 0.0145s/iter; left time: 0.1591s
Epoch: 10 cost time: 3.0419702529907227
Epoch: 10, Steps: 210 | Train Loss: 1.0372368 Vali Loss: 1.0475124 Test Loss: 1.0226514
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0226486921310425, mae:0.8060339093208313
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0392281
	speed: 0.0206s/iter; left time: 41.2554s
	iters: 200, epoch: 1 | loss: 1.0664507
	speed: 0.0210s/iter; left time: 39.9179s
Epoch: 1 cost time: 4.563594579696655
Epoch: 1, Steps: 210 | Train Loss: 1.0605135 Vali Loss: 1.0520412 Test Loss: 1.0252683
Validation loss decreased (inf --> 1.052041).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0402646
	speed: 0.0209s/iter; left time: 37.4069s
	iters: 200, epoch: 2 | loss: 1.0315126
	speed: 0.0172s/iter; left time: 29.0814s
Epoch: 2 cost time: 3.7467546463012695
Epoch: 2, Steps: 210 | Train Loss: 1.0473072 Vali Loss: 1.0510348 Test Loss: 1.0249393
Validation loss decreased (1.052041 --> 1.051035).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0379126
	speed: 0.0218s/iter; left time: 34.4316s
	iters: 200, epoch: 3 | loss: 1.0331227
	speed: 0.0174s/iter; left time: 25.6963s
Epoch: 3 cost time: 3.6212692260742188
Epoch: 3, Steps: 210 | Train Loss: 1.0435395 Vali Loss: 1.0505376 Test Loss: 1.0230328
Validation loss decreased (1.051035 --> 1.050538).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0259490
	speed: 0.0176s/iter; left time: 24.0663s
	iters: 200, epoch: 4 | loss: 1.0419478
	speed: 0.0149s/iter; left time: 18.8817s
Epoch: 4 cost time: 3.1780049800872803
Epoch: 4, Steps: 210 | Train Loss: 1.0404317 Vali Loss: 1.0485632 Test Loss: 1.0226451
Validation loss decreased (1.050538 --> 1.048563).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0213223
	speed: 0.0143s/iter; left time: 16.5692s
	iters: 200, epoch: 5 | loss: 1.0309074
	speed: 0.0165s/iter; left time: 17.5265s
Epoch: 5 cost time: 3.521544933319092
Epoch: 5, Steps: 210 | Train Loss: 1.0389706 Vali Loss: 1.0492070 Test Loss: 1.0223233
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0260285
	speed: 0.0190s/iter; left time: 18.0987s
	iters: 200, epoch: 6 | loss: 1.0526701
	speed: 0.0184s/iter; left time: 15.6994s
Epoch: 6 cost time: 3.9454727172851562
Epoch: 6, Steps: 210 | Train Loss: 1.0382099 Vali Loss: 1.0469244 Test Loss: 1.0225763
Validation loss decreased (1.048563 --> 1.046924).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0718905
	speed: 0.0143s/iter; left time: 10.6218s
	iters: 200, epoch: 7 | loss: 1.0515174
	speed: 0.0126s/iter; left time: 8.0898s
Epoch: 7 cost time: 2.718435764312744
Epoch: 7, Steps: 210 | Train Loss: 1.0377282 Vali Loss: 1.0473263 Test Loss: 1.0223690
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0390773
	speed: 0.0152s/iter; left time: 8.0964s
	iters: 200, epoch: 8 | loss: 1.0855919
	speed: 0.0126s/iter; left time: 5.4387s
Epoch: 8 cost time: 2.6619248390197754
Epoch: 8, Steps: 210 | Train Loss: 1.0375024 Vali Loss: 1.0472741 Test Loss: 1.0223697
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0703291
	speed: 0.0243s/iter; left time: 7.7902s
	iters: 200, epoch: 9 | loss: 1.0533588
	speed: 0.0178s/iter; left time: 3.9291s
Epoch: 9 cost time: 3.7330925464630127
Epoch: 9, Steps: 210 | Train Loss: 1.0371897 Vali Loss: 1.0476586 Test Loss: 1.0223764
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0169481
	speed: 0.0264s/iter; left time: 2.9351s
	iters: 200, epoch: 10 | loss: 1.0443615
	speed: 0.0197s/iter; left time: 0.2167s
Epoch: 10 cost time: 4.126226425170898
Epoch: 10, Steps: 210 | Train Loss: 1.0370983 Vali Loss: 1.0481516 Test Loss: 1.0223930
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0225762128829956, mae:0.8060325980186462
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0523970
	speed: 0.0295s/iter; left time: 57.9021s
	iters: 200, epoch: 1 | loss: 1.0493155
	speed: 0.0219s/iter; left time: 40.7869s
Epoch: 1 cost time: 4.553494215011597
Epoch: 1, Steps: 206 | Train Loss: 1.0590412 Vali Loss: 1.0594378 Test Loss: 1.0392076
Validation loss decreased (inf --> 1.059438).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0577216
	speed: 0.0230s/iter; left time: 40.3255s
	iters: 200, epoch: 2 | loss: 1.0398824
	speed: 0.0220s/iter; left time: 36.4180s
Epoch: 2 cost time: 4.637004375457764
Epoch: 2, Steps: 206 | Train Loss: 1.0472500 Vali Loss: 1.0586344 Test Loss: 1.0391983
Validation loss decreased (1.059438 --> 1.058634).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0540982
	speed: 0.0165s/iter; left time: 25.6065s
	iters: 200, epoch: 3 | loss: 1.0355475
	speed: 0.0163s/iter; left time: 23.6585s
Epoch: 3 cost time: 3.5441839694976807
Epoch: 3, Steps: 206 | Train Loss: 1.0437341 Vali Loss: 1.0607363 Test Loss: 1.0361077
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0506197
	speed: 0.0208s/iter; left time: 27.8727s
	iters: 200, epoch: 4 | loss: 1.0290999
	speed: 0.0173s/iter; left time: 21.4627s
Epoch: 4 cost time: 3.6249802112579346
Epoch: 4, Steps: 206 | Train Loss: 1.0417949 Vali Loss: 1.0566641 Test Loss: 1.0359713
Validation loss decreased (1.058634 --> 1.056664).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0243808
	speed: 0.0232s/iter; left time: 26.3333s
	iters: 200, epoch: 5 | loss: 1.0400245
	speed: 0.0193s/iter; left time: 20.0014s
Epoch: 5 cost time: 4.094520092010498
Epoch: 5, Steps: 206 | Train Loss: 1.0406474 Vali Loss: 1.0564468 Test Loss: 1.0357703
Validation loss decreased (1.056664 --> 1.056447).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0374146
	speed: 0.0210s/iter; left time: 19.5710s
	iters: 200, epoch: 6 | loss: 1.0465167
	speed: 0.0174s/iter; left time: 14.4491s
Epoch: 6 cost time: 3.7669334411621094
Epoch: 6, Steps: 206 | Train Loss: 1.0399042 Vali Loss: 1.0560144 Test Loss: 1.0358052
Validation loss decreased (1.056447 --> 1.056014).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0430893
	speed: 0.0155s/iter; left time: 11.2151s
	iters: 200, epoch: 7 | loss: 1.0370289
	speed: 0.0142s/iter; left time: 8.8648s
Epoch: 7 cost time: 2.9806015491485596
Epoch: 7, Steps: 206 | Train Loss: 1.0396345 Vali Loss: 1.0562674 Test Loss: 1.0355762
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0215541
	speed: 0.0162s/iter; left time: 8.4046s
	iters: 200, epoch: 8 | loss: 1.0486928
	speed: 0.0129s/iter; left time: 5.4181s
Epoch: 8 cost time: 2.705970287322998
Epoch: 8, Steps: 206 | Train Loss: 1.0394424 Vali Loss: 1.0562212 Test Loss: 1.0355273
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0288700
	speed: 0.0168s/iter; left time: 5.2584s
	iters: 200, epoch: 9 | loss: 1.0598581
	speed: 0.0152s/iter; left time: 3.2308s
Epoch: 9 cost time: 3.245359182357788
Epoch: 9, Steps: 206 | Train Loss: 1.0392860 Vali Loss: 1.0560510 Test Loss: 1.0355825
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0436258
	speed: 0.0164s/iter; left time: 1.7538s
	iters: 200, epoch: 10 | loss: 1.0502901
	speed: 0.0145s/iter; left time: 0.1018s
Epoch: 10 cost time: 3.0922553539276123
Epoch: 10, Steps: 206 | Train Loss: 1.0392285 Vali Loss: 1.0561612 Test Loss: 1.0356225
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0358052253723145, mae:0.809268593788147
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0575475
	speed: 0.0160s/iter; left time: 31.3709s
	iters: 200, epoch: 1 | loss: 1.0499749
	speed: 0.0179s/iter; left time: 33.2793s
Epoch: 1 cost time: 3.798626184463501
Epoch: 1, Steps: 206 | Train Loss: 1.0594901 Vali Loss: 1.0612379 Test Loss: 1.0387555
Validation loss decreased (inf --> 1.061238).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0575495
	speed: 0.0172s/iter; left time: 30.1363s
	iters: 200, epoch: 2 | loss: 1.0509691
	speed: 0.0147s/iter; left time: 24.3017s
Epoch: 2 cost time: 3.0607244968414307
Epoch: 2, Steps: 206 | Train Loss: 1.0476007 Vali Loss: 1.0600963 Test Loss: 1.0380733
Validation loss decreased (1.061238 --> 1.060096).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0326728
	speed: 0.0180s/iter; left time: 27.9549s
	iters: 200, epoch: 3 | loss: 1.0392358
	speed: 0.0149s/iter; left time: 21.6333s
Epoch: 3 cost time: 3.174064874649048
Epoch: 3, Steps: 206 | Train Loss: 1.0436770 Vali Loss: 1.0570848 Test Loss: 1.0372871
Validation loss decreased (1.060096 --> 1.057085).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0502684
	speed: 0.0312s/iter; left time: 41.8449s
	iters: 200, epoch: 4 | loss: 1.0477146
	speed: 0.0242s/iter; left time: 30.0312s
Epoch: 4 cost time: 5.005768060684204
Epoch: 4, Steps: 206 | Train Loss: 1.0417963 Vali Loss: 1.0570151 Test Loss: 1.0359329
Validation loss decreased (1.057085 --> 1.057015).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0426475
	speed: 0.0207s/iter; left time: 23.4915s
	iters: 200, epoch: 5 | loss: 1.0457530
	speed: 0.0168s/iter; left time: 17.4265s
Epoch: 5 cost time: 3.5387701988220215
Epoch: 5, Steps: 206 | Train Loss: 1.0406763 Vali Loss: 1.0559748 Test Loss: 1.0360754
Validation loss decreased (1.057015 --> 1.055975).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0341476
	speed: 0.0146s/iter; left time: 13.6373s
	iters: 200, epoch: 6 | loss: 1.0458187
	speed: 0.0131s/iter; left time: 10.8482s
Epoch: 6 cost time: 2.846914768218994
Epoch: 6, Steps: 206 | Train Loss: 1.0401806 Vali Loss: 1.0559911 Test Loss: 1.0359091
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0475761
	speed: 0.0171s/iter; left time: 12.4130s
	iters: 200, epoch: 7 | loss: 1.0393507
	speed: 0.0139s/iter; left time: 8.7082s
Epoch: 7 cost time: 2.957965612411499
Epoch: 7, Steps: 206 | Train Loss: 1.0397555 Vali Loss: 1.0559679 Test Loss: 1.0358168
Validation loss decreased (1.055975 --> 1.055968).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0491537
	speed: 0.0179s/iter; left time: 9.3157s
	iters: 200, epoch: 8 | loss: 1.0523143
	speed: 0.0180s/iter; left time: 7.5535s
Epoch: 8 cost time: 3.7652721405029297
Epoch: 8, Steps: 206 | Train Loss: 1.0395686 Vali Loss: 1.0558511 Test Loss: 1.0357243
Validation loss decreased (1.055968 --> 1.055851).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0320410
	speed: 0.0249s/iter; left time: 7.7835s
	iters: 200, epoch: 9 | loss: 1.0295200
	speed: 0.0209s/iter; left time: 4.4542s
Epoch: 9 cost time: 4.345177173614502
Epoch: 9, Steps: 206 | Train Loss: 1.0394527 Vali Loss: 1.0560732 Test Loss: 1.0357453
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0359955
	speed: 0.0168s/iter; left time: 1.8007s
	iters: 200, epoch: 10 | loss: 1.0401843
	speed: 0.0149s/iter; left time: 0.1040s
Epoch: 10 cost time: 3.1496973037719727
Epoch: 10, Steps: 206 | Train Loss: 1.0393208 Vali Loss: 1.0559429 Test Loss: 1.0357337
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.035724401473999, mae:0.8092604875564575
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0520636
	speed: 0.0127s/iter; left time: 24.9243s
	iters: 200, epoch: 1 | loss: 1.0433724
	speed: 0.0121s/iter; left time: 22.5203s
Epoch: 1 cost time: 2.613961935043335
Epoch: 1, Steps: 206 | Train Loss: 1.0590021 Vali Loss: 1.0595605 Test Loss: 1.0413455
Validation loss decreased (inf --> 1.059561).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0405579
	speed: 0.0141s/iter; left time: 24.8327s
	iters: 200, epoch: 2 | loss: 1.0339491
	speed: 0.0148s/iter; left time: 24.4768s
Epoch: 2 cost time: 3.12018084526062
Epoch: 2, Steps: 206 | Train Loss: 1.0474961 Vali Loss: 1.0580683 Test Loss: 1.0378745
Validation loss decreased (1.059561 --> 1.058068).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0485588
	speed: 0.0200s/iter; left time: 30.9064s
	iters: 200, epoch: 3 | loss: 1.0388809
	speed: 0.0222s/iter; left time: 32.2333s
Epoch: 3 cost time: 4.575931072235107
Epoch: 3, Steps: 206 | Train Loss: 1.0437958 Vali Loss: 1.0571493 Test Loss: 1.0373794
Validation loss decreased (1.058068 --> 1.057149).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0544850
	speed: 0.0211s/iter; left time: 28.3271s
	iters: 200, epoch: 4 | loss: 1.0606872
	speed: 0.0187s/iter; left time: 23.2086s
Epoch: 4 cost time: 3.907386064529419
Epoch: 4, Steps: 206 | Train Loss: 1.0417129 Vali Loss: 1.0568143 Test Loss: 1.0360006
Validation loss decreased (1.057149 --> 1.056814).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0359486
	speed: 0.0209s/iter; left time: 23.7701s
	iters: 200, epoch: 5 | loss: 1.0772070
	speed: 0.0174s/iter; left time: 18.0449s
Epoch: 5 cost time: 3.672111749649048
Epoch: 5, Steps: 206 | Train Loss: 1.0405163 Vali Loss: 1.0568746 Test Loss: 1.0357137
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0327351
	speed: 0.0187s/iter; left time: 17.4135s
	iters: 200, epoch: 6 | loss: 1.0566953
	speed: 0.0145s/iter; left time: 12.0240s
Epoch: 6 cost time: 3.0664970874786377
Epoch: 6, Steps: 206 | Train Loss: 1.0399132 Vali Loss: 1.0564144 Test Loss: 1.0356402
Validation loss decreased (1.056814 --> 1.056414).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0535798
	speed: 0.0201s/iter; left time: 14.5766s
	iters: 200, epoch: 7 | loss: 1.0384052
	speed: 0.0187s/iter; left time: 11.6707s
Epoch: 7 cost time: 3.9426841735839844
Epoch: 7, Steps: 206 | Train Loss: 1.0398752 Vali Loss: 1.0563577 Test Loss: 1.0355556
Validation loss decreased (1.056414 --> 1.056358).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0375313
	speed: 0.0208s/iter; left time: 10.8069s
	iters: 200, epoch: 8 | loss: 1.0199970
	speed: 0.0170s/iter; left time: 7.1337s
Epoch: 8 cost time: 3.5698888301849365
Epoch: 8, Steps: 206 | Train Loss: 1.0394835 Vali Loss: 1.0561509 Test Loss: 1.0355890
Validation loss decreased (1.056358 --> 1.056151).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0421079
	speed: 0.0176s/iter; left time: 5.5064s
	iters: 200, epoch: 9 | loss: 1.0402560
	speed: 0.0197s/iter; left time: 4.1907s
Epoch: 9 cost time: 4.128065586090088
Epoch: 9, Steps: 206 | Train Loss: 1.0393079 Vali Loss: 1.0562119 Test Loss: 1.0355936
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0522537
	speed: 0.0132s/iter; left time: 1.4155s
	iters: 200, epoch: 10 | loss: 1.0479064
	speed: 0.0114s/iter; left time: 0.0798s
Epoch: 10 cost time: 2.4721174240112305
Epoch: 10, Steps: 206 | Train Loss: 1.0394029 Vali Loss: 1.0561885 Test Loss: 1.0356072
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0355888605117798, mae:0.8091947436332703
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0625260
	speed: 0.0269s/iter; left time: 49.4341s
Epoch: 1 cost time: 4.177475690841675
Epoch: 1, Steps: 194 | Train Loss: 1.0627518 Vali Loss: 1.0593576 Test Loss: 1.0309235
Validation loss decreased (inf --> 1.059358).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0599462
	speed: 0.0206s/iter; left time: 33.9774s
Epoch: 2 cost time: 3.2482643127441406
Epoch: 2, Steps: 194 | Train Loss: 1.0496405 Vali Loss: 1.0588299 Test Loss: 1.0303895
Validation loss decreased (1.059358 --> 1.058830).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0498104
	speed: 0.0176s/iter; left time: 25.6041s
Epoch: 3 cost time: 2.8850786685943604
Epoch: 3, Steps: 194 | Train Loss: 1.0466014 Vali Loss: 1.0555812 Test Loss: 1.0290576
Validation loss decreased (1.058830 --> 1.055581).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0295676
	speed: 0.0204s/iter; left time: 25.6655s
Epoch: 4 cost time: 3.6599340438842773
Epoch: 4, Steps: 194 | Train Loss: 1.0450419 Vali Loss: 1.0563077 Test Loss: 1.0280448
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0403239
	speed: 0.0180s/iter; left time: 19.1677s
Epoch: 5 cost time: 3.24303936958313
Epoch: 5, Steps: 194 | Train Loss: 1.0443537 Vali Loss: 1.0543761 Test Loss: 1.0279157
Validation loss decreased (1.055581 --> 1.054376).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0451739
	speed: 0.0206s/iter; left time: 17.9184s
Epoch: 6 cost time: 3.1125872135162354
Epoch: 6, Steps: 194 | Train Loss: 1.0438810 Vali Loss: 1.0541798 Test Loss: 1.0277417
Validation loss decreased (1.054376 --> 1.054180).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0408114
	speed: 0.0151s/iter; left time: 10.2075s
Epoch: 7 cost time: 2.490795612335205
Epoch: 7, Steps: 194 | Train Loss: 1.0434964 Vali Loss: 1.0542213 Test Loss: 1.0276885
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0379386
	speed: 0.0187s/iter; left time: 9.0183s
Epoch: 8 cost time: 3.244077205657959
Epoch: 8, Steps: 194 | Train Loss: 1.0432002 Vali Loss: 1.0542326 Test Loss: 1.0276508
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0271111
	speed: 0.0183s/iter; left time: 5.3021s
Epoch: 9 cost time: 3.663919687271118
Epoch: 9, Steps: 194 | Train Loss: 1.0434198 Vali Loss: 1.0541385 Test Loss: 1.0276400
Validation loss decreased (1.054180 --> 1.054139).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0472945
	speed: 0.0166s/iter; left time: 1.5780s
Epoch: 10 cost time: 3.143523693084717
Epoch: 10, Steps: 194 | Train Loss: 1.0431807 Vali Loss: 1.0541134 Test Loss: 1.0276327
Validation loss decreased (1.054139 --> 1.054113).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0276325941085815, mae:0.8045722842216492
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0509266
	speed: 0.0181s/iter; left time: 33.4040s
Epoch: 1 cost time: 3.494091272354126
Epoch: 1, Steps: 194 | Train Loss: 1.0641065 Vali Loss: 1.0580754 Test Loss: 1.0307132
Validation loss decreased (inf --> 1.058075).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0421876
	speed: 0.0149s/iter; left time: 24.5151s
Epoch: 2 cost time: 3.2406415939331055
Epoch: 2, Steps: 194 | Train Loss: 1.0493457 Vali Loss: 1.0580820 Test Loss: 1.0306759
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0399792
	speed: 0.0150s/iter; left time: 21.8319s
Epoch: 3 cost time: 3.348115921020508
Epoch: 3, Steps: 194 | Train Loss: 1.0465764 Vali Loss: 1.0561402 Test Loss: 1.0287539
Validation loss decreased (1.058075 --> 1.056140).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0359409
	speed: 0.0203s/iter; left time: 25.6060s
Epoch: 4 cost time: 3.2435367107391357
Epoch: 4, Steps: 194 | Train Loss: 1.0449202 Vali Loss: 1.0551419 Test Loss: 1.0279483
Validation loss decreased (1.056140 --> 1.055142).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0336393
	speed: 0.0212s/iter; left time: 22.5842s
Epoch: 5 cost time: 3.5705175399780273
Epoch: 5, Steps: 194 | Train Loss: 1.0438592 Vali Loss: 1.0545850 Test Loss: 1.0278410
Validation loss decreased (1.055142 --> 1.054585).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0487121
	speed: 0.0152s/iter; left time: 13.2035s
Epoch: 6 cost time: 2.6581056118011475
Epoch: 6, Steps: 194 | Train Loss: 1.0432788 Vali Loss: 1.0542572 Test Loss: 1.0276958
Validation loss decreased (1.054585 --> 1.054257).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0392542
	speed: 0.0131s/iter; left time: 8.8472s
Epoch: 7 cost time: 2.7125751972198486
Epoch: 7, Steps: 194 | Train Loss: 1.0431307 Vali Loss: 1.0543865 Test Loss: 1.0275694
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0307788
	speed: 0.0150s/iter; left time: 7.2299s
Epoch: 8 cost time: 2.7152578830718994
Epoch: 8, Steps: 194 | Train Loss: 1.0429014 Vali Loss: 1.0540470 Test Loss: 1.0275779
Validation loss decreased (1.054257 --> 1.054047).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0407692
	speed: 0.0244s/iter; left time: 7.0491s
Epoch: 9 cost time: 4.168524742126465
Epoch: 9, Steps: 194 | Train Loss: 1.0428326 Vali Loss: 1.0540833 Test Loss: 1.0275421
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0442139
	speed: 0.0195s/iter; left time: 1.8479s
Epoch: 10 cost time: 3.5633561611175537
Epoch: 10, Steps: 194 | Train Loss: 1.0427530 Vali Loss: 1.0540080 Test Loss: 1.0275401
Validation loss decreased (1.054047 --> 1.054008).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275400876998901, mae:0.8045321106910706
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0495981
	speed: 0.0144s/iter; left time: 26.5482s
Epoch: 1 cost time: 2.968839168548584
Epoch: 1, Steps: 194 | Train Loss: 1.0621468 Vali Loss: 1.0574986 Test Loss: 1.0310651
Validation loss decreased (inf --> 1.057499).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0571507
	speed: 0.0231s/iter; left time: 38.0319s
Epoch: 2 cost time: 3.645742177963257
Epoch: 2, Steps: 194 | Train Loss: 1.0497588 Vali Loss: 1.0575825 Test Loss: 1.0301092
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0533720
	speed: 0.0159s/iter; left time: 23.1256s
Epoch: 3 cost time: 3.008714199066162
Epoch: 3, Steps: 194 | Train Loss: 1.0463915 Vali Loss: 1.0561008 Test Loss: 1.0287956
Validation loss decreased (1.057499 --> 1.056101).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0505358
	speed: 0.0186s/iter; left time: 23.4795s
Epoch: 4 cost time: 3.4845974445343018
Epoch: 4, Steps: 194 | Train Loss: 1.0450399 Vali Loss: 1.0547042 Test Loss: 1.0280861
Validation loss decreased (1.056101 --> 1.054704).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0509441
	speed: 0.0200s/iter; left time: 21.3305s
Epoch: 5 cost time: 3.503213882446289
Epoch: 5, Steps: 194 | Train Loss: 1.0440409 Vali Loss: 1.0539193 Test Loss: 1.0278339
Validation loss decreased (1.054704 --> 1.053919).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0299356
	speed: 0.0152s/iter; left time: 13.2364s
Epoch: 6 cost time: 2.7149264812469482
Epoch: 6, Steps: 194 | Train Loss: 1.0435277 Vali Loss: 1.0541183 Test Loss: 1.0277520
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0439589
	speed: 0.0170s/iter; left time: 11.4840s
Epoch: 7 cost time: 3.0815746784210205
Epoch: 7, Steps: 194 | Train Loss: 1.0433556 Vali Loss: 1.0535896 Test Loss: 1.0276617
Validation loss decreased (1.053919 --> 1.053590).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0374361
	speed: 0.0173s/iter; left time: 8.3608s
Epoch: 8 cost time: 3.221883535385132
Epoch: 8, Steps: 194 | Train Loss: 1.0431591 Vali Loss: 1.0538167 Test Loss: 1.0275899
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0415391
	speed: 0.0181s/iter; left time: 5.2388s
Epoch: 9 cost time: 3.2913849353790283
Epoch: 9, Steps: 194 | Train Loss: 1.0429184 Vali Loss: 1.0540268 Test Loss: 1.0275582
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0412530
	speed: 0.0172s/iter; left time: 1.6347s
Epoch: 10 cost time: 3.0162851810455322
Epoch: 10, Steps: 194 | Train Loss: 1.0429065 Vali Loss: 1.0539116 Test Loss: 1.0275544
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0276618003845215, mae:0.8045915365219116
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0201559
	speed: 0.0299s/iter; left time: 60.7299s
	iters: 200, epoch: 1 | loss: 1.0499710
	speed: 0.0214s/iter; left time: 41.3800s
Epoch: 1 cost time: 4.5684285163879395
Epoch: 1, Steps: 213 | Train Loss: 1.0575155 Vali Loss: 1.0448517 Test Loss: 1.0274445
Validation loss decreased (inf --> 1.044852).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0190282
	speed: 0.0129s/iter; left time: 23.4974s
	iters: 200, epoch: 2 | loss: 1.0371070
	speed: 0.0121s/iter; left time: 20.7876s
Epoch: 2 cost time: 2.6791791915893555
Epoch: 2, Steps: 213 | Train Loss: 1.0433937 Vali Loss: 1.0479921 Test Loss: 1.0278187
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0254792
	speed: 0.0140s/iter; left time: 22.4588s
	iters: 200, epoch: 3 | loss: 1.0523615
	speed: 0.0126s/iter; left time: 19.0133s
Epoch: 3 cost time: 2.7366862297058105
Epoch: 3, Steps: 213 | Train Loss: 1.0374914 Vali Loss: 1.0441506 Test Loss: 1.0253314
Validation loss decreased (1.044852 --> 1.044151).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0479330
	speed: 0.0206s/iter; left time: 28.6773s
	iters: 200, epoch: 4 | loss: 1.0070882
	speed: 0.0195s/iter; left time: 25.2387s
Epoch: 4 cost time: 4.245584011077881
Epoch: 4, Steps: 213 | Train Loss: 1.0336496 Vali Loss: 1.0419658 Test Loss: 1.0265100
Validation loss decreased (1.044151 --> 1.041966).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0561463
	speed: 0.0232s/iter; left time: 27.3530s
	iters: 200, epoch: 5 | loss: 1.0308081
	speed: 0.0193s/iter; left time: 20.7982s
Epoch: 5 cost time: 4.152165412902832
Epoch: 5, Steps: 213 | Train Loss: 1.0318918 Vali Loss: 1.0428172 Test Loss: 1.0259906
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0638812
	speed: 0.0164s/iter; left time: 15.8272s
	iters: 200, epoch: 6 | loss: 1.0376446
	speed: 0.0145s/iter; left time: 12.5436s
Epoch: 6 cost time: 3.254955530166626
Epoch: 6, Steps: 213 | Train Loss: 1.0313581 Vali Loss: 1.0420951 Test Loss: 1.0263761
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0108981
	speed: 0.0132s/iter; left time: 9.9741s
	iters: 200, epoch: 7 | loss: 1.0397089
	speed: 0.0129s/iter; left time: 8.4364s
Epoch: 7 cost time: 2.9471333026885986
Epoch: 7, Steps: 213 | Train Loss: 1.0306062 Vali Loss: 1.0424371 Test Loss: 1.0262930
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0315235
	speed: 0.0180s/iter; left time: 9.7449s
	iters: 200, epoch: 8 | loss: 1.0262086
	speed: 0.0231s/iter; left time: 10.1791s
Epoch: 8 cost time: 5.140296697616577
Epoch: 8, Steps: 213 | Train Loss: 1.0301332 Vali Loss: 1.0420191 Test Loss: 1.0263877
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0244486
	speed: 0.0161s/iter; left time: 5.2578s
	iters: 200, epoch: 9 | loss: 1.0282521
	speed: 0.0156s/iter; left time: 3.5338s
Epoch: 9 cost time: 3.3604490756988525
Epoch: 9, Steps: 213 | Train Loss: 1.0300743 Vali Loss: 1.0416970 Test Loss: 1.0264651
Validation loss decreased (1.041966 --> 1.041697).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0623059
	speed: 0.0189s/iter; left time: 2.1535s
	iters: 200, epoch: 10 | loss: 1.0254657
	speed: 0.0143s/iter; left time: 0.1996s
Epoch: 10 cost time: 3.0672826766967773
Epoch: 10, Steps: 213 | Train Loss: 1.0300502 Vali Loss: 1.0425061 Test Loss: 1.0265143
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0264649391174316, mae:0.8081640005111694
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0222366
	speed: 0.0165s/iter; left time: 33.5062s
	iters: 200, epoch: 1 | loss: 1.0555903
	speed: 0.0171s/iter; left time: 33.0085s
Epoch: 1 cost time: 3.7072455883026123
Epoch: 1, Steps: 213 | Train Loss: 1.0572691 Vali Loss: 1.0459138 Test Loss: 1.0276024
Validation loss decreased (inf --> 1.045914).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0224272
	speed: 0.0198s/iter; left time: 36.0619s
	iters: 200, epoch: 2 | loss: 1.0457733
	speed: 0.0177s/iter; left time: 30.4049s
Epoch: 2 cost time: 3.828134298324585
Epoch: 2, Steps: 213 | Train Loss: 1.0429799 Vali Loss: 1.0447354 Test Loss: 1.0261400
Validation loss decreased (1.045914 --> 1.044735).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0404375
	speed: 0.0343s/iter; left time: 55.0834s
	iters: 200, epoch: 3 | loss: 1.0254565
	speed: 0.0227s/iter; left time: 34.1881s
Epoch: 3 cost time: 4.7734081745147705
Epoch: 3, Steps: 213 | Train Loss: 1.0375910 Vali Loss: 1.0428544 Test Loss: 1.0259210
Validation loss decreased (1.044735 --> 1.042854).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0532436
	speed: 0.0159s/iter; left time: 22.1924s
	iters: 200, epoch: 4 | loss: 1.0133299
	speed: 0.0129s/iter; left time: 16.6493s
Epoch: 4 cost time: 2.763674736022949
Epoch: 4, Steps: 213 | Train Loss: 1.0340022 Vali Loss: 1.0425805 Test Loss: 1.0257379
Validation loss decreased (1.042854 --> 1.042580).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9871167
	speed: 0.0272s/iter; left time: 32.0156s
	iters: 200, epoch: 5 | loss: 1.0169849
	speed: 0.0205s/iter; left time: 22.1387s
Epoch: 5 cost time: 4.319779396057129
Epoch: 5, Steps: 213 | Train Loss: 1.0322045 Vali Loss: 1.0440451 Test Loss: 1.0258582
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0229949
	speed: 0.0216s/iter; left time: 20.8520s
	iters: 200, epoch: 6 | loss: 1.0391506
	speed: 0.0194s/iter; left time: 16.8359s
Epoch: 6 cost time: 4.166735649108887
Epoch: 6, Steps: 213 | Train Loss: 1.0312377 Vali Loss: 1.0427129 Test Loss: 1.0257565
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0302510
	speed: 0.0189s/iter; left time: 14.2375s
	iters: 200, epoch: 7 | loss: 1.0361540
	speed: 0.0151s/iter; left time: 9.8855s
Epoch: 7 cost time: 3.230928421020508
Epoch: 7, Steps: 213 | Train Loss: 1.0304237 Vali Loss: 1.0410146 Test Loss: 1.0260270
Validation loss decreased (1.042580 --> 1.041015).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0088695
	speed: 0.0207s/iter; left time: 11.1986s
	iters: 200, epoch: 8 | loss: 1.0499698
	speed: 0.0181s/iter; left time: 7.9792s
Epoch: 8 cost time: 3.9101409912109375
Epoch: 8, Steps: 213 | Train Loss: 1.0299501 Vali Loss: 1.0417756 Test Loss: 1.0261136
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0366915
	speed: 0.0167s/iter; left time: 5.4474s
	iters: 200, epoch: 9 | loss: 1.0210304
	speed: 0.0147s/iter; left time: 3.3324s
Epoch: 9 cost time: 3.2672486305236816
Epoch: 9, Steps: 213 | Train Loss: 1.0296718 Vali Loss: 1.0417662 Test Loss: 1.0261503
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0113087
	speed: 0.0170s/iter; left time: 1.9422s
	iters: 200, epoch: 10 | loss: 1.0586746
	speed: 0.0154s/iter; left time: 0.2157s
Epoch: 10 cost time: 3.302963972091675
Epoch: 10, Steps: 213 | Train Loss: 1.0295153 Vali Loss: 1.0409696 Test Loss: 1.0261805
Validation loss decreased (1.041015 --> 1.040970).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0261805057525635, mae:0.8080506920814514
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0464444
	speed: 0.0144s/iter; left time: 29.3383s
	iters: 200, epoch: 1 | loss: 1.0462053
	speed: 0.0132s/iter; left time: 25.5176s
Epoch: 1 cost time: 2.944544553756714
Epoch: 1, Steps: 213 | Train Loss: 1.0573715 Vali Loss: 1.0456879 Test Loss: 1.0276064
Validation loss decreased (inf --> 1.045688).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0743852
	speed: 0.0195s/iter; left time: 35.4421s
	iters: 200, epoch: 2 | loss: 1.0616726
	speed: 0.0158s/iter; left time: 27.2049s
Epoch: 2 cost time: 3.3676979541778564
Epoch: 2, Steps: 213 | Train Loss: 1.0423747 Vali Loss: 1.0438508 Test Loss: 1.0280834
Validation loss decreased (1.045688 --> 1.043851).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0074134
	speed: 0.0172s/iter; left time: 27.6724s
	iters: 200, epoch: 3 | loss: 1.0354334
	speed: 0.0167s/iter; left time: 25.1416s
Epoch: 3 cost time: 3.611011266708374
Epoch: 3, Steps: 213 | Train Loss: 1.0372094 Vali Loss: 1.0455778 Test Loss: 1.0264245
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0329261
	speed: 0.0190s/iter; left time: 26.3813s
	iters: 200, epoch: 4 | loss: 1.0500288
	speed: 0.0162s/iter; left time: 20.9409s
Epoch: 4 cost time: 3.526021957397461
Epoch: 4, Steps: 213 | Train Loss: 1.0339221 Vali Loss: 1.0423117 Test Loss: 1.0268857
Validation loss decreased (1.043851 --> 1.042312).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0276476
	speed: 0.0203s/iter; left time: 23.9127s
	iters: 200, epoch: 5 | loss: 1.0253574
	speed: 0.0156s/iter; left time: 16.7998s
Epoch: 5 cost time: 3.295297861099243
Epoch: 5, Steps: 213 | Train Loss: 1.0313603 Vali Loss: 1.0427642 Test Loss: 1.0260367
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0634627
	speed: 0.0207s/iter; left time: 20.0001s
	iters: 200, epoch: 6 | loss: 1.0116718
	speed: 0.0182s/iter; left time: 15.7612s
Epoch: 6 cost time: 3.873873233795166
Epoch: 6, Steps: 213 | Train Loss: 1.0301822 Vali Loss: 1.0430951 Test Loss: 1.0260642
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0146151
	speed: 0.0273s/iter; left time: 20.5934s
	iters: 200, epoch: 7 | loss: 1.0121675
	speed: 0.0215s/iter; left time: 14.0440s
Epoch: 7 cost time: 4.549344062805176
Epoch: 7, Steps: 213 | Train Loss: 1.0295467 Vali Loss: 1.0409482 Test Loss: 1.0263003
Validation loss decreased (1.042312 --> 1.040948).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0431540
	speed: 0.0192s/iter; left time: 10.3807s
	iters: 200, epoch: 8 | loss: 1.0293331
	speed: 0.0150s/iter; left time: 6.5966s
Epoch: 8 cost time: 3.2034361362457275
Epoch: 8, Steps: 213 | Train Loss: 1.0292049 Vali Loss: 1.0411991 Test Loss: 1.0263634
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0268745
	speed: 0.0139s/iter; left time: 4.5410s
	iters: 200, epoch: 9 | loss: 1.0130922
	speed: 0.0136s/iter; left time: 3.0877s
Epoch: 9 cost time: 2.975874185562134
Epoch: 9, Steps: 213 | Train Loss: 1.0292522 Vali Loss: 1.0417504 Test Loss: 1.0263594
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0542549
	speed: 0.0144s/iter; left time: 1.6428s
	iters: 200, epoch: 10 | loss: 1.0346208
	speed: 0.0179s/iter; left time: 0.2507s
Epoch: 10 cost time: 3.955091953277588
Epoch: 10, Steps: 213 | Train Loss: 1.0289935 Vali Loss: 1.0411307 Test Loss: 1.0264007
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.026300072669983, mae:0.8081674575805664
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0713536
	speed: 0.0286s/iter; left time: 57.2355s
	iters: 200, epoch: 1 | loss: 1.0249791
	speed: 0.0196s/iter; left time: 37.2758s
Epoch: 1 cost time: 4.072186470031738
Epoch: 1, Steps: 210 | Train Loss: 1.0609335 Vali Loss: 1.0523216 Test Loss: 1.0252482
Validation loss decreased (inf --> 1.052322).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0817418
	speed: 0.0253s/iter; left time: 45.3115s
	iters: 200, epoch: 2 | loss: 1.0431902
	speed: 0.0203s/iter; left time: 34.3660s
Epoch: 2 cost time: 4.235851287841797
Epoch: 2, Steps: 210 | Train Loss: 1.0471373 Vali Loss: 1.0499115 Test Loss: 1.0248168
Validation loss decreased (1.052322 --> 1.049911).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0234765
	speed: 0.0183s/iter; left time: 28.9274s
	iters: 200, epoch: 3 | loss: 1.0551023
	speed: 0.0156s/iter; left time: 23.1495s
Epoch: 3 cost time: 3.348454475402832
Epoch: 3, Steps: 210 | Train Loss: 1.0429898 Vali Loss: 1.0474547 Test Loss: 1.0244600
Validation loss decreased (1.049911 --> 1.047455).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0240442
	speed: 0.0183s/iter; left time: 25.1056s
	iters: 200, epoch: 4 | loss: 1.0183866
	speed: 0.0156s/iter; left time: 19.8563s
Epoch: 4 cost time: 3.309394121170044
Epoch: 4, Steps: 210 | Train Loss: 1.0402915 Vali Loss: 1.0489777 Test Loss: 1.0227385
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0354497
	speed: 0.0172s/iter; left time: 19.9221s
	iters: 200, epoch: 5 | loss: 1.0336232
	speed: 0.0135s/iter; left time: 14.3473s
Epoch: 5 cost time: 2.9200069904327393
Epoch: 5, Steps: 210 | Train Loss: 1.0385145 Vali Loss: 1.0475689 Test Loss: 1.0227590
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0583510
	speed: 0.0260s/iter; left time: 24.6822s
	iters: 200, epoch: 6 | loss: 1.0323464
	speed: 0.0239s/iter; left time: 20.3655s
Epoch: 6 cost time: 5.139335870742798
Epoch: 6, Steps: 210 | Train Loss: 1.0377855 Vali Loss: 1.0473207 Test Loss: 1.0226692
Validation loss decreased (1.047455 --> 1.047321).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0347214
	speed: 0.0186s/iter; left time: 13.7559s
	iters: 200, epoch: 7 | loss: 1.0068882
	speed: 0.0160s/iter; left time: 10.2321s
Epoch: 7 cost time: 3.411090612411499
Epoch: 7, Steps: 210 | Train Loss: 1.0373274 Vali Loss: 1.0480521 Test Loss: 1.0224462
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0181688
	speed: 0.0169s/iter; left time: 8.9985s
	iters: 200, epoch: 8 | loss: 1.0676450
	speed: 0.0133s/iter; left time: 5.7407s
Epoch: 8 cost time: 2.8893394470214844
Epoch: 8, Steps: 210 | Train Loss: 1.0371425 Vali Loss: 1.0470726 Test Loss: 1.0225775
Validation loss decreased (1.047321 --> 1.047073).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0461361
	speed: 0.0168s/iter; left time: 5.3957s
	iters: 200, epoch: 9 | loss: 1.0436984
	speed: 0.0136s/iter; left time: 3.0160s
Epoch: 9 cost time: 2.924720287322998
Epoch: 9, Steps: 210 | Train Loss: 1.0370992 Vali Loss: 1.0485114 Test Loss: 1.0225843
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0274185
	speed: 0.0134s/iter; left time: 1.4929s
	iters: 200, epoch: 10 | loss: 1.0273557
	speed: 0.0122s/iter; left time: 0.1344s
Epoch: 10 cost time: 2.5957725048065186
Epoch: 10, Steps: 210 | Train Loss: 1.0368457 Vali Loss: 1.0482690 Test Loss: 1.0226033
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0225776433944702, mae:0.8059542775154114
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0491039
	speed: 0.0116s/iter; left time: 23.1398s
	iters: 200, epoch: 1 | loss: 1.0428113
	speed: 0.0111s/iter; left time: 21.0976s
Epoch: 1 cost time: 2.426227331161499
Epoch: 1, Steps: 210 | Train Loss: 1.0603995 Vali Loss: 1.0514392 Test Loss: 1.0244125
Validation loss decreased (inf --> 1.051439).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0597628
	speed: 0.0213s/iter; left time: 38.0881s
	iters: 200, epoch: 2 | loss: 1.0166059
	speed: 0.0190s/iter; left time: 32.1512s
Epoch: 2 cost time: 4.089610576629639
Epoch: 2, Steps: 210 | Train Loss: 1.0472146 Vali Loss: 1.0501832 Test Loss: 1.0249907
Validation loss decreased (1.051439 --> 1.050183).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0522323
	speed: 0.0174s/iter; left time: 27.4423s
	iters: 200, epoch: 3 | loss: 1.0346451
	speed: 0.0161s/iter; left time: 23.8773s
Epoch: 3 cost time: 3.5387020111083984
Epoch: 3, Steps: 210 | Train Loss: 1.0431620 Vali Loss: 1.0492676 Test Loss: 1.0237048
Validation loss decreased (1.050183 --> 1.049268).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0547560
	speed: 0.0175s/iter; left time: 24.0472s
	iters: 200, epoch: 4 | loss: 1.0361857
	speed: 0.0160s/iter; left time: 20.3254s
Epoch: 4 cost time: 3.455209732055664
Epoch: 4, Steps: 210 | Train Loss: 1.0406575 Vali Loss: 1.0483732 Test Loss: 1.0230247
Validation loss decreased (1.049268 --> 1.048373).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0369328
	speed: 0.0158s/iter; left time: 18.3549s
	iters: 200, epoch: 5 | loss: 1.0428083
	speed: 0.0126s/iter; left time: 13.3379s
Epoch: 5 cost time: 2.6862292289733887
Epoch: 5, Steps: 210 | Train Loss: 1.0391228 Vali Loss: 1.0501456 Test Loss: 1.0221786
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0373375
	speed: 0.0176s/iter; left time: 16.7226s
	iters: 200, epoch: 6 | loss: 1.0249557
	speed: 0.0162s/iter; left time: 13.7736s
Epoch: 6 cost time: 3.3996222019195557
Epoch: 6, Steps: 210 | Train Loss: 1.0382300 Vali Loss: 1.0482484 Test Loss: 1.0221972
Validation loss decreased (1.048373 --> 1.048248).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0231342
	speed: 0.0251s/iter; left time: 18.5621s
	iters: 200, epoch: 7 | loss: 1.0568230
	speed: 0.0187s/iter; left time: 11.9798s
Epoch: 7 cost time: 3.9727437496185303
Epoch: 7, Steps: 210 | Train Loss: 1.0376466 Vali Loss: 1.0484138 Test Loss: 1.0223681
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0349487
	speed: 0.0201s/iter; left time: 10.6954s
	iters: 200, epoch: 8 | loss: 1.0175447
	speed: 0.0173s/iter; left time: 7.4392s
Epoch: 8 cost time: 3.6287732124328613
Epoch: 8, Steps: 210 | Train Loss: 1.0374803 Vali Loss: 1.0478899 Test Loss: 1.0222899
Validation loss decreased (1.048248 --> 1.047890).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0283647
	speed: 0.0157s/iter; left time: 5.0535s
	iters: 200, epoch: 9 | loss: 1.0362300
	speed: 0.0140s/iter; left time: 3.0988s
Epoch: 9 cost time: 2.998286008834839
Epoch: 9, Steps: 210 | Train Loss: 1.0372646 Vali Loss: 1.0479784 Test Loss: 1.0222826
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0138116
	speed: 0.0204s/iter; left time: 2.2591s
	iters: 200, epoch: 10 | loss: 1.0470603
	speed: 0.0175s/iter; left time: 0.1921s
Epoch: 10 cost time: 3.7722926139831543
Epoch: 10, Steps: 210 | Train Loss: 1.0371807 Vali Loss: 1.0473340 Test Loss: 1.0223033
Validation loss decreased (1.047890 --> 1.047334).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0223034620285034, mae:0.8058394193649292
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0467509
	speed: 0.0265s/iter; left time: 53.1195s
	iters: 200, epoch: 1 | loss: 1.0425918
	speed: 0.0222s/iter; left time: 42.2360s
Epoch: 1 cost time: 4.638782262802124
Epoch: 1, Steps: 210 | Train Loss: 1.0611515 Vali Loss: 1.0513072 Test Loss: 1.0250324
Validation loss decreased (inf --> 1.051307).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0729883
	speed: 0.0194s/iter; left time: 34.7945s
	iters: 200, epoch: 2 | loss: 1.0389471
	speed: 0.0159s/iter; left time: 26.8298s
Epoch: 2 cost time: 3.3849470615386963
Epoch: 2, Steps: 210 | Train Loss: 1.0475775 Vali Loss: 1.0517303 Test Loss: 1.0250785
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0195348
	speed: 0.0122s/iter; left time: 19.2473s
	iters: 200, epoch: 3 | loss: 1.0363877
	speed: 0.0135s/iter; left time: 19.9352s
Epoch: 3 cost time: 2.9667670726776123
Epoch: 3, Steps: 210 | Train Loss: 1.0429602 Vali Loss: 1.0494130 Test Loss: 1.0231239
Validation loss decreased (1.051307 --> 1.049413).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0181502
	speed: 0.0170s/iter; left time: 23.3515s
	iters: 200, epoch: 4 | loss: 1.0450143
	speed: 0.0167s/iter; left time: 21.2023s
Epoch: 4 cost time: 3.5897531509399414
Epoch: 4, Steps: 210 | Train Loss: 1.0406426 Vali Loss: 1.0489099 Test Loss: 1.0224831
Validation loss decreased (1.049413 --> 1.048910).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0147157
	speed: 0.0203s/iter; left time: 23.5221s
	iters: 200, epoch: 5 | loss: 1.0530685
	speed: 0.0186s/iter; left time: 19.7030s
Epoch: 5 cost time: 3.904418468475342
Epoch: 5, Steps: 210 | Train Loss: 1.0389183 Vali Loss: 1.0477934 Test Loss: 1.0227928
Validation loss decreased (1.048910 --> 1.047793).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0219071
	speed: 0.0154s/iter; left time: 14.6172s
	iters: 200, epoch: 6 | loss: 1.0518764
	speed: 0.0133s/iter; left time: 11.3400s
Epoch: 6 cost time: 2.915288209915161
Epoch: 6, Steps: 210 | Train Loss: 1.0382474 Vali Loss: 1.0476339 Test Loss: 1.0225272
Validation loss decreased (1.047793 --> 1.047634).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0408127
	speed: 0.0167s/iter; left time: 12.3954s
	iters: 200, epoch: 7 | loss: 1.0188076
	speed: 0.0175s/iter; left time: 11.1935s
Epoch: 7 cost time: 3.858013391494751
Epoch: 7, Steps: 210 | Train Loss: 1.0374629 Vali Loss: 1.0486509 Test Loss: 1.0223228
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0657212
	speed: 0.0160s/iter; left time: 8.4722s
	iters: 200, epoch: 8 | loss: 1.0439675
	speed: 0.0152s/iter; left time: 6.5564s
Epoch: 8 cost time: 3.212822198867798
Epoch: 8, Steps: 210 | Train Loss: 1.0372688 Vali Loss: 1.0471249 Test Loss: 1.0224479
Validation loss decreased (1.047634 --> 1.047125).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0334238
	speed: 0.0193s/iter; left time: 6.2110s
	iters: 200, epoch: 9 | loss: 1.0672953
	speed: 0.0172s/iter; left time: 3.7987s
Epoch: 9 cost time: 3.634183406829834
Epoch: 9, Steps: 210 | Train Loss: 1.0371886 Vali Loss: 1.0483563 Test Loss: 1.0224812
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0631425
	speed: 0.0153s/iter; left time: 1.7036s
	iters: 200, epoch: 10 | loss: 1.0352014
	speed: 0.0118s/iter; left time: 0.1296s
Epoch: 10 cost time: 2.5048739910125732
Epoch: 10, Steps: 210 | Train Loss: 1.0371208 Vali Loss: 1.0478512 Test Loss: 1.0224972
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0224478244781494, mae:0.8059088587760925
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0444922
	speed: 0.0260s/iter; left time: 50.9528s
	iters: 200, epoch: 1 | loss: 1.0374506
	speed: 0.0198s/iter; left time: 36.7673s
Epoch: 1 cost time: 4.117800951004028
Epoch: 1, Steps: 206 | Train Loss: 1.0598871 Vali Loss: 1.0602973 Test Loss: 1.0401366
Validation loss decreased (inf --> 1.060297).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0327315
	speed: 0.0140s/iter; left time: 24.6492s
	iters: 200, epoch: 2 | loss: 1.0425959
	speed: 0.0152s/iter; left time: 25.1273s
Epoch: 2 cost time: 3.169222593307495
Epoch: 2, Steps: 206 | Train Loss: 1.0474397 Vali Loss: 1.0604703 Test Loss: 1.0380667
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0379156
	speed: 0.0132s/iter; left time: 20.4130s
	iters: 200, epoch: 3 | loss: 1.0437056
	speed: 0.0130s/iter; left time: 18.8934s
Epoch: 3 cost time: 2.8015222549438477
Epoch: 3, Steps: 206 | Train Loss: 1.0438484 Vali Loss: 1.0579824 Test Loss: 1.0363413
Validation loss decreased (1.060297 --> 1.057982).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0502998
	speed: 0.0178s/iter; left time: 23.8670s
	iters: 200, epoch: 4 | loss: 1.0505582
	speed: 0.0166s/iter; left time: 20.6345s
Epoch: 4 cost time: 3.494063138961792
Epoch: 4, Steps: 206 | Train Loss: 1.0421392 Vali Loss: 1.0569155 Test Loss: 1.0361594
Validation loss decreased (1.057982 --> 1.056916).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0259130
	speed: 0.0213s/iter; left time: 24.2471s
	iters: 200, epoch: 5 | loss: 1.0375904
	speed: 0.0187s/iter; left time: 19.4410s
Epoch: 5 cost time: 3.9684391021728516
Epoch: 5, Steps: 206 | Train Loss: 1.0405922 Vali Loss: 1.0560818 Test Loss: 1.0361481
Validation loss decreased (1.056916 --> 1.056082).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0548469
	speed: 0.0191s/iter; left time: 17.7936s
	iters: 200, epoch: 6 | loss: 1.0501624
	speed: 0.0159s/iter; left time: 13.2499s
Epoch: 6 cost time: 3.3822336196899414
Epoch: 6, Steps: 206 | Train Loss: 1.0402426 Vali Loss: 1.0558863 Test Loss: 1.0359794
Validation loss decreased (1.056082 --> 1.055886).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0399542
	speed: 0.0171s/iter; left time: 12.3701s
	iters: 200, epoch: 7 | loss: 1.0311271
	speed: 0.0139s/iter; left time: 8.6969s
Epoch: 7 cost time: 2.944214105606079
Epoch: 7, Steps: 206 | Train Loss: 1.0398427 Vali Loss: 1.0556152 Test Loss: 1.0359145
Validation loss decreased (1.055886 --> 1.055615).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0541139
	speed: 0.0190s/iter; left time: 9.8546s
	iters: 200, epoch: 8 | loss: 1.0606925
	speed: 0.0211s/iter; left time: 8.8247s
Epoch: 8 cost time: 4.4542577266693115
Epoch: 8, Steps: 206 | Train Loss: 1.0396098 Vali Loss: 1.0560820 Test Loss: 1.0356808
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0292556
	speed: 0.0159s/iter; left time: 4.9644s
	iters: 200, epoch: 9 | loss: 1.0211127
	speed: 0.0152s/iter; left time: 3.2396s
Epoch: 9 cost time: 3.2448668479919434
Epoch: 9, Steps: 206 | Train Loss: 1.0394866 Vali Loss: 1.0559609 Test Loss: 1.0357094
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0330443
	speed: 0.0192s/iter; left time: 2.0539s
	iters: 200, epoch: 10 | loss: 1.0322772
	speed: 0.0177s/iter; left time: 0.1240s
Epoch: 10 cost time: 3.774435043334961
Epoch: 10, Steps: 206 | Train Loss: 1.0393315 Vali Loss: 1.0562522 Test Loss: 1.0357141
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0359147787094116, mae:0.8093209862709045
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0629151
	speed: 0.0150s/iter; left time: 29.4574s
	iters: 200, epoch: 1 | loss: 1.0412418
	speed: 0.0130s/iter; left time: 24.1379s
Epoch: 1 cost time: 2.6960926055908203
Epoch: 1, Steps: 206 | Train Loss: 1.0599563 Vali Loss: 1.0594848 Test Loss: 1.0384721
Validation loss decreased (inf --> 1.059485).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0336269
	speed: 0.0160s/iter; left time: 28.0122s
	iters: 200, epoch: 2 | loss: 1.0426528
	speed: 0.0135s/iter; left time: 22.2937s
Epoch: 2 cost time: 2.8754520416259766
Epoch: 2, Steps: 206 | Train Loss: 1.0472044 Vali Loss: 1.0591774 Test Loss: 1.0379245
Validation loss decreased (1.059485 --> 1.059177).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0334891
	speed: 0.0220s/iter; left time: 34.1396s
	iters: 200, epoch: 3 | loss: 1.0636832
	speed: 0.0214s/iter; left time: 31.0089s
Epoch: 3 cost time: 4.466547966003418
Epoch: 3, Steps: 206 | Train Loss: 1.0433131 Vali Loss: 1.0571078 Test Loss: 1.0373683
Validation loss decreased (1.059177 --> 1.057108).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0560504
	speed: 0.0201s/iter; left time: 27.0332s
	iters: 200, epoch: 4 | loss: 1.0333362
	speed: 0.0170s/iter; left time: 21.1238s
Epoch: 4 cost time: 3.571312189102173
Epoch: 4, Steps: 206 | Train Loss: 1.0417328 Vali Loss: 1.0564744 Test Loss: 1.0363468
Validation loss decreased (1.057108 --> 1.056474).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0343052
	speed: 0.0238s/iter; left time: 27.0804s
	iters: 200, epoch: 5 | loss: 1.0380647
	speed: 0.0195s/iter; left time: 20.2499s
Epoch: 5 cost time: 4.175181150436401
Epoch: 5, Steps: 206 | Train Loss: 1.0405880 Vali Loss: 1.0560622 Test Loss: 1.0362893
Validation loss decreased (1.056474 --> 1.056062).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0416821
	speed: 0.0180s/iter; left time: 16.7709s
	iters: 200, epoch: 6 | loss: 1.0383364
	speed: 0.0140s/iter; left time: 11.6734s
Epoch: 6 cost time: 2.9582979679107666
Epoch: 6, Steps: 206 | Train Loss: 1.0397033 Vali Loss: 1.0563898 Test Loss: 1.0357715
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0244727
	speed: 0.0167s/iter; left time: 12.1152s
	iters: 200, epoch: 7 | loss: 1.0385233
	speed: 0.0144s/iter; left time: 9.0195s
Epoch: 7 cost time: 3.084350347518921
Epoch: 7, Steps: 206 | Train Loss: 1.0395925 Vali Loss: 1.0563810 Test Loss: 1.0357060
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0222608
	speed: 0.0174s/iter; left time: 9.0233s
	iters: 200, epoch: 8 | loss: 1.0163864
	speed: 0.0149s/iter; left time: 6.2409s
Epoch: 8 cost time: 3.138909101486206
Epoch: 8, Steps: 206 | Train Loss: 1.0394382 Vali Loss: 1.0561171 Test Loss: 1.0358118
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0319184
	speed: 0.0192s/iter; left time: 6.0235s
	iters: 200, epoch: 9 | loss: 1.0467973
	speed: 0.0150s/iter; left time: 3.1948s
Epoch: 9 cost time: 3.211362838745117
Epoch: 9, Steps: 206 | Train Loss: 1.0391852 Vali Loss: 1.0560493 Test Loss: 1.0358331
Validation loss decreased (1.056062 --> 1.056049).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0235411
	speed: 0.0148s/iter; left time: 1.5843s
	iters: 200, epoch: 10 | loss: 1.0235443
	speed: 0.0121s/iter; left time: 0.0849s
Epoch: 10 cost time: 2.5656213760375977
Epoch: 10, Steps: 206 | Train Loss: 1.0392210 Vali Loss: 1.0562303 Test Loss: 1.0358139
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0358330011367798, mae:0.809293806552887
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0665830
	speed: 0.0226s/iter; left time: 44.3930s
	iters: 200, epoch: 1 | loss: 1.0579598
	speed: 0.0196s/iter; left time: 36.3921s
Epoch: 1 cost time: 4.122321844100952
Epoch: 1, Steps: 206 | Train Loss: 1.0601237 Vali Loss: 1.0612015 Test Loss: 1.0382727
Validation loss decreased (inf --> 1.061201).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0323069
	speed: 0.0216s/iter; left time: 37.9203s
	iters: 200, epoch: 2 | loss: 1.0510478
	speed: 0.0196s/iter; left time: 32.4763s
Epoch: 2 cost time: 4.119887113571167
Epoch: 2, Steps: 206 | Train Loss: 1.0476156 Vali Loss: 1.0576032 Test Loss: 1.0386524
Validation loss decreased (1.061201 --> 1.057603).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0503888
	speed: 0.0191s/iter; left time: 29.5313s
	iters: 200, epoch: 3 | loss: 1.0421053
	speed: 0.0181s/iter; left time: 26.2441s
Epoch: 3 cost time: 3.8291733264923096
Epoch: 3, Steps: 206 | Train Loss: 1.0440135 Vali Loss: 1.0583918 Test Loss: 1.0362215
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0296623
	speed: 0.0183s/iter; left time: 24.5963s
	iters: 200, epoch: 4 | loss: 1.0452260
	speed: 0.0151s/iter; left time: 18.8036s
Epoch: 4 cost time: 3.177490711212158
Epoch: 4, Steps: 206 | Train Loss: 1.0423195 Vali Loss: 1.0565058 Test Loss: 1.0362679
Validation loss decreased (1.057603 --> 1.056506).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0418042
	speed: 0.0171s/iter; left time: 19.4419s
	iters: 200, epoch: 5 | loss: 1.0488992
	speed: 0.0153s/iter; left time: 15.8571s
Epoch: 5 cost time: 3.2871105670928955
Epoch: 5, Steps: 206 | Train Loss: 1.0411032 Vali Loss: 1.0559995 Test Loss: 1.0357633
Validation loss decreased (1.056506 --> 1.056000).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0283996
	speed: 0.0159s/iter; left time: 14.7889s
	iters: 200, epoch: 6 | loss: 1.0387877
	speed: 0.0148s/iter; left time: 12.3306s
Epoch: 6 cost time: 3.1843042373657227
Epoch: 6, Steps: 206 | Train Loss: 1.0403434 Vali Loss: 1.0560788 Test Loss: 1.0355716
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0230128
	speed: 0.0175s/iter; left time: 12.6760s
	iters: 200, epoch: 7 | loss: 1.0319713
	speed: 0.0152s/iter; left time: 9.4820s
Epoch: 7 cost time: 3.2648823261260986
Epoch: 7, Steps: 206 | Train Loss: 1.0398982 Vali Loss: 1.0559992 Test Loss: 1.0355058
Validation loss decreased (1.056000 --> 1.055999).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0511245
	speed: 0.0175s/iter; left time: 9.0901s
	iters: 200, epoch: 8 | loss: 1.0286696
	speed: 0.0151s/iter; left time: 6.3238s
Epoch: 8 cost time: 3.204136848449707
Epoch: 8, Steps: 206 | Train Loss: 1.0401863 Vali Loss: 1.0556673 Test Loss: 1.0355959
Validation loss decreased (1.055999 --> 1.055667).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0317630
	speed: 0.0127s/iter; left time: 3.9762s
	iters: 200, epoch: 9 | loss: 1.0537341
	speed: 0.0117s/iter; left time: 2.4837s
Epoch: 9 cost time: 2.4884860515594482
Epoch: 9, Steps: 206 | Train Loss: 1.0397801 Vali Loss: 1.0558611 Test Loss: 1.0355842
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0420668
	speed: 0.0134s/iter; left time: 1.4388s
	iters: 200, epoch: 10 | loss: 1.0365483
	speed: 0.0120s/iter; left time: 0.0838s
Epoch: 10 cost time: 2.5264956951141357
Epoch: 10, Steps: 206 | Train Loss: 1.0399106 Vali Loss: 1.0558224 Test Loss: 1.0355822
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0355960130691528, mae:0.8091989159584045
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0545192
	speed: 0.0272s/iter; left time: 50.1092s
Epoch: 1 cost time: 3.859987497329712
Epoch: 1, Steps: 194 | Train Loss: 1.0629543 Vali Loss: 1.0591602 Test Loss: 1.0310513
Validation loss decreased (inf --> 1.059160).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0496752
	speed: 0.0218s/iter; left time: 35.9742s
Epoch: 2 cost time: 3.67106556892395
Epoch: 2, Steps: 194 | Train Loss: 1.0494997 Vali Loss: 1.0570625 Test Loss: 1.0305898
Validation loss decreased (1.059160 --> 1.057063).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0561018
	speed: 0.0158s/iter; left time: 23.0194s
Epoch: 3 cost time: 3.0297510623931885
Epoch: 3, Steps: 194 | Train Loss: 1.0464960 Vali Loss: 1.0558590 Test Loss: 1.0289176
Validation loss decreased (1.057063 --> 1.055859).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0454363
	speed: 0.0210s/iter; left time: 26.4690s
Epoch: 4 cost time: 3.4363884925842285
Epoch: 4, Steps: 194 | Train Loss: 1.0450689 Vali Loss: 1.0547334 Test Loss: 1.0282574
Validation loss decreased (1.055859 --> 1.054733).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0521435
	speed: 0.0180s/iter; left time: 19.1755s
Epoch: 5 cost time: 2.781372547149658
Epoch: 5, Steps: 194 | Train Loss: 1.0442855 Vali Loss: 1.0537163 Test Loss: 1.0279840
Validation loss decreased (1.054733 --> 1.053716).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0447077
	speed: 0.0228s/iter; left time: 19.8481s
Epoch: 6 cost time: 3.4446792602539062
Epoch: 6, Steps: 194 | Train Loss: 1.0436007 Vali Loss: 1.0533984 Test Loss: 1.0278598
Validation loss decreased (1.053716 --> 1.053398).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0529583
	speed: 0.0199s/iter; left time: 13.5008s
Epoch: 7 cost time: 3.265104293823242
Epoch: 7, Steps: 194 | Train Loss: 1.0433704 Vali Loss: 1.0535961 Test Loss: 1.0276054
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0383544
	speed: 0.0176s/iter; left time: 8.4992s
Epoch: 8 cost time: 3.234912633895874
Epoch: 8, Steps: 194 | Train Loss: 1.0434260 Vali Loss: 1.0538867 Test Loss: 1.0275621
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0479900
	speed: 0.0184s/iter; left time: 5.3115s
Epoch: 9 cost time: 3.060062885284424
Epoch: 9, Steps: 194 | Train Loss: 1.0432603 Vali Loss: 1.0538622 Test Loss: 1.0275788
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0354750
	speed: 0.0164s/iter; left time: 1.5618s
Epoch: 10 cost time: 2.573324680328369
Epoch: 10, Steps: 194 | Train Loss: 1.0432615 Vali Loss: 1.0533757 Test Loss: 1.0275906
Validation loss decreased (1.053398 --> 1.053376).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275905132293701, mae:0.8045703172683716
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0536851
	speed: 0.0222s/iter; left time: 40.8484s
Epoch: 1 cost time: 3.7366201877593994
Epoch: 1, Steps: 194 | Train Loss: 1.0636140 Vali Loss: 1.0589352 Test Loss: 1.0312483
Validation loss decreased (inf --> 1.058935).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0542843
	speed: 0.0183s/iter; left time: 30.1987s
Epoch: 2 cost time: 3.585601568222046
Epoch: 2, Steps: 194 | Train Loss: 1.0495437 Vali Loss: 1.0571177 Test Loss: 1.0310807
Validation loss decreased (1.058935 --> 1.057118).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0335997
	speed: 0.0207s/iter; left time: 30.0615s
Epoch: 3 cost time: 3.7820777893066406
Epoch: 3, Steps: 194 | Train Loss: 1.0465372 Vali Loss: 1.0553260 Test Loss: 1.0295547
Validation loss decreased (1.057118 --> 1.055326).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0517626
	speed: 0.0165s/iter; left time: 20.7972s
Epoch: 4 cost time: 2.87007212638855
Epoch: 4, Steps: 194 | Train Loss: 1.0450830 Vali Loss: 1.0544401 Test Loss: 1.0284694
Validation loss decreased (1.055326 --> 1.054440).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0533102
	speed: 0.0136s/iter; left time: 14.4974s
Epoch: 5 cost time: 2.8807737827301025
Epoch: 5, Steps: 194 | Train Loss: 1.0441118 Vali Loss: 1.0544581 Test Loss: 1.0279335
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0534283
	speed: 0.0164s/iter; left time: 14.3266s
Epoch: 6 cost time: 3.135807991027832
Epoch: 6, Steps: 194 | Train Loss: 1.0438216 Vali Loss: 1.0536600 Test Loss: 1.0278724
Validation loss decreased (1.054440 --> 1.053660).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0531077
	speed: 0.0219s/iter; left time: 14.7997s
Epoch: 7 cost time: 3.5643365383148193
Epoch: 7, Steps: 194 | Train Loss: 1.0433231 Vali Loss: 1.0536424 Test Loss: 1.0276684
Validation loss decreased (1.053660 --> 1.053642).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0453787
	speed: 0.0183s/iter; left time: 8.8217s
Epoch: 8 cost time: 3.3102030754089355
Epoch: 8, Steps: 194 | Train Loss: 1.0432238 Vali Loss: 1.0539429 Test Loss: 1.0275624
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0474172
	speed: 0.0135s/iter; left time: 3.9128s
Epoch: 9 cost time: 2.6261463165283203
Epoch: 9, Steps: 194 | Train Loss: 1.0431911 Vali Loss: 1.0537586 Test Loss: 1.0275699
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0520035
	speed: 0.0178s/iter; left time: 1.6919s
Epoch: 10 cost time: 2.99411940574646
Epoch: 10, Steps: 194 | Train Loss: 1.0432208 Vali Loss: 1.0532832 Test Loss: 1.0275792
Validation loss decreased (1.053642 --> 1.053283).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275790691375732, mae:0.8045616745948792
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0473832
	speed: 0.0208s/iter; left time: 38.2424s
Epoch: 1 cost time: 3.6215596199035645
Epoch: 1, Steps: 194 | Train Loss: 1.0631588 Vali Loss: 1.0575497 Test Loss: 1.0314307
Validation loss decreased (inf --> 1.057550).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0537808
	speed: 0.0176s/iter; left time: 28.9438s
Epoch: 2 cost time: 3.2057297229766846
Epoch: 2, Steps: 194 | Train Loss: 1.0496031 Vali Loss: 1.0564222 Test Loss: 1.0311420
Validation loss decreased (1.057550 --> 1.056422).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0452558
	speed: 0.0196s/iter; left time: 28.4849s
Epoch: 3 cost time: 3.7185781002044678
Epoch: 3, Steps: 194 | Train Loss: 1.0466333 Vali Loss: 1.0557532 Test Loss: 1.0294269
Validation loss decreased (1.056422 --> 1.055753).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0395982
	speed: 0.0139s/iter; left time: 17.4830s
Epoch: 4 cost time: 2.660734176635742
Epoch: 4, Steps: 194 | Train Loss: 1.0448215 Vali Loss: 1.0549151 Test Loss: 1.0281196
Validation loss decreased (1.055753 --> 1.054915).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0435674
	speed: 0.0153s/iter; left time: 16.2825s
Epoch: 5 cost time: 3.3203177452087402
Epoch: 5, Steps: 194 | Train Loss: 1.0439988 Vali Loss: 1.0543320 Test Loss: 1.0278584
Validation loss decreased (1.054915 --> 1.054332).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0408210
	speed: 0.0156s/iter; left time: 13.6153s
Epoch: 6 cost time: 2.799457311630249
Epoch: 6, Steps: 194 | Train Loss: 1.0436043 Vali Loss: 1.0538826 Test Loss: 1.0277585
Validation loss decreased (1.054332 --> 1.053883).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0372952
	speed: 0.0198s/iter; left time: 13.4210s
Epoch: 7 cost time: 3.371273994445801
Epoch: 7, Steps: 194 | Train Loss: 1.0430822 Vali Loss: 1.0541390 Test Loss: 1.0276504
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0461569
	speed: 0.0189s/iter; left time: 9.1134s
Epoch: 8 cost time: 3.339651346206665
Epoch: 8, Steps: 194 | Train Loss: 1.0430702 Vali Loss: 1.0536329 Test Loss: 1.0275948
Validation loss decreased (1.053883 --> 1.053633).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0321394
	speed: 0.0170s/iter; left time: 4.9010s
Epoch: 9 cost time: 2.8192243576049805
Epoch: 9, Steps: 194 | Train Loss: 1.0429319 Vali Loss: 1.0537406 Test Loss: 1.0275732
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0383642
	speed: 0.0198s/iter; left time: 1.8795s
Epoch: 10 cost time: 3.3975143432617188
Epoch: 10, Steps: 194 | Train Loss: 1.0428980 Vali Loss: 1.0536923 Test Loss: 1.0275711
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275946855545044, mae:0.8045595288276672
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0232538
	speed: 0.0247s/iter; left time: 50.1539s
	iters: 200, epoch: 1 | loss: 1.0352898
	speed: 0.0175s/iter; left time: 33.7987s
Epoch: 1 cost time: 3.710268020629883
Epoch: 1, Steps: 213 | Train Loss: 1.0579732 Vali Loss: 1.0455574 Test Loss: 1.0269603
Validation loss decreased (inf --> 1.045557).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0136704
	speed: 0.0167s/iter; left time: 30.3948s
	iters: 200, epoch: 2 | loss: 1.0396134
	speed: 0.0144s/iter; left time: 24.7350s
Epoch: 2 cost time: 3.1513891220092773
Epoch: 2, Steps: 213 | Train Loss: 1.0427999 Vali Loss: 1.0440921 Test Loss: 1.0267946
Validation loss decreased (1.045557 --> 1.044092).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0198368
	speed: 0.0159s/iter; left time: 25.5304s
	iters: 200, epoch: 3 | loss: 1.0246137
	speed: 0.0159s/iter; left time: 23.9995s
Epoch: 3 cost time: 3.6913859844207764
Epoch: 3, Steps: 213 | Train Loss: 1.0376702 Vali Loss: 1.0438777 Test Loss: 1.0261953
Validation loss decreased (1.044092 --> 1.043878).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0269932
	speed: 0.0218s/iter; left time: 30.3704s
	iters: 200, epoch: 4 | loss: 1.0195729
	speed: 0.0185s/iter; left time: 23.9539s
Epoch: 4 cost time: 4.019035339355469
Epoch: 4, Steps: 213 | Train Loss: 1.0339362 Vali Loss: 1.0435345 Test Loss: 1.0254773
Validation loss decreased (1.043878 --> 1.043535).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9987345
	speed: 0.0189s/iter; left time: 22.3365s
	iters: 200, epoch: 5 | loss: 1.0013170
	speed: 0.0171s/iter; left time: 18.4338s
Epoch: 5 cost time: 3.6179866790771484
Epoch: 5, Steps: 213 | Train Loss: 1.0319459 Vali Loss: 1.0430869 Test Loss: 1.0255978
Validation loss decreased (1.043535 --> 1.043087).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0369300
	speed: 0.0146s/iter; left time: 14.1248s
	iters: 200, epoch: 6 | loss: 1.0203128
	speed: 0.0171s/iter; left time: 14.7745s
Epoch: 6 cost time: 3.890228271484375
Epoch: 6, Steps: 213 | Train Loss: 1.0305064 Vali Loss: 1.0415659 Test Loss: 1.0259970
Validation loss decreased (1.043087 --> 1.041566).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0387189
	speed: 0.0196s/iter; left time: 14.7511s
	iters: 200, epoch: 7 | loss: 1.0200019
	speed: 0.0173s/iter; left time: 11.3066s
Epoch: 7 cost time: 3.7612342834472656
Epoch: 7, Steps: 213 | Train Loss: 1.0303353 Vali Loss: 1.0416981 Test Loss: 1.0259650
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0278542
	speed: 0.0161s/iter; left time: 8.7017s
	iters: 200, epoch: 8 | loss: 1.0283054
	speed: 0.0169s/iter; left time: 7.4212s
Epoch: 8 cost time: 3.7951467037200928
Epoch: 8, Steps: 213 | Train Loss: 1.0301266 Vali Loss: 1.0414239 Test Loss: 1.0259389
Validation loss decreased (1.041566 --> 1.041424).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0358055
	speed: 0.0162s/iter; left time: 5.2897s
	iters: 200, epoch: 9 | loss: 1.0192126
	speed: 0.0132s/iter; left time: 3.0020s
Epoch: 9 cost time: 2.865330934524536
Epoch: 9, Steps: 213 | Train Loss: 1.0294788 Vali Loss: 1.0412561 Test Loss: 1.0260071
Validation loss decreased (1.041424 --> 1.041256).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0486162
	speed: 0.0154s/iter; left time: 1.7514s
	iters: 200, epoch: 10 | loss: 1.0285755
	speed: 0.0171s/iter; left time: 0.2397s
Epoch: 10 cost time: 3.8105309009552
Epoch: 10, Steps: 213 | Train Loss: 1.0296982 Vali Loss: 1.0417429 Test Loss: 1.0260347
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0260072946548462, mae:0.8079718351364136
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0405319
	speed: 0.0207s/iter; left time: 42.0634s
	iters: 200, epoch: 1 | loss: 1.0668325
	speed: 0.0190s/iter; left time: 36.6249s
Epoch: 1 cost time: 4.079559564590454
Epoch: 1, Steps: 213 | Train Loss: 1.0585324 Vali Loss: 1.0457762 Test Loss: 1.0271866
Validation loss decreased (inf --> 1.045776).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0439900
	speed: 0.0181s/iter; left time: 32.9771s
	iters: 200, epoch: 2 | loss: 1.0495820
	speed: 0.0171s/iter; left time: 29.3724s
Epoch: 2 cost time: 3.7431018352508545
Epoch: 2, Steps: 213 | Train Loss: 1.0429044 Vali Loss: 1.0462313 Test Loss: 1.0279536
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0257342
	speed: 0.0137s/iter; left time: 21.9293s
	iters: 200, epoch: 3 | loss: 1.0733347
	speed: 0.0155s/iter; left time: 23.2637s
Epoch: 3 cost time: 3.3981258869171143
Epoch: 3, Steps: 213 | Train Loss: 1.0375583 Vali Loss: 1.0423111 Test Loss: 1.0253781
Validation loss decreased (1.045776 --> 1.042311).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0564852
	speed: 0.0186s/iter; left time: 25.8942s
	iters: 200, epoch: 4 | loss: 1.0057201
	speed: 0.0203s/iter; left time: 26.1655s
Epoch: 4 cost time: 4.586171388626099
Epoch: 4, Steps: 213 | Train Loss: 1.0344498 Vali Loss: 1.0421764 Test Loss: 1.0253494
Validation loss decreased (1.042311 --> 1.042176).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0208007
	speed: 0.0186s/iter; left time: 21.9859s
	iters: 200, epoch: 5 | loss: 1.0608091
	speed: 0.0156s/iter; left time: 16.8113s
Epoch: 5 cost time: 3.4470763206481934
Epoch: 5, Steps: 213 | Train Loss: 1.0327194 Vali Loss: 1.0413152 Test Loss: 1.0260168
Validation loss decreased (1.042176 --> 1.041315).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0537121
	speed: 0.0185s/iter; left time: 17.9139s
	iters: 200, epoch: 6 | loss: 1.0441401
	speed: 0.0148s/iter; left time: 12.8330s
Epoch: 6 cost time: 3.1485390663146973
Epoch: 6, Steps: 213 | Train Loss: 1.0316879 Vali Loss: 1.0415967 Test Loss: 1.0258944
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0443454
	speed: 0.0133s/iter; left time: 10.0184s
	iters: 200, epoch: 7 | loss: 1.0683613
	speed: 0.0141s/iter; left time: 9.2206s
Epoch: 7 cost time: 3.0294747352600098
Epoch: 7, Steps: 213 | Train Loss: 1.0309749 Vali Loss: 1.0409040 Test Loss: 1.0260965
Validation loss decreased (1.041315 --> 1.040904).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0634755
	speed: 0.0163s/iter; left time: 8.8089s
	iters: 200, epoch: 8 | loss: 1.0255169
	speed: 0.0163s/iter; left time: 7.1772s
Epoch: 8 cost time: 3.4899404048919678
Epoch: 8, Steps: 213 | Train Loss: 1.0306492 Vali Loss: 1.0416352 Test Loss: 1.0261610
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0384840
	speed: 0.0175s/iter; left time: 5.7130s
	iters: 200, epoch: 9 | loss: 1.0066428
	speed: 0.0163s/iter; left time: 3.7112s
Epoch: 9 cost time: 3.5851693153381348
Epoch: 9, Steps: 213 | Train Loss: 1.0305587 Vali Loss: 1.0402858 Test Loss: 1.0262048
Validation loss decreased (1.040904 --> 1.040286).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0223894
	speed: 0.0152s/iter; left time: 1.7360s
	iters: 200, epoch: 10 | loss: 1.0204600
	speed: 0.0143s/iter; left time: 0.2006s
Epoch: 10 cost time: 3.1870810985565186
Epoch: 10, Steps: 213 | Train Loss: 1.0303109 Vali Loss: 1.0410305 Test Loss: 1.0262066
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0262049436569214, mae:0.8080943822860718
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0262036
	speed: 0.0149s/iter; left time: 30.3071s
	iters: 200, epoch: 1 | loss: 1.0300181
	speed: 0.0149s/iter; left time: 28.7358s
Epoch: 1 cost time: 3.2270848751068115
Epoch: 1, Steps: 213 | Train Loss: 1.0579441 Vali Loss: 1.0440484 Test Loss: 1.0261697
Validation loss decreased (inf --> 1.044048).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0686525
	speed: 0.0227s/iter; left time: 41.1798s
	iters: 200, epoch: 2 | loss: 1.0609257
	speed: 0.0232s/iter; left time: 39.8595s
Epoch: 2 cost time: 4.93104887008667
Epoch: 2, Steps: 213 | Train Loss: 1.0430888 Vali Loss: 1.0467404 Test Loss: 1.0273606
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0361686
	speed: 0.0253s/iter; left time: 40.5672s
	iters: 200, epoch: 3 | loss: 1.0411682
	speed: 0.0191s/iter; left time: 28.8054s
Epoch: 3 cost time: 4.143367290496826
Epoch: 3, Steps: 213 | Train Loss: 1.0372406 Vali Loss: 1.0445333 Test Loss: 1.0255096
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0370080
	speed: 0.0239s/iter; left time: 33.2678s
	iters: 200, epoch: 4 | loss: 0.9997651
	speed: 0.0193s/iter; left time: 24.9138s
Epoch: 4 cost time: 4.087838649749756
Epoch: 4, Steps: 213 | Train Loss: 1.0338597 Vali Loss: 1.0408014 Test Loss: 1.0258448
Validation loss decreased (1.044048 --> 1.040801).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0360411
	speed: 0.0153s/iter; left time: 18.0841s
	iters: 200, epoch: 5 | loss: 1.0556947
	speed: 0.0141s/iter; left time: 15.2584s
Epoch: 5 cost time: 3.2851037979125977
Epoch: 5, Steps: 213 | Train Loss: 1.0322468 Vali Loss: 1.0421783 Test Loss: 1.0262830
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0153455
	speed: 0.0164s/iter; left time: 15.8534s
	iters: 200, epoch: 6 | loss: 1.0372196
	speed: 0.0147s/iter; left time: 12.7552s
Epoch: 6 cost time: 3.273613214492798
Epoch: 6, Steps: 213 | Train Loss: 1.0313042 Vali Loss: 1.0422711 Test Loss: 1.0263892
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0548385
	speed: 0.0162s/iter; left time: 12.1788s
	iters: 200, epoch: 7 | loss: 1.0446380
	speed: 0.0148s/iter; left time: 9.6606s
Epoch: 7 cost time: 3.2658679485321045
Epoch: 7, Steps: 213 | Train Loss: 1.0305315 Vali Loss: 1.0412246 Test Loss: 1.0263302
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0275733
	speed: 0.0151s/iter; left time: 8.1483s
	iters: 200, epoch: 8 | loss: 1.0448368
	speed: 0.0129s/iter; left time: 5.6637s
Epoch: 8 cost time: 2.787506580352783
Epoch: 8, Steps: 213 | Train Loss: 1.0306260 Vali Loss: 1.0424254 Test Loss: 1.0265005
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0581429
	speed: 0.0159s/iter; left time: 5.1859s
	iters: 200, epoch: 9 | loss: 1.0447764
	speed: 0.0149s/iter; left time: 3.3722s
Epoch: 9 cost time: 3.274623394012451
Epoch: 9, Steps: 213 | Train Loss: 1.0302190 Vali Loss: 1.0415806 Test Loss: 1.0265723
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.025844693183899, mae:0.8079941272735596
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0606668
	speed: 0.0324s/iter; left time: 64.7422s
	iters: 200, epoch: 1 | loss: 1.0508944
	speed: 0.0217s/iter; left time: 41.3130s
Epoch: 1 cost time: 4.565770864486694
Epoch: 1, Steps: 210 | Train Loss: 1.0600588 Vali Loss: 1.0504636 Test Loss: 1.0256228
Validation loss decreased (inf --> 1.050464).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0514977
	speed: 0.0128s/iter; left time: 22.8832s
	iters: 200, epoch: 2 | loss: 1.0591148
	speed: 0.0113s/iter; left time: 19.0805s
Epoch: 2 cost time: 2.445192575454712
Epoch: 2, Steps: 210 | Train Loss: 1.0472240 Vali Loss: 1.0502589 Test Loss: 1.0244143
Validation loss decreased (1.050464 --> 1.050259).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0469602
	speed: 0.0130s/iter; left time: 20.6162s
	iters: 200, epoch: 3 | loss: 1.0291939
	speed: 0.0111s/iter; left time: 16.3975s
Epoch: 3 cost time: 2.3788845539093018
Epoch: 3, Steps: 210 | Train Loss: 1.0431575 Vali Loss: 1.0485610 Test Loss: 1.0234237
Validation loss decreased (1.050259 --> 1.048561).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0208434
	speed: 0.0146s/iter; left time: 19.9583s
	iters: 200, epoch: 4 | loss: 1.0411206
	speed: 0.0120s/iter; left time: 15.2464s
Epoch: 4 cost time: 2.7129313945770264
Epoch: 4, Steps: 210 | Train Loss: 1.0407765 Vali Loss: 1.0508988 Test Loss: 1.0223440
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0526458
	speed: 0.0189s/iter; left time: 21.8894s
	iters: 200, epoch: 5 | loss: 1.0392153
	speed: 0.0178s/iter; left time: 18.9234s
Epoch: 5 cost time: 3.817560911178589
Epoch: 5, Steps: 210 | Train Loss: 1.0392735 Vali Loss: 1.0471842 Test Loss: 1.0227882
Validation loss decreased (1.048561 --> 1.047184).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0441434
	speed: 0.0151s/iter; left time: 14.3176s
	iters: 200, epoch: 6 | loss: 1.0245613
	speed: 0.0144s/iter; left time: 12.2303s
Epoch: 6 cost time: 3.128606081008911
Epoch: 6, Steps: 210 | Train Loss: 1.0383046 Vali Loss: 1.0494195 Test Loss: 1.0219902
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0134180
	speed: 0.0176s/iter; left time: 13.0078s
	iters: 200, epoch: 7 | loss: 1.0276113
	speed: 0.0155s/iter; left time: 9.9274s
Epoch: 7 cost time: 3.336322546005249
Epoch: 7, Steps: 210 | Train Loss: 1.0378202 Vali Loss: 1.0465358 Test Loss: 1.0222852
Validation loss decreased (1.047184 --> 1.046536).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0318317
	speed: 0.0154s/iter; left time: 8.1746s
	iters: 200, epoch: 8 | loss: 1.0390100
	speed: 0.0147s/iter; left time: 6.3213s
Epoch: 8 cost time: 3.1739726066589355
Epoch: 8, Steps: 210 | Train Loss: 1.0375022 Vali Loss: 1.0472220 Test Loss: 1.0221909
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0338407
	speed: 0.0136s/iter; left time: 4.3570s
	iters: 200, epoch: 9 | loss: 1.0394622
	speed: 0.0125s/iter; left time: 2.7529s
Epoch: 9 cost time: 2.7043654918670654
Epoch: 9, Steps: 210 | Train Loss: 1.0376184 Vali Loss: 1.0480075 Test Loss: 1.0222073
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0343022
	speed: 0.0159s/iter; left time: 1.7672s
	iters: 200, epoch: 10 | loss: 1.0246919
	speed: 0.0143s/iter; left time: 0.1572s
Epoch: 10 cost time: 3.102212905883789
Epoch: 10, Steps: 210 | Train Loss: 1.0373468 Vali Loss: 1.0478842 Test Loss: 1.0222245
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0222853422164917, mae:0.8058051466941833
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0622940
	speed: 0.0170s/iter; left time: 33.9804s
	iters: 200, epoch: 1 | loss: 1.0502672
	speed: 0.0146s/iter; left time: 27.6990s
Epoch: 1 cost time: 3.122358798980713
Epoch: 1, Steps: 210 | Train Loss: 1.0612496 Vali Loss: 1.0525228 Test Loss: 1.0251182
Validation loss decreased (inf --> 1.052523).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0456722
	speed: 0.0217s/iter; left time: 38.9084s
	iters: 200, epoch: 2 | loss: 1.0556791
	speed: 0.0173s/iter; left time: 29.2265s
Epoch: 2 cost time: 3.67870831489563
Epoch: 2, Steps: 210 | Train Loss: 1.0473319 Vali Loss: 1.0503780 Test Loss: 1.0249802
Validation loss decreased (1.052523 --> 1.050378).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0586857
	speed: 0.0147s/iter; left time: 23.2120s
	iters: 200, epoch: 3 | loss: 1.0060285
	speed: 0.0127s/iter; left time: 18.8297s
Epoch: 3 cost time: 2.7142584323883057
Epoch: 3, Steps: 210 | Train Loss: 1.0429992 Vali Loss: 1.0472944 Test Loss: 1.0237794
Validation loss decreased (1.050378 --> 1.047294).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0556242
	speed: 0.0197s/iter; left time: 27.0580s
	iters: 200, epoch: 4 | loss: 1.0455474
	speed: 0.0173s/iter; left time: 21.9377s
Epoch: 4 cost time: 3.7539100646972656
Epoch: 4, Steps: 210 | Train Loss: 1.0405366 Vali Loss: 1.0497967 Test Loss: 1.0227216
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0432351
	speed: 0.0179s/iter; left time: 20.7359s
	iters: 200, epoch: 5 | loss: 1.0449288
	speed: 0.0165s/iter; left time: 17.5134s
Epoch: 5 cost time: 3.5280909538269043
Epoch: 5, Steps: 210 | Train Loss: 1.0389897 Vali Loss: 1.0483407 Test Loss: 1.0231333
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0540037
	speed: 0.0177s/iter; left time: 16.7882s
	iters: 200, epoch: 6 | loss: 1.0497693
	speed: 0.0165s/iter; left time: 14.0820s
Epoch: 6 cost time: 3.593906879425049
Epoch: 6, Steps: 210 | Train Loss: 1.0381837 Vali Loss: 1.0479754 Test Loss: 1.0227959
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0056636
	speed: 0.0144s/iter; left time: 10.6775s
	iters: 200, epoch: 7 | loss: 1.0189707
	speed: 0.0134s/iter; left time: 8.6212s
Epoch: 7 cost time: 2.9235267639160156
Epoch: 7, Steps: 210 | Train Loss: 1.0374843 Vali Loss: 1.0496749 Test Loss: 1.0228620
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0358003
	speed: 0.0159s/iter; left time: 8.4377s
	iters: 200, epoch: 8 | loss: 1.0265965
	speed: 0.0172s/iter; left time: 7.4108s
Epoch: 8 cost time: 3.682739734649658
Epoch: 8, Steps: 210 | Train Loss: 1.0372601 Vali Loss: 1.0486093 Test Loss: 1.0228156
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0237795114517212, mae:0.806396484375
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0735824
	speed: 0.0235s/iter; left time: 46.9310s
	iters: 200, epoch: 1 | loss: 1.0493860
	speed: 0.0202s/iter; left time: 38.3094s
Epoch: 1 cost time: 4.240887403488159
Epoch: 1, Steps: 210 | Train Loss: 1.0605186 Vali Loss: 1.0517018 Test Loss: 1.0250584
Validation loss decreased (inf --> 1.051702).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0458040
	speed: 0.0206s/iter; left time: 36.9460s
	iters: 200, epoch: 2 | loss: 1.0646929
	speed: 0.0165s/iter; left time: 27.9308s
Epoch: 2 cost time: 3.539961338043213
Epoch: 2, Steps: 210 | Train Loss: 1.0471749 Vali Loss: 1.0520740 Test Loss: 1.0252458
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0373410
	speed: 0.0153s/iter; left time: 24.1755s
	iters: 200, epoch: 3 | loss: 1.0370884
	speed: 0.0130s/iter; left time: 19.2803s
Epoch: 3 cost time: 2.817063570022583
Epoch: 3, Steps: 210 | Train Loss: 1.0430016 Vali Loss: 1.0467117 Test Loss: 1.0242090
Validation loss decreased (1.051702 --> 1.046712).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0242282
	speed: 0.0164s/iter; left time: 22.4965s
	iters: 200, epoch: 4 | loss: 1.0227206
	speed: 0.0152s/iter; left time: 19.3291s
Epoch: 4 cost time: 3.2313973903656006
Epoch: 4, Steps: 210 | Train Loss: 1.0404175 Vali Loss: 1.0486729 Test Loss: 1.0223713
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0498323
	speed: 0.0171s/iter; left time: 19.8352s
	iters: 200, epoch: 5 | loss: 1.0373766
	speed: 0.0162s/iter; left time: 17.2046s
Epoch: 5 cost time: 3.566394805908203
Epoch: 5, Steps: 210 | Train Loss: 1.0386824 Vali Loss: 1.0474521 Test Loss: 1.0224749
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0375782
	speed: 0.0177s/iter; left time: 16.8525s
	iters: 200, epoch: 6 | loss: 1.0444032
	speed: 0.0163s/iter; left time: 13.8783s
Epoch: 6 cost time: 3.509979724884033
Epoch: 6, Steps: 210 | Train Loss: 1.0378784 Vali Loss: 1.0477967 Test Loss: 1.0220361
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0414994
	speed: 0.0170s/iter; left time: 12.6076s
	iters: 200, epoch: 7 | loss: 1.0167722
	speed: 0.0161s/iter; left time: 10.3120s
Epoch: 7 cost time: 3.428276777267456
Epoch: 7, Steps: 210 | Train Loss: 1.0373442 Vali Loss: 1.0472524 Test Loss: 1.0222069
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0590281
	speed: 0.0178s/iter; left time: 9.4342s
	iters: 200, epoch: 8 | loss: 1.0424420
	speed: 0.0148s/iter; left time: 6.3988s
Epoch: 8 cost time: 3.2194275856018066
Epoch: 8, Steps: 210 | Train Loss: 1.0372691 Vali Loss: 1.0475348 Test Loss: 1.0222175
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.024208903312683, mae:0.8065544366836548
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0408210
	speed: 0.0255s/iter; left time: 50.0279s
	iters: 200, epoch: 1 | loss: 1.0374734
	speed: 0.0183s/iter; left time: 34.0528s
Epoch: 1 cost time: 3.7938356399536133
Epoch: 1, Steps: 206 | Train Loss: 1.0593791 Vali Loss: 1.0585653 Test Loss: 1.0399477
Validation loss decreased (inf --> 1.058565).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0509220
	speed: 0.0133s/iter; left time: 23.3725s
	iters: 200, epoch: 2 | loss: 1.0399311
	speed: 0.0142s/iter; left time: 23.4528s
Epoch: 2 cost time: 2.9927616119384766
Epoch: 2, Steps: 206 | Train Loss: 1.0471116 Vali Loss: 1.0609287 Test Loss: 1.0378760
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0358253
	speed: 0.0196s/iter; left time: 30.4091s
	iters: 200, epoch: 3 | loss: 1.0379717
	speed: 0.0164s/iter; left time: 23.7668s
Epoch: 3 cost time: 3.4772789478302
Epoch: 3, Steps: 206 | Train Loss: 1.0435300 Vali Loss: 1.0584381 Test Loss: 1.0366309
Validation loss decreased (1.058565 --> 1.058438).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0522381
	speed: 0.0199s/iter; left time: 26.6782s
	iters: 200, epoch: 4 | loss: 1.0340614
	speed: 0.0180s/iter; left time: 22.4100s
Epoch: 4 cost time: 3.7968809604644775
Epoch: 4, Steps: 206 | Train Loss: 1.0420909 Vali Loss: 1.0562843 Test Loss: 1.0363512
Validation loss decreased (1.058438 --> 1.056284).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0485711
	speed: 0.0213s/iter; left time: 24.1668s
	iters: 200, epoch: 5 | loss: 1.0534110
	speed: 0.0180s/iter; left time: 18.6424s
Epoch: 5 cost time: 3.7270448207855225
Epoch: 5, Steps: 206 | Train Loss: 1.0407714 Vali Loss: 1.0567291 Test Loss: 1.0359040
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0272280
	speed: 0.0155s/iter; left time: 14.4453s
	iters: 200, epoch: 6 | loss: 1.0588187
	speed: 0.0131s/iter; left time: 10.8835s
Epoch: 6 cost time: 2.7374682426452637
Epoch: 6, Steps: 206 | Train Loss: 1.0397711 Vali Loss: 1.0560942 Test Loss: 1.0359426
Validation loss decreased (1.056284 --> 1.056094).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0538374
	speed: 0.0161s/iter; left time: 11.6408s
	iters: 200, epoch: 7 | loss: 1.0501120
	speed: 0.0158s/iter; left time: 9.8490s
Epoch: 7 cost time: 3.3257322311401367
Epoch: 7, Steps: 206 | Train Loss: 1.0394638 Vali Loss: 1.0563097 Test Loss: 1.0357896
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0425034
	speed: 0.0186s/iter; left time: 9.6356s
	iters: 200, epoch: 8 | loss: 1.0325502
	speed: 0.0172s/iter; left time: 7.2084s
Epoch: 8 cost time: 3.69179105758667
Epoch: 8, Steps: 206 | Train Loss: 1.0397847 Vali Loss: 1.0559553 Test Loss: 1.0358791
Validation loss decreased (1.056094 --> 1.055955).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0694873
	speed: 0.0186s/iter; left time: 5.8171s
	iters: 200, epoch: 9 | loss: 1.0108947
	speed: 0.0161s/iter; left time: 3.4267s
Epoch: 9 cost time: 3.3945658206939697
Epoch: 9, Steps: 206 | Train Loss: 1.0395870 Vali Loss: 1.0559263 Test Loss: 1.0358748
Validation loss decreased (1.055955 --> 1.055926).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0124129
	speed: 0.0210s/iter; left time: 2.2452s
	iters: 200, epoch: 10 | loss: 1.0326308
	speed: 0.0165s/iter; left time: 0.1153s
Epoch: 10 cost time: 3.4760801792144775
Epoch: 10, Steps: 206 | Train Loss: 1.0392376 Vali Loss: 1.0559286 Test Loss: 1.0358776
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0358749628067017, mae:0.8092968463897705
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0637556
	speed: 0.0209s/iter; left time: 40.9698s
	iters: 200, epoch: 1 | loss: 1.0506799
	speed: 0.0168s/iter; left time: 31.2946s
Epoch: 1 cost time: 3.5154497623443604
Epoch: 1, Steps: 206 | Train Loss: 1.0599340 Vali Loss: 1.0609369 Test Loss: 1.0378108
Validation loss decreased (inf --> 1.060937).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0603538
	speed: 0.0206s/iter; left time: 36.1750s
	iters: 200, epoch: 2 | loss: 1.0493133
	speed: 0.0173s/iter; left time: 28.6727s
Epoch: 2 cost time: 3.664203405380249
Epoch: 2, Steps: 206 | Train Loss: 1.0472359 Vali Loss: 1.0598367 Test Loss: 1.0378249
Validation loss decreased (1.060937 --> 1.059837).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0480332
	speed: 0.0191s/iter; left time: 29.5300s
	iters: 200, epoch: 3 | loss: 1.0589767
	speed: 0.0163s/iter; left time: 23.5872s
Epoch: 3 cost time: 3.4654829502105713
Epoch: 3, Steps: 206 | Train Loss: 1.0435938 Vali Loss: 1.0576485 Test Loss: 1.0364088
Validation loss decreased (1.059837 --> 1.057649).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0447412
	speed: 0.0155s/iter; left time: 20.8373s
	iters: 200, epoch: 4 | loss: 1.0261912
	speed: 0.0138s/iter; left time: 17.1332s
Epoch: 4 cost time: 2.9049689769744873
Epoch: 4, Steps: 206 | Train Loss: 1.0419401 Vali Loss: 1.0565169 Test Loss: 1.0363326
Validation loss decreased (1.057649 --> 1.056517).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0309969
	speed: 0.0179s/iter; left time: 20.3521s
	iters: 200, epoch: 5 | loss: 1.0393302
	speed: 0.0143s/iter; left time: 14.8202s
Epoch: 5 cost time: 3.072110176086426
Epoch: 5, Steps: 206 | Train Loss: 1.0409861 Vali Loss: 1.0565469 Test Loss: 1.0358046
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0424227
	speed: 0.0238s/iter; left time: 22.1286s
	iters: 200, epoch: 6 | loss: 1.0350634
	speed: 0.0207s/iter; left time: 17.2409s
Epoch: 6 cost time: 4.30083966255188
Epoch: 6, Steps: 206 | Train Loss: 1.0397985 Vali Loss: 1.0566146 Test Loss: 1.0355375
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0421110
	speed: 0.0169s/iter; left time: 12.2764s
	iters: 200, epoch: 7 | loss: 1.0417601
	speed: 0.0175s/iter; left time: 10.9349s
Epoch: 7 cost time: 3.6509344577789307
Epoch: 7, Steps: 206 | Train Loss: 1.0396013 Vali Loss: 1.0563514 Test Loss: 1.0356200
Validation loss decreased (1.056517 --> 1.056351).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0389292
	speed: 0.0219s/iter; left time: 11.3508s
	iters: 200, epoch: 8 | loss: 1.0445406
	speed: 0.0165s/iter; left time: 6.9158s
Epoch: 8 cost time: 3.4148366451263428
Epoch: 8, Steps: 206 | Train Loss: 1.0395619 Vali Loss: 1.0560962 Test Loss: 1.0357095
Validation loss decreased (1.056351 --> 1.056096).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0387832
	speed: 0.0151s/iter; left time: 4.7350s
	iters: 200, epoch: 9 | loss: 1.0531210
	speed: 0.0130s/iter; left time: 2.7652s
Epoch: 9 cost time: 2.707826852798462
Epoch: 9, Steps: 206 | Train Loss: 1.0389056 Vali Loss: 1.0560981 Test Loss: 1.0357358
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0221258
	speed: 0.0182s/iter; left time: 1.9427s
	iters: 200, epoch: 10 | loss: 1.0381942
	speed: 0.0199s/iter; left time: 0.1393s
Epoch: 10 cost time: 4.154583930969238
Epoch: 10, Steps: 206 | Train Loss: 1.0395873 Vali Loss: 1.0559231 Test Loss: 1.0357298
Validation loss decreased (1.056096 --> 1.055923).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0357298851013184, mae:0.8092308044433594
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0641015
	speed: 0.0195s/iter; left time: 38.3073s
	iters: 200, epoch: 1 | loss: 1.0299218
	speed: 0.0172s/iter; left time: 31.9420s
Epoch: 1 cost time: 3.6496098041534424
Epoch: 1, Steps: 206 | Train Loss: 1.0600627 Vali Loss: 1.0605603 Test Loss: 1.0377705
Validation loss decreased (inf --> 1.060560).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0389636
	speed: 0.0206s/iter; left time: 36.1330s
	iters: 200, epoch: 2 | loss: 1.0333496
	speed: 0.0180s/iter; left time: 29.7080s
Epoch: 2 cost time: 3.787379264831543
Epoch: 2, Steps: 206 | Train Loss: 1.0472583 Vali Loss: 1.0591266 Test Loss: 1.0386864
Validation loss decreased (1.060560 --> 1.059127).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0428396
	speed: 0.0174s/iter; left time: 26.9362s
	iters: 200, epoch: 3 | loss: 1.0615609
	speed: 0.0148s/iter; left time: 21.4491s
Epoch: 3 cost time: 3.170445680618286
Epoch: 3, Steps: 206 | Train Loss: 1.0435453 Vali Loss: 1.0582933 Test Loss: 1.0365056
Validation loss decreased (1.059127 --> 1.058293).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0443126
	speed: 0.0178s/iter; left time: 23.9121s
	iters: 200, epoch: 4 | loss: 1.0551150
	speed: 0.0163s/iter; left time: 20.2499s
Epoch: 4 cost time: 3.466594934463501
Epoch: 4, Steps: 206 | Train Loss: 1.0416423 Vali Loss: 1.0563513 Test Loss: 1.0369928
Validation loss decreased (1.058293 --> 1.056351).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0516621
	speed: 0.0220s/iter; left time: 25.0168s
	iters: 200, epoch: 5 | loss: 1.0432925
	speed: 0.0172s/iter; left time: 17.8826s
Epoch: 5 cost time: 3.6062166690826416
Epoch: 5, Steps: 206 | Train Loss: 1.0404769 Vali Loss: 1.0560716 Test Loss: 1.0361700
Validation loss decreased (1.056351 --> 1.056072).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0435199
	speed: 0.0233s/iter; left time: 21.6466s
	iters: 200, epoch: 6 | loss: 1.0593729
	speed: 0.0177s/iter; left time: 14.6947s
Epoch: 6 cost time: 3.68644642829895
Epoch: 6, Steps: 206 | Train Loss: 1.0398858 Vali Loss: 1.0561361 Test Loss: 1.0359184
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0331310
	speed: 0.0159s/iter; left time: 11.5483s
	iters: 200, epoch: 7 | loss: 1.0322772
	speed: 0.0128s/iter; left time: 8.0024s
Epoch: 7 cost time: 2.6849544048309326
Epoch: 7, Steps: 206 | Train Loss: 1.0393204 Vali Loss: 1.0563745 Test Loss: 1.0358697
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0373234
	speed: 0.0135s/iter; left time: 7.0257s
	iters: 200, epoch: 8 | loss: 1.0421368
	speed: 0.0118s/iter; left time: 4.9632s
Epoch: 8 cost time: 2.5327401161193848
Epoch: 8, Steps: 206 | Train Loss: 1.0391985 Vali Loss: 1.0562074 Test Loss: 1.0358645
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0384982
	speed: 0.0138s/iter; left time: 4.3160s
	iters: 200, epoch: 9 | loss: 1.0390353
	speed: 0.0144s/iter; left time: 3.0733s
Epoch: 9 cost time: 3.0534818172454834
Epoch: 9, Steps: 206 | Train Loss: 1.0389846 Vali Loss: 1.0561515 Test Loss: 1.0358829
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0386262
	speed: 0.0217s/iter; left time: 2.3247s
	iters: 200, epoch: 10 | loss: 1.0483221
	speed: 0.0175s/iter; left time: 0.1224s
Epoch: 10 cost time: 3.674755811691284
Epoch: 10, Steps: 206 | Train Loss: 1.0390219 Vali Loss: 1.0561587 Test Loss: 1.0358757
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0361701250076294, mae:0.8094093799591064
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0516269
	speed: 0.0318s/iter; left time: 58.6038s
Epoch: 1 cost time: 5.107105255126953
Epoch: 1, Steps: 194 | Train Loss: 1.0623465 Vali Loss: 1.0570619 Test Loss: 1.0310225
Validation loss decreased (inf --> 1.057062).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0440434
	speed: 0.0156s/iter; left time: 25.6563s
Epoch: 2 cost time: 3.0213282108306885
Epoch: 2, Steps: 194 | Train Loss: 1.0499306 Vali Loss: 1.0582229 Test Loss: 1.0306195
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0539507
	speed: 0.0207s/iter; left time: 30.0585s
Epoch: 3 cost time: 3.3328850269317627
Epoch: 3, Steps: 194 | Train Loss: 1.0467808 Vali Loss: 1.0557735 Test Loss: 1.0295029
Validation loss decreased (1.057062 --> 1.055773).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0457844
	speed: 0.0173s/iter; left time: 21.7797s
Epoch: 4 cost time: 2.752452850341797
Epoch: 4, Steps: 194 | Train Loss: 1.0450984 Vali Loss: 1.0547333 Test Loss: 1.0281597
Validation loss decreased (1.055773 --> 1.054733).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0346346
	speed: 0.0157s/iter; left time: 16.6893s
Epoch: 5 cost time: 3.179980516433716
Epoch: 5, Steps: 194 | Train Loss: 1.0442536 Vali Loss: 1.0547150 Test Loss: 1.0277395
Validation loss decreased (1.054733 --> 1.054715).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0433743
	speed: 0.0179s/iter; left time: 15.5527s
Epoch: 6 cost time: 3.2484352588653564
Epoch: 6, Steps: 194 | Train Loss: 1.0438930 Vali Loss: 1.0536774 Test Loss: 1.0275774
Validation loss decreased (1.054715 --> 1.053677).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0530591
	speed: 0.0218s/iter; left time: 14.7731s
Epoch: 7 cost time: 3.439586877822876
Epoch: 7, Steps: 194 | Train Loss: 1.0434805 Vali Loss: 1.0538193 Test Loss: 1.0276583
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0456079
	speed: 0.0194s/iter; left time: 9.3778s
Epoch: 8 cost time: 3.4439613819122314
Epoch: 8, Steps: 194 | Train Loss: 1.0433380 Vali Loss: 1.0534811 Test Loss: 1.0275551
Validation loss decreased (1.053677 --> 1.053481).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0420147
	speed: 0.0156s/iter; left time: 4.5193s
Epoch: 9 cost time: 2.8884992599487305
Epoch: 9, Steps: 194 | Train Loss: 1.0432268 Vali Loss: 1.0534980 Test Loss: 1.0275053
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0308180
	speed: 0.0159s/iter; left time: 1.5066s
Epoch: 10 cost time: 3.1336047649383545
Epoch: 10, Steps: 194 | Train Loss: 1.0432373 Vali Loss: 1.0540211 Test Loss: 1.0274993
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275551080703735, mae:0.8045663237571716
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0494360
	speed: 0.0235s/iter; left time: 43.2858s
Epoch: 1 cost time: 4.76085901260376
Epoch: 1, Steps: 194 | Train Loss: 1.0633299 Vali Loss: 1.0576673 Test Loss: 1.0317502
Validation loss decreased (inf --> 1.057667).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0500820
	speed: 0.0196s/iter; left time: 32.2664s
Epoch: 2 cost time: 3.458307981491089
Epoch: 2, Steps: 194 | Train Loss: 1.0494171 Vali Loss: 1.0576409 Test Loss: 1.0304809
Validation loss decreased (1.057667 --> 1.057641).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0447187
	speed: 0.0168s/iter; left time: 24.4556s
Epoch: 3 cost time: 2.840841770172119
Epoch: 3, Steps: 194 | Train Loss: 1.0467794 Vali Loss: 1.0546943 Test Loss: 1.0295162
Validation loss decreased (1.057641 --> 1.054694).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0430394
	speed: 0.0159s/iter; left time: 20.0732s
Epoch: 4 cost time: 2.978309392929077
Epoch: 4, Steps: 194 | Train Loss: 1.0449170 Vali Loss: 1.0547717 Test Loss: 1.0284421
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0466079
	speed: 0.0157s/iter; left time: 16.6908s
Epoch: 5 cost time: 2.86940860748291
Epoch: 5, Steps: 194 | Train Loss: 1.0443049 Vali Loss: 1.0547637 Test Loss: 1.0276135
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0449563
	speed: 0.0175s/iter; left time: 15.2184s
Epoch: 6 cost time: 3.240060806274414
Epoch: 6, Steps: 194 | Train Loss: 1.0437489 Vali Loss: 1.0541354 Test Loss: 1.0277271
Validation loss decreased (1.054694 --> 1.054135).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0427846
	speed: 0.0193s/iter; left time: 13.0720s
Epoch: 7 cost time: 3.3917489051818848
Epoch: 7, Steps: 194 | Train Loss: 1.0435400 Vali Loss: 1.0541997 Test Loss: 1.0275911
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0444579
	speed: 0.0169s/iter; left time: 8.1610s
Epoch: 8 cost time: 3.400040626525879
Epoch: 8, Steps: 194 | Train Loss: 1.0432228 Vali Loss: 1.0543036 Test Loss: 1.0275582
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0304829
	speed: 0.0214s/iter; left time: 6.1976s
Epoch: 9 cost time: 3.416045904159546
Epoch: 9, Steps: 194 | Train Loss: 1.0433860 Vali Loss: 1.0543623 Test Loss: 1.0275525
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0427572
	speed: 0.0150s/iter; left time: 1.4229s
Epoch: 10 cost time: 2.536954641342163
Epoch: 10, Steps: 194 | Train Loss: 1.0432851 Vali Loss: 1.0537105 Test Loss: 1.0275558
Validation loss decreased (1.054135 --> 1.053710).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0275557041168213, mae:0.8045477271080017
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0550423
	speed: 0.0162s/iter; left time: 29.7652s
Epoch: 1 cost time: 3.2162530422210693
Epoch: 1, Steps: 194 | Train Loss: 1.0628877 Vali Loss: 1.0572767 Test Loss: 1.0318825
Validation loss decreased (inf --> 1.057277).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0382463
	speed: 0.0164s/iter; left time: 26.9617s
Epoch: 2 cost time: 3.2728874683380127
Epoch: 2, Steps: 194 | Train Loss: 1.0495318 Vali Loss: 1.0586658 Test Loss: 1.0304179
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0359755
	speed: 0.0163s/iter; left time: 23.7214s
Epoch: 3 cost time: 3.0471534729003906
Epoch: 3, Steps: 194 | Train Loss: 1.0465658 Vali Loss: 1.0540547 Test Loss: 1.0298653
Validation loss decreased (1.057277 --> 1.054055).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0421548
	speed: 0.0163s/iter; left time: 20.5417s
Epoch: 4 cost time: 3.025106191635132
Epoch: 4, Steps: 194 | Train Loss: 1.0450257 Vali Loss: 1.0546031 Test Loss: 1.0280297
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0301874
	speed: 0.0185s/iter; left time: 19.7472s
Epoch: 5 cost time: 2.8228533267974854
Epoch: 5, Steps: 194 | Train Loss: 1.0441628 Vali Loss: 1.0536361 Test Loss: 1.0282096
Validation loss decreased (1.054055 --> 1.053636).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0491568
	speed: 0.0228s/iter; left time: 19.8320s
Epoch: 6 cost time: 3.6307430267333984
Epoch: 6, Steps: 194 | Train Loss: 1.0436932 Vali Loss: 1.0533099 Test Loss: 1.0278524
Validation loss decreased (1.053636 --> 1.053310).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0421964
	speed: 0.0251s/iter; left time: 17.0237s
Epoch: 7 cost time: 4.07291316986084
Epoch: 7, Steps: 194 | Train Loss: 1.0435443 Vali Loss: 1.0536609 Test Loss: 1.0276511
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0505363
	speed: 0.0191s/iter; left time: 9.2336s
Epoch: 8 cost time: 3.175964117050171
Epoch: 8, Steps: 194 | Train Loss: 1.0432770 Vali Loss: 1.0535951 Test Loss: 1.0276142
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0483985
	speed: 0.0191s/iter; left time: 5.5258s
Epoch: 9 cost time: 3.032007932662964
Epoch: 9, Steps: 194 | Train Loss: 1.0432919 Vali Loss: 1.0536406 Test Loss: 1.0276068
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0267748
	speed: 0.0158s/iter; left time: 1.5041s
Epoch: 10 cost time: 2.5639634132385254
Epoch: 10, Steps: 194 | Train Loss: 1.0432544 Vali Loss: 1.0534810 Test Loss: 1.0276083
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.027852177619934, mae:0.8046779632568359
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7407178
	speed: 0.0292s/iter; left time: 59.3233s
	iters: 200, epoch: 1 | loss: 0.7231418
	speed: 0.0242s/iter; left time: 46.7114s
Epoch: 1 cost time: 5.140610218048096
Epoch: 1, Steps: 213 | Train Loss: 0.7477294 Vali Loss: 0.6663846 Test Loss: 0.6628491
Validation loss decreased (inf --> 0.666385).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7479814
	speed: 0.0155s/iter; left time: 28.0969s
	iters: 200, epoch: 2 | loss: 0.7574517
	speed: 0.0132s/iter; left time: 22.7051s
Epoch: 2 cost time: 2.821409225463867
Epoch: 2, Steps: 213 | Train Loss: 0.7159886 Vali Loss: 0.6650069 Test Loss: 0.6522585
Validation loss decreased (0.666385 --> 0.665007).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7176329
	speed: 0.0180s/iter; left time: 28.9195s
	iters: 200, epoch: 3 | loss: 0.6969582
	speed: 0.0152s/iter; left time: 22.9398s
Epoch: 3 cost time: 3.331305503845215
Epoch: 3, Steps: 213 | Train Loss: 0.7041888 Vali Loss: 0.6615157 Test Loss: 0.6498744
Validation loss decreased (0.665007 --> 0.661516).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6968675
	speed: 0.0179s/iter; left time: 24.9247s
	iters: 200, epoch: 4 | loss: 0.6807808
	speed: 0.0168s/iter; left time: 21.6650s
Epoch: 4 cost time: 3.671238422393799
Epoch: 4, Steps: 213 | Train Loss: 0.6987346 Vali Loss: 0.6647134 Test Loss: 0.6522410
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6550838
	speed: 0.0214s/iter; left time: 25.1783s
	iters: 200, epoch: 5 | loss: 0.6803306
	speed: 0.0195s/iter; left time: 21.0006s
Epoch: 5 cost time: 4.186112880706787
Epoch: 5, Steps: 213 | Train Loss: 0.6961799 Vali Loss: 0.6684436 Test Loss: 0.6500159
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6888024
	speed: 0.0172s/iter; left time: 16.6295s
	iters: 200, epoch: 6 | loss: 0.6603914
	speed: 0.0145s/iter; left time: 12.5360s
Epoch: 6 cost time: 3.1395885944366455
Epoch: 6, Steps: 213 | Train Loss: 0.6943495 Vali Loss: 0.6707960 Test Loss: 0.6507882
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7259201
	speed: 0.0194s/iter; left time: 14.6247s
	iters: 200, epoch: 7 | loss: 0.7005525
	speed: 0.0172s/iter; left time: 11.2619s
Epoch: 7 cost time: 3.7552883625030518
Epoch: 7, Steps: 213 | Train Loss: 0.6928054 Vali Loss: 0.6714249 Test Loss: 0.6513723
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6621724
	speed: 0.0225s/iter; left time: 12.1391s
	iters: 200, epoch: 8 | loss: 0.6936665
	speed: 0.0215s/iter; left time: 9.4393s
Epoch: 8 cost time: 4.500104665756226
Epoch: 8, Steps: 213 | Train Loss: 0.6925283 Vali Loss: 0.6756766 Test Loss: 0.6508929
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6498744487762451, mae:0.6477177143096924
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7480941
	speed: 0.0163s/iter; left time: 33.1567s
	iters: 200, epoch: 1 | loss: 0.7488471
	speed: 0.0144s/iter; left time: 27.7839s
Epoch: 1 cost time: 3.1942622661590576
Epoch: 1, Steps: 213 | Train Loss: 0.7463600 Vali Loss: 0.7006177 Test Loss: 0.6637954
Validation loss decreased (inf --> 0.700618).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7083585
	speed: 0.0143s/iter; left time: 26.0170s
	iters: 200, epoch: 2 | loss: 0.7010431
	speed: 0.0130s/iter; left time: 22.2735s
Epoch: 2 cost time: 2.8524136543273926
Epoch: 2, Steps: 213 | Train Loss: 0.7156024 Vali Loss: 0.6782729 Test Loss: 0.6570667
Validation loss decreased (0.700618 --> 0.678273).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6968643
	speed: 0.0155s/iter; left time: 24.9150s
	iters: 200, epoch: 3 | loss: 0.7238805
	speed: 0.0151s/iter; left time: 22.7299s
Epoch: 3 cost time: 3.266618013381958
Epoch: 3, Steps: 213 | Train Loss: 0.7037155 Vali Loss: 0.6726038 Test Loss: 0.6520025
Validation loss decreased (0.678273 --> 0.672604).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7221845
	speed: 0.0152s/iter; left time: 21.1049s
	iters: 200, epoch: 4 | loss: 0.6813621
	speed: 0.0153s/iter; left time: 19.7174s
Epoch: 4 cost time: 3.37634015083313
Epoch: 4, Steps: 213 | Train Loss: 0.6977106 Vali Loss: 0.6754265 Test Loss: 0.6517774
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6858592
	speed: 0.0136s/iter; left time: 16.0094s
	iters: 200, epoch: 5 | loss: 0.6704202
	speed: 0.0168s/iter; left time: 18.1167s
Epoch: 5 cost time: 3.6355390548706055
Epoch: 5, Steps: 213 | Train Loss: 0.6941788 Vali Loss: 0.6832656 Test Loss: 0.6542093
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7263884
	speed: 0.0135s/iter; left time: 12.9977s
	iters: 200, epoch: 6 | loss: 0.7066147
	speed: 0.0125s/iter; left time: 10.8096s
Epoch: 6 cost time: 2.7602994441986084
Epoch: 6, Steps: 213 | Train Loss: 0.6923604 Vali Loss: 0.6864148 Test Loss: 0.6552882
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7212807
	speed: 0.0134s/iter; left time: 10.0982s
	iters: 200, epoch: 7 | loss: 0.6475246
	speed: 0.0124s/iter; left time: 8.0837s
Epoch: 7 cost time: 2.7767562866210938
Epoch: 7, Steps: 213 | Train Loss: 0.6919213 Vali Loss: 0.6912293 Test Loss: 0.6563422
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7660262
	speed: 0.0179s/iter; left time: 9.6709s
	iters: 200, epoch: 8 | loss: 0.7227602
	speed: 0.0146s/iter; left time: 6.4442s
Epoch: 8 cost time: 3.1784439086914062
Epoch: 8, Steps: 213 | Train Loss: 0.6912683 Vali Loss: 0.6912131 Test Loss: 0.6559879
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6520026922225952, mae:0.648237407207489
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7102391
	speed: 0.0197s/iter; left time: 40.0492s
	iters: 200, epoch: 1 | loss: 0.6959440
	speed: 0.0180s/iter; left time: 34.8060s
Epoch: 1 cost time: 3.948585033416748
Epoch: 1, Steps: 213 | Train Loss: 0.7472678 Vali Loss: 0.6711508 Test Loss: 0.6576102
Validation loss decreased (inf --> 0.671151).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7220448
	speed: 0.0129s/iter; left time: 23.4515s
	iters: 200, epoch: 2 | loss: 0.7059764
	speed: 0.0131s/iter; left time: 22.4546s
Epoch: 2 cost time: 2.892983913421631
Epoch: 2, Steps: 213 | Train Loss: 0.7143544 Vali Loss: 0.6630460 Test Loss: 0.6522688
Validation loss decreased (0.671151 --> 0.663046).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7090663
	speed: 0.0179s/iter; left time: 28.7611s
	iters: 200, epoch: 3 | loss: 0.6646793
	speed: 0.0158s/iter; left time: 23.7529s
Epoch: 3 cost time: 3.48081636428833
Epoch: 3, Steps: 213 | Train Loss: 0.7016480 Vali Loss: 0.6597156 Test Loss: 0.6490167
Validation loss decreased (0.663046 --> 0.659716).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6395262
	speed: 0.0195s/iter; left time: 27.1595s
	iters: 200, epoch: 4 | loss: 0.6844044
	speed: 0.0182s/iter; left time: 23.4828s
Epoch: 4 cost time: 3.905142068862915
Epoch: 4, Steps: 213 | Train Loss: 0.6960064 Vali Loss: 0.6797106 Test Loss: 0.6523386
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6447589
	speed: 0.0183s/iter; left time: 21.5752s
	iters: 200, epoch: 5 | loss: 0.7528358
	speed: 0.0167s/iter; left time: 17.9690s
Epoch: 5 cost time: 3.6208956241607666
Epoch: 5, Steps: 213 | Train Loss: 0.6923479 Vali Loss: 0.6806787 Test Loss: 0.6515624
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6508240
	speed: 0.0170s/iter; left time: 16.4049s
	iters: 200, epoch: 6 | loss: 0.6825405
	speed: 0.0129s/iter; left time: 11.2083s
Epoch: 6 cost time: 2.768538236618042
Epoch: 6, Steps: 213 | Train Loss: 0.6898902 Vali Loss: 0.6894075 Test Loss: 0.6530520
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6859876
	speed: 0.0105s/iter; left time: 7.8765s
	iters: 200, epoch: 7 | loss: 0.6393052
	speed: 0.0099s/iter; left time: 6.4409s
Epoch: 7 cost time: 2.17724347114563
Epoch: 7, Steps: 213 | Train Loss: 0.6889664 Vali Loss: 0.6914087 Test Loss: 0.6537216
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6612254
	speed: 0.0168s/iter; left time: 9.0713s
	iters: 200, epoch: 8 | loss: 0.6831261
	speed: 0.0140s/iter; left time: 6.1490s
Epoch: 8 cost time: 3.0478572845458984
Epoch: 8, Steps: 213 | Train Loss: 0.6887032 Vali Loss: 0.6860164 Test Loss: 0.6540175
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6490167379379272, mae:0.6470913290977478
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7543519
	speed: 0.0305s/iter; left time: 60.9956s
	iters: 200, epoch: 1 | loss: 0.8180767
	speed: 0.0218s/iter; left time: 41.5081s
Epoch: 1 cost time: 4.51530385017395
Epoch: 1, Steps: 210 | Train Loss: 0.8436007 Vali Loss: 0.8706424 Test Loss: 0.7342875
Validation loss decreased (inf --> 0.870642).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8255563
	speed: 0.0213s/iter; left time: 38.1471s
	iters: 200, epoch: 2 | loss: 0.8385844
	speed: 0.0174s/iter; left time: 29.3909s
Epoch: 2 cost time: 3.6975386142730713
Epoch: 2, Steps: 210 | Train Loss: 0.8161544 Vali Loss: 0.8924335 Test Loss: 0.7418795
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7947770
	speed: 0.0177s/iter; left time: 28.0080s
	iters: 200, epoch: 3 | loss: 0.7734003
	speed: 0.0145s/iter; left time: 21.4488s
Epoch: 3 cost time: 3.0843281745910645
Epoch: 3, Steps: 210 | Train Loss: 0.7973260 Vali Loss: 0.9088433 Test Loss: 0.7436050
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7321602
	speed: 0.0174s/iter; left time: 23.8898s
	iters: 200, epoch: 4 | loss: 0.8188086
	speed: 0.0222s/iter; left time: 28.2203s
Epoch: 4 cost time: 4.822940826416016
Epoch: 4, Steps: 210 | Train Loss: 0.7884956 Vali Loss: 0.9386128 Test Loss: 0.7576680
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8080295
	speed: 0.0174s/iter; left time: 20.1864s
	iters: 200, epoch: 5 | loss: 0.7713218
	speed: 0.0164s/iter; left time: 17.3825s
Epoch: 5 cost time: 3.578528881072998
Epoch: 5, Steps: 210 | Train Loss: 0.7835346 Vali Loss: 0.9530640 Test Loss: 0.7636933
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7426669
	speed: 0.0173s/iter; left time: 16.4225s
	iters: 200, epoch: 6 | loss: 0.8346356
	speed: 0.0180s/iter; left time: 15.3191s
Epoch: 6 cost time: 3.8877816200256348
Epoch: 6, Steps: 210 | Train Loss: 0.7814387 Vali Loss: 0.9418678 Test Loss: 0.7593676
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.734287440776825, mae:0.6873984932899475
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8369857
	speed: 0.0147s/iter; left time: 29.4080s
	iters: 200, epoch: 1 | loss: 0.8250083
	speed: 0.0146s/iter; left time: 27.7732s
Epoch: 1 cost time: 3.1268086433410645
Epoch: 1, Steps: 210 | Train Loss: 0.8440744 Vali Loss: 0.9240425 Test Loss: 0.7458495
Validation loss decreased (inf --> 0.924042).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8327955
	speed: 0.0158s/iter; left time: 28.3667s
	iters: 200, epoch: 2 | loss: 0.7811958
	speed: 0.0165s/iter; left time: 27.9070s
Epoch: 2 cost time: 3.532221555709839
Epoch: 2, Steps: 210 | Train Loss: 0.8157855 Vali Loss: 0.9158760 Test Loss: 0.7489305
Validation loss decreased (0.924042 --> 0.915876).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7995407
	speed: 0.0164s/iter; left time: 25.8846s
	iters: 200, epoch: 3 | loss: 0.7360204
	speed: 0.0155s/iter; left time: 22.9440s
Epoch: 3 cost time: 3.3736894130706787
Epoch: 3, Steps: 210 | Train Loss: 0.7969600 Vali Loss: 0.9307470 Test Loss: 0.7551720
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8093491
	speed: 0.0142s/iter; left time: 19.4656s
	iters: 200, epoch: 4 | loss: 0.7557318
	speed: 0.0143s/iter; left time: 18.1567s
Epoch: 4 cost time: 3.059739112854004
Epoch: 4, Steps: 210 | Train Loss: 0.7883352 Vali Loss: 0.9375673 Test Loss: 0.7585067
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8107328
	speed: 0.0138s/iter; left time: 16.0579s
	iters: 200, epoch: 5 | loss: 0.8562231
	speed: 0.0136s/iter; left time: 14.4086s
Epoch: 5 cost time: 2.965984582901001
Epoch: 5, Steps: 210 | Train Loss: 0.7831768 Vali Loss: 0.9394613 Test Loss: 0.7584831
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8033006
	speed: 0.0168s/iter; left time: 15.9789s
	iters: 200, epoch: 6 | loss: 0.7733876
	speed: 0.0165s/iter; left time: 14.0143s
Epoch: 6 cost time: 3.5750482082366943
Epoch: 6, Steps: 210 | Train Loss: 0.7802869 Vali Loss: 0.9445185 Test Loss: 0.7606356
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7053520
	speed: 0.0225s/iter; left time: 16.7055s
	iters: 200, epoch: 7 | loss: 0.8008878
	speed: 0.0202s/iter; left time: 12.9297s
Epoch: 7 cost time: 4.289059400558472
Epoch: 7, Steps: 210 | Train Loss: 0.7791269 Vali Loss: 0.9420943 Test Loss: 0.7632026
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7489303946495056, mae:0.691517174243927
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7411598
	speed: 0.0197s/iter; left time: 39.3563s
	iters: 200, epoch: 1 | loss: 0.8669591
	speed: 0.0142s/iter; left time: 27.0012s
Epoch: 1 cost time: 3.0197930335998535
Epoch: 1, Steps: 210 | Train Loss: 0.8441528 Vali Loss: 0.8835553 Test Loss: 0.7419569
Validation loss decreased (inf --> 0.883555).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7777483
	speed: 0.0215s/iter; left time: 38.5311s
	iters: 200, epoch: 2 | loss: 0.7989345
	speed: 0.0169s/iter; left time: 28.5704s
Epoch: 2 cost time: 3.6225852966308594
Epoch: 2, Steps: 210 | Train Loss: 0.8133679 Vali Loss: 0.9093124 Test Loss: 0.7482452
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7223474
	speed: 0.0239s/iter; left time: 37.7552s
	iters: 200, epoch: 3 | loss: 0.7671704
	speed: 0.0188s/iter; left time: 27.7793s
Epoch: 3 cost time: 4.055302858352661
Epoch: 3, Steps: 210 | Train Loss: 0.7933458 Vali Loss: 0.9553462 Test Loss: 0.7729520
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7502186
	speed: 0.0174s/iter; left time: 23.8993s
	iters: 200, epoch: 4 | loss: 0.7683215
	speed: 0.0141s/iter; left time: 17.8670s
Epoch: 4 cost time: 2.998544931411743
Epoch: 4, Steps: 210 | Train Loss: 0.7850867 Vali Loss: 0.9440935 Test Loss: 0.7637787
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7556199
	speed: 0.0126s/iter; left time: 14.6821s
	iters: 200, epoch: 5 | loss: 0.7845424
	speed: 0.0103s/iter; left time: 10.9308s
Epoch: 5 cost time: 2.2121212482452393
Epoch: 5, Steps: 210 | Train Loss: 0.7799566 Vali Loss: 0.9501371 Test Loss: 0.7636178
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7936074
	speed: 0.0154s/iter; left time: 14.6810s
	iters: 200, epoch: 6 | loss: 0.8393739
	speed: 0.0181s/iter; left time: 15.3996s
Epoch: 6 cost time: 3.886021614074707
Epoch: 6, Steps: 210 | Train Loss: 0.7777556 Vali Loss: 0.9614391 Test Loss: 0.7706749
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7419568300247192, mae:0.6920632123947144
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9514034
	speed: 0.0282s/iter; left time: 55.3524s
	iters: 200, epoch: 1 | loss: 0.9478818
	speed: 0.0193s/iter; left time: 35.9277s
Epoch: 1 cost time: 3.983031749725342
Epoch: 1, Steps: 206 | Train Loss: 0.9596597 Vali Loss: 1.1175786 Test Loss: 0.8312725
Validation loss decreased (inf --> 1.117579).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9073263
	speed: 0.0156s/iter; left time: 27.2952s
	iters: 200, epoch: 2 | loss: 0.9111561
	speed: 0.0154s/iter; left time: 25.5145s
Epoch: 2 cost time: 3.382017135620117
Epoch: 2, Steps: 206 | Train Loss: 0.9223478 Vali Loss: 1.0938642 Test Loss: 0.8558782
Validation loss decreased (1.117579 --> 1.093864).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9248003
	speed: 0.0197s/iter; left time: 30.5818s
	iters: 200, epoch: 3 | loss: 0.8848048
	speed: 0.0182s/iter; left time: 26.3117s
Epoch: 3 cost time: 3.7910842895507812
Epoch: 3, Steps: 206 | Train Loss: 0.9002040 Vali Loss: 1.0577539 Test Loss: 0.8470050
Validation loss decreased (1.093864 --> 1.057754).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8700502
	speed: 0.0210s/iter; left time: 28.1840s
	iters: 200, epoch: 4 | loss: 0.9153149
	speed: 0.0185s/iter; left time: 22.9643s
Epoch: 4 cost time: 3.9106149673461914
Epoch: 4, Steps: 206 | Train Loss: 0.8878817 Vali Loss: 1.0876745 Test Loss: 0.8572908
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8881765
	speed: 0.0161s/iter; left time: 18.2861s
	iters: 200, epoch: 5 | loss: 0.8858250
	speed: 0.0138s/iter; left time: 14.3147s
Epoch: 5 cost time: 2.862940788269043
Epoch: 5, Steps: 206 | Train Loss: 0.8815486 Vali Loss: 1.1106504 Test Loss: 0.8687150
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8902581
	speed: 0.0181s/iter; left time: 16.8313s
	iters: 200, epoch: 6 | loss: 0.8203567
	speed: 0.0192s/iter; left time: 15.9419s
Epoch: 6 cost time: 4.061443090438843
Epoch: 6, Steps: 206 | Train Loss: 0.8773906 Vali Loss: 1.1050287 Test Loss: 0.8729510
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8699909
	speed: 0.0171s/iter; left time: 12.3933s
	iters: 200, epoch: 7 | loss: 0.8822173
	speed: 0.0156s/iter; left time: 9.7464s
Epoch: 7 cost time: 3.304429769515991
Epoch: 7, Steps: 206 | Train Loss: 0.8784425 Vali Loss: 1.1055037 Test Loss: 0.8728234
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8644178
	speed: 0.0214s/iter; left time: 11.0892s
	iters: 200, epoch: 8 | loss: 0.8362598
	speed: 0.0174s/iter; left time: 7.2987s
Epoch: 8 cost time: 3.6524062156677246
Epoch: 8, Steps: 206 | Train Loss: 0.8759838 Vali Loss: 1.1110967 Test Loss: 0.8765870
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8470048308372498, mae:0.7383965849876404
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9085237
	speed: 0.0137s/iter; left time: 26.8380s
	iters: 200, epoch: 1 | loss: 0.8697919
	speed: 0.0139s/iter; left time: 25.9143s
Epoch: 1 cost time: 2.9235761165618896
Epoch: 1, Steps: 206 | Train Loss: 0.9600374 Vali Loss: 1.0601904 Test Loss: 0.8274242
Validation loss decreased (inf --> 1.060190).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8177020
	speed: 0.0201s/iter; left time: 35.2060s
	iters: 200, epoch: 2 | loss: 0.9246332
	speed: 0.0171s/iter; left time: 28.3702s
Epoch: 2 cost time: 3.6183032989501953
Epoch: 2, Steps: 206 | Train Loss: 0.9219036 Vali Loss: 1.1107825 Test Loss: 0.8534707
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9714487
	speed: 0.0167s/iter; left time: 25.9213s
	iters: 200, epoch: 3 | loss: 0.9205337
	speed: 0.0148s/iter; left time: 21.4437s
Epoch: 3 cost time: 3.145319938659668
Epoch: 3, Steps: 206 | Train Loss: 0.8981705 Vali Loss: 1.1176987 Test Loss: 0.8576555
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8564945
	speed: 0.0165s/iter; left time: 22.1074s
	iters: 200, epoch: 4 | loss: 0.8386270
	speed: 0.0153s/iter; left time: 18.9825s
Epoch: 4 cost time: 3.239169120788574
Epoch: 4, Steps: 206 | Train Loss: 0.8862102 Vali Loss: 1.1065902 Test Loss: 0.8576355
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9400101
	speed: 0.0153s/iter; left time: 17.3939s
	iters: 200, epoch: 5 | loss: 0.8949140
	speed: 0.0149s/iter; left time: 15.4916s
Epoch: 5 cost time: 3.1763079166412354
Epoch: 5, Steps: 206 | Train Loss: 0.8794574 Vali Loss: 1.1222690 Test Loss: 0.8676724
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8800362
	speed: 0.0126s/iter; left time: 11.7481s
	iters: 200, epoch: 6 | loss: 0.8960056
	speed: 0.0115s/iter; left time: 9.5794s
Epoch: 6 cost time: 2.4927937984466553
Epoch: 6, Steps: 206 | Train Loss: 0.8761859 Vali Loss: 1.1163788 Test Loss: 0.8676989
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8274242877960205, mae:0.7299227714538574
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9505454
	speed: 0.0169s/iter; left time: 33.2092s
	iters: 200, epoch: 1 | loss: 0.8994860
	speed: 0.0190s/iter; left time: 35.3768s
Epoch: 1 cost time: 3.9594223499298096
Epoch: 1, Steps: 206 | Train Loss: 0.9592357 Vali Loss: 1.0760845 Test Loss: 0.8292866
Validation loss decreased (inf --> 1.076084).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8819235
	speed: 0.0267s/iter; left time: 46.8226s
	iters: 200, epoch: 2 | loss: 0.9721705
	speed: 0.0218s/iter; left time: 36.0628s
Epoch: 2 cost time: 4.492952585220337
Epoch: 2, Steps: 206 | Train Loss: 0.9252299 Vali Loss: 1.0594271 Test Loss: 0.8341262
Validation loss decreased (1.076084 --> 1.059427).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8639937
	speed: 0.0220s/iter; left time: 34.0076s
	iters: 200, epoch: 3 | loss: 0.8589556
	speed: 0.0187s/iter; left time: 27.0866s
Epoch: 3 cost time: 3.923351764678955
Epoch: 3, Steps: 206 | Train Loss: 0.9031498 Vali Loss: 1.1218046 Test Loss: 0.8500623
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9416875
	speed: 0.0142s/iter; left time: 19.0665s
	iters: 200, epoch: 4 | loss: 0.8882274
	speed: 0.0135s/iter; left time: 16.7844s
Epoch: 4 cost time: 2.824643850326538
Epoch: 4, Steps: 206 | Train Loss: 0.8926144 Vali Loss: 1.1245395 Test Loss: 0.8563884
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9667902
	speed: 0.0118s/iter; left time: 13.4229s
	iters: 200, epoch: 5 | loss: 0.8550083
	speed: 0.0123s/iter; left time: 12.7668s
Epoch: 5 cost time: 2.6254994869232178
Epoch: 5, Steps: 206 | Train Loss: 0.8874662 Vali Loss: 1.1186781 Test Loss: 0.8537064
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8124183
	speed: 0.0186s/iter; left time: 17.3194s
	iters: 200, epoch: 6 | loss: 0.8586051
	speed: 0.0162s/iter; left time: 13.4530s
Epoch: 6 cost time: 3.4326233863830566
Epoch: 6, Steps: 206 | Train Loss: 0.8845790 Vali Loss: 1.1285601 Test Loss: 0.8592182
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8868555
	speed: 0.0180s/iter; left time: 13.0388s
	iters: 200, epoch: 7 | loss: 0.9124766
	speed: 0.0162s/iter; left time: 10.1315s
Epoch: 7 cost time: 3.4295895099639893
Epoch: 7, Steps: 206 | Train Loss: 0.8831301 Vali Loss: 1.1345809 Test Loss: 0.8617427
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8341261744499207, mae:0.7323522567749023
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0836020
	speed: 0.0267s/iter; left time: 49.0870s
Epoch: 1 cost time: 4.176356077194214
Epoch: 1, Steps: 194 | Train Loss: 1.1503893 Vali Loss: 1.7230325 Test Loss: 0.9146825
Validation loss decreased (inf --> 1.723032).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0366023
	speed: 0.0152s/iter; left time: 25.0408s
Epoch: 2 cost time: 2.757779121398926
Epoch: 2, Steps: 194 | Train Loss: 1.1129906 Vali Loss: 1.5744073 Test Loss: 0.9049748
Validation loss decreased (1.723032 --> 1.574407).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1187849
	speed: 0.0156s/iter; left time: 22.6134s
Epoch: 3 cost time: 3.034472703933716
Epoch: 3, Steps: 194 | Train Loss: 1.0922302 Vali Loss: 1.6934388 Test Loss: 0.9436820
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0215465
	speed: 0.0252s/iter; left time: 31.7097s
Epoch: 4 cost time: 3.6920053958892822
Epoch: 4, Steps: 194 | Train Loss: 1.0790139 Vali Loss: 1.6989712 Test Loss: 0.9464259
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0882454
	speed: 0.0162s/iter; left time: 17.2595s
Epoch: 5 cost time: 2.924180507659912
Epoch: 5, Steps: 194 | Train Loss: 1.0716089 Vali Loss: 1.6984420 Test Loss: 0.9556021
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.1020821
	speed: 0.0205s/iter; left time: 17.8644s
Epoch: 6 cost time: 3.627376079559326
Epoch: 6, Steps: 194 | Train Loss: 1.0698486 Vali Loss: 1.6872604 Test Loss: 0.9572007
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0721227
	speed: 0.0186s/iter; left time: 12.5633s
Epoch: 7 cost time: 3.3714983463287354
Epoch: 7, Steps: 194 | Train Loss: 1.0679062 Vali Loss: 1.7006640 Test Loss: 0.9595981
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9049747586250305, mae:0.7639526724815369
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1685674
	speed: 0.0167s/iter; left time: 30.7447s
Epoch: 1 cost time: 3.9234440326690674
Epoch: 1, Steps: 194 | Train Loss: 1.1497108 Vali Loss: 1.6067505 Test Loss: 0.8983405
Validation loss decreased (inf --> 1.606750).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1332692
	speed: 0.0142s/iter; left time: 23.4178s
Epoch: 2 cost time: 2.6648387908935547
Epoch: 2, Steps: 194 | Train Loss: 1.1137007 Vali Loss: 1.7075417 Test Loss: 0.9289484
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0232922
	speed: 0.0145s/iter; left time: 21.1330s
Epoch: 3 cost time: 2.378826379776001
Epoch: 3, Steps: 194 | Train Loss: 1.0904609 Vali Loss: 1.6249464 Test Loss: 0.9235082
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1364374
	speed: 0.0145s/iter; left time: 18.3092s
Epoch: 4 cost time: 3.440732002258301
Epoch: 4, Steps: 194 | Train Loss: 1.0755484 Vali Loss: 1.6567726 Test Loss: 0.9525310
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0942097
	speed: 0.0174s/iter; left time: 18.5111s
Epoch: 5 cost time: 3.6985397338867188
Epoch: 5, Steps: 194 | Train Loss: 1.0686105 Vali Loss: 1.6680548 Test Loss: 0.9562872
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0933022
	speed: 0.0195s/iter; left time: 17.0271s
Epoch: 6 cost time: 3.2981762886047363
Epoch: 6, Steps: 194 | Train Loss: 1.0625528 Vali Loss: 1.6500416 Test Loss: 0.9547396
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8983403444290161, mae:0.7613822817802429
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0748398
	speed: 0.0149s/iter; left time: 27.4004s
Epoch: 1 cost time: 2.7314274311065674
Epoch: 1, Steps: 194 | Train Loss: 1.1494699 Vali Loss: 1.6571909 Test Loss: 0.9038275
Validation loss decreased (inf --> 1.657191).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1193626
	speed: 0.0148s/iter; left time: 24.3677s
Epoch: 2 cost time: 3.2436485290527344
Epoch: 2, Steps: 194 | Train Loss: 1.1142712 Vali Loss: 1.7198789 Test Loss: 0.9356474
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0703326
	speed: 0.0148s/iter; left time: 21.5746s
Epoch: 3 cost time: 2.7650060653686523
Epoch: 3, Steps: 194 | Train Loss: 1.0924913 Vali Loss: 1.6169934 Test Loss: 0.9270695
Validation loss decreased (1.657191 --> 1.616993).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0854310
	speed: 0.0197s/iter; left time: 24.7773s
Epoch: 4 cost time: 3.445087432861328
Epoch: 4, Steps: 194 | Train Loss: 1.0763842 Vali Loss: 1.6232824 Test Loss: 0.9289095
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0692888
	speed: 0.0175s/iter; left time: 18.6047s
Epoch: 5 cost time: 3.1122524738311768
Epoch: 5, Steps: 194 | Train Loss: 1.0694023 Vali Loss: 1.6230892 Test Loss: 0.9407057
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0384052
	speed: 0.0139s/iter; left time: 12.1413s
Epoch: 6 cost time: 2.5148239135742188
Epoch: 6, Steps: 194 | Train Loss: 1.0647774 Vali Loss: 1.6175113 Test Loss: 0.9394292
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9657941
	speed: 0.0212s/iter; left time: 14.3757s
Epoch: 7 cost time: 3.624373197555542
Epoch: 7, Steps: 194 | Train Loss: 1.0613987 Vali Loss: 1.5969408 Test Loss: 0.9405227
Validation loss decreased (1.616993 --> 1.596941).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0369070
	speed: 0.0214s/iter; left time: 10.3540s
Epoch: 8 cost time: 3.592890977859497
Epoch: 8, Steps: 194 | Train Loss: 1.0605743 Vali Loss: 1.5987138 Test Loss: 0.9394589
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0279491
	speed: 0.0182s/iter; left time: 5.2622s
Epoch: 9 cost time: 3.11116361618042
Epoch: 9, Steps: 194 | Train Loss: 1.0597725 Vali Loss: 1.5958676 Test Loss: 0.9399669
Validation loss decreased (1.596941 --> 1.595868).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9979516
	speed: 0.0195s/iter; left time: 1.8487s
Epoch: 10 cost time: 3.209690570831299
Epoch: 10, Steps: 194 | Train Loss: 1.0595773 Vali Loss: 1.5957227 Test Loss: 0.9397830
Validation loss decreased (1.595868 --> 1.595723).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9397830963134766, mae:0.7796480059623718
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6981233
	speed: 0.0271s/iter; left time: 55.0992s
	iters: 200, epoch: 1 | loss: 0.7391843
	speed: 0.0205s/iter; left time: 39.6411s
Epoch: 1 cost time: 4.4072043895721436
Epoch: 1, Steps: 213 | Train Loss: 0.7481931 Vali Loss: 0.6738820 Test Loss: 0.6600800
Validation loss decreased (inf --> 0.673882).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7292781
	speed: 0.0167s/iter; left time: 30.4397s
	iters: 200, epoch: 2 | loss: 0.7081780
	speed: 0.0143s/iter; left time: 24.6424s
Epoch: 2 cost time: 3.1353378295898438
Epoch: 2, Steps: 213 | Train Loss: 0.7149882 Vali Loss: 0.6765386 Test Loss: 0.6562442
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7296330
	speed: 0.0146s/iter; left time: 23.3821s
	iters: 200, epoch: 3 | loss: 0.7186620
	speed: 0.0139s/iter; left time: 20.8932s
Epoch: 3 cost time: 3.072587013244629
Epoch: 3, Steps: 213 | Train Loss: 0.7022337 Vali Loss: 0.6960793 Test Loss: 0.6557128
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7661285
	speed: 0.0241s/iter; left time: 33.5621s
	iters: 200, epoch: 4 | loss: 0.6695747
	speed: 0.0206s/iter; left time: 26.6153s
Epoch: 4 cost time: 4.3809614181518555
Epoch: 4, Steps: 213 | Train Loss: 0.6953358 Vali Loss: 0.6913291 Test Loss: 0.6589548
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6601489
	speed: 0.0190s/iter; left time: 22.3883s
	iters: 200, epoch: 5 | loss: 0.7147669
	speed: 0.0179s/iter; left time: 19.2690s
Epoch: 5 cost time: 4.07265043258667
Epoch: 5, Steps: 213 | Train Loss: 0.6913892 Vali Loss: 0.7035872 Test Loss: 0.6597279
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6237062
	speed: 0.0147s/iter; left time: 14.2073s
	iters: 200, epoch: 6 | loss: 0.6689008
	speed: 0.0141s/iter; left time: 12.2087s
Epoch: 6 cost time: 3.2588376998901367
Epoch: 6, Steps: 213 | Train Loss: 0.6896203 Vali Loss: 0.7080526 Test Loss: 0.6646063
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6600799560546875, mae:0.6524607539176941
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7547881
	speed: 0.0139s/iter; left time: 28.1814s
	iters: 200, epoch: 1 | loss: 0.7645053
	speed: 0.0133s/iter; left time: 25.5924s
Epoch: 1 cost time: 2.927035093307495
Epoch: 1, Steps: 213 | Train Loss: 0.7471886 Vali Loss: 0.6685848 Test Loss: 0.6615813
Validation loss decreased (inf --> 0.668585).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7302326
	speed: 0.0179s/iter; left time: 32.6269s
	iters: 200, epoch: 2 | loss: 0.6658933
	speed: 0.0171s/iter; left time: 29.3023s
Epoch: 2 cost time: 3.7136077880859375
Epoch: 2, Steps: 213 | Train Loss: 0.7157128 Vali Loss: 0.6739967 Test Loss: 0.6529685
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7019547
	speed: 0.0187s/iter; left time: 30.0436s
	iters: 200, epoch: 3 | loss: 0.6843695
	speed: 0.0172s/iter; left time: 25.9572s
Epoch: 3 cost time: 3.725963830947876
Epoch: 3, Steps: 213 | Train Loss: 0.7041340 Vali Loss: 0.6644472 Test Loss: 0.6518657
Validation loss decreased (0.668585 --> 0.664447).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6822747
	speed: 0.0170s/iter; left time: 23.6778s
	iters: 200, epoch: 4 | loss: 0.7396504
	speed: 0.0151s/iter; left time: 19.4941s
Epoch: 4 cost time: 3.305847406387329
Epoch: 4, Steps: 213 | Train Loss: 0.6976234 Vali Loss: 0.6688341 Test Loss: 0.6507363
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7174556
	speed: 0.0139s/iter; left time: 16.3806s
	iters: 200, epoch: 5 | loss: 0.6992079
	speed: 0.0128s/iter; left time: 13.7573s
Epoch: 5 cost time: 2.7398202419281006
Epoch: 5, Steps: 213 | Train Loss: 0.6942417 Vali Loss: 0.6771554 Test Loss: 0.6511332
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6851227
	speed: 0.0163s/iter; left time: 15.7665s
	iters: 200, epoch: 6 | loss: 0.6569917
	speed: 0.0133s/iter; left time: 11.5549s
Epoch: 6 cost time: 2.8942694664001465
Epoch: 6, Steps: 213 | Train Loss: 0.6928758 Vali Loss: 0.6787266 Test Loss: 0.6531879
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6392285
	speed: 0.0148s/iter; left time: 11.1170s
	iters: 200, epoch: 7 | loss: 0.7031433
	speed: 0.0139s/iter; left time: 9.0706s
Epoch: 7 cost time: 3.0989997386932373
Epoch: 7, Steps: 213 | Train Loss: 0.6914217 Vali Loss: 0.6829433 Test Loss: 0.6533372
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6614991
	speed: 0.0230s/iter; left time: 12.4044s
	iters: 200, epoch: 8 | loss: 0.7044656
	speed: 0.0186s/iter; left time: 8.1939s
Epoch: 8 cost time: 3.9262702465057373
Epoch: 8, Steps: 213 | Train Loss: 0.6909067 Vali Loss: 0.6826746 Test Loss: 0.6529008
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6518657207489014, mae:0.6482987999916077
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6975107
	speed: 0.0101s/iter; left time: 20.4338s
	iters: 200, epoch: 1 | loss: 0.7871073
	speed: 0.0097s/iter; left time: 18.6386s
Epoch: 1 cost time: 2.2944324016571045
Epoch: 1, Steps: 213 | Train Loss: 0.7482136 Vali Loss: 0.6752499 Test Loss: 0.6639816
Validation loss decreased (inf --> 0.675250).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7400235
	speed: 0.0154s/iter; left time: 28.0317s
	iters: 200, epoch: 2 | loss: 0.7618026
	speed: 0.0145s/iter; left time: 24.9341s
Epoch: 2 cost time: 3.2277045249938965
Epoch: 2, Steps: 213 | Train Loss: 0.7167590 Vali Loss: 0.6780124 Test Loss: 0.6541062
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6483364
	speed: 0.0159s/iter; left time: 25.5695s
	iters: 200, epoch: 3 | loss: 0.6782494
	speed: 0.0151s/iter; left time: 22.7770s
Epoch: 3 cost time: 3.3330540657043457
Epoch: 3, Steps: 213 | Train Loss: 0.7028737 Vali Loss: 0.6752034 Test Loss: 0.6514015
Validation loss decreased (0.675250 --> 0.675203).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6903971
	speed: 0.0173s/iter; left time: 24.0818s
	iters: 200, epoch: 4 | loss: 0.6571912
	speed: 0.0155s/iter; left time: 20.0140s
Epoch: 4 cost time: 3.307335376739502
Epoch: 4, Steps: 213 | Train Loss: 0.6970514 Vali Loss: 0.6833072 Test Loss: 0.6532654
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7144989
	speed: 0.0139s/iter; left time: 16.3381s
	iters: 200, epoch: 5 | loss: 0.6662273
	speed: 0.0140s/iter; left time: 15.1584s
Epoch: 5 cost time: 3.09539532661438
Epoch: 5, Steps: 213 | Train Loss: 0.6932230 Vali Loss: 0.6886529 Test Loss: 0.6546987
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6552910
	speed: 0.0188s/iter; left time: 18.1636s
	iters: 200, epoch: 6 | loss: 0.6502897
	speed: 0.0164s/iter; left time: 14.1927s
Epoch: 6 cost time: 3.552227735519409
Epoch: 6, Steps: 213 | Train Loss: 0.6917470 Vali Loss: 0.6989174 Test Loss: 0.6573264
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6561071
	speed: 0.0223s/iter; left time: 16.8128s
	iters: 200, epoch: 7 | loss: 0.6635524
	speed: 0.0183s/iter; left time: 11.9667s
Epoch: 7 cost time: 3.980551242828369
Epoch: 7, Steps: 213 | Train Loss: 0.6906075 Vali Loss: 0.6958318 Test Loss: 0.6575497
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6791446
	speed: 0.0133s/iter; left time: 7.1728s
	iters: 200, epoch: 8 | loss: 0.6457972
	speed: 0.0111s/iter; left time: 4.8952s
Epoch: 8 cost time: 2.456739664077759
Epoch: 8, Steps: 213 | Train Loss: 0.6901790 Vali Loss: 0.6973806 Test Loss: 0.6576367
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6514015793800354, mae:0.6477181911468506
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8551506
	speed: 0.0341s/iter; left time: 68.1466s
	iters: 200, epoch: 1 | loss: 0.7951178
	speed: 0.0249s/iter; left time: 47.3322s
Epoch: 1 cost time: 5.1927454471588135
Epoch: 1, Steps: 210 | Train Loss: 0.8429507 Vali Loss: 0.8887129 Test Loss: 0.7382782
Validation loss decreased (inf --> 0.888713).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7764742
	speed: 0.0174s/iter; left time: 31.0888s
	iters: 200, epoch: 2 | loss: 0.8170484
	speed: 0.0150s/iter; left time: 25.2930s
Epoch: 2 cost time: 3.175755262374878
Epoch: 2, Steps: 210 | Train Loss: 0.8148813 Vali Loss: 0.9521717 Test Loss: 0.7622423
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8118591
	speed: 0.0144s/iter; left time: 22.8297s
	iters: 200, epoch: 3 | loss: 0.7178282
	speed: 0.0186s/iter; left time: 27.5871s
Epoch: 3 cost time: 4.04435920715332
Epoch: 3, Steps: 210 | Train Loss: 0.7938910 Vali Loss: 0.9573314 Test Loss: 0.7615330
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7831070
	speed: 0.0175s/iter; left time: 23.9550s
	iters: 200, epoch: 4 | loss: 0.8223721
	speed: 0.0167s/iter; left time: 21.1645s
Epoch: 4 cost time: 3.6052238941192627
Epoch: 4, Steps: 210 | Train Loss: 0.7850118 Vali Loss: 0.9504914 Test Loss: 0.7636010
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7991657
	speed: 0.0205s/iter; left time: 23.7790s
	iters: 200, epoch: 5 | loss: 0.7865947
	speed: 0.0224s/iter; left time: 23.7912s
Epoch: 5 cost time: 4.772356033325195
Epoch: 5, Steps: 210 | Train Loss: 0.7803868 Vali Loss: 0.9296420 Test Loss: 0.7591599
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7571476
	speed: 0.0218s/iter; left time: 20.7700s
	iters: 200, epoch: 6 | loss: 0.8231405
	speed: 0.0178s/iter; left time: 15.1688s
Epoch: 6 cost time: 3.7411317825317383
Epoch: 6, Steps: 210 | Train Loss: 0.7780698 Vali Loss: 0.9401420 Test Loss: 0.7633587
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7382783889770508, mae:0.6886310577392578
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9095806
	speed: 0.0281s/iter; left time: 56.1520s
	iters: 200, epoch: 1 | loss: 0.8095111
	speed: 0.0224s/iter; left time: 42.6054s
Epoch: 1 cost time: 4.703962802886963
Epoch: 1, Steps: 210 | Train Loss: 0.8431183 Vali Loss: 0.9173674 Test Loss: 0.7422431
Validation loss decreased (inf --> 0.917367).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8365352
	speed: 0.0292s/iter; left time: 52.2395s
	iters: 200, epoch: 2 | loss: 0.8060533
	speed: 0.0207s/iter; left time: 35.0217s
Epoch: 2 cost time: 4.355761289596558
Epoch: 2, Steps: 210 | Train Loss: 0.8130650 Vali Loss: 0.8780394 Test Loss: 0.7368904
Validation loss decreased (0.917367 --> 0.878039).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8179220
	speed: 0.0197s/iter; left time: 31.1891s
	iters: 200, epoch: 3 | loss: 0.9304931
	speed: 0.0165s/iter; left time: 24.4368s
Epoch: 3 cost time: 3.5401883125305176
Epoch: 3, Steps: 210 | Train Loss: 0.7941286 Vali Loss: 0.9222257 Test Loss: 0.7597535
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8006341
	speed: 0.0133s/iter; left time: 18.2412s
	iters: 200, epoch: 4 | loss: 0.8000953
	speed: 0.0119s/iter; left time: 15.1796s
Epoch: 4 cost time: 2.598642349243164
Epoch: 4, Steps: 210 | Train Loss: 0.7859033 Vali Loss: 0.9360844 Test Loss: 0.7647400
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8894553
	speed: 0.0188s/iter; left time: 21.7960s
	iters: 200, epoch: 5 | loss: 0.8285317
	speed: 0.0178s/iter; left time: 18.8502s
Epoch: 5 cost time: 3.7897768020629883
Epoch: 5, Steps: 210 | Train Loss: 0.7819668 Vali Loss: 0.9358765 Test Loss: 0.7644315
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7653060
	speed: 0.0228s/iter; left time: 21.6581s
	iters: 200, epoch: 6 | loss: 0.8354936
	speed: 0.0188s/iter; left time: 16.0394s
Epoch: 6 cost time: 4.018615961074829
Epoch: 6, Steps: 210 | Train Loss: 0.7790738 Vali Loss: 0.9424540 Test Loss: 0.7686160
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7303594
	speed: 0.0179s/iter; left time: 13.2806s
	iters: 200, epoch: 7 | loss: 0.8078238
	speed: 0.0144s/iter; left time: 9.2505s
Epoch: 7 cost time: 3.0290298461914062
Epoch: 7, Steps: 210 | Train Loss: 0.7781950 Vali Loss: 0.9452575 Test Loss: 0.7714183
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.736890435218811, mae:0.6874231696128845
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7916512
	speed: 0.0120s/iter; left time: 24.1112s
	iters: 200, epoch: 1 | loss: 0.8461413
	speed: 0.0121s/iter; left time: 22.9995s
Epoch: 1 cost time: 2.662935256958008
Epoch: 1, Steps: 210 | Train Loss: 0.8419110 Vali Loss: 0.9017192 Test Loss: 0.7406424
Validation loss decreased (inf --> 0.901719).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8309174
	speed: 0.0200s/iter; left time: 35.8023s
	iters: 200, epoch: 2 | loss: 0.8420903
	speed: 0.0188s/iter; left time: 31.7511s
Epoch: 2 cost time: 4.099709987640381
Epoch: 2, Steps: 210 | Train Loss: 0.8139892 Vali Loss: 0.9518687 Test Loss: 0.7591433
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8378357
	speed: 0.0212s/iter; left time: 33.5284s
	iters: 200, epoch: 3 | loss: 0.7399693
	speed: 0.0195s/iter; left time: 28.9151s
Epoch: 3 cost time: 4.224581956863403
Epoch: 3, Steps: 210 | Train Loss: 0.7943023 Vali Loss: 0.9095846 Test Loss: 0.7522261
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7869233
	speed: 0.0154s/iter; left time: 21.1487s
	iters: 200, epoch: 4 | loss: 0.8041868
	speed: 0.0126s/iter; left time: 15.9834s
Epoch: 4 cost time: 2.680328130722046
Epoch: 4, Steps: 210 | Train Loss: 0.7847471 Vali Loss: 0.9609214 Test Loss: 0.7725857
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7608746
	speed: 0.0146s/iter; left time: 17.0047s
	iters: 200, epoch: 5 | loss: 0.8053546
	speed: 0.0144s/iter; left time: 15.2274s
Epoch: 5 cost time: 3.128530740737915
Epoch: 5, Steps: 210 | Train Loss: 0.7803769 Vali Loss: 0.9477164 Test Loss: 0.7641722
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7609423
	speed: 0.0200s/iter; left time: 18.9968s
	iters: 200, epoch: 6 | loss: 0.7634346
	speed: 0.0175s/iter; left time: 14.9052s
Epoch: 6 cost time: 3.7125179767608643
Epoch: 6, Steps: 210 | Train Loss: 0.7777237 Vali Loss: 0.9572968 Test Loss: 0.7717850
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7406424880027771, mae:0.6898977756500244
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9251733
	speed: 0.0270s/iter; left time: 52.8828s
	iters: 200, epoch: 1 | loss: 0.8455547
	speed: 0.0196s/iter; left time: 36.5559s
Epoch: 1 cost time: 4.165785074234009
Epoch: 1, Steps: 206 | Train Loss: 0.9619556 Vali Loss: 1.0568075 Test Loss: 0.8255775
Validation loss decreased (inf --> 1.056808).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9625644
	speed: 0.0122s/iter; left time: 21.4008s
	iters: 200, epoch: 2 | loss: 0.9153492
	speed: 0.0115s/iter; left time: 19.0849s
Epoch: 2 cost time: 2.4415905475616455
Epoch: 2, Steps: 206 | Train Loss: 0.9231478 Vali Loss: 1.0491246 Test Loss: 0.8400984
Validation loss decreased (1.056808 --> 1.049125).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9007178
	speed: 0.0124s/iter; left time: 19.1886s
	iters: 200, epoch: 3 | loss: 0.8587879
	speed: 0.0117s/iter; left time: 17.0002s
Epoch: 3 cost time: 2.572896718978882
Epoch: 3, Steps: 206 | Train Loss: 0.9016360 Vali Loss: 1.0889238 Test Loss: 0.8491158
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8446875
	speed: 0.0144s/iter; left time: 19.3445s
	iters: 200, epoch: 4 | loss: 0.7974617
	speed: 0.0148s/iter; left time: 18.3458s
Epoch: 4 cost time: 3.1106271743774414
Epoch: 4, Steps: 206 | Train Loss: 0.8908567 Vali Loss: 1.1206553 Test Loss: 0.8621369
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8983012
	speed: 0.0138s/iter; left time: 15.7408s
	iters: 200, epoch: 5 | loss: 0.9351850
	speed: 0.0132s/iter; left time: 13.7123s
Epoch: 5 cost time: 2.843101739883423
Epoch: 5, Steps: 206 | Train Loss: 0.8855765 Vali Loss: 1.1316824 Test Loss: 0.8736843
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8489756
	speed: 0.0150s/iter; left time: 13.9198s
	iters: 200, epoch: 6 | loss: 0.9125357
	speed: 0.0139s/iter; left time: 11.5911s
Epoch: 6 cost time: 2.9277443885803223
Epoch: 6, Steps: 206 | Train Loss: 0.8820163 Vali Loss: 1.1356846 Test Loss: 0.8731877
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8616714
	speed: 0.0195s/iter; left time: 14.1070s
	iters: 200, epoch: 7 | loss: 0.8889274
	speed: 0.0168s/iter; left time: 10.4950s
Epoch: 7 cost time: 3.4599249362945557
Epoch: 7, Steps: 206 | Train Loss: 0.8811089 Vali Loss: 1.1284492 Test Loss: 0.8705450
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8400984406471252, mae:0.7349791526794434
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8963773
	speed: 0.0134s/iter; left time: 26.2097s
	iters: 200, epoch: 1 | loss: 0.9341472
	speed: 0.0125s/iter; left time: 23.2134s
Epoch: 1 cost time: 2.625689744949341
Epoch: 1, Steps: 206 | Train Loss: 0.9610093 Vali Loss: 1.1054821 Test Loss: 0.8294352
Validation loss decreased (inf --> 1.105482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9203139
	speed: 0.0195s/iter; left time: 34.2147s
	iters: 200, epoch: 2 | loss: 0.8800206
	speed: 0.0166s/iter; left time: 27.4234s
Epoch: 2 cost time: 3.4426212310791016
Epoch: 2, Steps: 206 | Train Loss: 0.9235099 Vali Loss: 1.1393594 Test Loss: 0.8623511
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8809739
	speed: 0.0156s/iter; left time: 24.1989s
	iters: 200, epoch: 3 | loss: 0.8861857
	speed: 0.0155s/iter; left time: 22.4034s
Epoch: 3 cost time: 3.2897403240203857
Epoch: 3, Steps: 206 | Train Loss: 0.9025438 Vali Loss: 1.1072658 Test Loss: 0.8444033
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9309071
	speed: 0.0148s/iter; left time: 19.9333s
	iters: 200, epoch: 4 | loss: 0.9468282
	speed: 0.0134s/iter; left time: 16.6547s
Epoch: 4 cost time: 2.8029487133026123
Epoch: 4, Steps: 206 | Train Loss: 0.8913798 Vali Loss: 1.1394378 Test Loss: 0.8669999
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8925161
	speed: 0.0180s/iter; left time: 20.4833s
	iters: 200, epoch: 5 | loss: 0.9054631
	speed: 0.0143s/iter; left time: 14.8344s
Epoch: 5 cost time: 3.0267646312713623
Epoch: 5, Steps: 206 | Train Loss: 0.8859416 Vali Loss: 1.1155066 Test Loss: 0.8612349
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9001098
	speed: 0.0152s/iter; left time: 14.1094s
	iters: 200, epoch: 6 | loss: 0.8395613
	speed: 0.0128s/iter; left time: 10.6409s
Epoch: 6 cost time: 2.751237392425537
Epoch: 6, Steps: 206 | Train Loss: 0.8832866 Vali Loss: 1.1295736 Test Loss: 0.8669825
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8294351696968079, mae:0.7299142479896545
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0288748
	speed: 0.0134s/iter; left time: 26.2623s
	iters: 200, epoch: 1 | loss: 0.9544929
	speed: 0.0130s/iter; left time: 24.1658s
Epoch: 1 cost time: 2.8272478580474854
Epoch: 1, Steps: 206 | Train Loss: 0.9608028 Vali Loss: 1.0670074 Test Loss: 0.8199531
Validation loss decreased (inf --> 1.067007).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8807188
	speed: 0.0255s/iter; left time: 44.8016s
	iters: 200, epoch: 2 | loss: 0.8638931
	speed: 0.0186s/iter; left time: 30.8631s
Epoch: 2 cost time: 3.8841538429260254
Epoch: 2, Steps: 206 | Train Loss: 0.9204844 Vali Loss: 1.0855531 Test Loss: 0.8352178
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8881061
	speed: 0.0145s/iter; left time: 22.4329s
	iters: 200, epoch: 3 | loss: 0.8865119
	speed: 0.0121s/iter; left time: 17.4936s
Epoch: 3 cost time: 2.5520880222320557
Epoch: 3, Steps: 206 | Train Loss: 0.8994808 Vali Loss: 1.1168509 Test Loss: 0.8611355
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9035522
	speed: 0.0208s/iter; left time: 27.9107s
	iters: 200, epoch: 4 | loss: 0.8954276
	speed: 0.0179s/iter; left time: 22.2507s
Epoch: 4 cost time: 3.740126609802246
Epoch: 4, Steps: 206 | Train Loss: 0.8883306 Vali Loss: 1.1198180 Test Loss: 0.8611338
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8769239
	speed: 0.0153s/iter; left time: 17.4026s
	iters: 200, epoch: 5 | loss: 0.8968208
	speed: 0.0176s/iter; left time: 18.2718s
Epoch: 5 cost time: 3.734647512435913
Epoch: 5, Steps: 206 | Train Loss: 0.8826681 Vali Loss: 1.1270554 Test Loss: 0.8708968
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8431415
	speed: 0.0200s/iter; left time: 18.6408s
	iters: 200, epoch: 6 | loss: 0.8505691
	speed: 0.0165s/iter; left time: 13.6997s
Epoch: 6 cost time: 3.5770511627197266
Epoch: 6, Steps: 206 | Train Loss: 0.8791786 Vali Loss: 1.1254269 Test Loss: 0.8699864
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.819953203201294, mae:0.7265034914016724
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2582620
	speed: 0.0343s/iter; left time: 63.0961s
Epoch: 1 cost time: 4.893748760223389
Epoch: 1, Steps: 194 | Train Loss: 1.1522113 Vali Loss: 1.6948663 Test Loss: 0.9094890
Validation loss decreased (inf --> 1.694866).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1120549
	speed: 0.0232s/iter; left time: 38.1427s
Epoch: 2 cost time: 3.7157299518585205
Epoch: 2, Steps: 194 | Train Loss: 1.1180826 Vali Loss: 1.6247880 Test Loss: 0.9080006
Validation loss decreased (1.694866 --> 1.624788).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0760797
	speed: 0.0159s/iter; left time: 23.0662s
Epoch: 3 cost time: 3.1798925399780273
Epoch: 3, Steps: 194 | Train Loss: 1.0938545 Vali Loss: 1.6733054 Test Loss: 0.9440786
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1130476
	speed: 0.0131s/iter; left time: 16.5151s
Epoch: 4 cost time: 2.9453675746917725
Epoch: 4, Steps: 194 | Train Loss: 1.0793988 Vali Loss: 1.6947148 Test Loss: 0.9474779
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0303530
	speed: 0.0190s/iter; left time: 20.2197s
Epoch: 5 cost time: 3.3171226978302
Epoch: 5, Steps: 194 | Train Loss: 1.0714499 Vali Loss: 1.7015916 Test Loss: 0.9535685
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0783280
	speed: 0.0195s/iter; left time: 16.9457s
Epoch: 6 cost time: 3.5266435146331787
Epoch: 6, Steps: 194 | Train Loss: 1.0656152 Vali Loss: 1.6792407 Test Loss: 0.9540876
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0203404
	speed: 0.0167s/iter; left time: 11.2986s
Epoch: 7 cost time: 3.052408218383789
Epoch: 7, Steps: 194 | Train Loss: 1.0650262 Vali Loss: 1.6759312 Test Loss: 0.9579327
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9080007076263428, mae:0.7650350332260132
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1882230
	speed: 0.0170s/iter; left time: 31.2390s
Epoch: 1 cost time: 2.9661154747009277
Epoch: 1, Steps: 194 | Train Loss: 1.1528412 Vali Loss: 1.6278989 Test Loss: 0.8994839
Validation loss decreased (inf --> 1.627899).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1539042
	speed: 0.0152s/iter; left time: 25.0713s
Epoch: 2 cost time: 2.772274971008301
Epoch: 2, Steps: 194 | Train Loss: 1.1141638 Vali Loss: 1.6137009 Test Loss: 0.9158274
Validation loss decreased (1.627899 --> 1.613701).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0707027
	speed: 0.0153s/iter; left time: 22.2660s
Epoch: 3 cost time: 3.0088741779327393
Epoch: 3, Steps: 194 | Train Loss: 1.0941282 Vali Loss: 1.6629738 Test Loss: 0.9475882
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0748535
	speed: 0.0154s/iter; left time: 19.4013s
Epoch: 4 cost time: 2.5661017894744873
Epoch: 4, Steps: 194 | Train Loss: 1.0782114 Vali Loss: 1.6733491 Test Loss: 0.9482548
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0817659
	speed: 0.0164s/iter; left time: 17.4980s
Epoch: 5 cost time: 3.1206092834472656
Epoch: 5, Steps: 194 | Train Loss: 1.0720228 Vali Loss: 1.6256523 Test Loss: 0.9456578
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.1181784
	speed: 0.0188s/iter; left time: 16.4097s
Epoch: 6 cost time: 2.8626999855041504
Epoch: 6, Steps: 194 | Train Loss: 1.0677487 Vali Loss: 1.6477830 Test Loss: 0.9530365
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.1018705
	speed: 0.0166s/iter; left time: 11.2478s
Epoch: 7 cost time: 2.967769145965576
Epoch: 7, Steps: 194 | Train Loss: 1.0662433 Vali Loss: 1.6183715 Test Loss: 0.9492680
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9158275723457336, mae:0.7684752345085144
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1204923
	speed: 0.0161s/iter; left time: 29.6897s
Epoch: 1 cost time: 2.8539469242095947
Epoch: 1, Steps: 194 | Train Loss: 1.1500923 Vali Loss: 1.6394308 Test Loss: 0.9028790
Validation loss decreased (inf --> 1.639431).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1730734
	speed: 0.0202s/iter; left time: 33.2659s
Epoch: 2 cost time: 3.444483995437622
Epoch: 2, Steps: 194 | Train Loss: 1.1099371 Vali Loss: 1.6357913 Test Loss: 0.9239690
Validation loss decreased (1.639431 --> 1.635791).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0590670
	speed: 0.0190s/iter; left time: 27.5975s
Epoch: 3 cost time: 2.9568145275115967
Epoch: 3, Steps: 194 | Train Loss: 1.0874222 Vali Loss: 1.5866693 Test Loss: 0.9240525
Validation loss decreased (1.635791 --> 1.586669).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1304911
	speed: 0.0165s/iter; left time: 20.7711s
Epoch: 4 cost time: 2.7649784088134766
Epoch: 4, Steps: 194 | Train Loss: 1.0701170 Vali Loss: 1.6513562 Test Loss: 0.9512110
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9483827
	speed: 0.0191s/iter; left time: 20.3548s
Epoch: 5 cost time: 3.4743428230285645
Epoch: 5, Steps: 194 | Train Loss: 1.0585316 Vali Loss: 1.6510081 Test Loss: 0.9595380
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0885006
	speed: 0.0180s/iter; left time: 15.7126s
Epoch: 6 cost time: 3.0077903270721436
Epoch: 6, Steps: 194 | Train Loss: 1.0523267 Vali Loss: 1.6506749 Test Loss: 0.9551810
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0503159
	speed: 0.0200s/iter; left time: 13.5289s
Epoch: 7 cost time: 3.345630407333374
Epoch: 7, Steps: 194 | Train Loss: 1.0517028 Vali Loss: 1.6486278 Test Loss: 0.9549538
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0004810
	speed: 0.0180s/iter; left time: 8.7020s
Epoch: 8 cost time: 3.010713577270508
Epoch: 8, Steps: 194 | Train Loss: 1.0491785 Vali Loss: 1.6411208 Test Loss: 0.9543113
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9240524172782898, mae:0.7718994617462158
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7314076
	speed: 0.0372s/iter; left time: 75.5022s
	iters: 200, epoch: 1 | loss: 0.6899361
	speed: 0.0253s/iter; left time: 48.8823s
Epoch: 1 cost time: 5.302336692810059
Epoch: 1, Steps: 213 | Train Loss: 0.7470497 Vali Loss: 0.6827157 Test Loss: 0.6612436
Validation loss decreased (inf --> 0.682716).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7718778
	speed: 0.0154s/iter; left time: 27.9218s
	iters: 200, epoch: 2 | loss: 0.6903642
	speed: 0.0123s/iter; left time: 21.1420s
Epoch: 2 cost time: 2.74595046043396
Epoch: 2, Steps: 213 | Train Loss: 0.7144907 Vali Loss: 0.6587812 Test Loss: 0.6555102
Validation loss decreased (0.682716 --> 0.658781).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6658990
	speed: 0.0141s/iter; left time: 22.6163s
	iters: 200, epoch: 3 | loss: 0.7312241
	speed: 0.0130s/iter; left time: 19.5595s
Epoch: 3 cost time: 2.8673951625823975
Epoch: 3, Steps: 213 | Train Loss: 0.7036991 Vali Loss: 0.6672401 Test Loss: 0.6515194
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6776199
	speed: 0.0164s/iter; left time: 22.8814s
	iters: 200, epoch: 4 | loss: 0.6957792
	speed: 0.0157s/iter; left time: 20.2325s
Epoch: 4 cost time: 3.4678966999053955
Epoch: 4, Steps: 213 | Train Loss: 0.6975466 Vali Loss: 0.6695629 Test Loss: 0.6488889
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7388799
	speed: 0.0141s/iter; left time: 16.6306s
	iters: 200, epoch: 5 | loss: 0.7105159
	speed: 0.0140s/iter; left time: 15.1592s
Epoch: 5 cost time: 3.1235740184783936
Epoch: 5, Steps: 213 | Train Loss: 0.6943056 Vali Loss: 0.6902118 Test Loss: 0.6514809
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6727012
	speed: 0.0167s/iter; left time: 16.0854s
	iters: 200, epoch: 6 | loss: 0.6591657
	speed: 0.0152s/iter; left time: 13.1915s
Epoch: 6 cost time: 3.317122459411621
Epoch: 6, Steps: 213 | Train Loss: 0.6921342 Vali Loss: 0.6864362 Test Loss: 0.6525558
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6907255
	speed: 0.0162s/iter; left time: 12.1713s
	iters: 200, epoch: 7 | loss: 0.7644975
	speed: 0.0143s/iter; left time: 9.3486s
Epoch: 7 cost time: 3.0704033374786377
Epoch: 7, Steps: 213 | Train Loss: 0.6909066 Vali Loss: 0.6906067 Test Loss: 0.6533383
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6555102467536926, mae:0.6498985290527344
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7064740
	speed: 0.0217s/iter; left time: 44.0502s
	iters: 200, epoch: 1 | loss: 0.7395985
	speed: 0.0166s/iter; left time: 32.0600s
Epoch: 1 cost time: 3.5387609004974365
Epoch: 1, Steps: 213 | Train Loss: 0.7484944 Vali Loss: 0.6834350 Test Loss: 0.6610827
Validation loss decreased (inf --> 0.683435).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7150013
	speed: 0.0187s/iter; left time: 33.9700s
	iters: 200, epoch: 2 | loss: 0.7191777
	speed: 0.0150s/iter; left time: 25.7930s
Epoch: 2 cost time: 3.268812656402588
Epoch: 2, Steps: 213 | Train Loss: 0.7148486 Vali Loss: 0.6647840 Test Loss: 0.6521859
Validation loss decreased (0.683435 --> 0.664784).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7210678
	speed: 0.0140s/iter; left time: 22.4231s
	iters: 200, epoch: 3 | loss: 0.7119817
	speed: 0.0132s/iter; left time: 19.9087s
Epoch: 3 cost time: 3.0433881282806396
Epoch: 3, Steps: 213 | Train Loss: 0.7016776 Vali Loss: 0.6828228 Test Loss: 0.6516315
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7232025
	speed: 0.0137s/iter; left time: 19.1301s
	iters: 200, epoch: 4 | loss: 0.7290496
	speed: 0.0128s/iter; left time: 16.5060s
Epoch: 4 cost time: 2.7957777976989746
Epoch: 4, Steps: 213 | Train Loss: 0.6953832 Vali Loss: 0.7035898 Test Loss: 0.6626633
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6551217
	speed: 0.0181s/iter; left time: 21.2842s
	iters: 200, epoch: 5 | loss: 0.6678940
	speed: 0.0192s/iter; left time: 20.7142s
Epoch: 5 cost time: 4.084930419921875
Epoch: 5, Steps: 213 | Train Loss: 0.6909432 Vali Loss: 0.7029473 Test Loss: 0.6639066
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7034730
	speed: 0.0281s/iter; left time: 27.1372s
	iters: 200, epoch: 6 | loss: 0.6539217
	speed: 0.0211s/iter; left time: 18.2468s
Epoch: 6 cost time: 4.511415958404541
Epoch: 6, Steps: 213 | Train Loss: 0.6891787 Vali Loss: 0.7072951 Test Loss: 0.6645416
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6987810
	speed: 0.0231s/iter; left time: 17.3574s
	iters: 200, epoch: 7 | loss: 0.6633174
	speed: 0.0176s/iter; left time: 11.5176s
Epoch: 7 cost time: 3.7789556980133057
Epoch: 7, Steps: 213 | Train Loss: 0.6885903 Vali Loss: 0.7055162 Test Loss: 0.6645585
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6521859169006348, mae:0.6487606763839722
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7014377
	speed: 0.0132s/iter; left time: 26.8543s
	iters: 200, epoch: 1 | loss: 0.6929902
	speed: 0.0127s/iter; left time: 24.5012s
Epoch: 1 cost time: 2.7256646156311035
Epoch: 1, Steps: 213 | Train Loss: 0.7466621 Vali Loss: 0.6635202 Test Loss: 0.6639158
Validation loss decreased (inf --> 0.663520).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7187128
	speed: 0.0152s/iter; left time: 27.7217s
	iters: 200, epoch: 2 | loss: 0.7158272
	speed: 0.0201s/iter; left time: 34.4933s
Epoch: 2 cost time: 4.518054723739624
Epoch: 2, Steps: 213 | Train Loss: 0.7139611 Vali Loss: 0.6731837 Test Loss: 0.6541460
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6630911
	speed: 0.0169s/iter; left time: 27.1434s
	iters: 200, epoch: 3 | loss: 0.6876420
	speed: 0.0157s/iter; left time: 23.6677s
Epoch: 3 cost time: 3.466414451599121
Epoch: 3, Steps: 213 | Train Loss: 0.7029530 Vali Loss: 0.6711220 Test Loss: 0.6511986
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6996675
	speed: 0.0218s/iter; left time: 30.3834s
	iters: 200, epoch: 4 | loss: 0.6288403
	speed: 0.0167s/iter; left time: 21.5995s
Epoch: 4 cost time: 3.5722060203552246
Epoch: 4, Steps: 213 | Train Loss: 0.6964402 Vali Loss: 0.7057963 Test Loss: 0.6597846
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7146385
	speed: 0.0188s/iter; left time: 22.1575s
	iters: 200, epoch: 5 | loss: 0.6773994
	speed: 0.0178s/iter; left time: 19.1917s
Epoch: 5 cost time: 3.81662654876709
Epoch: 5, Steps: 213 | Train Loss: 0.6928194 Vali Loss: 0.6902657 Test Loss: 0.6585851
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6993575
	speed: 0.0171s/iter; left time: 16.4781s
	iters: 200, epoch: 6 | loss: 0.6899875
	speed: 0.0160s/iter; left time: 13.8464s
Epoch: 6 cost time: 3.502509832382202
Epoch: 6, Steps: 213 | Train Loss: 0.6904936 Vali Loss: 0.7017387 Test Loss: 0.6635971
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6639158129692078, mae:0.6549228429794312
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8827745
	speed: 0.0290s/iter; left time: 57.9973s
	iters: 200, epoch: 1 | loss: 0.8258629
	speed: 0.0212s/iter; left time: 40.3853s
Epoch: 1 cost time: 4.4672932624816895
Epoch: 1, Steps: 210 | Train Loss: 0.8431060 Vali Loss: 0.9083752 Test Loss: 0.7397305
Validation loss decreased (inf --> 0.908375).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7826349
	speed: 0.0245s/iter; left time: 43.8513s
	iters: 200, epoch: 2 | loss: 0.8352513
	speed: 0.0190s/iter; left time: 32.1972s
Epoch: 2 cost time: 3.985837697982788
Epoch: 2, Steps: 210 | Train Loss: 0.8134776 Vali Loss: 0.9225870 Test Loss: 0.7498546
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8164021
	speed: 0.0305s/iter; left time: 48.2290s
	iters: 200, epoch: 3 | loss: 0.7970912
	speed: 0.0213s/iter; left time: 31.6114s
Epoch: 3 cost time: 4.45374059677124
Epoch: 3, Steps: 210 | Train Loss: 0.7959401 Vali Loss: 0.9266005 Test Loss: 0.7547230
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8183354
	speed: 0.0211s/iter; left time: 28.9613s
	iters: 200, epoch: 4 | loss: 0.7952223
	speed: 0.0147s/iter; left time: 18.6864s
Epoch: 4 cost time: 3.069859504699707
Epoch: 4, Steps: 210 | Train Loss: 0.7863811 Vali Loss: 0.9213318 Test Loss: 0.7580960
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8171791
	speed: 0.0280s/iter; left time: 32.5123s
	iters: 200, epoch: 5 | loss: 0.8328389
	speed: 0.0209s/iter; left time: 22.1634s
Epoch: 5 cost time: 4.420928001403809
Epoch: 5, Steps: 210 | Train Loss: 0.7824095 Vali Loss: 0.9443693 Test Loss: 0.7692998
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7929497
	speed: 0.0184s/iter; left time: 17.4755s
	iters: 200, epoch: 6 | loss: 0.8639714
	speed: 0.0159s/iter; left time: 13.5044s
Epoch: 6 cost time: 3.449282169342041
Epoch: 6, Steps: 210 | Train Loss: 0.7809175 Vali Loss: 0.9559590 Test Loss: 0.7722817
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7397303581237793, mae:0.6889544725418091
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7973828
	speed: 0.0136s/iter; left time: 27.2804s
	iters: 200, epoch: 1 | loss: 0.8338003
	speed: 0.0127s/iter; left time: 24.2063s
Epoch: 1 cost time: 2.7650535106658936
Epoch: 1, Steps: 210 | Train Loss: 0.8434561 Vali Loss: 0.8840743 Test Loss: 0.7327679
Validation loss decreased (inf --> 0.884074).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7843908
	speed: 0.0144s/iter; left time: 25.8369s
	iters: 200, epoch: 2 | loss: 0.8801368
	speed: 0.0147s/iter; left time: 24.8392s
Epoch: 2 cost time: 3.2104711532592773
Epoch: 2, Steps: 210 | Train Loss: 0.8135332 Vali Loss: 0.9097078 Test Loss: 0.7463053
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7652310
	speed: 0.0175s/iter; left time: 27.7376s
	iters: 200, epoch: 3 | loss: 0.7667689
	speed: 0.0200s/iter; left time: 29.5487s
Epoch: 3 cost time: 4.2470176219940186
Epoch: 3, Steps: 210 | Train Loss: 0.7953058 Vali Loss: 0.8877040 Test Loss: 0.7448986
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7681505
	speed: 0.0166s/iter; left time: 22.8090s
	iters: 200, epoch: 4 | loss: 0.7966509
	speed: 0.0153s/iter; left time: 19.4119s
Epoch: 4 cost time: 3.3129143714904785
Epoch: 4, Steps: 210 | Train Loss: 0.7865938 Vali Loss: 0.9497420 Test Loss: 0.7672904
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7886984
	speed: 0.0166s/iter; left time: 19.3013s
	iters: 200, epoch: 5 | loss: 0.7860816
	speed: 0.0140s/iter; left time: 14.8248s
Epoch: 5 cost time: 2.9545106887817383
Epoch: 5, Steps: 210 | Train Loss: 0.7814957 Vali Loss: 0.9260893 Test Loss: 0.7608192
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7490529
	speed: 0.0152s/iter; left time: 14.4945s
	iters: 200, epoch: 6 | loss: 0.7196247
	speed: 0.0126s/iter; left time: 10.7323s
Epoch: 6 cost time: 2.737915277481079
Epoch: 6, Steps: 210 | Train Loss: 0.7785861 Vali Loss: 0.9567435 Test Loss: 0.7739246
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7327678799629211, mae:0.6866723299026489
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9301146
	speed: 0.0200s/iter; left time: 39.9269s
	iters: 200, epoch: 1 | loss: 0.8773025
	speed: 0.0160s/iter; left time: 30.3919s
Epoch: 1 cost time: 3.4026331901550293
Epoch: 1, Steps: 210 | Train Loss: 0.8419011 Vali Loss: 0.8868408 Test Loss: 0.7403346
Validation loss decreased (inf --> 0.886841).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8029997
	speed: 0.0189s/iter; left time: 33.7913s
	iters: 200, epoch: 2 | loss: 0.8129866
	speed: 0.0171s/iter; left time: 28.8451s
Epoch: 2 cost time: 3.6988415718078613
Epoch: 2, Steps: 210 | Train Loss: 0.8137837 Vali Loss: 0.9622503 Test Loss: 0.7726216
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8471562
	speed: 0.0153s/iter; left time: 24.2347s
	iters: 200, epoch: 3 | loss: 0.7781669
	speed: 0.0146s/iter; left time: 21.6061s
Epoch: 3 cost time: 3.2355895042419434
Epoch: 3, Steps: 210 | Train Loss: 0.7962571 Vali Loss: 0.8912919 Test Loss: 0.7559351
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7937226
	speed: 0.0112s/iter; left time: 15.3398s
	iters: 200, epoch: 4 | loss: 0.7837180
	speed: 0.0117s/iter; left time: 14.8571s
Epoch: 4 cost time: 2.6348395347595215
Epoch: 4, Steps: 210 | Train Loss: 0.7869782 Vali Loss: 0.9383498 Test Loss: 0.7604464
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8069236
	speed: 0.0174s/iter; left time: 20.2415s
	iters: 200, epoch: 5 | loss: 0.8462806
	speed: 0.0151s/iter; left time: 16.0611s
Epoch: 5 cost time: 3.2225728034973145
Epoch: 5, Steps: 210 | Train Loss: 0.7819478 Vali Loss: 0.9318338 Test Loss: 0.7589442
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7251413
	speed: 0.0209s/iter; left time: 19.8949s
	iters: 200, epoch: 6 | loss: 0.8366841
	speed: 0.0180s/iter; left time: 15.2957s
Epoch: 6 cost time: 3.8778913021087646
Epoch: 6, Steps: 210 | Train Loss: 0.7797258 Vali Loss: 0.9496604 Test Loss: 0.7662023
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7403345704078674, mae:0.6893789172172546
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9207405
	speed: 0.0350s/iter; left time: 68.6396s
	iters: 200, epoch: 1 | loss: 0.9313552
	speed: 0.0265s/iter; left time: 49.3361s
Epoch: 1 cost time: 5.512416124343872
Epoch: 1, Steps: 206 | Train Loss: 0.9609122 Vali Loss: 1.1120751 Test Loss: 0.8364848
Validation loss decreased (inf --> 1.112075).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9390421
	speed: 0.0188s/iter; left time: 33.0037s
	iters: 200, epoch: 2 | loss: 0.8915464
	speed: 0.0154s/iter; left time: 25.5458s
Epoch: 2 cost time: 3.1977267265319824
Epoch: 2, Steps: 206 | Train Loss: 0.9232442 Vali Loss: 1.1412432 Test Loss: 0.8569813
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9165230
	speed: 0.0178s/iter; left time: 27.5117s
	iters: 200, epoch: 3 | loss: 0.8720321
	speed: 0.0147s/iter; left time: 21.3516s
Epoch: 3 cost time: 3.0544357299804688
Epoch: 3, Steps: 206 | Train Loss: 0.8984278 Vali Loss: 1.0930655 Test Loss: 0.8560926
Validation loss decreased (1.112075 --> 1.093066).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8917809
	speed: 0.0213s/iter; left time: 28.6271s
	iters: 200, epoch: 4 | loss: 0.8525314
	speed: 0.0164s/iter; left time: 20.3242s
Epoch: 4 cost time: 3.4671967029571533
Epoch: 4, Steps: 206 | Train Loss: 0.8883310 Vali Loss: 1.1060777 Test Loss: 0.8633699
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9323415
	speed: 0.0198s/iter; left time: 22.4872s
	iters: 200, epoch: 5 | loss: 0.8797868
	speed: 0.0160s/iter; left time: 16.6119s
Epoch: 5 cost time: 3.416327953338623
Epoch: 5, Steps: 206 | Train Loss: 0.8845913 Vali Loss: 1.1408647 Test Loss: 0.8784763
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8761916
	speed: 0.0185s/iter; left time: 17.1962s
	iters: 200, epoch: 6 | loss: 0.9045717
	speed: 0.0162s/iter; left time: 13.4633s
Epoch: 6 cost time: 3.4445221424102783
Epoch: 6, Steps: 206 | Train Loss: 0.8820317 Vali Loss: 1.1238477 Test Loss: 0.8716930
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8773880
	speed: 0.0186s/iter; left time: 13.4979s
	iters: 200, epoch: 7 | loss: 0.8928692
	speed: 0.0162s/iter; left time: 10.1144s
Epoch: 7 cost time: 3.383868932723999
Epoch: 7, Steps: 206 | Train Loss: 0.8789788 Vali Loss: 1.1309798 Test Loss: 0.8759515
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9214121
	speed: 0.0179s/iter; left time: 9.3073s
	iters: 200, epoch: 8 | loss: 0.8145695
	speed: 0.0152s/iter; left time: 6.3782s
Epoch: 8 cost time: 3.175801992416382
Epoch: 8, Steps: 206 | Train Loss: 0.8787985 Vali Loss: 1.1316214 Test Loss: 0.8761910
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8560925722122192, mae:0.7417575120925903
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9398842
	speed: 0.0159s/iter; left time: 31.2000s
	iters: 200, epoch: 1 | loss: 0.8855594
	speed: 0.0135s/iter; left time: 25.1479s
Epoch: 1 cost time: 2.8826420307159424
Epoch: 1, Steps: 206 | Train Loss: 0.9604915 Vali Loss: 1.0559973 Test Loss: 0.8440806
Validation loss decreased (inf --> 1.055997).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9423869
	speed: 0.0225s/iter; left time: 39.4660s
	iters: 200, epoch: 2 | loss: 0.9336008
	speed: 0.0175s/iter; left time: 28.9821s
Epoch: 2 cost time: 3.66862154006958
Epoch: 2, Steps: 206 | Train Loss: 0.9219694 Vali Loss: 1.0547491 Test Loss: 0.8412157
Validation loss decreased (1.055997 --> 1.054749).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8131073
	speed: 0.0199s/iter; left time: 30.7641s
	iters: 200, epoch: 3 | loss: 0.9264377
	speed: 0.0176s/iter; left time: 25.4763s
Epoch: 3 cost time: 3.702378749847412
Epoch: 3, Steps: 206 | Train Loss: 0.8981976 Vali Loss: 1.1122659 Test Loss: 0.8548949
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9343697
	speed: 0.0171s/iter; left time: 22.9991s
	iters: 200, epoch: 4 | loss: 0.8589930
	speed: 0.0163s/iter; left time: 20.3203s
Epoch: 4 cost time: 3.4458742141723633
Epoch: 4, Steps: 206 | Train Loss: 0.8887487 Vali Loss: 1.1095208 Test Loss: 0.8597741
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8335651
	speed: 0.0135s/iter; left time: 15.4053s
	iters: 200, epoch: 5 | loss: 0.8539562
	speed: 0.0122s/iter; left time: 12.6071s
Epoch: 5 cost time: 2.610443592071533
Epoch: 5, Steps: 206 | Train Loss: 0.8827011 Vali Loss: 1.1236311 Test Loss: 0.8680232
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8949106
	speed: 0.0310s/iter; left time: 28.8831s
	iters: 200, epoch: 6 | loss: 0.8796799
	speed: 0.0229s/iter; left time: 19.0304s
Epoch: 6 cost time: 4.6938512325286865
Epoch: 6, Steps: 206 | Train Loss: 0.8791463 Vali Loss: 1.1265351 Test Loss: 0.8683006
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8755477
	speed: 0.0168s/iter; left time: 12.1879s
	iters: 200, epoch: 7 | loss: 0.8232643
	speed: 0.0176s/iter; left time: 11.0041s
Epoch: 7 cost time: 3.824092388153076
Epoch: 7, Steps: 206 | Train Loss: 0.8786675 Vali Loss: 1.1225883 Test Loss: 0.8642203
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8412156701087952, mae:0.7351452708244324
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9248999
	speed: 0.0183s/iter; left time: 35.8174s
	iters: 200, epoch: 1 | loss: 0.8850459
	speed: 0.0178s/iter; left time: 33.1242s
Epoch: 1 cost time: 3.7039053440093994
Epoch: 1, Steps: 206 | Train Loss: 0.9596617 Vali Loss: 1.1278980 Test Loss: 0.8358720
Validation loss decreased (inf --> 1.127898).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8415128
	speed: 0.0167s/iter; left time: 29.3022s
	iters: 200, epoch: 2 | loss: 0.9149355
	speed: 0.0155s/iter; left time: 25.6908s
Epoch: 2 cost time: 3.341308832168579
Epoch: 2, Steps: 206 | Train Loss: 0.9205946 Vali Loss: 1.0699505 Test Loss: 0.8353631
Validation loss decreased (1.127898 --> 1.069950).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9232883
	speed: 0.0190s/iter; left time: 29.4811s
	iters: 200, epoch: 3 | loss: 0.8906382
	speed: 0.0170s/iter; left time: 24.6400s
Epoch: 3 cost time: 3.6911189556121826
Epoch: 3, Steps: 206 | Train Loss: 0.8975286 Vali Loss: 1.1174326 Test Loss: 0.8607916
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8880152
	speed: 0.0198s/iter; left time: 26.5804s
	iters: 200, epoch: 4 | loss: 0.8595733
	speed: 0.0167s/iter; left time: 20.7291s
Epoch: 4 cost time: 3.5078558921813965
Epoch: 4, Steps: 206 | Train Loss: 0.8852862 Vali Loss: 1.1477869 Test Loss: 0.8732089
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9120776
	speed: 0.0194s/iter; left time: 22.0586s
	iters: 200, epoch: 5 | loss: 0.8655972
	speed: 0.0168s/iter; left time: 17.4385s
Epoch: 5 cost time: 3.5784428119659424
Epoch: 5, Steps: 206 | Train Loss: 0.8784322 Vali Loss: 1.1474298 Test Loss: 0.8781294
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8561992
	speed: 0.0165s/iter; left time: 15.3652s
	iters: 200, epoch: 6 | loss: 0.9088442
	speed: 0.0131s/iter; left time: 10.9158s
Epoch: 6 cost time: 2.759817123413086
Epoch: 6, Steps: 206 | Train Loss: 0.8742075 Vali Loss: 1.1435438 Test Loss: 0.8755172
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8560461
	speed: 0.0270s/iter; left time: 19.5744s
	iters: 200, epoch: 7 | loss: 0.9866510
	speed: 0.0224s/iter; left time: 13.9692s
Epoch: 7 cost time: 4.673521995544434
Epoch: 7, Steps: 206 | Train Loss: 0.8734908 Vali Loss: 1.1411002 Test Loss: 0.8748426
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8353630900382996, mae:0.7334789037704468
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1892626
	speed: 0.0227s/iter; left time: 41.8700s
Epoch: 1 cost time: 3.410276412963867
Epoch: 1, Steps: 194 | Train Loss: 1.1510980 Vali Loss: 1.5518584 Test Loss: 0.8952597
Validation loss decreased (inf --> 1.551858).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0517780
	speed: 0.0160s/iter; left time: 26.3179s
Epoch: 2 cost time: 2.7341723442077637
Epoch: 2, Steps: 194 | Train Loss: 1.1154286 Vali Loss: 1.7426438 Test Loss: 0.9500200
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0778105
	speed: 0.0220s/iter; left time: 31.9415s
Epoch: 3 cost time: 3.4631972312927246
Epoch: 3, Steps: 194 | Train Loss: 1.0926520 Vali Loss: 1.6821170 Test Loss: 0.9255993
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1082491
	speed: 0.0170s/iter; left time: 21.4502s
Epoch: 4 cost time: 3.4426212310791016
Epoch: 4, Steps: 194 | Train Loss: 1.0802538 Vali Loss: 1.6943557 Test Loss: 0.9459403
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1422625
	speed: 0.0165s/iter; left time: 17.5682s
Epoch: 5 cost time: 2.811500072479248
Epoch: 5, Steps: 194 | Train Loss: 1.0733212 Vali Loss: 1.6871951 Test Loss: 0.9507668
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0892363
	speed: 0.0139s/iter; left time: 12.0990s
Epoch: 6 cost time: 2.545398235321045
Epoch: 6, Steps: 194 | Train Loss: 1.0691717 Vali Loss: 1.6794817 Test Loss: 0.9468800
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8952597379684448, mae:0.7595921158790588
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1340723
	speed: 0.0206s/iter; left time: 37.9609s
Epoch: 1 cost time: 4.0317370891571045
Epoch: 1, Steps: 194 | Train Loss: 1.1493944 Vali Loss: 1.5648751 Test Loss: 0.8944828
Validation loss decreased (inf --> 1.564875).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2236923
	speed: 0.0200s/iter; left time: 32.8617s
Epoch: 2 cost time: 3.378138303756714
Epoch: 2, Steps: 194 | Train Loss: 1.1147470 Vali Loss: 1.6726961 Test Loss: 0.9220594
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1259632
	speed: 0.0195s/iter; left time: 28.2949s
Epoch: 3 cost time: 3.304408311843872
Epoch: 3, Steps: 194 | Train Loss: 1.0945135 Vali Loss: 1.6858518 Test Loss: 0.9362493
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1361074
	speed: 0.0173s/iter; left time: 21.8110s
Epoch: 4 cost time: 2.7024879455566406
Epoch: 4, Steps: 194 | Train Loss: 1.0822551 Vali Loss: 1.5872309 Test Loss: 0.9365177
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0832989
	speed: 0.0215s/iter; left time: 22.9326s
Epoch: 5 cost time: 3.3999428749084473
Epoch: 5, Steps: 194 | Train Loss: 1.0741136 Vali Loss: 1.6488048 Test Loss: 0.9504902
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0073904
	speed: 0.0214s/iter; left time: 18.6341s
Epoch: 6 cost time: 3.5811240673065186
Epoch: 6, Steps: 194 | Train Loss: 1.0707721 Vali Loss: 1.6518826 Test Loss: 0.9489554
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8944828510284424, mae:0.7594720721244812
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1907548
	speed: 0.0221s/iter; left time: 40.7360s
Epoch: 1 cost time: 3.8646388053894043
Epoch: 1, Steps: 194 | Train Loss: 1.1511281 Vali Loss: 1.5519290 Test Loss: 0.8885102
Validation loss decreased (inf --> 1.551929).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1286995
	speed: 0.0188s/iter; left time: 30.9532s
Epoch: 2 cost time: 3.4456946849823
Epoch: 2, Steps: 194 | Train Loss: 1.1140949 Vali Loss: 1.6601040 Test Loss: 0.9257820
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0004691
	speed: 0.0183s/iter; left time: 26.6059s
Epoch: 3 cost time: 3.387234926223755
Epoch: 3, Steps: 194 | Train Loss: 1.0921512 Vali Loss: 1.7025422 Test Loss: 0.9403071
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0821902
	speed: 0.0168s/iter; left time: 21.1548s
Epoch: 4 cost time: 3.152534008026123
Epoch: 4, Steps: 194 | Train Loss: 1.0771235 Vali Loss: 1.6271889 Test Loss: 0.9351937
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9718951
	speed: 0.0167s/iter; left time: 17.8203s
Epoch: 5 cost time: 3.0133156776428223
Epoch: 5, Steps: 194 | Train Loss: 1.0684343 Vali Loss: 1.6773469 Test Loss: 0.9411229
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9985954
	speed: 0.0187s/iter; left time: 16.2923s
Epoch: 6 cost time: 3.0107545852661133
Epoch: 6, Steps: 194 | Train Loss: 1.0648685 Vali Loss: 1.6024184 Test Loss: 0.9389102
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8885100483894348, mae:0.7576860785484314
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0508132
	speed: 0.0225s/iter; left time: 45.7903s
	iters: 200, epoch: 1 | loss: 1.0504503
	speed: 0.0169s/iter; left time: 32.6464s
Epoch: 1 cost time: 3.723745584487915
Epoch: 1, Steps: 213 | Train Loss: 1.0596729 Vali Loss: 1.0597053 Test Loss: 1.0468214
Validation loss decreased (inf --> 1.059705).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0505265
	speed: 0.0173s/iter; left time: 31.4129s
	iters: 200, epoch: 2 | loss: 1.0271847
	speed: 0.0144s/iter; left time: 24.8184s
Epoch: 2 cost time: 3.104689121246338
Epoch: 2, Steps: 213 | Train Loss: 1.0385393 Vali Loss: 1.0531969 Test Loss: 1.0453607
Validation loss decreased (1.059705 --> 1.053197).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0434482
	speed: 0.0194s/iter; left time: 31.1944s
	iters: 200, epoch: 3 | loss: 0.9991686
	speed: 0.0162s/iter; left time: 24.3268s
Epoch: 3 cost time: 3.533167839050293
Epoch: 3, Steps: 213 | Train Loss: 1.0320224 Vali Loss: 1.0554272 Test Loss: 1.0440689
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0507224
	speed: 0.0188s/iter; left time: 26.2163s
	iters: 200, epoch: 4 | loss: 1.0524716
	speed: 0.0180s/iter; left time: 23.2302s
Epoch: 4 cost time: 3.9042515754699707
Epoch: 4, Steps: 213 | Train Loss: 1.0274574 Vali Loss: 1.0513861 Test Loss: 1.0417588
Validation loss decreased (1.053197 --> 1.051386).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9975247
	speed: 0.0202s/iter; left time: 23.8393s
	iters: 200, epoch: 5 | loss: 1.0068724
	speed: 0.0170s/iter; left time: 18.3020s
Epoch: 5 cost time: 3.674098014831543
Epoch: 5, Steps: 213 | Train Loss: 1.0253462 Vali Loss: 1.0523354 Test Loss: 1.0419737
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0389719
	speed: 0.0189s/iter; left time: 18.2851s
	iters: 200, epoch: 6 | loss: 1.0168022
	speed: 0.0170s/iter; left time: 14.6795s
Epoch: 6 cost time: 3.6987640857696533
Epoch: 6, Steps: 213 | Train Loss: 1.0235276 Vali Loss: 1.0525866 Test Loss: 1.0419953
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0156846
	speed: 0.0170s/iter; left time: 12.7997s
	iters: 200, epoch: 7 | loss: 1.0218928
	speed: 0.0165s/iter; left time: 10.7453s
Epoch: 7 cost time: 3.6072802543640137
Epoch: 7, Steps: 213 | Train Loss: 1.0228644 Vali Loss: 1.0514967 Test Loss: 1.0419396
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0680814
	speed: 0.0205s/iter; left time: 11.0485s
	iters: 200, epoch: 8 | loss: 1.0006008
	speed: 0.0201s/iter; left time: 8.8251s
Epoch: 8 cost time: 4.2873194217681885
Epoch: 8, Steps: 213 | Train Loss: 1.0224760 Vali Loss: 1.0514872 Test Loss: 1.0419163
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0134168
	speed: 0.0157s/iter; left time: 5.1320s
	iters: 200, epoch: 9 | loss: 1.0084170
	speed: 0.0140s/iter; left time: 3.1866s
Epoch: 9 cost time: 3.1462512016296387
Epoch: 9, Steps: 213 | Train Loss: 1.0222230 Vali Loss: 1.0526925 Test Loss: 1.0419097
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.04175865650177, mae:0.8190419673919678
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0433888
	speed: 0.0187s/iter; left time: 37.9894s
	iters: 200, epoch: 1 | loss: 1.0526373
	speed: 0.0164s/iter; left time: 31.7254s
Epoch: 1 cost time: 3.511326789855957
Epoch: 1, Steps: 213 | Train Loss: 1.0610875 Vali Loss: 1.0601069 Test Loss: 1.0464684
Validation loss decreased (inf --> 1.060107).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0522768
	speed: 0.0189s/iter; left time: 34.3514s
	iters: 200, epoch: 2 | loss: 1.0309379
	speed: 0.0173s/iter; left time: 29.7670s
Epoch: 2 cost time: 3.8792834281921387
Epoch: 2, Steps: 213 | Train Loss: 1.0390665 Vali Loss: 1.0580997 Test Loss: 1.0459235
Validation loss decreased (1.060107 --> 1.058100).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0258613
	speed: 0.0167s/iter; left time: 26.7807s
	iters: 200, epoch: 3 | loss: 1.0649481
	speed: 0.0136s/iter; left time: 20.5052s
Epoch: 3 cost time: 2.930565118789673
Epoch: 3, Steps: 213 | Train Loss: 1.0317918 Vali Loss: 1.0518752 Test Loss: 1.0432838
Validation loss decreased (1.058100 --> 1.051875).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0208130
	speed: 0.0140s/iter; left time: 19.4715s
	iters: 200, epoch: 4 | loss: 1.0545003
	speed: 0.0146s/iter; left time: 18.8172s
Epoch: 4 cost time: 3.195117235183716
Epoch: 4, Steps: 213 | Train Loss: 1.0279568 Vali Loss: 1.0525092 Test Loss: 1.0412992
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0311244
	speed: 0.0173s/iter; left time: 20.3612s
	iters: 200, epoch: 5 | loss: 0.9640131
	speed: 0.0160s/iter; left time: 17.2539s
Epoch: 5 cost time: 3.5307817459106445
Epoch: 5, Steps: 213 | Train Loss: 1.0248039 Vali Loss: 1.0524949 Test Loss: 1.0418208
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0341897
	speed: 0.0229s/iter; left time: 22.0809s
	iters: 200, epoch: 6 | loss: 1.0656545
	speed: 0.0179s/iter; left time: 15.4929s
Epoch: 6 cost time: 3.8080146312713623
Epoch: 6, Steps: 213 | Train Loss: 1.0233096 Vali Loss: 1.0532745 Test Loss: 1.0419354
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0319047
	speed: 0.0185s/iter; left time: 13.9108s
	iters: 200, epoch: 7 | loss: 1.0436852
	speed: 0.0157s/iter; left time: 10.2314s
Epoch: 7 cost time: 3.346891403198242
Epoch: 7, Steps: 213 | Train Loss: 1.0225621 Vali Loss: 1.0529459 Test Loss: 1.0419461
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0130839
	speed: 0.0166s/iter; left time: 8.9552s
	iters: 200, epoch: 8 | loss: 1.0054827
	speed: 0.0134s/iter; left time: 5.9170s
Epoch: 8 cost time: 2.9550342559814453
Epoch: 8, Steps: 213 | Train Loss: 1.0222398 Vali Loss: 1.0526735 Test Loss: 1.0420146
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0432837009429932, mae:0.8195958137512207
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0826044
	speed: 0.0195s/iter; left time: 39.6959s
	iters: 200, epoch: 1 | loss: 1.0637099
	speed: 0.0170s/iter; left time: 32.8290s
Epoch: 1 cost time: 3.768676280975342
Epoch: 1, Steps: 213 | Train Loss: 1.0598897 Vali Loss: 1.0598950 Test Loss: 1.0471035
Validation loss decreased (inf --> 1.059895).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0052691
	speed: 0.0175s/iter; left time: 31.7385s
	iters: 200, epoch: 2 | loss: 1.0441771
	speed: 0.0151s/iter; left time: 25.8735s
Epoch: 2 cost time: 3.293862819671631
Epoch: 2, Steps: 213 | Train Loss: 1.0397617 Vali Loss: 1.0572240 Test Loss: 1.0456750
Validation loss decreased (1.059895 --> 1.057224).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0519805
	speed: 0.0181s/iter; left time: 28.9871s
	iters: 200, epoch: 3 | loss: 0.9848409
	speed: 0.0135s/iter; left time: 20.3176s
Epoch: 3 cost time: 2.8336544036865234
Epoch: 3, Steps: 213 | Train Loss: 1.0318569 Vali Loss: 1.0551556 Test Loss: 1.0432031
Validation loss decreased (1.057224 --> 1.055156).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0049118
	speed: 0.0117s/iter; left time: 16.2537s
	iters: 200, epoch: 4 | loss: 1.0287793
	speed: 0.0138s/iter; left time: 17.7856s
Epoch: 4 cost time: 2.967190980911255
Epoch: 4, Steps: 213 | Train Loss: 1.0275481 Vali Loss: 1.0562811 Test Loss: 1.0418847
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0190284
	speed: 0.0184s/iter; left time: 21.7472s
	iters: 200, epoch: 5 | loss: 1.0203260
	speed: 0.0153s/iter; left time: 16.5231s
Epoch: 5 cost time: 3.321504831314087
Epoch: 5, Steps: 213 | Train Loss: 1.0251820 Vali Loss: 1.0515568 Test Loss: 1.0419003
Validation loss decreased (1.055156 --> 1.051557).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0630767
	speed: 0.0148s/iter; left time: 14.2903s
	iters: 200, epoch: 6 | loss: 0.9972362
	speed: 0.0183s/iter; left time: 15.8666s
Epoch: 6 cost time: 4.0145721435546875
Epoch: 6, Steps: 213 | Train Loss: 1.0234889 Vali Loss: 1.0531932 Test Loss: 1.0414068
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0505052
	speed: 0.0198s/iter; left time: 14.9329s
	iters: 200, epoch: 7 | loss: 1.0264394
	speed: 0.0160s/iter; left time: 10.4344s
Epoch: 7 cost time: 3.45058274269104
Epoch: 7, Steps: 213 | Train Loss: 1.0223267 Vali Loss: 1.0505375 Test Loss: 1.0414972
Validation loss decreased (1.051557 --> 1.050537).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0716052
	speed: 0.0182s/iter; left time: 9.8508s
	iters: 200, epoch: 8 | loss: 0.9861566
	speed: 0.0164s/iter; left time: 7.2225s
Epoch: 8 cost time: 3.5829551219940186
Epoch: 8, Steps: 213 | Train Loss: 1.0220577 Vali Loss: 1.0515122 Test Loss: 1.0415502
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0119231
	speed: 0.0218s/iter; left time: 7.1338s
	iters: 200, epoch: 9 | loss: 1.0051906
	speed: 0.0179s/iter; left time: 4.0631s
Epoch: 9 cost time: 3.8813772201538086
Epoch: 9, Steps: 213 | Train Loss: 1.0215367 Vali Loss: 1.0537425 Test Loss: 1.0415998
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0310979
	speed: 0.0158s/iter; left time: 1.8010s
	iters: 200, epoch: 10 | loss: 1.0838110
	speed: 0.0153s/iter; left time: 0.2137s
Epoch: 10 cost time: 3.379180908203125
Epoch: 10, Steps: 213 | Train Loss: 1.0219265 Vali Loss: 1.0509404 Test Loss: 1.0416226
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0414972305297852, mae:0.8191295266151428
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0572777
	speed: 0.0284s/iter; left time: 56.8262s
	iters: 200, epoch: 1 | loss: 1.0709299
	speed: 0.0266s/iter; left time: 50.4909s
Epoch: 1 cost time: 5.519278526306152
Epoch: 1, Steps: 210 | Train Loss: 1.0624633 Vali Loss: 1.0683591 Test Loss: 1.0515356
Validation loss decreased (inf --> 1.068359).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0186102
	speed: 0.0233s/iter; left time: 41.8104s
	iters: 200, epoch: 2 | loss: 1.0312108
	speed: 0.0229s/iter; left time: 38.6618s
Epoch: 2 cost time: 4.90926456451416
Epoch: 2, Steps: 210 | Train Loss: 1.0448855 Vali Loss: 1.0634823 Test Loss: 1.0520194
Validation loss decreased (1.068359 --> 1.063482).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0573293
	speed: 0.0146s/iter; left time: 23.1183s
	iters: 200, epoch: 3 | loss: 1.0584886
	speed: 0.0129s/iter; left time: 19.0524s
Epoch: 3 cost time: 2.7802224159240723
Epoch: 3, Steps: 210 | Train Loss: 1.0391759 Vali Loss: 1.0610791 Test Loss: 1.0505826
Validation loss decreased (1.063482 --> 1.061079).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0006632
	speed: 0.0191s/iter; left time: 26.1566s
	iters: 200, epoch: 4 | loss: 1.0684195
	speed: 0.0162s/iter; left time: 20.6225s
Epoch: 4 cost time: 3.5009050369262695
Epoch: 4, Steps: 210 | Train Loss: 1.0354311 Vali Loss: 1.0611335 Test Loss: 1.0501145
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0273827
	speed: 0.0193s/iter; left time: 22.3906s
	iters: 200, epoch: 5 | loss: 1.0419915
	speed: 0.0189s/iter; left time: 20.1019s
Epoch: 5 cost time: 4.169682264328003
Epoch: 5, Steps: 210 | Train Loss: 1.0335586 Vali Loss: 1.0590065 Test Loss: 1.0500317
Validation loss decreased (1.061079 --> 1.059006).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0253110
	speed: 0.0170s/iter; left time: 16.1504s
	iters: 200, epoch: 6 | loss: 1.0347724
	speed: 0.0174s/iter; left time: 14.8210s
Epoch: 6 cost time: 3.7193644046783447
Epoch: 6, Steps: 210 | Train Loss: 1.0319375 Vali Loss: 1.0615178 Test Loss: 1.0504086
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0359387
	speed: 0.0175s/iter; left time: 12.9567s
	iters: 200, epoch: 7 | loss: 1.0205870
	speed: 0.0160s/iter; left time: 10.2729s
Epoch: 7 cost time: 3.445308208465576
Epoch: 7, Steps: 210 | Train Loss: 1.0316085 Vali Loss: 1.0582120 Test Loss: 1.0499910
Validation loss decreased (1.059006 --> 1.058212).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0311866
	speed: 0.0239s/iter; left time: 12.6821s
	iters: 200, epoch: 8 | loss: 1.0175767
	speed: 0.0216s/iter; left time: 9.3103s
Epoch: 8 cost time: 4.521449327468872
Epoch: 8, Steps: 210 | Train Loss: 1.0308488 Vali Loss: 1.0596633 Test Loss: 1.0500382
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0390384
	speed: 0.0244s/iter; left time: 7.8427s
	iters: 200, epoch: 9 | loss: 1.0463617
	speed: 0.0210s/iter; left time: 4.6341s
Epoch: 9 cost time: 4.453187942504883
Epoch: 9, Steps: 210 | Train Loss: 1.0306970 Vali Loss: 1.0589677 Test Loss: 1.0501233
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0442603
	speed: 0.0185s/iter; left time: 2.0578s
	iters: 200, epoch: 10 | loss: 1.0446656
	speed: 0.0165s/iter; left time: 0.1816s
Epoch: 10 cost time: 3.567704677581787
Epoch: 10, Steps: 210 | Train Loss: 1.0306198 Vali Loss: 1.0596992 Test Loss: 1.0501500
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0499911308288574, mae:0.822024941444397
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0703630
	speed: 0.0141s/iter; left time: 28.1705s
	iters: 200, epoch: 1 | loss: 1.0634813
	speed: 0.0113s/iter; left time: 21.4726s
Epoch: 1 cost time: 2.4670066833496094
Epoch: 1, Steps: 210 | Train Loss: 1.0624920 Vali Loss: 1.0681781 Test Loss: 1.0533276
Validation loss decreased (inf --> 1.068178).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9948230
	speed: 0.0165s/iter; left time: 29.5803s
	iters: 200, epoch: 2 | loss: 1.0531009
	speed: 0.0138s/iter; left time: 23.2796s
Epoch: 2 cost time: 2.9532439708709717
Epoch: 2, Steps: 210 | Train Loss: 1.0454014 Vali Loss: 1.0650904 Test Loss: 1.0523924
Validation loss decreased (1.068178 --> 1.065090).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0281954
	speed: 0.0161s/iter; left time: 25.4735s
	iters: 200, epoch: 3 | loss: 1.0362630
	speed: 0.0138s/iter; left time: 20.4853s
Epoch: 3 cost time: 2.913456439971924
Epoch: 3, Steps: 210 | Train Loss: 1.0393701 Vali Loss: 1.0601804 Test Loss: 1.0504934
Validation loss decreased (1.065090 --> 1.060180).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0676663
	speed: 0.0231s/iter; left time: 31.6087s
	iters: 200, epoch: 4 | loss: 1.0483445
	speed: 0.0200s/iter; left time: 25.4208s
Epoch: 4 cost time: 4.409130096435547
Epoch: 4, Steps: 210 | Train Loss: 1.0358105 Vali Loss: 1.0604556 Test Loss: 1.0499532
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0144967
	speed: 0.0161s/iter; left time: 18.6878s
	iters: 200, epoch: 5 | loss: 1.0461068
	speed: 0.0135s/iter; left time: 14.3550s
Epoch: 5 cost time: 2.93449068069458
Epoch: 5, Steps: 210 | Train Loss: 1.0338803 Vali Loss: 1.0607682 Test Loss: 1.0497288
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0173799
	speed: 0.0196s/iter; left time: 18.6056s
	iters: 200, epoch: 6 | loss: 1.0004718
	speed: 0.0196s/iter; left time: 16.6743s
Epoch: 6 cost time: 4.183100938796997
Epoch: 6, Steps: 210 | Train Loss: 1.0323483 Vali Loss: 1.0598935 Test Loss: 1.0498331
Validation loss decreased (1.060180 --> 1.059893).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0265077
	speed: 0.0256s/iter; left time: 18.9990s
	iters: 200, epoch: 7 | loss: 1.0401554
	speed: 0.0197s/iter; left time: 12.6289s
Epoch: 7 cost time: 4.16947340965271
Epoch: 7, Steps: 210 | Train Loss: 1.0318912 Vali Loss: 1.0588953 Test Loss: 1.0499854
Validation loss decreased (1.059893 --> 1.058895).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0380573
	speed: 0.0260s/iter; left time: 13.8057s
	iters: 200, epoch: 8 | loss: 1.0211725
	speed: 0.0204s/iter; left time: 8.7791s
Epoch: 8 cost time: 4.263780355453491
Epoch: 8, Steps: 210 | Train Loss: 1.0315329 Vali Loss: 1.0597913 Test Loss: 1.0499229
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0450392
	speed: 0.0144s/iter; left time: 4.6081s
	iters: 200, epoch: 9 | loss: 1.0128163
	speed: 0.0133s/iter; left time: 2.9292s
Epoch: 9 cost time: 2.872270345687866
Epoch: 9, Steps: 210 | Train Loss: 1.0312122 Vali Loss: 1.0585607 Test Loss: 1.0499804
Validation loss decreased (1.058895 --> 1.058561).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0368994
	speed: 0.0162s/iter; left time: 1.7946s
	iters: 200, epoch: 10 | loss: 1.0524173
	speed: 0.0152s/iter; left time: 0.1668s
Epoch: 10 cost time: 3.273831605911255
Epoch: 10, Steps: 210 | Train Loss: 1.0310612 Vali Loss: 1.0589759 Test Loss: 1.0500193
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0499805212020874, mae:0.8220073580741882
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0566863
	speed: 0.0171s/iter; left time: 34.3133s
	iters: 200, epoch: 1 | loss: 1.0531714
	speed: 0.0146s/iter; left time: 27.7759s
Epoch: 1 cost time: 3.1401329040527344
Epoch: 1, Steps: 210 | Train Loss: 1.0627470 Vali Loss: 1.0646446 Test Loss: 1.0526392
Validation loss decreased (inf --> 1.064645).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0654566
	speed: 0.0160s/iter; left time: 28.7173s
	iters: 200, epoch: 2 | loss: 1.0394921
	speed: 0.0162s/iter; left time: 27.3208s
Epoch: 2 cost time: 3.407069444656372
Epoch: 2, Steps: 210 | Train Loss: 1.0454354 Vali Loss: 1.0660764 Test Loss: 1.0519012
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0599856
	speed: 0.0148s/iter; left time: 23.4764s
	iters: 200, epoch: 3 | loss: 1.0371404
	speed: 0.0142s/iter; left time: 21.0446s
Epoch: 3 cost time: 3.0871944427490234
Epoch: 3, Steps: 210 | Train Loss: 1.0395362 Vali Loss: 1.0628144 Test Loss: 1.0507876
Validation loss decreased (1.064645 --> 1.062814).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0353818
	speed: 0.0194s/iter; left time: 26.5636s
	iters: 200, epoch: 4 | loss: 1.0553560
	speed: 0.0194s/iter; left time: 24.6540s
Epoch: 4 cost time: 4.1137776374816895
Epoch: 4, Steps: 210 | Train Loss: 1.0359544 Vali Loss: 1.0590478 Test Loss: 1.0497037
Validation loss decreased (1.062814 --> 1.059048).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0565971
	speed: 0.0219s/iter; left time: 25.4070s
	iters: 200, epoch: 5 | loss: 1.0387156
	speed: 0.0189s/iter; left time: 20.0953s
Epoch: 5 cost time: 4.006968259811401
Epoch: 5, Steps: 210 | Train Loss: 1.0339195 Vali Loss: 1.0610942 Test Loss: 1.0494549
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0317744
	speed: 0.0189s/iter; left time: 17.9887s
	iters: 200, epoch: 6 | loss: 1.0388645
	speed: 0.0172s/iter; left time: 14.6269s
Epoch: 6 cost time: 3.6786537170410156
Epoch: 6, Steps: 210 | Train Loss: 1.0326377 Vali Loss: 1.0615904 Test Loss: 1.0494061
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0227475
	speed: 0.0151s/iter; left time: 11.1846s
	iters: 200, epoch: 7 | loss: 1.0046453
	speed: 0.0136s/iter; left time: 8.7407s
Epoch: 7 cost time: 2.9359958171844482
Epoch: 7, Steps: 210 | Train Loss: 1.0317438 Vali Loss: 1.0599484 Test Loss: 1.0496501
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0617908
	speed: 0.0168s/iter; left time: 8.8960s
	iters: 200, epoch: 8 | loss: 0.9969035
	speed: 0.0202s/iter; left time: 8.6956s
Epoch: 8 cost time: 4.3210461139678955
Epoch: 8, Steps: 210 | Train Loss: 1.0317719 Vali Loss: 1.0597211 Test Loss: 1.0497754
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0630164
	speed: 0.0189s/iter; left time: 6.0564s
	iters: 200, epoch: 9 | loss: 1.0171244
	speed: 0.0186s/iter; left time: 4.1035s
Epoch: 9 cost time: 4.022737264633179
Epoch: 9, Steps: 210 | Train Loss: 1.0313441 Vali Loss: 1.0619264 Test Loss: 1.0497732
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.049703598022461, mae:0.8218176960945129
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0769020
	speed: 0.0322s/iter; left time: 63.2112s
	iters: 200, epoch: 1 | loss: 1.0386130
	speed: 0.0241s/iter; left time: 44.8144s
Epoch: 1 cost time: 4.995578765869141
Epoch: 1, Steps: 206 | Train Loss: 1.0663233 Vali Loss: 1.0587118 Test Loss: 1.0431083
Validation loss decreased (inf --> 1.058712).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0922245
	speed: 0.0182s/iter; left time: 31.9227s
	iters: 200, epoch: 2 | loss: 1.0472999
	speed: 0.0162s/iter; left time: 26.7649s
Epoch: 2 cost time: 3.431973934173584
Epoch: 2, Steps: 206 | Train Loss: 1.0502738 Vali Loss: 1.0559967 Test Loss: 1.0431650
Validation loss decreased (1.058712 --> 1.055997).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0732796
	speed: 0.0159s/iter; left time: 24.6724s
	iters: 200, epoch: 3 | loss: 1.0381557
	speed: 0.0153s/iter; left time: 22.1623s
Epoch: 3 cost time: 3.2468509674072266
Epoch: 3, Steps: 206 | Train Loss: 1.0452747 Vali Loss: 1.0531499 Test Loss: 1.0422660
Validation loss decreased (1.055997 --> 1.053150).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0321490
	speed: 0.0168s/iter; left time: 22.5958s
	iters: 200, epoch: 4 | loss: 1.0315627
	speed: 0.0123s/iter; left time: 15.3416s
Epoch: 4 cost time: 2.6191179752349854
Epoch: 4, Steps: 206 | Train Loss: 1.0423142 Vali Loss: 1.0517104 Test Loss: 1.0408375
Validation loss decreased (1.053150 --> 1.051710).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0438263
	speed: 0.0256s/iter; left time: 29.1311s
	iters: 200, epoch: 5 | loss: 1.0597674
	speed: 0.0202s/iter; left time: 20.9225s
Epoch: 5 cost time: 4.273266553878784
Epoch: 5, Steps: 206 | Train Loss: 1.0405328 Vali Loss: 1.0508343 Test Loss: 1.0404340
Validation loss decreased (1.051710 --> 1.050834).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0277035
	speed: 0.0235s/iter; left time: 21.9041s
	iters: 200, epoch: 6 | loss: 1.0435697
	speed: 0.0172s/iter; left time: 14.2909s
Epoch: 6 cost time: 3.6586241722106934
Epoch: 6, Steps: 206 | Train Loss: 1.0394089 Vali Loss: 1.0506624 Test Loss: 1.0406408
Validation loss decreased (1.050834 --> 1.050662).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0495135
	speed: 0.0184s/iter; left time: 13.3754s
	iters: 200, epoch: 7 | loss: 1.0393566
	speed: 0.0159s/iter; left time: 9.9632s
Epoch: 7 cost time: 3.3433775901794434
Epoch: 7, Steps: 206 | Train Loss: 1.0389041 Vali Loss: 1.0505388 Test Loss: 1.0405511
Validation loss decreased (1.050662 --> 1.050539).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0464337
	speed: 0.0134s/iter; left time: 6.9794s
	iters: 200, epoch: 8 | loss: 1.0332199
	speed: 0.0104s/iter; left time: 4.3602s
Epoch: 8 cost time: 2.210783004760742
Epoch: 8, Steps: 206 | Train Loss: 1.0386205 Vali Loss: 1.0504693 Test Loss: 1.0405802
Validation loss decreased (1.050539 --> 1.050469).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0682726
	speed: 0.0165s/iter; left time: 5.1605s
	iters: 200, epoch: 9 | loss: 1.0381455
	speed: 0.0155s/iter; left time: 3.3021s
Epoch: 9 cost time: 3.3599352836608887
Epoch: 9, Steps: 206 | Train Loss: 1.0387385 Vali Loss: 1.0504892 Test Loss: 1.0406212
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0478030
	speed: 0.0178s/iter; left time: 1.9071s
	iters: 200, epoch: 10 | loss: 1.0390956
	speed: 0.0185s/iter; left time: 0.1298s
Epoch: 10 cost time: 3.8829433917999268
Epoch: 10, Steps: 206 | Train Loss: 1.0385544 Vali Loss: 1.0505899 Test Loss: 1.0406539
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405802726745605, mae:0.8192355632781982
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0502287
	speed: 0.0173s/iter; left time: 33.9342s
	iters: 200, epoch: 1 | loss: 1.0509061
	speed: 0.0154s/iter; left time: 28.6944s
Epoch: 1 cost time: 3.2931981086730957
Epoch: 1, Steps: 206 | Train Loss: 1.0661648 Vali Loss: 1.0609101 Test Loss: 1.0457586
Validation loss decreased (inf --> 1.060910).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0260273
	speed: 0.0152s/iter; left time: 26.7473s
	iters: 200, epoch: 2 | loss: 1.0597402
	speed: 0.0138s/iter; left time: 22.8617s
Epoch: 2 cost time: 2.9811203479766846
Epoch: 2, Steps: 206 | Train Loss: 1.0501749 Vali Loss: 1.0566196 Test Loss: 1.0434219
Validation loss decreased (1.060910 --> 1.056620).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0484875
	speed: 0.0134s/iter; left time: 20.7276s
	iters: 200, epoch: 3 | loss: 1.0499036
	speed: 0.0131s/iter; left time: 18.9666s
Epoch: 3 cost time: 2.7690577507019043
Epoch: 3, Steps: 206 | Train Loss: 1.0447775 Vali Loss: 1.0516809 Test Loss: 1.0406183
Validation loss decreased (1.056620 --> 1.051681).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0549598
	speed: 0.0148s/iter; left time: 19.9278s
	iters: 200, epoch: 4 | loss: 1.0477433
	speed: 0.0144s/iter; left time: 17.9603s
Epoch: 4 cost time: 3.0840134620666504
Epoch: 4, Steps: 206 | Train Loss: 1.0423899 Vali Loss: 1.0510876 Test Loss: 1.0409378
Validation loss decreased (1.051681 --> 1.051088).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0628312
	speed: 0.0190s/iter; left time: 21.5633s
	iters: 200, epoch: 5 | loss: 1.0417120
	speed: 0.0181s/iter; left time: 18.7542s
Epoch: 5 cost time: 3.869457483291626
Epoch: 5, Steps: 206 | Train Loss: 1.0403333 Vali Loss: 1.0513458 Test Loss: 1.0413134
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0466822
	speed: 0.0140s/iter; left time: 13.0659s
	iters: 200, epoch: 6 | loss: 1.0371346
	speed: 0.0152s/iter; left time: 12.6625s
Epoch: 6 cost time: 3.2356040477752686
Epoch: 6, Steps: 206 | Train Loss: 1.0392704 Vali Loss: 1.0505041 Test Loss: 1.0407553
Validation loss decreased (1.051088 --> 1.050504).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0239482
	speed: 0.0166s/iter; left time: 12.0602s
	iters: 200, epoch: 7 | loss: 1.0286989
	speed: 0.0152s/iter; left time: 9.5194s
Epoch: 7 cost time: 3.2536375522613525
Epoch: 7, Steps: 206 | Train Loss: 1.0386717 Vali Loss: 1.0507497 Test Loss: 1.0411159
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0376097
	speed: 0.0161s/iter; left time: 8.3627s
	iters: 200, epoch: 8 | loss: 1.0193287
	speed: 0.0153s/iter; left time: 6.4082s
Epoch: 8 cost time: 3.2454135417938232
Epoch: 8, Steps: 206 | Train Loss: 1.0386601 Vali Loss: 1.0506066 Test Loss: 1.0410893
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0615344
	speed: 0.0206s/iter; left time: 6.4583s
	iters: 200, epoch: 9 | loss: 1.0495706
	speed: 0.0172s/iter; left time: 3.6561s
Epoch: 9 cost time: 3.589002847671509
Epoch: 9, Steps: 206 | Train Loss: 1.0383602 Vali Loss: 1.0507052 Test Loss: 1.0410784
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0256464
	speed: 0.0196s/iter; left time: 2.1016s
	iters: 200, epoch: 10 | loss: 1.0069926
	speed: 0.0179s/iter; left time: 0.1253s
Epoch: 10 cost time: 3.801065683364868
Epoch: 10, Steps: 206 | Train Loss: 1.0381878 Vali Loss: 1.0506182 Test Loss: 1.0410517
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040755271911621, mae:0.8193255066871643
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0181264
	speed: 0.0140s/iter; left time: 27.3605s
	iters: 200, epoch: 1 | loss: 1.0587925
	speed: 0.0118s/iter; left time: 21.8962s
Epoch: 1 cost time: 2.5052363872528076
Epoch: 1, Steps: 206 | Train Loss: 1.0663517 Vali Loss: 1.0570036 Test Loss: 1.0419257
Validation loss decreased (inf --> 1.057004).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0595177
	speed: 0.0123s/iter; left time: 21.5665s
	iters: 200, epoch: 2 | loss: 1.0648940
	speed: 0.0108s/iter; left time: 17.9053s
Epoch: 2 cost time: 2.350008964538574
Epoch: 2, Steps: 206 | Train Loss: 1.0500793 Vali Loss: 1.0557413 Test Loss: 1.0424426
Validation loss decreased (1.057004 --> 1.055741).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0580081
	speed: 0.0157s/iter; left time: 24.2693s
	iters: 200, epoch: 3 | loss: 1.0542454
	speed: 0.0155s/iter; left time: 22.5114s
Epoch: 3 cost time: 3.294342517852783
Epoch: 3, Steps: 206 | Train Loss: 1.0451779 Vali Loss: 1.0517583 Test Loss: 1.0406287
Validation loss decreased (1.055741 --> 1.051758).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0665491
	speed: 0.0201s/iter; left time: 27.0255s
	iters: 200, epoch: 4 | loss: 1.0458026
	speed: 0.0175s/iter; left time: 21.7704s
Epoch: 4 cost time: 3.7131075859069824
Epoch: 4, Steps: 206 | Train Loss: 1.0423174 Vali Loss: 1.0518572 Test Loss: 1.0417180
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0219964
	speed: 0.0180s/iter; left time: 20.4598s
	iters: 200, epoch: 5 | loss: 1.0545242
	speed: 0.0165s/iter; left time: 17.0813s
Epoch: 5 cost time: 3.5019185543060303
Epoch: 5, Steps: 206 | Train Loss: 1.0403648 Vali Loss: 1.0504245 Test Loss: 1.0406193
Validation loss decreased (1.051758 --> 1.050424).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0424639
	speed: 0.0162s/iter; left time: 15.0393s
	iters: 200, epoch: 6 | loss: 1.0537978
	speed: 0.0171s/iter; left time: 14.1799s
Epoch: 6 cost time: 3.630171060562134
Epoch: 6, Steps: 206 | Train Loss: 1.0396858 Vali Loss: 1.0503918 Test Loss: 1.0405692
Validation loss decreased (1.050424 --> 1.050392).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0369960
	speed: 0.0234s/iter; left time: 16.9891s
	iters: 200, epoch: 7 | loss: 1.0453432
	speed: 0.0214s/iter; left time: 13.4059s
Epoch: 7 cost time: 4.460692405700684
Epoch: 7, Steps: 206 | Train Loss: 1.0388484 Vali Loss: 1.0506610 Test Loss: 1.0410124
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0552199
	speed: 0.0258s/iter; left time: 13.4134s
	iters: 200, epoch: 8 | loss: 1.0257024
	speed: 0.0201s/iter; left time: 8.4400s
Epoch: 8 cost time: 4.26931095123291
Epoch: 8, Steps: 206 | Train Loss: 1.0388249 Vali Loss: 1.0501366 Test Loss: 1.0408636
Validation loss decreased (1.050392 --> 1.050137).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0552565
	speed: 0.0177s/iter; left time: 5.5284s
	iters: 200, epoch: 9 | loss: 1.0417372
	speed: 0.0164s/iter; left time: 3.4915s
Epoch: 9 cost time: 3.485775947570801
Epoch: 9, Steps: 206 | Train Loss: 1.0386348 Vali Loss: 1.0502645 Test Loss: 1.0409415
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0393682
	speed: 0.0158s/iter; left time: 1.6900s
	iters: 200, epoch: 10 | loss: 1.0464110
	speed: 0.0138s/iter; left time: 0.0965s
Epoch: 10 cost time: 2.8940742015838623
Epoch: 10, Steps: 206 | Train Loss: 1.0388257 Vali Loss: 1.0505171 Test Loss: 1.0409433
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0408637523651123, mae:0.8193281888961792
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0773805
	speed: 0.0280s/iter; left time: 51.5673s
Epoch: 1 cost time: 4.96332311630249
Epoch: 1, Steps: 194 | Train Loss: 1.0729210 Vali Loss: 1.0461183 Test Loss: 1.0438763
Validation loss decreased (inf --> 1.046118).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0547252
	speed: 0.0151s/iter; left time: 24.8992s
Epoch: 2 cost time: 2.792965888977051
Epoch: 2, Steps: 194 | Train Loss: 1.0563935 Vali Loss: 1.0469799 Test Loss: 1.0453510
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0285316
	speed: 0.0159s/iter; left time: 23.0398s
Epoch: 3 cost time: 2.7768938541412354
Epoch: 3, Steps: 194 | Train Loss: 1.0524282 Vali Loss: 1.0471830 Test Loss: 1.0370407
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0797724
	speed: 0.0166s/iter; left time: 20.9038s
Epoch: 4 cost time: 2.880357265472412
Epoch: 4, Steps: 194 | Train Loss: 1.0502151 Vali Loss: 1.0429691 Test Loss: 1.0403677
Validation loss decreased (1.046118 --> 1.042969).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0477241
	speed: 0.0159s/iter; left time: 16.9798s
Epoch: 5 cost time: 2.862611770629883
Epoch: 5, Steps: 194 | Train Loss: 1.0490917 Vali Loss: 1.0436891 Test Loss: 1.0394697
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0475416
	speed: 0.0183s/iter; left time: 15.8998s
Epoch: 6 cost time: 3.2644670009613037
Epoch: 6, Steps: 194 | Train Loss: 1.0482445 Vali Loss: 1.0433235 Test Loss: 1.0399554
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0486069
	speed: 0.0128s/iter; left time: 8.6730s
Epoch: 7 cost time: 2.226100206375122
Epoch: 7, Steps: 194 | Train Loss: 1.0478332 Vali Loss: 1.0436944 Test Loss: 1.0394869
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0425036
	speed: 0.0171s/iter; left time: 8.2353s
Epoch: 8 cost time: 3.0226166248321533
Epoch: 8, Steps: 194 | Train Loss: 1.0477105 Vali Loss: 1.0431904 Test Loss: 1.0396439
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0403037
	speed: 0.0181s/iter; left time: 5.2370s
Epoch: 9 cost time: 3.2556021213531494
Epoch: 9, Steps: 194 | Train Loss: 1.0474615 Vali Loss: 1.0432497 Test Loss: 1.0397067
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0403679609298706, mae:0.818473756313324
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0445484
	speed: 0.0199s/iter; left time: 36.5975s
Epoch: 1 cost time: 3.35040283203125
Epoch: 1, Steps: 194 | Train Loss: 1.0715342 Vali Loss: 1.0489845 Test Loss: 1.0425023
Validation loss decreased (inf --> 1.048985).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0689062
	speed: 0.0157s/iter; left time: 25.7771s
Epoch: 2 cost time: 2.9095139503479004
Epoch: 2, Steps: 194 | Train Loss: 1.0569866 Vali Loss: 1.0482085 Test Loss: 1.0427232
Validation loss decreased (1.048985 --> 1.048208).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0446665
	speed: 0.0166s/iter; left time: 24.1133s
Epoch: 3 cost time: 2.686192512512207
Epoch: 3, Steps: 194 | Train Loss: 1.0525892 Vali Loss: 1.0440012 Test Loss: 1.0414317
Validation loss decreased (1.048208 --> 1.044001).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0558118
	speed: 0.0192s/iter; left time: 24.1950s
Epoch: 4 cost time: 3.0555195808410645
Epoch: 4, Steps: 194 | Train Loss: 1.0503366 Vali Loss: 1.0445317 Test Loss: 1.0408593
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0504941
	speed: 0.0289s/iter; left time: 30.7724s
Epoch: 5 cost time: 3.956428289413452
Epoch: 5, Steps: 194 | Train Loss: 1.0491179 Vali Loss: 1.0436314 Test Loss: 1.0393928
Validation loss decreased (1.044001 --> 1.043631).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0408348
	speed: 0.0204s/iter; left time: 17.7634s
Epoch: 6 cost time: 3.3591020107269287
Epoch: 6, Steps: 194 | Train Loss: 1.0483332 Vali Loss: 1.0434279 Test Loss: 1.0398741
Validation loss decreased (1.043631 --> 1.043428).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0353287
	speed: 0.0163s/iter; left time: 11.0461s
Epoch: 7 cost time: 2.6622629165649414
Epoch: 7, Steps: 194 | Train Loss: 1.0479418 Vali Loss: 1.0436815 Test Loss: 1.0396004
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0561486
	speed: 0.0170s/iter; left time: 8.2348s
Epoch: 8 cost time: 3.371319532394409
Epoch: 8, Steps: 194 | Train Loss: 1.0475015 Vali Loss: 1.0438020 Test Loss: 1.0396172
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0520060
	speed: 0.0218s/iter; left time: 6.2994s
Epoch: 9 cost time: 3.7298426628112793
Epoch: 9, Steps: 194 | Train Loss: 1.0474580 Vali Loss: 1.0437452 Test Loss: 1.0394969
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0356603
	speed: 0.0163s/iter; left time: 1.5528s
Epoch: 10 cost time: 3.0499629974365234
Epoch: 10, Steps: 194 | Train Loss: 1.0473780 Vali Loss: 1.0440087 Test Loss: 1.0394517
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0398740768432617, mae:0.8182723522186279
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0588942
	speed: 0.0168s/iter; left time: 30.8793s
Epoch: 1 cost time: 2.586481809616089
Epoch: 1, Steps: 194 | Train Loss: 1.0717024 Vali Loss: 1.0509082 Test Loss: 1.0441927
Validation loss decreased (inf --> 1.050908).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0568901
	speed: 0.0200s/iter; left time: 32.9096s
Epoch: 2 cost time: 3.1406404972076416
Epoch: 2, Steps: 194 | Train Loss: 1.0562295 Vali Loss: 1.0455337 Test Loss: 1.0501801
Validation loss decreased (1.050908 --> 1.045534).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0623040
	speed: 0.0296s/iter; left time: 43.0707s
Epoch: 3 cost time: 4.518255233764648
Epoch: 3, Steps: 194 | Train Loss: 1.0524822 Vali Loss: 1.0449966 Test Loss: 1.0392197
Validation loss decreased (1.045534 --> 1.044997).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0460601
	speed: 0.0246s/iter; left time: 30.9706s
Epoch: 4 cost time: 4.040765047073364
Epoch: 4, Steps: 194 | Train Loss: 1.0504782 Vali Loss: 1.0427434 Test Loss: 1.0425463
Validation loss decreased (1.044997 --> 1.042743).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0339588
	speed: 0.0184s/iter; left time: 19.6446s
Epoch: 5 cost time: 3.30147647857666
Epoch: 5, Steps: 194 | Train Loss: 1.0488876 Vali Loss: 1.0440810 Test Loss: 1.0405903
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0231261
	speed: 0.0187s/iter; left time: 16.3021s
Epoch: 6 cost time: 3.0910871028900146
Epoch: 6, Steps: 194 | Train Loss: 1.0480938 Vali Loss: 1.0432017 Test Loss: 1.0406246
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0377029
	speed: 0.0190s/iter; left time: 12.8370s
Epoch: 7 cost time: 3.1823320388793945
Epoch: 7, Steps: 194 | Train Loss: 1.0479425 Vali Loss: 1.0441518 Test Loss: 1.0393080
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0262861
	speed: 0.0172s/iter; left time: 8.2958s
Epoch: 8 cost time: 3.2794625759124756
Epoch: 8, Steps: 194 | Train Loss: 1.0477687 Vali Loss: 1.0438896 Test Loss: 1.0395077
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0656885
	speed: 0.0214s/iter; left time: 6.1873s
Epoch: 9 cost time: 3.8954310417175293
Epoch: 9, Steps: 194 | Train Loss: 1.0472917 Vali Loss: 1.0439059 Test Loss: 1.0396580
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.042546272277832, mae:0.8193709850311279
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0316771
	speed: 0.0292s/iter; left time: 59.3015s
	iters: 200, epoch: 1 | loss: 1.0178016
	speed: 0.0233s/iter; left time: 45.0051s
Epoch: 1 cost time: 4.938155651092529
Epoch: 1, Steps: 213 | Train Loss: 1.0598071 Vali Loss: 1.0583838 Test Loss: 1.0473398
Validation loss decreased (inf --> 1.058384).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0620544
	speed: 0.0193s/iter; left time: 35.1592s
	iters: 200, epoch: 2 | loss: 1.0229701
	speed: 0.0173s/iter; left time: 29.7311s
Epoch: 2 cost time: 3.7167153358459473
Epoch: 2, Steps: 213 | Train Loss: 1.0392326 Vali Loss: 1.0570441 Test Loss: 1.0443974
Validation loss decreased (1.058384 --> 1.057044).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0250750
	speed: 0.0138s/iter; left time: 22.1284s
	iters: 200, epoch: 3 | loss: 1.0396723
	speed: 0.0118s/iter; left time: 17.7217s
Epoch: 3 cost time: 2.58345365524292
Epoch: 3, Steps: 213 | Train Loss: 1.0322043 Vali Loss: 1.0571553 Test Loss: 1.0444269
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9704913
	speed: 0.0118s/iter; left time: 16.4617s
	iters: 200, epoch: 4 | loss: 1.0627332
	speed: 0.0112s/iter; left time: 14.4128s
Epoch: 4 cost time: 2.465841054916382
Epoch: 4, Steps: 213 | Train Loss: 1.0280184 Vali Loss: 1.0509440 Test Loss: 1.0415082
Validation loss decreased (1.057044 --> 1.050944).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0266020
	speed: 0.0144s/iter; left time: 16.9450s
	iters: 200, epoch: 5 | loss: 1.0288383
	speed: 0.0128s/iter; left time: 13.8616s
Epoch: 5 cost time: 2.8234894275665283
Epoch: 5, Steps: 213 | Train Loss: 1.0251827 Vali Loss: 1.0559149 Test Loss: 1.0415386
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9670219
	speed: 0.0131s/iter; left time: 12.6891s
	iters: 200, epoch: 6 | loss: 1.0657651
	speed: 0.0141s/iter; left time: 12.2113s
Epoch: 6 cost time: 3.0592706203460693
Epoch: 6, Steps: 213 | Train Loss: 1.0235485 Vali Loss: 1.0520459 Test Loss: 1.0413315
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9860702
	speed: 0.0179s/iter; left time: 13.4745s
	iters: 200, epoch: 7 | loss: 1.0465813
	speed: 0.0194s/iter; left time: 12.6404s
Epoch: 7 cost time: 4.129426717758179
Epoch: 7, Steps: 213 | Train Loss: 1.0224583 Vali Loss: 1.0519046 Test Loss: 1.0411662
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0219996
	speed: 0.0168s/iter; left time: 9.0565s
	iters: 200, epoch: 8 | loss: 1.0216943
	speed: 0.0157s/iter; left time: 6.9190s
Epoch: 8 cost time: 3.4594147205352783
Epoch: 8, Steps: 213 | Train Loss: 1.0220466 Vali Loss: 1.0524067 Test Loss: 1.0412455
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0452726
	speed: 0.0183s/iter; left time: 5.9953s
	iters: 200, epoch: 9 | loss: 1.0586468
	speed: 0.0157s/iter; left time: 3.5733s
Epoch: 9 cost time: 3.398911237716675
Epoch: 9, Steps: 213 | Train Loss: 1.0219006 Vali Loss: 1.0528644 Test Loss: 1.0412799
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0415083169937134, mae:0.8189789652824402
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0669267
	speed: 0.0141s/iter; left time: 28.6689s
	iters: 200, epoch: 1 | loss: 1.0552815
	speed: 0.0211s/iter; left time: 40.8390s
Epoch: 1 cost time: 4.775641918182373
Epoch: 1, Steps: 213 | Train Loss: 1.0600848 Vali Loss: 1.0568590 Test Loss: 1.0478410
Validation loss decreased (inf --> 1.056859).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0060002
	speed: 0.0310s/iter; left time: 56.3591s
	iters: 200, epoch: 2 | loss: 1.0171521
	speed: 0.0246s/iter; left time: 42.2977s
Epoch: 2 cost time: 5.1653358936309814
Epoch: 2, Steps: 213 | Train Loss: 1.0390663 Vali Loss: 1.0559148 Test Loss: 1.0451159
Validation loss decreased (1.056859 --> 1.055915).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0757687
	speed: 0.0254s/iter; left time: 40.6969s
	iters: 200, epoch: 3 | loss: 1.0559549
	speed: 0.0188s/iter; left time: 28.2230s
Epoch: 3 cost time: 3.961193561553955
Epoch: 3, Steps: 213 | Train Loss: 1.0315891 Vali Loss: 1.0559394 Test Loss: 1.0424997
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0166392
	speed: 0.0157s/iter; left time: 21.9015s
	iters: 200, epoch: 4 | loss: 1.0429543
	speed: 0.0144s/iter; left time: 18.6168s
Epoch: 4 cost time: 3.2457356452941895
Epoch: 4, Steps: 213 | Train Loss: 1.0274794 Vali Loss: 1.0540395 Test Loss: 1.0420307
Validation loss decreased (1.055915 --> 1.054039).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0165257
	speed: 0.0188s/iter; left time: 22.1300s
	iters: 200, epoch: 5 | loss: 1.0362529
	speed: 0.0174s/iter; left time: 18.7298s
Epoch: 5 cost time: 3.9907617568969727
Epoch: 5, Steps: 213 | Train Loss: 1.0246335 Vali Loss: 1.0519400 Test Loss: 1.0413196
Validation loss decreased (1.054039 --> 1.051940).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0065486
	speed: 0.0186s/iter; left time: 17.9757s
	iters: 200, epoch: 6 | loss: 1.0618979
	speed: 0.0165s/iter; left time: 14.3030s
Epoch: 6 cost time: 3.5728468894958496
Epoch: 6, Steps: 213 | Train Loss: 1.0237594 Vali Loss: 1.0514971 Test Loss: 1.0414028
Validation loss decreased (1.051940 --> 1.051497).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9992188
	speed: 0.0177s/iter; left time: 13.3121s
	iters: 200, epoch: 7 | loss: 1.0001143
	speed: 0.0164s/iter; left time: 10.7295s
Epoch: 7 cost time: 3.560204267501831
Epoch: 7, Steps: 213 | Train Loss: 1.0226169 Vali Loss: 1.0526086 Test Loss: 1.0413146
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0168073
	speed: 0.0134s/iter; left time: 7.2563s
	iters: 200, epoch: 8 | loss: 1.0041628
	speed: 0.0119s/iter; left time: 5.2570s
Epoch: 8 cost time: 2.6356916427612305
Epoch: 8, Steps: 213 | Train Loss: 1.0218416 Vali Loss: 1.0525365 Test Loss: 1.0412933
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0312607
	speed: 0.0182s/iter; left time: 5.9417s
	iters: 200, epoch: 9 | loss: 1.0190392
	speed: 0.0169s/iter; left time: 3.8337s
Epoch: 9 cost time: 3.749213933944702
Epoch: 9, Steps: 213 | Train Loss: 1.0216034 Vali Loss: 1.0522119 Test Loss: 1.0413392
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0242596
	speed: 0.0178s/iter; left time: 2.0307s
	iters: 200, epoch: 10 | loss: 1.0255116
	speed: 0.0183s/iter; left time: 0.2559s
Epoch: 10 cost time: 4.035873889923096
Epoch: 10, Steps: 213 | Train Loss: 1.0211769 Vali Loss: 1.0530543 Test Loss: 1.0413735
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.041402816772461, mae:0.8190354704856873
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0827444
	speed: 0.0171s/iter; left time: 34.6530s
	iters: 200, epoch: 1 | loss: 1.0630778
	speed: 0.0157s/iter; left time: 30.3547s
Epoch: 1 cost time: 3.450723886489868
Epoch: 1, Steps: 213 | Train Loss: 1.0598094 Vali Loss: 1.0581217 Test Loss: 1.0462022
Validation loss decreased (inf --> 1.058122).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0340641
	speed: 0.0173s/iter; left time: 31.5237s
	iters: 200, epoch: 2 | loss: 1.0473857
	speed: 0.0149s/iter; left time: 25.6211s
Epoch: 2 cost time: 3.21940279006958
Epoch: 2, Steps: 213 | Train Loss: 1.0388731 Vali Loss: 1.0582273 Test Loss: 1.0452029
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9905765
	speed: 0.0161s/iter; left time: 25.8819s
	iters: 200, epoch: 3 | loss: 1.0500450
	speed: 0.0153s/iter; left time: 22.9732s
Epoch: 3 cost time: 3.3684070110321045
Epoch: 3, Steps: 213 | Train Loss: 1.0315217 Vali Loss: 1.0560368 Test Loss: 1.0435126
Validation loss decreased (1.058122 --> 1.056037).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0017548
	speed: 0.0184s/iter; left time: 25.5824s
	iters: 200, epoch: 4 | loss: 0.9706216
	speed: 0.0162s/iter; left time: 20.9607s
Epoch: 4 cost time: 3.439626932144165
Epoch: 4, Steps: 213 | Train Loss: 1.0273790 Vali Loss: 1.0535454 Test Loss: 1.0418321
Validation loss decreased (1.056037 --> 1.053545).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0665659
	speed: 0.0173s/iter; left time: 20.3556s
	iters: 200, epoch: 5 | loss: 1.0110265
	speed: 0.0149s/iter; left time: 16.0379s
Epoch: 5 cost time: 3.2007925510406494
Epoch: 5, Steps: 213 | Train Loss: 1.0246834 Vali Loss: 1.0530413 Test Loss: 1.0420871
Validation loss decreased (1.053545 --> 1.053041).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0667087
	speed: 0.0166s/iter; left time: 16.0607s
	iters: 200, epoch: 6 | loss: 1.0193532
	speed: 0.0133s/iter; left time: 11.5414s
Epoch: 6 cost time: 2.94102144241333
Epoch: 6, Steps: 213 | Train Loss: 1.0228685 Vali Loss: 1.0528295 Test Loss: 1.0418468
Validation loss decreased (1.053041 --> 1.052830).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0072374
	speed: 0.0193s/iter; left time: 14.5673s
	iters: 200, epoch: 7 | loss: 1.0543740
	speed: 0.0159s/iter; left time: 10.3584s
Epoch: 7 cost time: 3.4528255462646484
Epoch: 7, Steps: 213 | Train Loss: 1.0222716 Vali Loss: 1.0530243 Test Loss: 1.0417150
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0111210
	speed: 0.0226s/iter; left time: 12.1780s
	iters: 200, epoch: 8 | loss: 0.9825864
	speed: 0.0235s/iter; left time: 10.3303s
Epoch: 8 cost time: 4.896060943603516
Epoch: 8, Steps: 213 | Train Loss: 1.0220594 Vali Loss: 1.0543818 Test Loss: 1.0417886
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0318227
	speed: 0.0184s/iter; left time: 6.0275s
	iters: 200, epoch: 9 | loss: 1.0226611
	speed: 0.0174s/iter; left time: 3.9533s
Epoch: 9 cost time: 3.7110586166381836
Epoch: 9, Steps: 213 | Train Loss: 1.0217027 Vali Loss: 1.0512087 Test Loss: 1.0418266
Validation loss decreased (1.052830 --> 1.051209).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0192149
	speed: 0.0162s/iter; left time: 1.8510s
	iters: 200, epoch: 10 | loss: 1.0237497
	speed: 0.0152s/iter; left time: 0.2130s
Epoch: 10 cost time: 3.247295618057251
Epoch: 10, Steps: 213 | Train Loss: 1.0212819 Vali Loss: 1.0511937 Test Loss: 1.0418451
Validation loss decreased (1.051209 --> 1.051194).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0418452024459839, mae:0.8191744089126587
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0424827
	speed: 0.0274s/iter; left time: 54.8234s
	iters: 200, epoch: 1 | loss: 1.0433898
	speed: 0.0210s/iter; left time: 39.9947s
Epoch: 1 cost time: 4.434743881225586
Epoch: 1, Steps: 210 | Train Loss: 1.0628457 Vali Loss: 1.0676161 Test Loss: 1.0528092
Validation loss decreased (inf --> 1.067616).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0503453
	speed: 0.0133s/iter; left time: 23.8601s
	iters: 200, epoch: 2 | loss: 1.0640326
	speed: 0.0131s/iter; left time: 22.1533s
Epoch: 2 cost time: 2.9579622745513916
Epoch: 2, Steps: 210 | Train Loss: 1.0452102 Vali Loss: 1.0616560 Test Loss: 1.0541302
Validation loss decreased (1.067616 --> 1.061656).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0325696
	speed: 0.0189s/iter; left time: 29.9576s
	iters: 200, epoch: 3 | loss: 1.0580499
	speed: 0.0206s/iter; left time: 30.4568s
Epoch: 3 cost time: 4.397465229034424
Epoch: 3, Steps: 210 | Train Loss: 1.0392828 Vali Loss: 1.0637510 Test Loss: 1.0502053
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0865369
	speed: 0.0197s/iter; left time: 27.0209s
	iters: 200, epoch: 4 | loss: 1.0301801
	speed: 0.0182s/iter; left time: 23.1008s
Epoch: 4 cost time: 4.033159255981445
Epoch: 4, Steps: 210 | Train Loss: 1.0353088 Vali Loss: 1.0640283 Test Loss: 1.0493585
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0487427
	speed: 0.0158s/iter; left time: 18.3961s
	iters: 200, epoch: 5 | loss: 1.0106133
	speed: 0.0177s/iter; left time: 18.7280s
Epoch: 5 cost time: 3.8110759258270264
Epoch: 5, Steps: 210 | Train Loss: 1.0336366 Vali Loss: 1.0596873 Test Loss: 1.0497993
Validation loss decreased (1.061656 --> 1.059687).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0633376
	speed: 0.0128s/iter; left time: 12.1354s
	iters: 200, epoch: 6 | loss: 1.0319898
	speed: 0.0125s/iter; left time: 10.6101s
Epoch: 6 cost time: 2.6665759086608887
Epoch: 6, Steps: 210 | Train Loss: 1.0319413 Vali Loss: 1.0584220 Test Loss: 1.0499038
Validation loss decreased (1.059687 --> 1.058422).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9963017
	speed: 0.0184s/iter; left time: 13.6592s
	iters: 200, epoch: 7 | loss: 1.0550345
	speed: 0.0178s/iter; left time: 11.4010s
Epoch: 7 cost time: 3.8510661125183105
Epoch: 7, Steps: 210 | Train Loss: 1.0312333 Vali Loss: 1.0599353 Test Loss: 1.0500569
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0378155
	speed: 0.0146s/iter; left time: 7.7313s
	iters: 200, epoch: 8 | loss: 1.0020598
	speed: 0.0158s/iter; left time: 6.8278s
Epoch: 8 cost time: 3.3989124298095703
Epoch: 8, Steps: 210 | Train Loss: 1.0310187 Vali Loss: 1.0585780 Test Loss: 1.0499506
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0316428
	speed: 0.0175s/iter; left time: 5.6326s
	iters: 200, epoch: 9 | loss: 1.0454463
	speed: 0.0161s/iter; left time: 3.5588s
Epoch: 9 cost time: 3.486112594604492
Epoch: 9, Steps: 210 | Train Loss: 1.0308498 Vali Loss: 1.0607493 Test Loss: 1.0500141
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0403681
	speed: 0.0146s/iter; left time: 1.6186s
	iters: 200, epoch: 10 | loss: 1.0332698
	speed: 0.0122s/iter; left time: 0.1339s
Epoch: 10 cost time: 2.646916389465332
Epoch: 10, Steps: 210 | Train Loss: 1.0305208 Vali Loss: 1.0601977 Test Loss: 1.0500530
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0499036312103271, mae:0.8220009207725525
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0452164
	speed: 0.0154s/iter; left time: 30.7370s
	iters: 200, epoch: 1 | loss: 1.0669067
	speed: 0.0145s/iter; left time: 27.6158s
Epoch: 1 cost time: 3.075615167617798
Epoch: 1, Steps: 210 | Train Loss: 1.0634162 Vali Loss: 1.0663821 Test Loss: 1.0514702
Validation loss decreased (inf --> 1.066382).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0508389
	speed: 0.0279s/iter; left time: 49.9437s
	iters: 200, epoch: 2 | loss: 1.0595931
	speed: 0.0200s/iter; left time: 33.8880s
Epoch: 2 cost time: 4.209118366241455
Epoch: 2, Steps: 210 | Train Loss: 1.0450779 Vali Loss: 1.0645627 Test Loss: 1.0522285
Validation loss decreased (1.066382 --> 1.064563).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0784471
	speed: 0.0199s/iter; left time: 31.3866s
	iters: 200, epoch: 3 | loss: 1.0250802
	speed: 0.0162s/iter; left time: 23.9339s
Epoch: 3 cost time: 3.4337430000305176
Epoch: 3, Steps: 210 | Train Loss: 1.0393943 Vali Loss: 1.0630974 Test Loss: 1.0495409
Validation loss decreased (1.064563 --> 1.063097).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0326523
	speed: 0.0245s/iter; left time: 33.5493s
	iters: 200, epoch: 4 | loss: 1.0615342
	speed: 0.0187s/iter; left time: 23.7463s
Epoch: 4 cost time: 3.9942474365234375
Epoch: 4, Steps: 210 | Train Loss: 1.0360512 Vali Loss: 1.0603293 Test Loss: 1.0492687
Validation loss decreased (1.063097 --> 1.060329).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0651675
	speed: 0.0203s/iter; left time: 23.5267s
	iters: 200, epoch: 5 | loss: 1.0308321
	speed: 0.0151s/iter; left time: 16.0228s
Epoch: 5 cost time: 3.186532497406006
Epoch: 5, Steps: 210 | Train Loss: 1.0341237 Vali Loss: 1.0604491 Test Loss: 1.0494598
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0223016
	speed: 0.0232s/iter; left time: 22.0938s
	iters: 200, epoch: 6 | loss: 1.0454220
	speed: 0.0181s/iter; left time: 15.4233s
Epoch: 6 cost time: 3.8850035667419434
Epoch: 6, Steps: 210 | Train Loss: 1.0327290 Vali Loss: 1.0609207 Test Loss: 1.0494140
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0409276
	speed: 0.0220s/iter; left time: 16.3177s
	iters: 200, epoch: 7 | loss: 1.0335442
	speed: 0.0213s/iter; left time: 13.6327s
Epoch: 7 cost time: 4.684424638748169
Epoch: 7, Steps: 210 | Train Loss: 1.0320207 Vali Loss: 1.0598575 Test Loss: 1.0494589
Validation loss decreased (1.060329 --> 1.059857).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0422218
	speed: 0.0181s/iter; left time: 9.6126s
	iters: 200, epoch: 8 | loss: 1.0384660
	speed: 0.0172s/iter; left time: 7.4312s
Epoch: 8 cost time: 3.6874518394470215
Epoch: 8, Steps: 210 | Train Loss: 1.0316193 Vali Loss: 1.0605643 Test Loss: 1.0494927
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0401216
	speed: 0.0156s/iter; left time: 4.9922s
	iters: 200, epoch: 9 | loss: 1.0514836
	speed: 0.0122s/iter; left time: 2.6868s
Epoch: 9 cost time: 2.6616835594177246
Epoch: 9, Steps: 210 | Train Loss: 1.0314160 Vali Loss: 1.0598288 Test Loss: 1.0495795
Validation loss decreased (1.059857 --> 1.059829).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0681537
	speed: 0.0193s/iter; left time: 2.1409s
	iters: 200, epoch: 10 | loss: 1.0281415
	speed: 0.0168s/iter; left time: 0.1849s
Epoch: 10 cost time: 3.5916309356689453
Epoch: 10, Steps: 210 | Train Loss: 1.0311407 Vali Loss: 1.0574406 Test Loss: 1.0496136
Validation loss decreased (1.059829 --> 1.057441).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.04961359500885, mae:0.8219172954559326
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0318702
	speed: 0.0204s/iter; left time: 40.8090s
	iters: 200, epoch: 1 | loss: 1.0583484
	speed: 0.0177s/iter; left time: 33.7301s
Epoch: 1 cost time: 3.8199732303619385
Epoch: 1, Steps: 210 | Train Loss: 1.0629887 Vali Loss: 1.0648299 Test Loss: 1.0524268
Validation loss decreased (inf --> 1.064830).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0632033
	speed: 0.0187s/iter; left time: 33.5151s
	iters: 200, epoch: 2 | loss: 1.0049115
	speed: 0.0157s/iter; left time: 26.6244s
Epoch: 2 cost time: 3.3119285106658936
Epoch: 2, Steps: 210 | Train Loss: 1.0450140 Vali Loss: 1.0655344 Test Loss: 1.0524417
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0509833
	speed: 0.0138s/iter; left time: 21.8740s
	iters: 200, epoch: 3 | loss: 1.0569525
	speed: 0.0131s/iter; left time: 19.3552s
Epoch: 3 cost time: 2.9129765033721924
Epoch: 3, Steps: 210 | Train Loss: 1.0387993 Vali Loss: 1.0635794 Test Loss: 1.0501727
Validation loss decreased (1.064830 --> 1.063579).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0206215
	speed: 0.0181s/iter; left time: 24.7639s
	iters: 200, epoch: 4 | loss: 1.0289205
	speed: 0.0193s/iter; left time: 24.4988s
Epoch: 4 cost time: 4.150683879852295
Epoch: 4, Steps: 210 | Train Loss: 1.0355228 Vali Loss: 1.0611777 Test Loss: 1.0508016
Validation loss decreased (1.063579 --> 1.061178).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0351527
	speed: 0.0184s/iter; left time: 21.3234s
	iters: 200, epoch: 5 | loss: 1.0052247
	speed: 0.0182s/iter; left time: 19.2838s
Epoch: 5 cost time: 3.9214940071105957
Epoch: 5, Steps: 210 | Train Loss: 1.0335522 Vali Loss: 1.0585275 Test Loss: 1.0501908
Validation loss decreased (1.061178 --> 1.058527).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0273993
	speed: 0.0229s/iter; left time: 21.7627s
	iters: 200, epoch: 6 | loss: 1.0576520
	speed: 0.0200s/iter; left time: 16.9866s
Epoch: 6 cost time: 4.184283018112183
Epoch: 6, Steps: 210 | Train Loss: 1.0317121 Vali Loss: 1.0603706 Test Loss: 1.0499810
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0139549
	speed: 0.0137s/iter; left time: 10.1642s
	iters: 200, epoch: 7 | loss: 1.0242119
	speed: 0.0128s/iter; left time: 8.1860s
Epoch: 7 cost time: 2.7798690795898438
Epoch: 7, Steps: 210 | Train Loss: 1.0313388 Vali Loss: 1.0580966 Test Loss: 1.0503002
Validation loss decreased (1.058527 --> 1.058097).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0029386
	speed: 0.0198s/iter; left time: 10.5185s
	iters: 200, epoch: 8 | loss: 1.0253134
	speed: 0.0177s/iter; left time: 7.6407s
Epoch: 8 cost time: 3.8338205814361572
Epoch: 8, Steps: 210 | Train Loss: 1.0309066 Vali Loss: 1.0605127 Test Loss: 1.0502151
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0025599
	speed: 0.0200s/iter; left time: 6.4173s
	iters: 200, epoch: 9 | loss: 1.0755675
	speed: 0.0176s/iter; left time: 3.8870s
Epoch: 9 cost time: 3.7392067909240723
Epoch: 9, Steps: 210 | Train Loss: 1.0305647 Vali Loss: 1.0600057 Test Loss: 1.0502203
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0247674
	speed: 0.0245s/iter; left time: 2.7215s
	iters: 200, epoch: 10 | loss: 1.0271622
	speed: 0.0218s/iter; left time: 0.2399s
Epoch: 10 cost time: 4.5963287353515625
Epoch: 10, Steps: 210 | Train Loss: 1.0305827 Vali Loss: 1.0615627 Test Loss: 1.0502443
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0503002405166626, mae:0.8221277594566345
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0643140
	speed: 0.0331s/iter; left time: 64.9663s
	iters: 200, epoch: 1 | loss: 1.0433924
	speed: 0.0228s/iter; left time: 42.3562s
Epoch: 1 cost time: 4.722594261169434
Epoch: 1, Steps: 206 | Train Loss: 1.0665964 Vali Loss: 1.0573993 Test Loss: 1.0421258
Validation loss decreased (inf --> 1.057399).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0394214
	speed: 0.0196s/iter; left time: 34.3138s
	iters: 200, epoch: 2 | loss: 1.0512893
	speed: 0.0185s/iter; left time: 30.5873s
Epoch: 2 cost time: 3.8358571529388428
Epoch: 2, Steps: 206 | Train Loss: 1.0504504 Vali Loss: 1.0554152 Test Loss: 1.0433573
Validation loss decreased (1.057399 --> 1.055415).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0271674
	speed: 0.0122s/iter; left time: 18.9236s
	iters: 200, epoch: 3 | loss: 1.0691458
	speed: 0.0103s/iter; left time: 14.9450s
Epoch: 3 cost time: 2.2405436038970947
Epoch: 3, Steps: 206 | Train Loss: 1.0451493 Vali Loss: 1.0536535 Test Loss: 1.0423250
Validation loss decreased (1.055415 --> 1.053653).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0804675
	speed: 0.0148s/iter; left time: 19.9048s
	iters: 200, epoch: 4 | loss: 1.0221972
	speed: 0.0135s/iter; left time: 16.7585s
Epoch: 4 cost time: 2.8579885959625244
Epoch: 4, Steps: 206 | Train Loss: 1.0423544 Vali Loss: 1.0514652 Test Loss: 1.0407704
Validation loss decreased (1.053653 --> 1.051465).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0276202
	speed: 0.0174s/iter; left time: 19.7950s
	iters: 200, epoch: 5 | loss: 1.0506904
	speed: 0.0156s/iter; left time: 16.1637s
Epoch: 5 cost time: 3.2983100414276123
Epoch: 5, Steps: 206 | Train Loss: 1.0403647 Vali Loss: 1.0504750 Test Loss: 1.0401269
Validation loss decreased (1.051465 --> 1.050475).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0367314
	speed: 0.0174s/iter; left time: 16.1530s
	iters: 200, epoch: 6 | loss: 1.0338674
	speed: 0.0166s/iter; left time: 13.7652s
Epoch: 6 cost time: 3.4625766277313232
Epoch: 6, Steps: 206 | Train Loss: 1.0395799 Vali Loss: 1.0508480 Test Loss: 1.0405982
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0481986
	speed: 0.0206s/iter; left time: 14.9657s
	iters: 200, epoch: 7 | loss: 1.0206152
	speed: 0.0155s/iter; left time: 9.6760s
Epoch: 7 cost time: 3.237602710723877
Epoch: 7, Steps: 206 | Train Loss: 1.0390607 Vali Loss: 1.0500730 Test Loss: 1.0403101
Validation loss decreased (1.050475 --> 1.050073).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0044992
	speed: 0.0222s/iter; left time: 11.5092s
	iters: 200, epoch: 8 | loss: 1.0422267
	speed: 0.0165s/iter; left time: 6.8933s
Epoch: 8 cost time: 3.4395132064819336
Epoch: 8, Steps: 206 | Train Loss: 1.0387417 Vali Loss: 1.0504837 Test Loss: 1.0405401
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0391135
	speed: 0.0197s/iter; left time: 6.1678s
	iters: 200, epoch: 9 | loss: 1.0453115
	speed: 0.0175s/iter; left time: 3.7326s
Epoch: 9 cost time: 3.6650125980377197
Epoch: 9, Steps: 206 | Train Loss: 1.0386017 Vali Loss: 1.0504084 Test Loss: 1.0404633
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0401918
	speed: 0.0201s/iter; left time: 2.1551s
	iters: 200, epoch: 10 | loss: 1.0363281
	speed: 0.0177s/iter; left time: 0.1237s
Epoch: 10 cost time: 3.7383413314819336
Epoch: 10, Steps: 206 | Train Loss: 1.0385549 Vali Loss: 1.0508004 Test Loss: 1.0405413
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040310263633728, mae:0.8191339373588562
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0483912
	speed: 0.0185s/iter; left time: 36.2285s
	iters: 200, epoch: 1 | loss: 1.0719701
	speed: 0.0152s/iter; left time: 28.2971s
Epoch: 1 cost time: 3.24014949798584
Epoch: 1, Steps: 206 | Train Loss: 1.0665705 Vali Loss: 1.0575035 Test Loss: 1.0421801
Validation loss decreased (inf --> 1.057503).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0688801
	speed: 0.0168s/iter; left time: 29.4484s
	iters: 200, epoch: 2 | loss: 1.0847890
	speed: 0.0160s/iter; left time: 26.5203s
Epoch: 2 cost time: 3.405682325363159
Epoch: 2, Steps: 206 | Train Loss: 1.0501141 Vali Loss: 1.0561918 Test Loss: 1.0436362
Validation loss decreased (1.057503 --> 1.056192).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0583202
	speed: 0.0160s/iter; left time: 24.7727s
	iters: 200, epoch: 3 | loss: 1.0487347
	speed: 0.0149s/iter; left time: 21.6224s
Epoch: 3 cost time: 3.1894426345825195
Epoch: 3, Steps: 206 | Train Loss: 1.0448806 Vali Loss: 1.0519497 Test Loss: 1.0403887
Validation loss decreased (1.056192 --> 1.051950).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0278924
	speed: 0.0167s/iter; left time: 22.3702s
	iters: 200, epoch: 4 | loss: 1.0664387
	speed: 0.0156s/iter; left time: 19.4429s
Epoch: 4 cost time: 3.30741548538208
Epoch: 4, Steps: 206 | Train Loss: 1.0422159 Vali Loss: 1.0530863 Test Loss: 1.0427561
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0551687
	speed: 0.0138s/iter; left time: 15.6350s
	iters: 200, epoch: 5 | loss: 1.0287378
	speed: 0.0124s/iter; left time: 12.8540s
Epoch: 5 cost time: 2.663024663925171
Epoch: 5, Steps: 206 | Train Loss: 1.0400192 Vali Loss: 1.0521383 Test Loss: 1.0414510
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0209025
	speed: 0.0125s/iter; left time: 11.6178s
	iters: 200, epoch: 6 | loss: 1.0311152
	speed: 0.0132s/iter; left time: 10.9783s
Epoch: 6 cost time: 2.7866458892822266
Epoch: 6, Steps: 206 | Train Loss: 1.0391964 Vali Loss: 1.0499684 Test Loss: 1.0398848
Validation loss decreased (1.051950 --> 1.049968).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0137398
	speed: 0.0151s/iter; left time: 10.9234s
	iters: 200, epoch: 7 | loss: 1.0287719
	speed: 0.0141s/iter; left time: 8.8036s
Epoch: 7 cost time: 3.0089144706726074
Epoch: 7, Steps: 206 | Train Loss: 1.0386128 Vali Loss: 1.0510254 Test Loss: 1.0408450
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0422934
	speed: 0.0176s/iter; left time: 9.1326s
	iters: 200, epoch: 8 | loss: 1.0394881
	speed: 0.0159s/iter; left time: 6.6674s
Epoch: 8 cost time: 3.3678529262542725
Epoch: 8, Steps: 206 | Train Loss: 1.0383805 Vali Loss: 1.0503367 Test Loss: 1.0406101
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0377673
	speed: 0.0173s/iter; left time: 5.4286s
	iters: 200, epoch: 9 | loss: 1.0598474
	speed: 0.0150s/iter; left time: 3.2031s
Epoch: 9 cost time: 3.163370132446289
Epoch: 9, Steps: 206 | Train Loss: 1.0383086 Vali Loss: 1.0509214 Test Loss: 1.0405825
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0472785
	speed: 0.0182s/iter; left time: 1.9511s
	iters: 200, epoch: 10 | loss: 1.0158314
	speed: 0.0171s/iter; left time: 0.1200s
Epoch: 10 cost time: 3.5787556171417236
Epoch: 10, Steps: 206 | Train Loss: 1.0381429 Vali Loss: 1.0505507 Test Loss: 1.0405604
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0398849248886108, mae:0.8189166188240051
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0474273
	speed: 0.0150s/iter; left time: 29.4545s
	iters: 200, epoch: 1 | loss: 1.0413231
	speed: 0.0117s/iter; left time: 21.8566s
Epoch: 1 cost time: 2.5078577995300293
Epoch: 1, Steps: 206 | Train Loss: 1.0662782 Vali Loss: 1.0595284 Test Loss: 1.0441779
Validation loss decreased (inf --> 1.059528).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0752918
	speed: 0.0159s/iter; left time: 27.9512s
	iters: 200, epoch: 2 | loss: 1.0677823
	speed: 0.0140s/iter; left time: 23.1165s
Epoch: 2 cost time: 3.0216822624206543
Epoch: 2, Steps: 206 | Train Loss: 1.0501630 Vali Loss: 1.0547622 Test Loss: 1.0418791
Validation loss decreased (1.059528 --> 1.054762).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0358770
	speed: 0.0230s/iter; left time: 35.6957s
	iters: 200, epoch: 3 | loss: 1.0444643
	speed: 0.0185s/iter; left time: 26.8136s
Epoch: 3 cost time: 3.8535332679748535
Epoch: 3, Steps: 206 | Train Loss: 1.0452525 Vali Loss: 1.0533447 Test Loss: 1.0419840
Validation loss decreased (1.054762 --> 1.053345).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0489968
	speed: 0.0162s/iter; left time: 21.7431s
	iters: 200, epoch: 4 | loss: 1.0169261
	speed: 0.0148s/iter; left time: 18.3366s
Epoch: 4 cost time: 3.1046864986419678
Epoch: 4, Steps: 206 | Train Loss: 1.0423670 Vali Loss: 1.0513403 Test Loss: 1.0406187
Validation loss decreased (1.053345 --> 1.051340).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0268108
	speed: 0.0136s/iter; left time: 15.4468s
	iters: 200, epoch: 5 | loss: 1.0367366
	speed: 0.0128s/iter; left time: 13.2957s
Epoch: 5 cost time: 2.7080209255218506
Epoch: 5, Steps: 206 | Train Loss: 1.0407768 Vali Loss: 1.0510904 Test Loss: 1.0412617
Validation loss decreased (1.051340 --> 1.051090).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0640188
	speed: 0.0177s/iter; left time: 16.5132s
	iters: 200, epoch: 6 | loss: 1.0310801
	speed: 0.0152s/iter; left time: 12.5913s
Epoch: 6 cost time: 3.2202136516571045
Epoch: 6, Steps: 206 | Train Loss: 1.0395745 Vali Loss: 1.0504854 Test Loss: 1.0406027
Validation loss decreased (1.051090 --> 1.050485).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0494741
	speed: 0.0207s/iter; left time: 14.9762s
	iters: 200, epoch: 7 | loss: 1.0244882
	speed: 0.0171s/iter; left time: 10.6883s
Epoch: 7 cost time: 3.6289663314819336
Epoch: 7, Steps: 206 | Train Loss: 1.0391588 Vali Loss: 1.0510926 Test Loss: 1.0405943
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0473880
	speed: 0.0184s/iter; left time: 9.5637s
	iters: 200, epoch: 8 | loss: 1.0454341
	speed: 0.0179s/iter; left time: 7.4943s
Epoch: 8 cost time: 3.799381732940674
Epoch: 8, Steps: 206 | Train Loss: 1.0381012 Vali Loss: 1.0506173 Test Loss: 1.0407858
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0670705
	speed: 0.0149s/iter; left time: 4.6632s
	iters: 200, epoch: 9 | loss: 1.0454341
	speed: 0.0134s/iter; left time: 2.8441s
Epoch: 9 cost time: 2.847769260406494
Epoch: 9, Steps: 206 | Train Loss: 1.0386518 Vali Loss: 1.0506930 Test Loss: 1.0408621
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0506040
	speed: 0.0198s/iter; left time: 2.1176s
	iters: 200, epoch: 10 | loss: 1.0162994
	speed: 0.0203s/iter; left time: 0.1424s
Epoch: 10 cost time: 4.308849334716797
Epoch: 10, Steps: 206 | Train Loss: 1.0383223 Vali Loss: 1.0509428 Test Loss: 1.0408833
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040602684020996, mae:0.8192589282989502
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0419041
	speed: 0.0251s/iter; left time: 46.2437s
Epoch: 1 cost time: 3.7166574001312256
Epoch: 1, Steps: 194 | Train Loss: 1.0722772 Vali Loss: 1.0498549 Test Loss: 1.0411083
Validation loss decreased (inf --> 1.049855).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0668539
	speed: 0.0201s/iter; left time: 33.0404s
Epoch: 2 cost time: 3.408569812774658
Epoch: 2, Steps: 194 | Train Loss: 1.0561909 Vali Loss: 1.0488381 Test Loss: 1.0441380
Validation loss decreased (1.049855 --> 1.048838).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0393900
	speed: 0.0182s/iter; left time: 26.4425s
Epoch: 3 cost time: 3.3032495975494385
Epoch: 3, Steps: 194 | Train Loss: 1.0525922 Vali Loss: 1.0458077 Test Loss: 1.0403417
Validation loss decreased (1.048838 --> 1.045808).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0604454
	speed: 0.0163s/iter; left time: 20.5243s
Epoch: 4 cost time: 3.4887547492980957
Epoch: 4, Steps: 194 | Train Loss: 1.0500863 Vali Loss: 1.0438130 Test Loss: 1.0406491
Validation loss decreased (1.045808 --> 1.043813).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0503985
	speed: 0.0169s/iter; left time: 17.9589s
Epoch: 5 cost time: 2.829258441925049
Epoch: 5, Steps: 194 | Train Loss: 1.0487458 Vali Loss: 1.0449573 Test Loss: 1.0384172
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0390748
	speed: 0.0132s/iter; left time: 11.4830s
Epoch: 6 cost time: 2.4531848430633545
Epoch: 6, Steps: 194 | Train Loss: 1.0485411 Vali Loss: 1.0435889 Test Loss: 1.0404075
Validation loss decreased (1.043813 --> 1.043589).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0407127
	speed: 0.0183s/iter; left time: 12.4177s
Epoch: 7 cost time: 3.477923631668091
Epoch: 7, Steps: 194 | Train Loss: 1.0478175 Vali Loss: 1.0436645 Test Loss: 1.0396794
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0531089
	speed: 0.0167s/iter; left time: 8.0858s
Epoch: 8 cost time: 3.0288496017456055
Epoch: 8, Steps: 194 | Train Loss: 1.0476455 Vali Loss: 1.0434200 Test Loss: 1.0397197
Validation loss decreased (1.043589 --> 1.043420).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0187680
	speed: 0.0188s/iter; left time: 5.4378s
Epoch: 9 cost time: 3.004389762878418
Epoch: 9, Steps: 194 | Train Loss: 1.0475291 Vali Loss: 1.0437000 Test Loss: 1.0397360
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0441345
	speed: 0.0156s/iter; left time: 1.4838s
Epoch: 10 cost time: 2.5041024684906006
Epoch: 10, Steps: 194 | Train Loss: 1.0474198 Vali Loss: 1.0434573 Test Loss: 1.0397168
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0397194623947144, mae:0.8182249069213867
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0370927
	speed: 0.0209s/iter; left time: 38.5209s
Epoch: 1 cost time: 3.3183910846710205
Epoch: 1, Steps: 194 | Train Loss: 1.0732493 Vali Loss: 1.0492508 Test Loss: 1.0466771
Validation loss decreased (inf --> 1.049251).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0668659
	speed: 0.0218s/iter; left time: 35.9004s
Epoch: 2 cost time: 3.661478281021118
Epoch: 2, Steps: 194 | Train Loss: 1.0565215 Vali Loss: 1.0481949 Test Loss: 1.0428513
Validation loss decreased (1.049251 --> 1.048195).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0891743
	speed: 0.0205s/iter; left time: 29.7322s
Epoch: 3 cost time: 3.509493350982666
Epoch: 3, Steps: 194 | Train Loss: 1.0524034 Vali Loss: 1.0450059 Test Loss: 1.0421764
Validation loss decreased (1.048195 --> 1.045006).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0696449
	speed: 0.0233s/iter; left time: 29.3266s
Epoch: 4 cost time: 3.6110801696777344
Epoch: 4, Steps: 194 | Train Loss: 1.0502880 Vali Loss: 1.0444607 Test Loss: 1.0409756
Validation loss decreased (1.045006 --> 1.044461).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0505719
	speed: 0.0142s/iter; left time: 15.1193s
Epoch: 5 cost time: 2.6165308952331543
Epoch: 5, Steps: 194 | Train Loss: 1.0487436 Vali Loss: 1.0429876 Test Loss: 1.0409112
Validation loss decreased (1.044461 --> 1.042988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0577164
	speed: 0.0275s/iter; left time: 23.9732s
Epoch: 6 cost time: 4.234111309051514
Epoch: 6, Steps: 194 | Train Loss: 1.0482073 Vali Loss: 1.0447555 Test Loss: 1.0390291
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0608650
	speed: 0.0286s/iter; left time: 19.3736s
Epoch: 7 cost time: 4.363842248916626
Epoch: 7, Steps: 194 | Train Loss: 1.0477852 Vali Loss: 1.0434592 Test Loss: 1.0398495
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0456696
	speed: 0.0150s/iter; left time: 7.2367s
Epoch: 8 cost time: 2.929142951965332
Epoch: 8, Steps: 194 | Train Loss: 1.0477234 Vali Loss: 1.0432070 Test Loss: 1.0397284
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0578381
	speed: 0.0129s/iter; left time: 3.7223s
Epoch: 9 cost time: 2.399603843688965
Epoch: 9, Steps: 194 | Train Loss: 1.0474373 Vali Loss: 1.0436101 Test Loss: 1.0396777
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0215069
	speed: 0.0125s/iter; left time: 1.1908s
Epoch: 10 cost time: 2.0778849124908447
Epoch: 10, Steps: 194 | Train Loss: 1.0475143 Vali Loss: 1.0437802 Test Loss: 1.0396353
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040911078453064, mae:0.8186979293823242
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0369772
	speed: 0.0204s/iter; left time: 37.6468s
Epoch: 1 cost time: 3.690293073654175
Epoch: 1, Steps: 194 | Train Loss: 1.0733757 Vali Loss: 1.0508202 Test Loss: 1.0430901
Validation loss decreased (inf --> 1.050820).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0649399
	speed: 0.0201s/iter; left time: 33.1224s
Epoch: 2 cost time: 3.5132408142089844
Epoch: 2, Steps: 194 | Train Loss: 1.0560027 Vali Loss: 1.0474318 Test Loss: 1.0407470
Validation loss decreased (1.050820 --> 1.047432).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0371070
	speed: 0.0182s/iter; left time: 26.3902s
Epoch: 3 cost time: 3.3002002239227295
Epoch: 3, Steps: 194 | Train Loss: 1.0522341 Vali Loss: 1.0449268 Test Loss: 1.0423537
Validation loss decreased (1.047432 --> 1.044927).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0774647
	speed: 0.0191s/iter; left time: 24.0697s
Epoch: 4 cost time: 3.2174935340881348
Epoch: 4, Steps: 194 | Train Loss: 1.0501613 Vali Loss: 1.0435750 Test Loss: 1.0397075
Validation loss decreased (1.044927 --> 1.043575).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0552962
	speed: 0.0139s/iter; left time: 14.8285s
Epoch: 5 cost time: 2.3784825801849365
Epoch: 5, Steps: 194 | Train Loss: 1.0488631 Vali Loss: 1.0441678 Test Loss: 1.0397111
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0446891
	speed: 0.0149s/iter; left time: 12.9861s
Epoch: 6 cost time: 2.7960197925567627
Epoch: 6, Steps: 194 | Train Loss: 1.0483319 Vali Loss: 1.0444144 Test Loss: 1.0390928
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0537642
	speed: 0.0141s/iter; left time: 9.5505s
Epoch: 7 cost time: 2.4969937801361084
Epoch: 7, Steps: 194 | Train Loss: 1.0479160 Vali Loss: 1.0438876 Test Loss: 1.0397737
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0291677
	speed: 0.0188s/iter; left time: 9.0677s
Epoch: 8 cost time: 3.2196316719055176
Epoch: 8, Steps: 194 | Train Loss: 1.0475862 Vali Loss: 1.0441313 Test Loss: 1.0395387
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0563470
	speed: 0.0167s/iter; left time: 4.8326s
Epoch: 9 cost time: 3.3664567470550537
Epoch: 9, Steps: 194 | Train Loss: 1.0475600 Vali Loss: 1.0440558 Test Loss: 1.0395499
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0397076606750488, mae:0.8181965947151184
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0481243
	speed: 0.0278s/iter; left time: 56.4505s
	iters: 200, epoch: 1 | loss: 1.0470674
	speed: 0.0230s/iter; left time: 44.3449s
Epoch: 1 cost time: 4.979864597320557
Epoch: 1, Steps: 213 | Train Loss: 1.0600713 Vali Loss: 1.0554726 Test Loss: 1.0460736
Validation loss decreased (inf --> 1.055473).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0119157
	speed: 0.0222s/iter; left time: 40.4410s
	iters: 200, epoch: 2 | loss: 1.0455403
	speed: 0.0188s/iter; left time: 32.3028s
Epoch: 2 cost time: 4.093426704406738
Epoch: 2, Steps: 213 | Train Loss: 1.0390990 Vali Loss: 1.0570294 Test Loss: 1.0464483
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0620451
	speed: 0.0193s/iter; left time: 30.9561s
	iters: 200, epoch: 3 | loss: 1.0606240
	speed: 0.0179s/iter; left time: 26.9702s
Epoch: 3 cost time: 3.8151450157165527
Epoch: 3, Steps: 213 | Train Loss: 1.0314479 Vali Loss: 1.0532843 Test Loss: 1.0426273
Validation loss decreased (1.055473 --> 1.053284).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0079391
	speed: 0.0171s/iter; left time: 23.8715s
	iters: 200, epoch: 4 | loss: 1.0487826
	speed: 0.0139s/iter; left time: 17.9762s
Epoch: 4 cost time: 3.030034065246582
Epoch: 4, Steps: 213 | Train Loss: 1.0276419 Vali Loss: 1.0531238 Test Loss: 1.0424960
Validation loss decreased (1.053284 --> 1.053124).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0580688
	speed: 0.0164s/iter; left time: 19.3332s
	iters: 200, epoch: 5 | loss: 0.9876036
	speed: 0.0139s/iter; left time: 14.9744s
Epoch: 5 cost time: 3.066531181335449
Epoch: 5, Steps: 213 | Train Loss: 1.0247919 Vali Loss: 1.0544332 Test Loss: 1.0416534
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0636839
	speed: 0.0205s/iter; left time: 19.7834s
	iters: 200, epoch: 6 | loss: 1.0111105
	speed: 0.0157s/iter; left time: 13.5789s
Epoch: 6 cost time: 3.458939790725708
Epoch: 6, Steps: 213 | Train Loss: 1.0235094 Vali Loss: 1.0522662 Test Loss: 1.0415609
Validation loss decreased (1.053124 --> 1.052266).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0177801
	speed: 0.0177s/iter; left time: 13.3358s
	iters: 200, epoch: 7 | loss: 1.0930521
	speed: 0.0189s/iter; left time: 12.3445s
Epoch: 7 cost time: 4.054624080657959
Epoch: 7, Steps: 213 | Train Loss: 1.0225339 Vali Loss: 1.0544814 Test Loss: 1.0417043
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0351219
	speed: 0.0127s/iter; left time: 6.8603s
	iters: 200, epoch: 8 | loss: 0.9870185
	speed: 0.0113s/iter; left time: 4.9725s
Epoch: 8 cost time: 2.5948679447174072
Epoch: 8, Steps: 213 | Train Loss: 1.0219844 Vali Loss: 1.0531467 Test Loss: 1.0417000
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0208607
	speed: 0.0179s/iter; left time: 5.8585s
	iters: 200, epoch: 9 | loss: 0.9680330
	speed: 0.0162s/iter; left time: 3.6682s
Epoch: 9 cost time: 3.5041050910949707
Epoch: 9, Steps: 213 | Train Loss: 1.0222029 Vali Loss: 1.0534189 Test Loss: 1.0417483
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0297288
	speed: 0.0163s/iter; left time: 1.8580s
	iters: 200, epoch: 10 | loss: 1.0831399
	speed: 0.0147s/iter; left time: 0.2064s
Epoch: 10 cost time: 3.271237850189209
Epoch: 10, Steps: 213 | Train Loss: 1.0218933 Vali Loss: 1.0545095 Test Loss: 1.0417737
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0415608882904053, mae:0.8191267251968384
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0797390
	speed: 0.0175s/iter; left time: 35.5471s
	iters: 200, epoch: 1 | loss: 1.0369380
	speed: 0.0152s/iter; left time: 29.3834s
Epoch: 1 cost time: 3.2770137786865234
Epoch: 1, Steps: 213 | Train Loss: 1.0609038 Vali Loss: 1.0606593 Test Loss: 1.0461323
Validation loss decreased (inf --> 1.060659).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0384398
	speed: 0.0230s/iter; left time: 41.7835s
	iters: 200, epoch: 2 | loss: 1.0874178
	speed: 0.0177s/iter; left time: 30.4576s
Epoch: 2 cost time: 3.9479594230651855
Epoch: 2, Steps: 213 | Train Loss: 1.0394446 Vali Loss: 1.0595009 Test Loss: 1.0471255
Validation loss decreased (1.060659 --> 1.059501).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0524069
	speed: 0.0228s/iter; left time: 36.5339s
	iters: 200, epoch: 3 | loss: 1.0595968
	speed: 0.0181s/iter; left time: 27.1983s
Epoch: 3 cost time: 4.09825325012207
Epoch: 3, Steps: 213 | Train Loss: 1.0319957 Vali Loss: 1.0591260 Test Loss: 1.0440849
Validation loss decreased (1.059501 --> 1.059126).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0665541
	speed: 0.0142s/iter; left time: 19.7776s
	iters: 200, epoch: 4 | loss: 1.0397992
	speed: 0.0144s/iter; left time: 18.5853s
Epoch: 4 cost time: 3.1322672367095947
Epoch: 4, Steps: 213 | Train Loss: 1.0282695 Vali Loss: 1.0545421 Test Loss: 1.0416051
Validation loss decreased (1.059126 --> 1.054542).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0465840
	speed: 0.0174s/iter; left time: 20.5109s
	iters: 200, epoch: 5 | loss: 1.0145270
	speed: 0.0143s/iter; left time: 15.4028s
Epoch: 5 cost time: 3.078007221221924
Epoch: 5, Steps: 213 | Train Loss: 1.0251086 Vali Loss: 1.0515352 Test Loss: 1.0415417
Validation loss decreased (1.054542 --> 1.051535).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0080645
	speed: 0.0185s/iter; left time: 17.8563s
	iters: 200, epoch: 6 | loss: 0.9911579
	speed: 0.0194s/iter; left time: 16.8378s
Epoch: 6 cost time: 4.206000804901123
Epoch: 6, Steps: 213 | Train Loss: 1.0238898 Vali Loss: 1.0534042 Test Loss: 1.0414404
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0015649
	speed: 0.0173s/iter; left time: 12.9937s
	iters: 200, epoch: 7 | loss: 0.9725961
	speed: 0.0160s/iter; left time: 10.4687s
Epoch: 7 cost time: 3.6427414417266846
Epoch: 7, Steps: 213 | Train Loss: 1.0231663 Vali Loss: 1.0525033 Test Loss: 1.0414237
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9920437
	speed: 0.0173s/iter; left time: 9.3559s
	iters: 200, epoch: 8 | loss: 1.0029457
	speed: 0.0177s/iter; left time: 7.7790s
Epoch: 8 cost time: 3.8454532623291016
Epoch: 8, Steps: 213 | Train Loss: 1.0225634 Vali Loss: 1.0552888 Test Loss: 1.0414208
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0085254
	speed: 0.0155s/iter; left time: 5.0527s
	iters: 200, epoch: 9 | loss: 1.0300796
	speed: 0.0139s/iter; left time: 3.1511s
Epoch: 9 cost time: 3.086116313934326
Epoch: 9, Steps: 213 | Train Loss: 1.0218454 Vali Loss: 1.0520535 Test Loss: 1.0414612
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0691755
	speed: 0.0201s/iter; left time: 2.2912s
	iters: 200, epoch: 10 | loss: 1.0011406
	speed: 0.0212s/iter; left time: 0.2971s
Epoch: 10 cost time: 4.549637079238892
Epoch: 10, Steps: 213 | Train Loss: 1.0220205 Vali Loss: 1.0546362 Test Loss: 1.0414776
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0415416955947876, mae:0.8190866708755493
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0699515
	speed: 0.0238s/iter; left time: 48.2801s
	iters: 200, epoch: 1 | loss: 1.0635641
	speed: 0.0186s/iter; left time: 35.9820s
Epoch: 1 cost time: 3.9488298892974854
Epoch: 1, Steps: 213 | Train Loss: 1.0610656 Vali Loss: 1.0592427 Test Loss: 1.0474927
Validation loss decreased (inf --> 1.059243).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0461721
	speed: 0.0154s/iter; left time: 28.0340s
	iters: 200, epoch: 2 | loss: 1.0550399
	speed: 0.0126s/iter; left time: 21.6148s
Epoch: 2 cost time: 2.743600606918335
Epoch: 2, Steps: 213 | Train Loss: 1.0386402 Vali Loss: 1.0595138 Test Loss: 1.0467708
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0323278
	speed: 0.0126s/iter; left time: 20.2181s
	iters: 200, epoch: 3 | loss: 1.0095675
	speed: 0.0130s/iter; left time: 19.6391s
Epoch: 3 cost time: 2.8348817825317383
Epoch: 3, Steps: 213 | Train Loss: 1.0321936 Vali Loss: 1.0556289 Test Loss: 1.0433747
Validation loss decreased (1.059243 --> 1.055629).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9961319
	speed: 0.0167s/iter; left time: 23.2757s
	iters: 200, epoch: 4 | loss: 1.0384316
	speed: 0.0149s/iter; left time: 19.2449s
Epoch: 4 cost time: 3.2295405864715576
Epoch: 4, Steps: 213 | Train Loss: 1.0276744 Vali Loss: 1.0543094 Test Loss: 1.0418819
Validation loss decreased (1.055629 --> 1.054309).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0741123
	speed: 0.0171s/iter; left time: 20.1035s
	iters: 200, epoch: 5 | loss: 1.0225005
	speed: 0.0159s/iter; left time: 17.1966s
Epoch: 5 cost time: 3.399672746658325
Epoch: 5, Steps: 213 | Train Loss: 1.0252161 Vali Loss: 1.0515288 Test Loss: 1.0414187
Validation loss decreased (1.054309 --> 1.051529).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0243692
	speed: 0.0206s/iter; left time: 19.9417s
	iters: 200, epoch: 6 | loss: 1.0237197
	speed: 0.0158s/iter; left time: 13.6754s
Epoch: 6 cost time: 3.3844680786132812
Epoch: 6, Steps: 213 | Train Loss: 1.0233894 Vali Loss: 1.0531315 Test Loss: 1.0414087
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9812819
	speed: 0.0149s/iter; left time: 11.2530s
	iters: 200, epoch: 7 | loss: 0.9979635
	speed: 0.0148s/iter; left time: 9.6603s
Epoch: 7 cost time: 3.289449453353882
Epoch: 7, Steps: 213 | Train Loss: 1.0232488 Vali Loss: 1.0551164 Test Loss: 1.0414115
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0877653
	speed: 0.0206s/iter; left time: 11.0996s
	iters: 200, epoch: 8 | loss: 1.0328612
	speed: 0.0226s/iter; left time: 9.9325s
Epoch: 8 cost time: 4.777580738067627
Epoch: 8, Steps: 213 | Train Loss: 1.0222719 Vali Loss: 1.0520786 Test Loss: 1.0414976
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0103846
	speed: 0.0246s/iter; left time: 8.0574s
	iters: 200, epoch: 9 | loss: 1.0180500
	speed: 0.0179s/iter; left time: 4.0745s
Epoch: 9 cost time: 3.8230371475219727
Epoch: 9, Steps: 213 | Train Loss: 1.0219400 Vali Loss: 1.0538416 Test Loss: 1.0415205
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0144083
	speed: 0.0164s/iter; left time: 1.8697s
	iters: 200, epoch: 10 | loss: 0.9865109
	speed: 0.0134s/iter; left time: 0.1870s
Epoch: 10 cost time: 2.888962507247925
Epoch: 10, Steps: 213 | Train Loss: 1.0220714 Vali Loss: 1.0522735 Test Loss: 1.0415397
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0414186716079712, mae:0.8189550042152405
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0416386
	speed: 0.0267s/iter; left time: 53.4331s
	iters: 200, epoch: 1 | loss: 1.0138969
	speed: 0.0220s/iter; left time: 41.8130s
Epoch: 1 cost time: 4.634988784790039
Epoch: 1, Steps: 210 | Train Loss: 1.0626957 Vali Loss: 1.0651575 Test Loss: 1.0529757
Validation loss decreased (inf --> 1.065158).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0488732
	speed: 0.0166s/iter; left time: 29.7331s
	iters: 200, epoch: 2 | loss: 1.0362756
	speed: 0.0142s/iter; left time: 23.9458s
Epoch: 2 cost time: 3.048912525177002
Epoch: 2, Steps: 210 | Train Loss: 1.0454364 Vali Loss: 1.0653955 Test Loss: 1.0528531
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0145775
	speed: 0.0159s/iter; left time: 25.1657s
	iters: 200, epoch: 3 | loss: 1.0119845
	speed: 0.0132s/iter; left time: 19.5704s
Epoch: 3 cost time: 2.816481828689575
Epoch: 3, Steps: 210 | Train Loss: 1.0392240 Vali Loss: 1.0630151 Test Loss: 1.0498189
Validation loss decreased (1.065158 --> 1.063015).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0426264
	speed: 0.0155s/iter; left time: 21.3053s
	iters: 200, epoch: 4 | loss: 1.0382522
	speed: 0.0142s/iter; left time: 18.0939s
Epoch: 4 cost time: 3.178567409515381
Epoch: 4, Steps: 210 | Train Loss: 1.0362356 Vali Loss: 1.0619223 Test Loss: 1.0497789
Validation loss decreased (1.063015 --> 1.061922).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0284171
	speed: 0.0192s/iter; left time: 22.3131s
	iters: 200, epoch: 5 | loss: 1.0397322
	speed: 0.0190s/iter; left time: 20.2072s
Epoch: 5 cost time: 4.038572788238525
Epoch: 5, Steps: 210 | Train Loss: 1.0337273 Vali Loss: 1.0583497 Test Loss: 1.0500692
Validation loss decreased (1.061922 --> 1.058350).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0263400
	speed: 0.0199s/iter; left time: 18.9557s
	iters: 200, epoch: 6 | loss: 1.0465149
	speed: 0.0179s/iter; left time: 15.1933s
Epoch: 6 cost time: 3.8372907638549805
Epoch: 6, Steps: 210 | Train Loss: 1.0323723 Vali Loss: 1.0584416 Test Loss: 1.0496629
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0390638
	speed: 0.0134s/iter; left time: 9.9306s
	iters: 200, epoch: 7 | loss: 1.0608093
	speed: 0.0112s/iter; left time: 7.2093s
Epoch: 7 cost time: 2.4411067962646484
Epoch: 7, Steps: 210 | Train Loss: 1.0315235 Vali Loss: 1.0597415 Test Loss: 1.0496715
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9871825
	speed: 0.0165s/iter; left time: 8.7740s
	iters: 200, epoch: 8 | loss: 0.9856896
	speed: 0.0152s/iter; left time: 6.5715s
Epoch: 8 cost time: 3.240539312362671
Epoch: 8, Steps: 210 | Train Loss: 1.0313189 Vali Loss: 1.0573145 Test Loss: 1.0497820
Validation loss decreased (1.058350 --> 1.057315).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0406343
	speed: 0.0149s/iter; left time: 4.7738s
	iters: 200, epoch: 9 | loss: 1.0232768
	speed: 0.0204s/iter; left time: 4.5149s
Epoch: 9 cost time: 4.530097961425781
Epoch: 9, Steps: 210 | Train Loss: 1.0313026 Vali Loss: 1.0615882 Test Loss: 1.0498544
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0444350
	speed: 0.0190s/iter; left time: 2.1140s
	iters: 200, epoch: 10 | loss: 1.0347650
	speed: 0.0202s/iter; left time: 0.2226s
Epoch: 10 cost time: 4.191890716552734
Epoch: 10, Steps: 210 | Train Loss: 1.0311622 Vali Loss: 1.0595692 Test Loss: 1.0498775
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0497820377349854, mae:0.8220049738883972
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0551056
	speed: 0.0160s/iter; left time: 31.9697s
	iters: 200, epoch: 1 | loss: 1.0358175
	speed: 0.0124s/iter; left time: 23.5448s
Epoch: 1 cost time: 2.6372013092041016
Epoch: 1, Steps: 210 | Train Loss: 1.0638229 Vali Loss: 1.0694132 Test Loss: 1.0524622
Validation loss decreased (inf --> 1.069413).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0905924
	speed: 0.0177s/iter; left time: 31.7431s
	iters: 200, epoch: 2 | loss: 1.0333589
	speed: 0.0158s/iter; left time: 26.7231s
Epoch: 2 cost time: 3.4114999771118164
Epoch: 2, Steps: 210 | Train Loss: 1.0456654 Vali Loss: 1.0610811 Test Loss: 1.0511881
Validation loss decreased (1.069413 --> 1.061081).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0408685
	speed: 0.0202s/iter; left time: 31.9389s
	iters: 200, epoch: 3 | loss: 1.0618311
	speed: 0.0171s/iter; left time: 25.3506s
Epoch: 3 cost time: 3.5967416763305664
Epoch: 3, Steps: 210 | Train Loss: 1.0392090 Vali Loss: 1.0602006 Test Loss: 1.0503820
Validation loss decreased (1.061081 --> 1.060201).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0087888
	speed: 0.0198s/iter; left time: 27.1364s
	iters: 200, epoch: 4 | loss: 1.0557244
	speed: 0.0180s/iter; left time: 22.8211s
Epoch: 4 cost time: 3.7928738594055176
Epoch: 4, Steps: 210 | Train Loss: 1.0354768 Vali Loss: 1.0602206 Test Loss: 1.0505130
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0105509
	speed: 0.0179s/iter; left time: 20.8123s
	iters: 200, epoch: 5 | loss: 1.0418646
	speed: 0.0160s/iter; left time: 16.9823s
Epoch: 5 cost time: 3.44468355178833
Epoch: 5, Steps: 210 | Train Loss: 1.0338349 Vali Loss: 1.0610231 Test Loss: 1.0501660
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0350186
	speed: 0.0215s/iter; left time: 20.4655s
	iters: 200, epoch: 6 | loss: 1.0310068
	speed: 0.0193s/iter; left time: 16.3822s
Epoch: 6 cost time: 4.066835641860962
Epoch: 6, Steps: 210 | Train Loss: 1.0323415 Vali Loss: 1.0590858 Test Loss: 1.0499498
Validation loss decreased (1.060201 --> 1.059086).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0259230
	speed: 0.0177s/iter; left time: 13.0863s
	iters: 200, epoch: 7 | loss: 1.0303583
	speed: 0.0163s/iter; left time: 10.4340s
Epoch: 7 cost time: 3.521432399749756
Epoch: 7, Steps: 210 | Train Loss: 1.0317451 Vali Loss: 1.0607904 Test Loss: 1.0499191
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0293562
	speed: 0.0235s/iter; left time: 12.4761s
	iters: 200, epoch: 8 | loss: 1.0124468
	speed: 0.0224s/iter; left time: 9.6626s
Epoch: 8 cost time: 4.690475702285767
Epoch: 8, Steps: 210 | Train Loss: 1.0311042 Vali Loss: 1.0602285 Test Loss: 1.0499849
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0247052
	speed: 0.0165s/iter; left time: 5.2892s
	iters: 200, epoch: 9 | loss: 1.0375962
	speed: 0.0154s/iter; left time: 3.4024s
Epoch: 9 cost time: 3.298916816711426
Epoch: 9, Steps: 210 | Train Loss: 1.0308271 Vali Loss: 1.0577600 Test Loss: 1.0500653
Validation loss decreased (1.059086 --> 1.057760).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0527302
	speed: 0.0196s/iter; left time: 2.1809s
	iters: 200, epoch: 10 | loss: 1.0440526
	speed: 0.0174s/iter; left time: 0.1917s
Epoch: 10 cost time: 3.7369775772094727
Epoch: 10, Steps: 210 | Train Loss: 1.0306113 Vali Loss: 1.0613186 Test Loss: 1.0500971
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0500649213790894, mae:0.821997344493866
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0375134
	speed: 0.0168s/iter; left time: 33.5313s
	iters: 200, epoch: 1 | loss: 1.0476692
	speed: 0.0154s/iter; left time: 29.2284s
Epoch: 1 cost time: 3.340845823287964
Epoch: 1, Steps: 210 | Train Loss: 1.0620076 Vali Loss: 1.0675745 Test Loss: 1.0531200
Validation loss decreased (inf --> 1.067575).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0307958
	speed: 0.0190s/iter; left time: 33.9786s
	iters: 200, epoch: 2 | loss: 1.0805302
	speed: 0.0165s/iter; left time: 27.9015s
Epoch: 2 cost time: 3.5577235221862793
Epoch: 2, Steps: 210 | Train Loss: 1.0449206 Vali Loss: 1.0649413 Test Loss: 1.0522337
Validation loss decreased (1.067575 --> 1.064941).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9985033
	speed: 0.0127s/iter; left time: 20.0888s
	iters: 200, epoch: 3 | loss: 1.0474964
	speed: 0.0114s/iter; left time: 16.8303s
Epoch: 3 cost time: 2.41190242767334
Epoch: 3, Steps: 210 | Train Loss: 1.0390817 Vali Loss: 1.0619057 Test Loss: 1.0502515
Validation loss decreased (1.064941 --> 1.061906).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0279188
	speed: 0.0123s/iter; left time: 16.8829s
	iters: 200, epoch: 4 | loss: 1.0451255
	speed: 0.0106s/iter; left time: 13.4882s
Epoch: 4 cost time: 2.2796642780303955
Epoch: 4, Steps: 210 | Train Loss: 1.0358408 Vali Loss: 1.0596669 Test Loss: 1.0496545
Validation loss decreased (1.061906 --> 1.059667).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0743847
	speed: 0.0116s/iter; left time: 13.4369s
	iters: 200, epoch: 5 | loss: 1.0318427
	speed: 0.0104s/iter; left time: 11.0338s
Epoch: 5 cost time: 2.237705707550049
Epoch: 5, Steps: 210 | Train Loss: 1.0332641 Vali Loss: 1.0591995 Test Loss: 1.0498642
Validation loss decreased (1.059667 --> 1.059199).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0480103
	speed: 0.0366s/iter; left time: 34.8198s
	iters: 200, epoch: 6 | loss: 1.0094759
	speed: 0.0288s/iter; left time: 24.5266s
Epoch: 6 cost time: 6.01544189453125
Epoch: 6, Steps: 210 | Train Loss: 1.0324696 Vali Loss: 1.0591061 Test Loss: 1.0499506
Validation loss decreased (1.059199 --> 1.059106).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0198811
	speed: 0.0147s/iter; left time: 10.8788s
	iters: 200, epoch: 7 | loss: 1.0059884
	speed: 0.0132s/iter; left time: 8.4653s
Epoch: 7 cost time: 2.8172175884246826
Epoch: 7, Steps: 210 | Train Loss: 1.0316242 Vali Loss: 1.0579728 Test Loss: 1.0498441
Validation loss decreased (1.059106 --> 1.057973).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0121114
	speed: 0.0218s/iter; left time: 11.5888s
	iters: 200, epoch: 8 | loss: 1.0169163
	speed: 0.0173s/iter; left time: 7.4649s
Epoch: 8 cost time: 3.6202802658081055
Epoch: 8, Steps: 210 | Train Loss: 1.0312156 Vali Loss: 1.0610518 Test Loss: 1.0500376
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0462711
	speed: 0.0216s/iter; left time: 6.9450s
	iters: 200, epoch: 9 | loss: 1.0404201
	speed: 0.0184s/iter; left time: 4.0705s
Epoch: 9 cost time: 3.9167423248291016
Epoch: 9, Steps: 210 | Train Loss: 1.0311395 Vali Loss: 1.0608207 Test Loss: 1.0500048
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0217068
	speed: 0.0231s/iter; left time: 2.5627s
	iters: 200, epoch: 10 | loss: 1.0170493
	speed: 0.0179s/iter; left time: 0.1966s
Epoch: 10 cost time: 3.810824394226074
Epoch: 10, Steps: 210 | Train Loss: 1.0307071 Vali Loss: 1.0605655 Test Loss: 1.0500290
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0498443841934204, mae:0.8219958543777466
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0666121
	speed: 0.0274s/iter; left time: 53.8129s
	iters: 200, epoch: 1 | loss: 1.0577093
	speed: 0.0202s/iter; left time: 37.5917s
Epoch: 1 cost time: 4.2175822257995605
Epoch: 1, Steps: 206 | Train Loss: 1.0662911 Vali Loss: 1.0562967 Test Loss: 1.0414355
Validation loss decreased (inf --> 1.056297).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0525959
	speed: 0.0145s/iter; left time: 25.5134s
	iters: 200, epoch: 2 | loss: 1.0531265
	speed: 0.0140s/iter; left time: 23.0880s
Epoch: 2 cost time: 2.9382364749908447
Epoch: 2, Steps: 206 | Train Loss: 1.0504998 Vali Loss: 1.0559680 Test Loss: 1.0424862
Validation loss decreased (1.056297 --> 1.055968).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0464053
	speed: 0.0146s/iter; left time: 22.6571s
	iters: 200, epoch: 3 | loss: 1.0501848
	speed: 0.0117s/iter; left time: 16.9518s
Epoch: 3 cost time: 2.46262264251709
Epoch: 3, Steps: 206 | Train Loss: 1.0453999 Vali Loss: 1.0523841 Test Loss: 1.0414219
Validation loss decreased (1.055968 --> 1.052384).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0495334
	speed: 0.0221s/iter; left time: 29.6298s
	iters: 200, epoch: 4 | loss: 1.0346154
	speed: 0.0173s/iter; left time: 21.4751s
Epoch: 4 cost time: 3.6772098541259766
Epoch: 4, Steps: 206 | Train Loss: 1.0425648 Vali Loss: 1.0503519 Test Loss: 1.0399356
Validation loss decreased (1.052384 --> 1.050352).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0456309
	speed: 0.0219s/iter; left time: 24.8654s
	iters: 200, epoch: 5 | loss: 1.0182372
	speed: 0.0179s/iter; left time: 18.5337s
Epoch: 5 cost time: 3.832725763320923
Epoch: 5, Steps: 206 | Train Loss: 1.0405374 Vali Loss: 1.0517927 Test Loss: 1.0416900
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0221938
	speed: 0.0206s/iter; left time: 19.2200s
	iters: 200, epoch: 6 | loss: 1.0472610
	speed: 0.0166s/iter; left time: 13.7966s
Epoch: 6 cost time: 3.4388318061828613
Epoch: 6, Steps: 206 | Train Loss: 1.0395577 Vali Loss: 1.0504396 Test Loss: 1.0406320
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0444200
	speed: 0.0130s/iter; left time: 9.4019s
	iters: 200, epoch: 7 | loss: 1.0441819
	speed: 0.0120s/iter; left time: 7.5073s
Epoch: 7 cost time: 2.6264820098876953
Epoch: 7, Steps: 206 | Train Loss: 1.0392343 Vali Loss: 1.0505379 Test Loss: 1.0405765
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0255107
	speed: 0.0206s/iter; left time: 10.7112s
	iters: 200, epoch: 8 | loss: 1.0231212
	speed: 0.0174s/iter; left time: 7.2924s
Epoch: 8 cost time: 3.6249544620513916
Epoch: 8, Steps: 206 | Train Loss: 1.0387396 Vali Loss: 1.0501356 Test Loss: 1.0405036
Validation loss decreased (1.050352 --> 1.050136).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0339946
	speed: 0.0155s/iter; left time: 4.8523s
	iters: 200, epoch: 9 | loss: 1.0600106
	speed: 0.0194s/iter; left time: 4.1399s
Epoch: 9 cost time: 4.153265953063965
Epoch: 9, Steps: 206 | Train Loss: 1.0388001 Vali Loss: 1.0507840 Test Loss: 1.0405694
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0485053
	speed: 0.0224s/iter; left time: 2.3956s
	iters: 200, epoch: 10 | loss: 1.0386440
	speed: 0.0189s/iter; left time: 0.1324s
Epoch: 10 cost time: 3.999408721923828
Epoch: 10, Steps: 206 | Train Loss: 1.0387028 Vali Loss: 1.0502732 Test Loss: 1.0406138
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405036211013794, mae:0.8192067742347717
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0545886
	speed: 0.0157s/iter; left time: 30.7156s
	iters: 200, epoch: 1 | loss: 1.0613487
	speed: 0.0158s/iter; left time: 29.4437s
Epoch: 1 cost time: 3.345771312713623
Epoch: 1, Steps: 206 | Train Loss: 1.0665605 Vali Loss: 1.0576731 Test Loss: 1.0430907
Validation loss decreased (inf --> 1.057673).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0636503
	speed: 0.0145s/iter; left time: 25.4535s
	iters: 200, epoch: 2 | loss: 1.0495898
	speed: 0.0122s/iter; left time: 20.1770s
Epoch: 2 cost time: 2.604511022567749
Epoch: 2, Steps: 206 | Train Loss: 1.0502629 Vali Loss: 1.0555403 Test Loss: 1.0427001
Validation loss decreased (1.057673 --> 1.055540).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0350201
	speed: 0.0153s/iter; left time: 23.7071s
	iters: 200, epoch: 3 | loss: 1.0228337
	speed: 0.0152s/iter; left time: 22.0826s
Epoch: 3 cost time: 3.203219175338745
Epoch: 3, Steps: 206 | Train Loss: 1.0451190 Vali Loss: 1.0534128 Test Loss: 1.0412221
Validation loss decreased (1.055540 --> 1.053413).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0144480
	speed: 0.0213s/iter; left time: 28.5742s
	iters: 200, epoch: 4 | loss: 1.0731030
	speed: 0.0177s/iter; left time: 22.0361s
Epoch: 4 cost time: 3.7460787296295166
Epoch: 4, Steps: 206 | Train Loss: 1.0421387 Vali Loss: 1.0517725 Test Loss: 1.0408664
Validation loss decreased (1.053413 --> 1.051772).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0289551
	speed: 0.0180s/iter; left time: 20.4831s
	iters: 200, epoch: 5 | loss: 1.0344470
	speed: 0.0145s/iter; left time: 15.0479s
Epoch: 5 cost time: 3.100950241088867
Epoch: 5, Steps: 206 | Train Loss: 1.0404624 Vali Loss: 1.0507699 Test Loss: 1.0405990
Validation loss decreased (1.051772 --> 1.050770).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0265503
	speed: 0.0144s/iter; left time: 13.4041s
	iters: 200, epoch: 6 | loss: 1.0578427
	speed: 0.0130s/iter; left time: 10.8178s
Epoch: 6 cost time: 2.716902494430542
Epoch: 6, Steps: 206 | Train Loss: 1.0392990 Vali Loss: 1.0512108 Test Loss: 1.0406815
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0134214
	speed: 0.0126s/iter; left time: 9.1212s
	iters: 200, epoch: 7 | loss: 1.0586697
	speed: 0.0124s/iter; left time: 7.7805s
Epoch: 7 cost time: 2.6842572689056396
Epoch: 7, Steps: 206 | Train Loss: 1.0391240 Vali Loss: 1.0509663 Test Loss: 1.0403819
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0633906
	speed: 0.0271s/iter; left time: 14.0489s
	iters: 200, epoch: 8 | loss: 1.0218023
	speed: 0.0246s/iter; left time: 10.2867s
Epoch: 8 cost time: 5.06004786491394
Epoch: 8, Steps: 206 | Train Loss: 1.0385491 Vali Loss: 1.0504858 Test Loss: 1.0405742
Validation loss decreased (1.050770 --> 1.050486).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0282878
	speed: 0.0259s/iter; left time: 8.1088s
	iters: 200, epoch: 9 | loss: 1.0399697
	speed: 0.0237s/iter; left time: 5.0489s
Epoch: 9 cost time: 4.95494532585144
Epoch: 9, Steps: 206 | Train Loss: 1.0383350 Vali Loss: 1.0504915 Test Loss: 1.0405593
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0233872
	speed: 0.0146s/iter; left time: 1.5671s
	iters: 200, epoch: 10 | loss: 1.0150439
	speed: 0.0126s/iter; left time: 0.0879s
Epoch: 10 cost time: 2.629786252975464
Epoch: 10, Steps: 206 | Train Loss: 1.0386296 Vali Loss: 1.0507008 Test Loss: 1.0405643
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040574312210083, mae:0.8192182779312134
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0711356
	speed: 0.0188s/iter; left time: 36.8169s
	iters: 200, epoch: 1 | loss: 1.0314966
	speed: 0.0153s/iter; left time: 28.4260s
Epoch: 1 cost time: 3.192443609237671
Epoch: 1, Steps: 206 | Train Loss: 1.0667626 Vali Loss: 1.0614387 Test Loss: 1.0456979
Validation loss decreased (inf --> 1.061439).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0510327
	speed: 0.0225s/iter; left time: 39.5571s
	iters: 200, epoch: 2 | loss: 1.0745169
	speed: 0.0175s/iter; left time: 28.9181s
Epoch: 2 cost time: 3.690748453140259
Epoch: 2, Steps: 206 | Train Loss: 1.0506621 Vali Loss: 1.0566511 Test Loss: 1.0440381
Validation loss decreased (1.061439 --> 1.056651).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0449042
	speed: 0.0262s/iter; left time: 40.6195s
	iters: 200, epoch: 3 | loss: 1.0352818
	speed: 0.0193s/iter; left time: 27.8956s
Epoch: 3 cost time: 4.04645037651062
Epoch: 3, Steps: 206 | Train Loss: 1.0448054 Vali Loss: 1.0532696 Test Loss: 1.0415573
Validation loss decreased (1.056651 --> 1.053270).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0534964
	speed: 0.0153s/iter; left time: 20.5548s
	iters: 200, epoch: 4 | loss: 1.0573500
	speed: 0.0130s/iter; left time: 16.1681s
Epoch: 4 cost time: 2.739798069000244
Epoch: 4, Steps: 206 | Train Loss: 1.0422843 Vali Loss: 1.0523517 Test Loss: 1.0421679
Validation loss decreased (1.053270 --> 1.052352).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0500950
	speed: 0.0136s/iter; left time: 15.4750s
	iters: 200, epoch: 5 | loss: 1.0627618
	speed: 0.0129s/iter; left time: 13.3985s
Epoch: 5 cost time: 2.7797083854675293
Epoch: 5, Steps: 206 | Train Loss: 1.0406566 Vali Loss: 1.0508956 Test Loss: 1.0407394
Validation loss decreased (1.052352 --> 1.050896).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0649248
	speed: 0.0294s/iter; left time: 27.3949s
	iters: 200, epoch: 6 | loss: 1.0616930
	speed: 0.0212s/iter; left time: 17.6163s
Epoch: 6 cost time: 4.336623191833496
Epoch: 6, Steps: 206 | Train Loss: 1.0394315 Vali Loss: 1.0506958 Test Loss: 1.0405394
Validation loss decreased (1.050896 --> 1.050696).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0381732
	speed: 0.0273s/iter; left time: 19.7920s
	iters: 200, epoch: 7 | loss: 1.0184807
	speed: 0.0204s/iter; left time: 12.7532s
Epoch: 7 cost time: 4.2153215408325195
Epoch: 7, Steps: 206 | Train Loss: 1.0392050 Vali Loss: 1.0506787 Test Loss: 1.0405955
Validation loss decreased (1.050696 --> 1.050679).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0288959
	speed: 0.0171s/iter; left time: 8.8939s
	iters: 200, epoch: 8 | loss: 1.0243850
	speed: 0.0132s/iter; left time: 5.5332s
Epoch: 8 cost time: 2.7880842685699463
Epoch: 8, Steps: 206 | Train Loss: 1.0389850 Vali Loss: 1.0509574 Test Loss: 1.0405380
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0325137
	speed: 0.0168s/iter; left time: 5.2720s
	iters: 200, epoch: 9 | loss: 1.0380943
	speed: 0.0175s/iter; left time: 3.7244s
Epoch: 9 cost time: 3.71071720123291
Epoch: 9, Steps: 206 | Train Loss: 1.0386472 Vali Loss: 1.0505496 Test Loss: 1.0405660
Validation loss decreased (1.050679 --> 1.050550).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0525596
	speed: 0.0194s/iter; left time: 2.0747s
	iters: 200, epoch: 10 | loss: 1.0074029
	speed: 0.0189s/iter; left time: 0.1323s
Epoch: 10 cost time: 4.059476375579834
Epoch: 10, Steps: 206 | Train Loss: 1.0383991 Vali Loss: 1.0504774 Test Loss: 1.0405861
Validation loss decreased (1.050550 --> 1.050477).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405863523483276, mae:0.8191803097724915
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0591967
	speed: 0.0309s/iter; left time: 56.8297s
Epoch: 1 cost time: 4.5357489585876465
Epoch: 1, Steps: 194 | Train Loss: 1.0720825 Vali Loss: 1.0488279 Test Loss: 1.0427849
Validation loss decreased (inf --> 1.048828).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0499370
	speed: 0.0156s/iter; left time: 25.7672s
Epoch: 2 cost time: 3.066708564758301
Epoch: 2, Steps: 194 | Train Loss: 1.0564389 Vali Loss: 1.0457253 Test Loss: 1.0464605
Validation loss decreased (1.048828 --> 1.045725).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0677018
	speed: 0.0175s/iter; left time: 25.3998s
Epoch: 3 cost time: 3.2109570503234863
Epoch: 3, Steps: 194 | Train Loss: 1.0523081 Vali Loss: 1.0453476 Test Loss: 1.0408775
Validation loss decreased (1.045725 --> 1.045348).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0447404
	speed: 0.0163s/iter; left time: 20.5040s
Epoch: 4 cost time: 2.645871162414551
Epoch: 4, Steps: 194 | Train Loss: 1.0502096 Vali Loss: 1.0430338 Test Loss: 1.0423720
Validation loss decreased (1.045348 --> 1.043034).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0508820
	speed: 0.0177s/iter; left time: 18.9018s
Epoch: 5 cost time: 3.3391029834747314
Epoch: 5, Steps: 194 | Train Loss: 1.0490049 Vali Loss: 1.0426949 Test Loss: 1.0412258
Validation loss decreased (1.043034 --> 1.042695).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0392475
	speed: 0.0182s/iter; left time: 15.8277s
Epoch: 6 cost time: 3.3903374671936035
Epoch: 6, Steps: 194 | Train Loss: 1.0481414 Vali Loss: 1.0436420 Test Loss: 1.0400525
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0451684
	speed: 0.0183s/iter; left time: 12.3747s
Epoch: 7 cost time: 3.335706949234009
Epoch: 7, Steps: 194 | Train Loss: 1.0477845 Vali Loss: 1.0437181 Test Loss: 1.0395889
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0556047
	speed: 0.0171s/iter; left time: 8.2634s
Epoch: 8 cost time: 2.887650489807129
Epoch: 8, Steps: 194 | Train Loss: 1.0476623 Vali Loss: 1.0443312 Test Loss: 1.0393122
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0658854
	speed: 0.0128s/iter; left time: 3.6876s
Epoch: 9 cost time: 2.4869487285614014
Epoch: 9, Steps: 194 | Train Loss: 1.0476660 Vali Loss: 1.0439327 Test Loss: 1.0394331
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0403932
	speed: 0.0183s/iter; left time: 1.7394s
Epoch: 10 cost time: 3.28720760345459
Epoch: 10, Steps: 194 | Train Loss: 1.0475044 Vali Loss: 1.0439034 Test Loss: 1.0395119
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0412256717681885, mae:0.8188155293464661
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0797417
	speed: 0.0171s/iter; left time: 31.5420s
Epoch: 1 cost time: 3.2548844814300537
Epoch: 1, Steps: 194 | Train Loss: 1.0728206 Vali Loss: 1.0508538 Test Loss: 1.0409715
Validation loss decreased (inf --> 1.050854).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0434051
	speed: 0.0210s/iter; left time: 34.5529s
Epoch: 2 cost time: 4.3720691204071045
Epoch: 2, Steps: 194 | Train Loss: 1.0560088 Vali Loss: 1.0476975 Test Loss: 1.0418345
Validation loss decreased (1.050854 --> 1.047698).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0687178
	speed: 0.0162s/iter; left time: 23.5540s
Epoch: 3 cost time: 2.6848506927490234
Epoch: 3, Steps: 194 | Train Loss: 1.0525503 Vali Loss: 1.0482106 Test Loss: 1.0385978
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0322627
	speed: 0.0181s/iter; left time: 22.8159s
Epoch: 4 cost time: 3.2937793731689453
Epoch: 4, Steps: 194 | Train Loss: 1.0503415 Vali Loss: 1.0444666 Test Loss: 1.0408117
Validation loss decreased (1.047698 --> 1.044467).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0545112
	speed: 0.0191s/iter; left time: 20.3287s
Epoch: 5 cost time: 3.1597821712493896
Epoch: 5, Steps: 194 | Train Loss: 1.0493435 Vali Loss: 1.0430897 Test Loss: 1.0390382
Validation loss decreased (1.044467 --> 1.043090).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0597708
	speed: 0.0189s/iter; left time: 16.4540s
Epoch: 6 cost time: 3.1682236194610596
Epoch: 6, Steps: 194 | Train Loss: 1.0482772 Vali Loss: 1.0429934 Test Loss: 1.0393686
Validation loss decreased (1.043090 --> 1.042993).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0674558
	speed: 0.0175s/iter; left time: 11.8341s
Epoch: 7 cost time: 2.6642141342163086
Epoch: 7, Steps: 194 | Train Loss: 1.0480922 Vali Loss: 1.0432559 Test Loss: 1.0392829
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0507179
	speed: 0.0159s/iter; left time: 7.6755s
Epoch: 8 cost time: 3.020888328552246
Epoch: 8, Steps: 194 | Train Loss: 1.0479221 Vali Loss: 1.0430349 Test Loss: 1.0394762
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0759226
	speed: 0.0156s/iter; left time: 4.5079s
Epoch: 9 cost time: 2.8638758659362793
Epoch: 9, Steps: 194 | Train Loss: 1.0478310 Vali Loss: 1.0431509 Test Loss: 1.0392946
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0362957
	speed: 0.0161s/iter; left time: 1.5261s
Epoch: 10 cost time: 2.9457883834838867
Epoch: 10, Steps: 194 | Train Loss: 1.0471950 Vali Loss: 1.0433830 Test Loss: 1.0393548
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0393686294555664, mae:0.818103015422821
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0597887
	speed: 0.0151s/iter; left time: 27.8604s
Epoch: 1 cost time: 2.69124698638916
Epoch: 1, Steps: 194 | Train Loss: 1.0731390 Vali Loss: 1.0514352 Test Loss: 1.0448436
Validation loss decreased (inf --> 1.051435).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0396824
	speed: 0.0165s/iter; left time: 27.1423s
Epoch: 2 cost time: 3.045809030532837
Epoch: 2, Steps: 194 | Train Loss: 1.0562571 Vali Loss: 1.0468462 Test Loss: 1.0427610
Validation loss decreased (1.051435 --> 1.046846).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0612068
	speed: 0.0176s/iter; left time: 25.5680s
Epoch: 3 cost time: 3.249781847000122
Epoch: 3, Steps: 194 | Train Loss: 1.0525696 Vali Loss: 1.0485723 Test Loss: 1.0397650
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0604746
	speed: 0.0267s/iter; left time: 33.5851s
Epoch: 4 cost time: 4.254873275756836
Epoch: 4, Steps: 194 | Train Loss: 1.0504690 Vali Loss: 1.0447185 Test Loss: 1.0399047
Validation loss decreased (1.046846 --> 1.044719).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0774075
	speed: 0.0173s/iter; left time: 18.3950s
Epoch: 5 cost time: 3.0980935096740723
Epoch: 5, Steps: 194 | Train Loss: 1.0490923 Vali Loss: 1.0454242 Test Loss: 1.0392956
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0504292
	speed: 0.0147s/iter; left time: 12.8452s
Epoch: 6 cost time: 2.9483251571655273
Epoch: 6, Steps: 194 | Train Loss: 1.0484493 Vali Loss: 1.0442940 Test Loss: 1.0398587
Validation loss decreased (1.044719 --> 1.044294).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0549164
	speed: 0.0189s/iter; left time: 12.8084s
Epoch: 7 cost time: 3.244432210922241
Epoch: 7, Steps: 194 | Train Loss: 1.0478708 Vali Loss: 1.0437819 Test Loss: 1.0396432
Validation loss decreased (1.044294 --> 1.043782).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0693504
	speed: 0.0224s/iter; left time: 10.8294s
Epoch: 8 cost time: 3.499483108520508
Epoch: 8, Steps: 194 | Train Loss: 1.0476701 Vali Loss: 1.0437920 Test Loss: 1.0395232
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0224154
	speed: 0.0181s/iter; left time: 5.2301s
Epoch: 9 cost time: 2.8442509174346924
Epoch: 9, Steps: 194 | Train Loss: 1.0474375 Vali Loss: 1.0436991 Test Loss: 1.0396291
Validation loss decreased (1.043782 --> 1.043699).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0439523
	speed: 0.0117s/iter; left time: 1.1118s
Epoch: 10 cost time: 2.2480382919311523
Epoch: 10, Steps: 194 | Train Loss: 1.0476258 Vali Loss: 1.0438789 Test Loss: 1.0396487
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0396289825439453, mae:0.8182194232940674
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5625817
	speed: 0.0294s/iter; left time: 59.6621s
	iters: 200, epoch: 1 | loss: 0.5403454
	speed: 0.0221s/iter; left time: 42.6457s
Epoch: 1 cost time: 4.665494680404663
Epoch: 1, Steps: 213 | Train Loss: 0.5476577 Vali Loss: 0.5015243 Test Loss: 0.6081737
Validation loss decreased (inf --> 0.501524).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5766087
	speed: 0.0147s/iter; left time: 26.7787s
	iters: 200, epoch: 2 | loss: 0.5750033
	speed: 0.0130s/iter; left time: 22.3964s
Epoch: 2 cost time: 2.816969394683838
Epoch: 2, Steps: 213 | Train Loss: 0.5302989 Vali Loss: 0.4979747 Test Loss: 0.6057929
Validation loss decreased (0.501524 --> 0.497975).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4930862
	speed: 0.0183s/iter; left time: 29.3528s
	iters: 200, epoch: 3 | loss: 0.4699143
	speed: 0.0166s/iter; left time: 24.9664s
Epoch: 3 cost time: 3.8626770973205566
Epoch: 3, Steps: 213 | Train Loss: 0.5202882 Vali Loss: 0.5098225 Test Loss: 0.6148533
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4612466
	speed: 0.0160s/iter; left time: 22.2978s
	iters: 200, epoch: 4 | loss: 0.4350641
	speed: 0.0158s/iter; left time: 20.3495s
Epoch: 4 cost time: 3.454472780227661
Epoch: 4, Steps: 213 | Train Loss: 0.5136234 Vali Loss: 0.5052509 Test Loss: 0.6207687
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5313593
	speed: 0.0173s/iter; left time: 20.4063s
	iters: 200, epoch: 5 | loss: 0.4973724
	speed: 0.0166s/iter; left time: 17.9451s
Epoch: 5 cost time: 3.5810067653656006
Epoch: 5, Steps: 213 | Train Loss: 0.5101647 Vali Loss: 0.5168856 Test Loss: 0.6211213
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4726727
	speed: 0.0155s/iter; left time: 14.9514s
	iters: 200, epoch: 6 | loss: 0.4632550
	speed: 0.0133s/iter; left time: 11.4874s
Epoch: 6 cost time: 2.905318021774292
Epoch: 6, Steps: 213 | Train Loss: 0.5078277 Vali Loss: 0.5149488 Test Loss: 0.6192946
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4909045
	speed: 0.0160s/iter; left time: 12.0533s
	iters: 200, epoch: 7 | loss: 0.4810255
	speed: 0.0138s/iter; left time: 9.0193s
Epoch: 7 cost time: 3.0098025798797607
Epoch: 7, Steps: 213 | Train Loss: 0.5070771 Vali Loss: 0.5201901 Test Loss: 0.6196319
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6057928800582886, mae:0.6161937117576599
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5033144
	speed: 0.0190s/iter; left time: 38.5324s
	iters: 200, epoch: 1 | loss: 0.5405979
	speed: 0.0158s/iter; left time: 30.4245s
Epoch: 1 cost time: 3.4250338077545166
Epoch: 1, Steps: 213 | Train Loss: 0.5477402 Vali Loss: 0.5095582 Test Loss: 0.5953390
Validation loss decreased (inf --> 0.509558).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5359101
	speed: 0.0154s/iter; left time: 27.9683s
	iters: 200, epoch: 2 | loss: 0.5122362
	speed: 0.0139s/iter; left time: 23.9403s
Epoch: 2 cost time: 3.143763303756714
Epoch: 2, Steps: 213 | Train Loss: 0.5321395 Vali Loss: 0.5035280 Test Loss: 0.6164543
Validation loss decreased (0.509558 --> 0.503528).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5351003
	speed: 0.0201s/iter; left time: 32.3339s
	iters: 200, epoch: 3 | loss: 0.4709240
	speed: 0.0157s/iter; left time: 23.6963s
Epoch: 3 cost time: 3.3266913890838623
Epoch: 3, Steps: 213 | Train Loss: 0.5216145 Vali Loss: 0.5111026 Test Loss: 0.6020595
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5358588
	speed: 0.0137s/iter; left time: 19.0176s
	iters: 200, epoch: 4 | loss: 0.6274393
	speed: 0.0146s/iter; left time: 18.8942s
Epoch: 4 cost time: 3.232001781463623
Epoch: 4, Steps: 213 | Train Loss: 0.5158552 Vali Loss: 0.5108146 Test Loss: 0.6089543
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4507527
	speed: 0.0168s/iter; left time: 19.7919s
	iters: 200, epoch: 5 | loss: 0.4911880
	speed: 0.0160s/iter; left time: 17.2247s
Epoch: 5 cost time: 3.4834938049316406
Epoch: 5, Steps: 213 | Train Loss: 0.5122971 Vali Loss: 0.5123575 Test Loss: 0.6099196
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4970394
	speed: 0.0195s/iter; left time: 18.8711s
	iters: 200, epoch: 6 | loss: 0.5023892
	speed: 0.0169s/iter; left time: 14.6735s
Epoch: 6 cost time: 3.7451894283294678
Epoch: 6, Steps: 213 | Train Loss: 0.5093111 Vali Loss: 0.5097970 Test Loss: 0.6124828
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5057778
	speed: 0.0154s/iter; left time: 11.5811s
	iters: 200, epoch: 7 | loss: 0.5529620
	speed: 0.0139s/iter; left time: 9.0619s
Epoch: 7 cost time: 3.0617270469665527
Epoch: 7, Steps: 213 | Train Loss: 0.5085425 Vali Loss: 0.5216415 Test Loss: 0.6090059
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6164543628692627, mae:0.6216724514961243
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5278574
	speed: 0.0168s/iter; left time: 34.0692s
	iters: 200, epoch: 1 | loss: 0.6244394
	speed: 0.0173s/iter; left time: 33.3904s
Epoch: 1 cost time: 3.7613425254821777
Epoch: 1, Steps: 213 | Train Loss: 0.5501628 Vali Loss: 0.5063570 Test Loss: 0.6258366
Validation loss decreased (inf --> 0.506357).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5370365
	speed: 0.0185s/iter; left time: 33.5535s
	iters: 200, epoch: 2 | loss: 0.5994956
	speed: 0.0163s/iter; left time: 28.0468s
Epoch: 2 cost time: 3.5348331928253174
Epoch: 2, Steps: 213 | Train Loss: 0.5308462 Vali Loss: 0.5088016 Test Loss: 0.6197511
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5067530
	speed: 0.0167s/iter; left time: 26.7455s
	iters: 200, epoch: 3 | loss: 0.4959315
	speed: 0.0185s/iter; left time: 27.8787s
Epoch: 3 cost time: 4.16349720954895
Epoch: 3, Steps: 213 | Train Loss: 0.5206053 Vali Loss: 0.5200747 Test Loss: 0.5949281
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4648628
	speed: 0.0197s/iter; left time: 27.3569s
	iters: 200, epoch: 4 | loss: 0.5320626
	speed: 0.0149s/iter; left time: 19.2530s
Epoch: 4 cost time: 3.1724650859832764
Epoch: 4, Steps: 213 | Train Loss: 0.5158656 Vali Loss: 0.5135255 Test Loss: 0.6019837
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5590388
	speed: 0.0139s/iter; left time: 16.3879s
	iters: 200, epoch: 5 | loss: 0.4899584
	speed: 0.0135s/iter; left time: 14.6009s
Epoch: 5 cost time: 2.9710018634796143
Epoch: 5, Steps: 213 | Train Loss: 0.5120516 Vali Loss: 0.5132607 Test Loss: 0.6102695
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5321437
	speed: 0.0134s/iter; left time: 12.9379s
	iters: 200, epoch: 6 | loss: 0.5190887
	speed: 0.0126s/iter; left time: 10.9129s
Epoch: 6 cost time: 2.7767982482910156
Epoch: 6, Steps: 213 | Train Loss: 0.5096978 Vali Loss: 0.5110282 Test Loss: 0.6080892
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6258366107940674, mae:0.6271689534187317
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7660181
	speed: 0.0252s/iter; left time: 50.3560s
	iters: 200, epoch: 1 | loss: 0.7605519
	speed: 0.0205s/iter; left time: 38.9908s
Epoch: 1 cost time: 4.353902101516724
Epoch: 1, Steps: 210 | Train Loss: 0.6759379 Vali Loss: 0.6460850 Test Loss: 0.8889552
Validation loss decreased (inf --> 0.646085).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6355807
	speed: 0.0188s/iter; left time: 33.6664s
	iters: 200, epoch: 2 | loss: 0.8088188
	speed: 0.0210s/iter; left time: 35.4429s
Epoch: 2 cost time: 4.592428207397461
Epoch: 2, Steps: 210 | Train Loss: 0.6607617 Vali Loss: 0.6136326 Test Loss: 0.8931056
Validation loss decreased (0.646085 --> 0.613633).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6556071
	speed: 0.0185s/iter; left time: 29.2889s
	iters: 200, epoch: 3 | loss: 0.6469349
	speed: 0.0159s/iter; left time: 23.6150s
Epoch: 3 cost time: 3.424229621887207
Epoch: 3, Steps: 210 | Train Loss: 0.6497512 Vali Loss: 0.6183499 Test Loss: 0.8961854
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6445767
	speed: 0.0174s/iter; left time: 23.8237s
	iters: 200, epoch: 4 | loss: 0.6888525
	speed: 0.0166s/iter; left time: 21.0817s
Epoch: 4 cost time: 3.554037094116211
Epoch: 4, Steps: 210 | Train Loss: 0.6417142 Vali Loss: 0.6227528 Test Loss: 0.9112195
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6132585
	speed: 0.0164s/iter; left time: 19.0285s
	iters: 200, epoch: 5 | loss: 0.6539435
	speed: 0.0151s/iter; left time: 16.0074s
Epoch: 5 cost time: 3.289921522140503
Epoch: 5, Steps: 210 | Train Loss: 0.6354292 Vali Loss: 0.6353085 Test Loss: 0.9085387
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6159625
	speed: 0.0126s/iter; left time: 12.0100s
	iters: 200, epoch: 6 | loss: 0.7127947
	speed: 0.0123s/iter; left time: 10.4426s
Epoch: 6 cost time: 2.694716453552246
Epoch: 6, Steps: 210 | Train Loss: 0.6323873 Vali Loss: 0.6358646 Test Loss: 0.9053816
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6744618
	speed: 0.0192s/iter; left time: 14.2571s
	iters: 200, epoch: 7 | loss: 0.7175953
	speed: 0.0160s/iter; left time: 10.2760s
Epoch: 7 cost time: 3.4013044834136963
Epoch: 7, Steps: 210 | Train Loss: 0.6305024 Vali Loss: 0.6444665 Test Loss: 0.9054578
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.893105685710907, mae:0.7431561946868896
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7064599
	speed: 0.0134s/iter; left time: 26.8622s
	iters: 200, epoch: 1 | loss: 0.6333086
	speed: 0.0131s/iter; left time: 24.8454s
Epoch: 1 cost time: 2.843045234680176
Epoch: 1, Steps: 210 | Train Loss: 0.6762831 Vali Loss: 0.6027952 Test Loss: 0.9104776
Validation loss decreased (inf --> 0.602795).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6508152
	speed: 0.0164s/iter; left time: 29.4124s
	iters: 200, epoch: 2 | loss: 0.7202329
	speed: 0.0153s/iter; left time: 25.8353s
Epoch: 2 cost time: 3.259528875350952
Epoch: 2, Steps: 210 | Train Loss: 0.6587151 Vali Loss: 0.6098782 Test Loss: 0.9014085
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7140446
	speed: 0.0212s/iter; left time: 33.5041s
	iters: 200, epoch: 3 | loss: 0.5661802
	speed: 0.0177s/iter; left time: 26.1914s
Epoch: 3 cost time: 3.7923336029052734
Epoch: 3, Steps: 210 | Train Loss: 0.6481173 Vali Loss: 0.6156460 Test Loss: 0.8982046
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6119092
	speed: 0.0228s/iter; left time: 31.2930s
	iters: 200, epoch: 4 | loss: 0.6139812
	speed: 0.0176s/iter; left time: 22.3144s
Epoch: 4 cost time: 3.7508556842803955
Epoch: 4, Steps: 210 | Train Loss: 0.6397231 Vali Loss: 0.6248995 Test Loss: 0.9051021
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6239464
	speed: 0.0191s/iter; left time: 22.2085s
	iters: 200, epoch: 5 | loss: 0.5259407
	speed: 0.0151s/iter; left time: 16.0207s
Epoch: 5 cost time: 3.2481470108032227
Epoch: 5, Steps: 210 | Train Loss: 0.6354514 Vali Loss: 0.6399940 Test Loss: 0.9062971
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5892498
	speed: 0.0148s/iter; left time: 14.0759s
	iters: 200, epoch: 6 | loss: 0.5796336
	speed: 0.0142s/iter; left time: 12.1102s
Epoch: 6 cost time: 3.1095519065856934
Epoch: 6, Steps: 210 | Train Loss: 0.6313146 Vali Loss: 0.6431558 Test Loss: 0.9094483
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9104777574539185, mae:0.751618504524231
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7232370
	speed: 0.0240s/iter; left time: 48.0577s
	iters: 200, epoch: 1 | loss: 0.6664756
	speed: 0.0218s/iter; left time: 41.4695s
Epoch: 1 cost time: 4.610276699066162
Epoch: 1, Steps: 210 | Train Loss: 0.6778776 Vali Loss: 0.6267898 Test Loss: 0.8855317
Validation loss decreased (inf --> 0.626790).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7088287
	speed: 0.0212s/iter; left time: 37.9752s
	iters: 200, epoch: 2 | loss: 0.6682836
	speed: 0.0186s/iter; left time: 31.4988s
Epoch: 2 cost time: 3.9322240352630615
Epoch: 2, Steps: 210 | Train Loss: 0.6583950 Vali Loss: 0.6388521 Test Loss: 0.8938470
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6244256
	speed: 0.0181s/iter; left time: 28.6714s
	iters: 200, epoch: 3 | loss: 0.5939746
	speed: 0.0173s/iter; left time: 25.5539s
Epoch: 3 cost time: 3.647753953933716
Epoch: 3, Steps: 210 | Train Loss: 0.6469022 Vali Loss: 0.6413714 Test Loss: 0.8972222
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7654495
	speed: 0.0163s/iter; left time: 22.3402s
	iters: 200, epoch: 4 | loss: 0.5430309
	speed: 0.0152s/iter; left time: 19.2936s
Epoch: 4 cost time: 3.23868989944458
Epoch: 4, Steps: 210 | Train Loss: 0.6378875 Vali Loss: 0.6515343 Test Loss: 0.9106300
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6347470
	speed: 0.0206s/iter; left time: 23.9030s
	iters: 200, epoch: 5 | loss: 0.5730225
	speed: 0.0171s/iter; left time: 18.1073s
Epoch: 5 cost time: 3.6268866062164307
Epoch: 5, Steps: 210 | Train Loss: 0.6309504 Vali Loss: 0.6459500 Test Loss: 0.9145368
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5421257
	speed: 0.0213s/iter; left time: 20.2972s
	iters: 200, epoch: 6 | loss: 0.5023302
	speed: 0.0177s/iter; left time: 15.0315s
Epoch: 6 cost time: 3.76172137260437
Epoch: 6, Steps: 210 | Train Loss: 0.6273805 Vali Loss: 0.6508796 Test Loss: 0.9241206
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8855316638946533, mae:0.7408443093299866
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8969821
	speed: 0.0311s/iter; left time: 60.9494s
	iters: 200, epoch: 1 | loss: 0.7341521
	speed: 0.0260s/iter; left time: 48.4554s
Epoch: 1 cost time: 5.419528245925903
Epoch: 1, Steps: 206 | Train Loss: 0.8571609 Vali Loss: 0.6911823 Test Loss: 1.2462503
Validation loss decreased (inf --> 0.691182).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7651594
	speed: 0.0142s/iter; left time: 24.9213s
	iters: 200, epoch: 2 | loss: 0.9784728
	speed: 0.0129s/iter; left time: 21.3792s
Epoch: 2 cost time: 2.7902839183807373
Epoch: 2, Steps: 206 | Train Loss: 0.8350743 Vali Loss: 0.7342421 Test Loss: 1.2721114
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8130206
	speed: 0.0165s/iter; left time: 25.4989s
	iters: 200, epoch: 3 | loss: 0.9008768
	speed: 0.0153s/iter; left time: 22.1853s
Epoch: 3 cost time: 3.2703542709350586
Epoch: 3, Steps: 206 | Train Loss: 0.8218972 Vali Loss: 0.7309753 Test Loss: 1.2689052
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8690004
	speed: 0.0186s/iter; left time: 24.9804s
	iters: 200, epoch: 4 | loss: 0.8801166
	speed: 0.0216s/iter; left time: 26.8403s
Epoch: 4 cost time: 4.486541032791138
Epoch: 4, Steps: 206 | Train Loss: 0.8081798 Vali Loss: 0.7138675 Test Loss: 1.2617705
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7319847
	speed: 0.0175s/iter; left time: 19.9432s
	iters: 200, epoch: 5 | loss: 0.7385474
	speed: 0.0160s/iter; left time: 16.6107s
Epoch: 5 cost time: 3.4080703258514404
Epoch: 5, Steps: 206 | Train Loss: 0.7990599 Vali Loss: 0.7267732 Test Loss: 1.2735687
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7833123
	speed: 0.0176s/iter; left time: 16.3719s
	iters: 200, epoch: 6 | loss: 0.6560421
	speed: 0.0144s/iter; left time: 11.9955s
Epoch: 6 cost time: 3.053375720977783
Epoch: 6, Steps: 206 | Train Loss: 0.7908385 Vali Loss: 0.7268717 Test Loss: 1.2796602
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2462503910064697, mae:0.8736368417739868
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8687761
	speed: 0.0200s/iter; left time: 39.2704s
	iters: 200, epoch: 1 | loss: 0.9124773
	speed: 0.0169s/iter; left time: 31.5327s
Epoch: 1 cost time: 3.619432210922241
Epoch: 1, Steps: 206 | Train Loss: 0.8576231 Vali Loss: 0.7001985 Test Loss: 1.2413356
Validation loss decreased (inf --> 0.700198).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8781618
	speed: 0.0229s/iter; left time: 40.1734s
	iters: 200, epoch: 2 | loss: 0.8336449
	speed: 0.0181s/iter; left time: 29.9256s
Epoch: 2 cost time: 3.787874460220337
Epoch: 2, Steps: 206 | Train Loss: 0.8365920 Vali Loss: 0.7085261 Test Loss: 1.2383629
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7776605
	speed: 0.0194s/iter; left time: 30.0015s
	iters: 200, epoch: 3 | loss: 0.7731392
	speed: 0.0164s/iter; left time: 23.6962s
Epoch: 3 cost time: 3.533599615097046
Epoch: 3, Steps: 206 | Train Loss: 0.8201300 Vali Loss: 0.7076694 Test Loss: 1.2532150
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7031301
	speed: 0.0143s/iter; left time: 19.2601s
	iters: 200, epoch: 4 | loss: 0.8188915
	speed: 0.0123s/iter; left time: 15.3449s
Epoch: 4 cost time: 2.6086201667785645
Epoch: 4, Steps: 206 | Train Loss: 0.8126844 Vali Loss: 0.7265147 Test Loss: 1.2488204
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7274946
	speed: 0.0176s/iter; left time: 19.9785s
	iters: 200, epoch: 5 | loss: 0.9379339
	speed: 0.0150s/iter; left time: 15.5946s
Epoch: 5 cost time: 3.173218250274658
Epoch: 5, Steps: 206 | Train Loss: 0.8069906 Vali Loss: 0.7236463 Test Loss: 1.2448366
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7850547
	speed: 0.0225s/iter; left time: 20.9357s
	iters: 200, epoch: 6 | loss: 0.6764358
	speed: 0.0177s/iter; left time: 14.7316s
Epoch: 6 cost time: 3.702634572982788
Epoch: 6, Steps: 206 | Train Loss: 0.8031036 Vali Loss: 0.7352371 Test Loss: 1.2505941
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2413355112075806, mae:0.8704338073730469
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7743630
	speed: 0.0177s/iter; left time: 34.6243s
	iters: 200, epoch: 1 | loss: 0.9282478
	speed: 0.0152s/iter; left time: 28.2827s
Epoch: 1 cost time: 3.198974847793579
Epoch: 1, Steps: 206 | Train Loss: 0.8554804 Vali Loss: 0.6814819 Test Loss: 1.2472910
Validation loss decreased (inf --> 0.681482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7071323
	speed: 0.0197s/iter; left time: 34.4987s
	iters: 200, epoch: 2 | loss: 0.7641572
	speed: 0.0145s/iter; left time: 24.0338s
Epoch: 2 cost time: 3.0814619064331055
Epoch: 2, Steps: 206 | Train Loss: 0.8345989 Vali Loss: 0.7208591 Test Loss: 1.2341292
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9448353
	speed: 0.0181s/iter; left time: 27.9800s
	iters: 200, epoch: 3 | loss: 0.8139778
	speed: 0.0150s/iter; left time: 21.7425s
Epoch: 3 cost time: 3.1532845497131348
Epoch: 3, Steps: 206 | Train Loss: 0.8202462 Vali Loss: 0.7091089 Test Loss: 1.2600707
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6989148
	speed: 0.0164s/iter; left time: 21.9793s
	iters: 200, epoch: 4 | loss: 0.6172728
	speed: 0.0150s/iter; left time: 18.6547s
Epoch: 4 cost time: 3.1459834575653076
Epoch: 4, Steps: 206 | Train Loss: 0.8064384 Vali Loss: 0.7329287 Test Loss: 1.2699506
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8313038
	speed: 0.0186s/iter; left time: 21.1715s
	iters: 200, epoch: 5 | loss: 0.6469287
	speed: 0.0190s/iter; left time: 19.6665s
Epoch: 5 cost time: 4.000753879547119
Epoch: 5, Steps: 206 | Train Loss: 0.7969849 Vali Loss: 0.7235839 Test Loss: 1.2703220
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7416197
	speed: 0.0192s/iter; left time: 17.8896s
	iters: 200, epoch: 6 | loss: 0.8251356
	speed: 0.0184s/iter; left time: 15.3150s
Epoch: 6 cost time: 3.898876428604126
Epoch: 6, Steps: 206 | Train Loss: 0.7891722 Vali Loss: 0.7428804 Test Loss: 1.2884340
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2472909688949585, mae:0.8735619187355042
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2517518
	speed: 0.0286s/iter; left time: 52.5995s
Epoch: 1 cost time: 4.1315531730651855
Epoch: 1, Steps: 194 | Train Loss: 1.2384584 Vali Loss: 0.6241048 Test Loss: 1.3692565
Validation loss decreased (inf --> 0.624105).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.4135427
	speed: 0.0217s/iter; left time: 35.7779s
Epoch: 2 cost time: 3.6815779209136963
Epoch: 2, Steps: 194 | Train Loss: 1.2135313 Vali Loss: 0.6006408 Test Loss: 1.3631755
Validation loss decreased (0.624105 --> 0.600641).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2028100
	speed: 0.0131s/iter; left time: 19.0423s
Epoch: 3 cost time: 2.2654623985290527
Epoch: 3, Steps: 194 | Train Loss: 1.1883170 Vali Loss: 0.6545894 Test Loss: 1.3334645
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1967301
	speed: 0.0152s/iter; left time: 19.1842s
Epoch: 4 cost time: 2.740727663040161
Epoch: 4, Steps: 194 | Train Loss: 1.1707296 Vali Loss: 0.6691889 Test Loss: 1.3793215
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1988640
	speed: 0.0165s/iter; left time: 17.5558s
Epoch: 5 cost time: 3.0818209648132324
Epoch: 5, Steps: 194 | Train Loss: 1.1612025 Vali Loss: 0.6581276 Test Loss: 1.3800583
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0328814
	speed: 0.0179s/iter; left time: 15.5967s
Epoch: 6 cost time: 3.9920523166656494
Epoch: 6, Steps: 194 | Train Loss: 1.1551696 Vali Loss: 0.6343825 Test Loss: 1.3774403
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9689783
	speed: 0.0186s/iter; left time: 12.5865s
Epoch: 7 cost time: 3.3482491970062256
Epoch: 7, Steps: 194 | Train Loss: 1.1520403 Vali Loss: 0.6412897 Test Loss: 1.3781080
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.363175392150879, mae:0.915184736251831
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.3049431
	speed: 0.0152s/iter; left time: 27.8932s
Epoch: 1 cost time: 2.5271711349487305
Epoch: 1, Steps: 194 | Train Loss: 1.2377783 Vali Loss: 0.5563898 Test Loss: 1.3766671
Validation loss decreased (inf --> 0.556390).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3630368
	speed: 0.0151s/iter; left time: 24.9084s
Epoch: 2 cost time: 2.412975311279297
Epoch: 2, Steps: 194 | Train Loss: 1.2095576 Vali Loss: 0.6924758 Test Loss: 1.3568738
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2020770
	speed: 0.0171s/iter; left time: 24.8058s
Epoch: 3 cost time: 3.555112838745117
Epoch: 3, Steps: 194 | Train Loss: 1.1808730 Vali Loss: 0.6514683 Test Loss: 1.3797433
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1325984
	speed: 0.0171s/iter; left time: 21.5651s
Epoch: 4 cost time: 3.1159682273864746
Epoch: 4, Steps: 194 | Train Loss: 1.1581602 Vali Loss: 0.6396428 Test Loss: 1.3727978
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9786615
	speed: 0.0189s/iter; left time: 20.0774s
Epoch: 5 cost time: 3.215444564819336
Epoch: 5, Steps: 194 | Train Loss: 1.1443757 Vali Loss: 0.6513891 Test Loss: 1.3966966
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9745834
	speed: 0.0212s/iter; left time: 18.4868s
Epoch: 6 cost time: 3.2780351638793945
Epoch: 6, Steps: 194 | Train Loss: 1.1358919 Vali Loss: 0.6660300 Test Loss: 1.3784438
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3766670227050781, mae:0.9202525019645691
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0898170
	speed: 0.0145s/iter; left time: 26.6502s
Epoch: 1 cost time: 3.01210355758667
Epoch: 1, Steps: 194 | Train Loss: 1.2401573 Vali Loss: 0.6202877 Test Loss: 1.3660419
Validation loss decreased (inf --> 0.620288).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3364623
	speed: 0.0216s/iter; left time: 35.5536s
Epoch: 2 cost time: 4.109480381011963
Epoch: 2, Steps: 194 | Train Loss: 1.2100912 Vali Loss: 0.6614885 Test Loss: 1.3590727
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1238663
	speed: 0.0150s/iter; left time: 21.8614s
Epoch: 3 cost time: 2.8792903423309326
Epoch: 3, Steps: 194 | Train Loss: 1.1900997 Vali Loss: 0.5790347 Test Loss: 1.4144629
Validation loss decreased (0.620288 --> 0.579035).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1868824
	speed: 0.0191s/iter; left time: 24.0289s
Epoch: 4 cost time: 3.3946518898010254
Epoch: 4, Steps: 194 | Train Loss: 1.1770557 Vali Loss: 0.6582509 Test Loss: 1.3650148
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1540653
	speed: 0.0165s/iter; left time: 17.6071s
Epoch: 5 cost time: 2.738203763961792
Epoch: 5, Steps: 194 | Train Loss: 1.1683306 Vali Loss: 0.6449628 Test Loss: 1.3751050
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0575491
	speed: 0.0236s/iter; left time: 20.5941s
Epoch: 6 cost time: 3.7305376529693604
Epoch: 6, Steps: 194 | Train Loss: 1.1622511 Vali Loss: 0.6473123 Test Loss: 1.3745645
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0807090
	speed: 0.0304s/iter; left time: 20.5900s
Epoch: 7 cost time: 4.614583730697632
Epoch: 7, Steps: 194 | Train Loss: 1.1597861 Vali Loss: 0.6411143 Test Loss: 1.3800955
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.3720073
	speed: 0.0221s/iter; left time: 10.6881s
Epoch: 8 cost time: 3.822455883026123
Epoch: 8, Steps: 194 | Train Loss: 1.1591361 Vali Loss: 0.6435868 Test Loss: 1.3810245
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4144630432128906, mae:0.9293093681335449
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5196829
	speed: 0.0228s/iter; left time: 46.3563s
	iters: 200, epoch: 1 | loss: 0.5467978
	speed: 0.0197s/iter; left time: 37.9959s
Epoch: 1 cost time: 4.38679313659668
Epoch: 1, Steps: 213 | Train Loss: 0.5488934 Vali Loss: 0.5015775 Test Loss: 0.6109456
Validation loss decreased (inf --> 0.501577).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5443636
	speed: 0.0170s/iter; left time: 30.9608s
	iters: 200, epoch: 2 | loss: 0.5943350
	speed: 0.0182s/iter; left time: 31.2075s
Epoch: 2 cost time: 3.9352102279663086
Epoch: 2, Steps: 213 | Train Loss: 0.5298104 Vali Loss: 0.5073808 Test Loss: 0.6028553
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4965362
	speed: 0.0171s/iter; left time: 27.3944s
	iters: 200, epoch: 3 | loss: 0.5310066
	speed: 0.0128s/iter; left time: 19.3273s
Epoch: 3 cost time: 2.73349666595459
Epoch: 3, Steps: 213 | Train Loss: 0.5211124 Vali Loss: 0.5124310 Test Loss: 0.6087049
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5262475
	speed: 0.0151s/iter; left time: 21.0565s
	iters: 200, epoch: 4 | loss: 0.4714022
	speed: 0.0134s/iter; left time: 17.2722s
Epoch: 4 cost time: 2.8565750122070312
Epoch: 4, Steps: 213 | Train Loss: 0.5146043 Vali Loss: 0.5144066 Test Loss: 0.6074628
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5062644
	speed: 0.0177s/iter; left time: 20.9146s
	iters: 200, epoch: 5 | loss: 0.4966115
	speed: 0.0165s/iter; left time: 17.8112s
Epoch: 5 cost time: 3.610874652862549
Epoch: 5, Steps: 213 | Train Loss: 0.5107298 Vali Loss: 0.5123700 Test Loss: 0.6118355
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5415683
	speed: 0.0188s/iter; left time: 18.1412s
	iters: 200, epoch: 6 | loss: 0.5312288
	speed: 0.0191s/iter; left time: 16.5535s
Epoch: 6 cost time: 4.3027448654174805
Epoch: 6, Steps: 213 | Train Loss: 0.5083259 Vali Loss: 0.5220535 Test Loss: 0.6103016
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6109456419944763, mae:0.6191674470901489
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6114964
	speed: 0.0129s/iter; left time: 26.2734s
	iters: 200, epoch: 1 | loss: 0.6060014
	speed: 0.0118s/iter; left time: 22.7933s
Epoch: 1 cost time: 2.545426368713379
Epoch: 1, Steps: 213 | Train Loss: 0.5469721 Vali Loss: 0.5034713 Test Loss: 0.6325993
Validation loss decreased (inf --> 0.503471).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5379229
	speed: 0.0227s/iter; left time: 41.2612s
	iters: 200, epoch: 2 | loss: 0.5636873
	speed: 0.0186s/iter; left time: 32.0136s
Epoch: 2 cost time: 3.9930617809295654
Epoch: 2, Steps: 213 | Train Loss: 0.5305048 Vali Loss: 0.5062252 Test Loss: 0.6036927
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4840594
	speed: 0.0181s/iter; left time: 28.9855s
	iters: 200, epoch: 3 | loss: 0.6080623
	speed: 0.0157s/iter; left time: 23.6042s
Epoch: 3 cost time: 3.444016456604004
Epoch: 3, Steps: 213 | Train Loss: 0.5212788 Vali Loss: 0.5059908 Test Loss: 0.6090578
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4842795
	speed: 0.0182s/iter; left time: 25.3407s
	iters: 200, epoch: 4 | loss: 0.5663323
	speed: 0.0146s/iter; left time: 18.8220s
Epoch: 4 cost time: 3.1037325859069824
Epoch: 4, Steps: 213 | Train Loss: 0.5156693 Vali Loss: 0.5196703 Test Loss: 0.6122351
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5780870
	speed: 0.0186s/iter; left time: 21.9353s
	iters: 200, epoch: 5 | loss: 0.5345190
	speed: 0.0154s/iter; left time: 16.5801s
Epoch: 5 cost time: 3.3144075870513916
Epoch: 5, Steps: 213 | Train Loss: 0.5116589 Vali Loss: 0.5127110 Test Loss: 0.6170136
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5004559
	speed: 0.0157s/iter; left time: 15.1661s
	iters: 200, epoch: 6 | loss: 0.4644741
	speed: 0.0151s/iter; left time: 13.0378s
Epoch: 6 cost time: 3.3547441959381104
Epoch: 6, Steps: 213 | Train Loss: 0.5095411 Vali Loss: 0.5143921 Test Loss: 0.6208290
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6325993537902832, mae:0.6303050518035889
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5537308
	speed: 0.0200s/iter; left time: 40.6858s
	iters: 200, epoch: 1 | loss: 0.5483285
	speed: 0.0173s/iter; left time: 33.5015s
Epoch: 1 cost time: 3.779555320739746
Epoch: 1, Steps: 213 | Train Loss: 0.5491768 Vali Loss: 0.5073281 Test Loss: 0.6130288
Validation loss decreased (inf --> 0.507328).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5372665
	speed: 0.0157s/iter; left time: 28.5508s
	iters: 200, epoch: 2 | loss: 0.4944595
	speed: 0.0135s/iter; left time: 23.2674s
Epoch: 2 cost time: 2.9000675678253174
Epoch: 2, Steps: 213 | Train Loss: 0.5303966 Vali Loss: 0.5061969 Test Loss: 0.6168461
Validation loss decreased (0.507328 --> 0.506197).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4673084
	speed: 0.0186s/iter; left time: 29.8072s
	iters: 200, epoch: 3 | loss: 0.4689826
	speed: 0.0169s/iter; left time: 25.4365s
Epoch: 3 cost time: 3.669963836669922
Epoch: 3, Steps: 213 | Train Loss: 0.5188802 Vali Loss: 0.5159702 Test Loss: 0.6170641
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5449460
	speed: 0.0177s/iter; left time: 24.6228s
	iters: 200, epoch: 4 | loss: 0.4802260
	speed: 0.0159s/iter; left time: 20.4819s
Epoch: 4 cost time: 3.446174144744873
Epoch: 4, Steps: 213 | Train Loss: 0.5113228 Vali Loss: 0.5231021 Test Loss: 0.6240442
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4841281
	speed: 0.0185s/iter; left time: 21.8251s
	iters: 200, epoch: 5 | loss: 0.5690020
	speed: 0.0178s/iter; left time: 19.1616s
Epoch: 5 cost time: 3.9477550983428955
Epoch: 5, Steps: 213 | Train Loss: 0.5068813 Vali Loss: 0.5306773 Test Loss: 0.6260666
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4523118
	speed: 0.0155s/iter; left time: 14.9760s
	iters: 200, epoch: 6 | loss: 0.4950370
	speed: 0.0135s/iter; left time: 11.7114s
Epoch: 6 cost time: 2.8865585327148438
Epoch: 6, Steps: 213 | Train Loss: 0.5047666 Vali Loss: 0.5385547 Test Loss: 0.6247323
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5867819
	speed: 0.0154s/iter; left time: 11.6125s
	iters: 200, epoch: 7 | loss: 0.4366537
	speed: 0.0139s/iter; left time: 9.0495s
Epoch: 7 cost time: 3.2954459190368652
Epoch: 7, Steps: 213 | Train Loss: 0.5029563 Vali Loss: 0.5399473 Test Loss: 0.6264327
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6168462038040161, mae:0.6214770674705505
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7825539
	speed: 0.0243s/iter; left time: 48.5509s
	iters: 200, epoch: 1 | loss: 0.6575114
	speed: 0.0179s/iter; left time: 34.1117s
Epoch: 1 cost time: 3.7414326667785645
Epoch: 1, Steps: 210 | Train Loss: 0.6770964 Vali Loss: 0.6100661 Test Loss: 0.9112996
Validation loss decreased (inf --> 0.610066).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6185410
	speed: 0.0186s/iter; left time: 33.2747s
	iters: 200, epoch: 2 | loss: 0.6656187
	speed: 0.0158s/iter; left time: 26.6775s
Epoch: 2 cost time: 3.289687395095825
Epoch: 2, Steps: 210 | Train Loss: 0.6586361 Vali Loss: 0.6100786 Test Loss: 0.9047368
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6643207
	speed: 0.0176s/iter; left time: 27.8947s
	iters: 200, epoch: 3 | loss: 0.5878156
	speed: 0.0152s/iter; left time: 22.4618s
Epoch: 3 cost time: 3.191842555999756
Epoch: 3, Steps: 210 | Train Loss: 0.6460271 Vali Loss: 0.6206778 Test Loss: 0.9109172
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5805809
	speed: 0.0109s/iter; left time: 14.9612s
	iters: 200, epoch: 4 | loss: 0.7545530
	speed: 0.0098s/iter; left time: 12.4273s
Epoch: 4 cost time: 2.089514970779419
Epoch: 4, Steps: 210 | Train Loss: 0.6354042 Vali Loss: 0.6378416 Test Loss: 0.9209269
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6799740
	speed: 0.0161s/iter; left time: 18.6484s
	iters: 200, epoch: 5 | loss: 0.5979773
	speed: 0.0143s/iter; left time: 15.2117s
Epoch: 5 cost time: 3.1221604347229004
Epoch: 5, Steps: 210 | Train Loss: 0.6288043 Vali Loss: 0.6445185 Test Loss: 0.9276544
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6817538
	speed: 0.0197s/iter; left time: 18.7256s
	iters: 200, epoch: 6 | loss: 0.5539066
	speed: 0.0202s/iter; left time: 17.1534s
Epoch: 6 cost time: 4.352596044540405
Epoch: 6, Steps: 210 | Train Loss: 0.6249076 Vali Loss: 0.6414136 Test Loss: 0.9304487
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9112997055053711, mae:0.7520902156829834
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6513916
	speed: 0.0214s/iter; left time: 42.8433s
	iters: 200, epoch: 1 | loss: 0.7580940
	speed: 0.0187s/iter; left time: 35.6192s
Epoch: 1 cost time: 4.082207202911377
Epoch: 1, Steps: 210 | Train Loss: 0.6757426 Vali Loss: 0.5973249 Test Loss: 0.9002715
Validation loss decreased (inf --> 0.597325).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6970443
	speed: 0.0210s/iter; left time: 37.5602s
	iters: 200, epoch: 2 | loss: 0.6541928
	speed: 0.0170s/iter; left time: 28.6955s
Epoch: 2 cost time: 3.5915660858154297
Epoch: 2, Steps: 210 | Train Loss: 0.6588040 Vali Loss: 0.6272072 Test Loss: 0.9032644
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7147147
	speed: 0.0192s/iter; left time: 30.3150s
	iters: 200, epoch: 3 | loss: 0.4999482
	speed: 0.0185s/iter; left time: 27.3589s
Epoch: 3 cost time: 3.971870183944702
Epoch: 3, Steps: 210 | Train Loss: 0.6498690 Vali Loss: 0.6307096 Test Loss: 0.8933684
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6308200
	speed: 0.0175s/iter; left time: 24.0517s
	iters: 200, epoch: 4 | loss: 0.6706234
	speed: 0.0153s/iter; left time: 19.4662s
Epoch: 4 cost time: 3.3366570472717285
Epoch: 4, Steps: 210 | Train Loss: 0.6424254 Vali Loss: 0.6222467 Test Loss: 0.8939503
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6707718
	speed: 0.0247s/iter; left time: 28.7125s
	iters: 200, epoch: 5 | loss: 0.5736205
	speed: 0.0204s/iter; left time: 21.6754s
Epoch: 5 cost time: 4.269359111785889
Epoch: 5, Steps: 210 | Train Loss: 0.6370706 Vali Loss: 0.6395102 Test Loss: 0.8992382
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5952863
	speed: 0.0170s/iter; left time: 16.1979s
	iters: 200, epoch: 6 | loss: 0.6222691
	speed: 0.0135s/iter; left time: 11.5097s
Epoch: 6 cost time: 2.8713788986206055
Epoch: 6, Steps: 210 | Train Loss: 0.6344208 Vali Loss: 0.6320473 Test Loss: 0.9035076
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9002714157104492, mae:0.7463585138320923
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6638507
	speed: 0.0194s/iter; left time: 38.7989s
	iters: 200, epoch: 1 | loss: 0.5878253
	speed: 0.0169s/iter; left time: 32.1836s
Epoch: 1 cost time: 3.551896095275879
Epoch: 1, Steps: 210 | Train Loss: 0.6758829 Vali Loss: 0.6072288 Test Loss: 0.9064553
Validation loss decreased (inf --> 0.607229).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6836482
	speed: 0.0197s/iter; left time: 35.2335s
	iters: 200, epoch: 2 | loss: 0.7103300
	speed: 0.0161s/iter; left time: 27.2648s
Epoch: 2 cost time: 3.512812852859497
Epoch: 2, Steps: 210 | Train Loss: 0.6592346 Vali Loss: 0.6024212 Test Loss: 0.8933432
Validation loss decreased (0.607229 --> 0.602421).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6226219
	speed: 0.0204s/iter; left time: 32.2165s
	iters: 200, epoch: 3 | loss: 0.6558012
	speed: 0.0170s/iter; left time: 25.1482s
Epoch: 3 cost time: 3.60418963432312
Epoch: 3, Steps: 210 | Train Loss: 0.6478506 Vali Loss: 0.6281741 Test Loss: 0.8957233
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5532472
	speed: 0.0225s/iter; left time: 30.9006s
	iters: 200, epoch: 4 | loss: 0.6500574
	speed: 0.0156s/iter; left time: 19.8235s
Epoch: 4 cost time: 3.3557329177856445
Epoch: 4, Steps: 210 | Train Loss: 0.6377889 Vali Loss: 0.6412312 Test Loss: 0.9192930
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6369283
	speed: 0.0220s/iter; left time: 25.5574s
	iters: 200, epoch: 5 | loss: 0.5659792
	speed: 0.0174s/iter; left time: 18.4521s
Epoch: 5 cost time: 3.6840713024139404
Epoch: 5, Steps: 210 | Train Loss: 0.6323304 Vali Loss: 0.6589770 Test Loss: 0.9095029
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6346561
	speed: 0.0276s/iter; left time: 26.2903s
	iters: 200, epoch: 6 | loss: 0.5742742
	speed: 0.0226s/iter; left time: 19.1910s
Epoch: 6 cost time: 4.717411994934082
Epoch: 6, Steps: 210 | Train Loss: 0.6290228 Vali Loss: 0.6500924 Test Loss: 0.9106987
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6132488
	speed: 0.0169s/iter; left time: 12.5498s
	iters: 200, epoch: 7 | loss: 0.7258379
	speed: 0.0138s/iter; left time: 8.8371s
Epoch: 7 cost time: 3.022042989730835
Epoch: 7, Steps: 210 | Train Loss: 0.6281821 Vali Loss: 0.6462132 Test Loss: 0.9084550
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8933430910110474, mae:0.7431230545043945
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8831144
	speed: 0.0309s/iter; left time: 60.6249s
	iters: 200, epoch: 1 | loss: 0.8439115
	speed: 0.0241s/iter; left time: 44.8988s
Epoch: 1 cost time: 4.98438024520874
Epoch: 1, Steps: 206 | Train Loss: 0.8554205 Vali Loss: 0.6917256 Test Loss: 1.2442091
Validation loss decreased (inf --> 0.691726).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7890285
	speed: 0.0158s/iter; left time: 27.7776s
	iters: 200, epoch: 2 | loss: 0.8565966
	speed: 0.0169s/iter; left time: 27.8886s
Epoch: 2 cost time: 3.516106128692627
Epoch: 2, Steps: 206 | Train Loss: 0.8346315 Vali Loss: 0.7050443 Test Loss: 1.2545348
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8496763
	speed: 0.0185s/iter; left time: 28.7311s
	iters: 200, epoch: 3 | loss: 0.7374151
	speed: 0.0153s/iter; left time: 22.1956s
Epoch: 3 cost time: 3.2331583499908447
Epoch: 3, Steps: 206 | Train Loss: 0.8201902 Vali Loss: 0.7185809 Test Loss: 1.2363638
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7382223
	speed: 0.0138s/iter; left time: 18.4691s
	iters: 200, epoch: 4 | loss: 0.9792166
	speed: 0.0127s/iter; left time: 15.7995s
Epoch: 4 cost time: 2.7337758541107178
Epoch: 4, Steps: 206 | Train Loss: 0.8096117 Vali Loss: 0.7377191 Test Loss: 1.2776787
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9197443
	speed: 0.0151s/iter; left time: 17.2039s
	iters: 200, epoch: 5 | loss: 0.8144731
	speed: 0.0136s/iter; left time: 14.0841s
Epoch: 5 cost time: 2.910590410232544
Epoch: 5, Steps: 206 | Train Loss: 0.8020450 Vali Loss: 0.7266277 Test Loss: 1.2678792
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6682404
	speed: 0.0166s/iter; left time: 15.4649s
	iters: 200, epoch: 6 | loss: 0.9086220
	speed: 0.0139s/iter; left time: 11.5211s
Epoch: 6 cost time: 2.9720678329467773
Epoch: 6, Steps: 206 | Train Loss: 0.7973776 Vali Loss: 0.7255523 Test Loss: 1.2778924
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2442089319229126, mae:0.8714157342910767
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8536153
	speed: 0.0145s/iter; left time: 28.4821s
	iters: 200, epoch: 1 | loss: 0.8265590
	speed: 0.0130s/iter; left time: 24.2836s
Epoch: 1 cost time: 2.79126238822937
Epoch: 1, Steps: 206 | Train Loss: 0.8545202 Vali Loss: 0.7218035 Test Loss: 1.2366161
Validation loss decreased (inf --> 0.721804).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9339268
	speed: 0.0179s/iter; left time: 31.3811s
	iters: 200, epoch: 2 | loss: 0.6452419
	speed: 0.0163s/iter; left time: 26.9907s
Epoch: 2 cost time: 3.460780620574951
Epoch: 2, Steps: 206 | Train Loss: 0.8348129 Vali Loss: 0.7049367 Test Loss: 1.2564511
Validation loss decreased (0.721804 --> 0.704937).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7595306
	speed: 0.0159s/iter; left time: 24.5961s
	iters: 200, epoch: 3 | loss: 0.9630669
	speed: 0.0156s/iter; left time: 22.5905s
Epoch: 3 cost time: 3.296665906906128
Epoch: 3, Steps: 206 | Train Loss: 0.8183346 Vali Loss: 0.7215501 Test Loss: 1.2723738
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7173225
	speed: 0.0166s/iter; left time: 22.2445s
	iters: 200, epoch: 4 | loss: 0.6720071
	speed: 0.0168s/iter; left time: 20.8244s
Epoch: 4 cost time: 3.5123794078826904
Epoch: 4, Steps: 206 | Train Loss: 0.8008943 Vali Loss: 0.7175791 Test Loss: 1.2667936
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7222809
	speed: 0.0173s/iter; left time: 19.6554s
	iters: 200, epoch: 5 | loss: 0.7054313
	speed: 0.0154s/iter; left time: 15.9937s
Epoch: 5 cost time: 3.214876413345337
Epoch: 5, Steps: 206 | Train Loss: 0.7936086 Vali Loss: 0.7188022 Test Loss: 1.2761933
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7602346
	speed: 0.0191s/iter; left time: 17.7680s
	iters: 200, epoch: 6 | loss: 0.9066049
	speed: 0.0205s/iter; left time: 17.0351s
Epoch: 6 cost time: 4.415990591049194
Epoch: 6, Steps: 206 | Train Loss: 0.7894425 Vali Loss: 0.7315361 Test Loss: 1.2782855
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9276422
	speed: 0.0151s/iter; left time: 10.9740s
	iters: 200, epoch: 7 | loss: 0.6479270
	speed: 0.0155s/iter; left time: 9.6963s
Epoch: 7 cost time: 3.323120355606079
Epoch: 7, Steps: 206 | Train Loss: 0.7861305 Vali Loss: 0.7336990 Test Loss: 1.2797145
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.25645112991333, mae:0.8766878247261047
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8035042
	speed: 0.0162s/iter; left time: 31.8372s
	iters: 200, epoch: 1 | loss: 0.7409976
	speed: 0.0142s/iter; left time: 26.3887s
Epoch: 1 cost time: 3.001727342605591
Epoch: 1, Steps: 206 | Train Loss: 0.8571010 Vali Loss: 0.7101547 Test Loss: 1.2444456
Validation loss decreased (inf --> 0.710155).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8578123
	speed: 0.0147s/iter; left time: 25.7842s
	iters: 200, epoch: 2 | loss: 0.8961414
	speed: 0.0142s/iter; left time: 23.5041s
Epoch: 2 cost time: 2.986016273498535
Epoch: 2, Steps: 206 | Train Loss: 0.8351681 Vali Loss: 0.7185495 Test Loss: 1.2625519
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8877638
	speed: 0.0189s/iter; left time: 29.2476s
	iters: 200, epoch: 3 | loss: 0.7424234
	speed: 0.0168s/iter; left time: 24.3355s
Epoch: 3 cost time: 3.567697763442993
Epoch: 3, Steps: 206 | Train Loss: 0.8210833 Vali Loss: 0.7367817 Test Loss: 1.2762444
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7189307
	speed: 0.0205s/iter; left time: 27.5234s
	iters: 200, epoch: 4 | loss: 0.7765912
	speed: 0.0173s/iter; left time: 21.4585s
Epoch: 4 cost time: 3.6078343391418457
Epoch: 4, Steps: 206 | Train Loss: 0.8109296 Vali Loss: 0.7388256 Test Loss: 1.2620142
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7904575
	speed: 0.0178s/iter; left time: 20.2092s
	iters: 200, epoch: 5 | loss: 0.7779700
	speed: 0.0158s/iter; left time: 16.4348s
Epoch: 5 cost time: 3.3383827209472656
Epoch: 5, Steps: 206 | Train Loss: 0.8014954 Vali Loss: 0.7337798 Test Loss: 1.2831692
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9095250
	speed: 0.0156s/iter; left time: 14.4912s
	iters: 200, epoch: 6 | loss: 0.6924719
	speed: 0.0129s/iter; left time: 10.7492s
Epoch: 6 cost time: 2.766371011734009
Epoch: 6, Steps: 206 | Train Loss: 0.7980149 Vali Loss: 0.7347512 Test Loss: 1.2820292
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2444454431533813, mae:0.872138500213623
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1015722
	speed: 0.0294s/iter; left time: 54.2076s
Epoch: 1 cost time: 4.243108749389648
Epoch: 1, Steps: 194 | Train Loss: 1.2379700 Vali Loss: 0.5410343 Test Loss: 1.4305060
Validation loss decreased (inf --> 0.541034).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1470855
	speed: 0.0140s/iter; left time: 23.0028s
Epoch: 2 cost time: 2.625643014907837
Epoch: 2, Steps: 194 | Train Loss: 1.2133840 Vali Loss: 0.5788891 Test Loss: 1.4106965
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1368933
	speed: 0.0176s/iter; left time: 25.6213s
Epoch: 3 cost time: 3.2223594188690186
Epoch: 3, Steps: 194 | Train Loss: 1.1879448 Vali Loss: 0.6170264 Test Loss: 1.3786788
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0858661
	speed: 0.0175s/iter; left time: 22.0529s
Epoch: 4 cost time: 3.1003267765045166
Epoch: 4, Steps: 194 | Train Loss: 1.1704402 Vali Loss: 0.6244683 Test Loss: 1.3962443
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1406745
	speed: 0.0178s/iter; left time: 19.0068s
Epoch: 5 cost time: 3.184321165084839
Epoch: 5, Steps: 194 | Train Loss: 1.1566610 Vali Loss: 0.6317785 Test Loss: 1.3972068
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0888413
	speed: 0.0181s/iter; left time: 15.7262s
Epoch: 6 cost time: 3.2130420207977295
Epoch: 6, Steps: 194 | Train Loss: 1.1492675 Vali Loss: 0.6218727 Test Loss: 1.3943114
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4305059909820557, mae:0.9321420192718506
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2775978
	speed: 0.0131s/iter; left time: 24.1135s
Epoch: 1 cost time: 2.4760708808898926
Epoch: 1, Steps: 194 | Train Loss: 1.2360360 Vali Loss: 0.6089970 Test Loss: 1.3803318
Validation loss decreased (inf --> 0.608997).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2586936
	speed: 0.0174s/iter; left time: 28.6257s
Epoch: 2 cost time: 3.270348072052002
Epoch: 2, Steps: 194 | Train Loss: 1.2107279 Vali Loss: 0.5978068 Test Loss: 1.3754482
Validation loss decreased (0.608997 --> 0.597807).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9791589
	speed: 0.0156s/iter; left time: 22.7120s
Epoch: 3 cost time: 3.0375869274139404
Epoch: 3, Steps: 194 | Train Loss: 1.1879557 Vali Loss: 0.5809004 Test Loss: 1.4086883
Validation loss decreased (0.597807 --> 0.580900).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.3370242
	speed: 0.0164s/iter; left time: 20.6407s
Epoch: 4 cost time: 2.832242488861084
Epoch: 4, Steps: 194 | Train Loss: 1.1741355 Vali Loss: 0.5963096 Test Loss: 1.3710952
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1807098
	speed: 0.0160s/iter; left time: 17.0889s
Epoch: 5 cost time: 2.8584213256835938
Epoch: 5, Steps: 194 | Train Loss: 1.1600141 Vali Loss: 0.6195869 Test Loss: 1.3930573
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2086952
	speed: 0.0179s/iter; left time: 15.6086s
Epoch: 6 cost time: 2.891047477722168
Epoch: 6, Steps: 194 | Train Loss: 1.1528819 Vali Loss: 0.6142552 Test Loss: 1.3984991
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9820381
	speed: 0.0170s/iter; left time: 11.5169s
Epoch: 7 cost time: 3.155705213546753
Epoch: 7, Steps: 194 | Train Loss: 1.1497766 Vali Loss: 0.6198382 Test Loss: 1.3970072
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0631074
	speed: 0.0182s/iter; left time: 8.8108s
Epoch: 8 cost time: 3.3674778938293457
Epoch: 8, Steps: 194 | Train Loss: 1.1463598 Vali Loss: 0.6218240 Test Loss: 1.4004148
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4086883068084717, mae:0.9276922941207886
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2806712
	speed: 0.0197s/iter; left time: 36.3090s
Epoch: 1 cost time: 3.347764492034912
Epoch: 1, Steps: 194 | Train Loss: 1.2392765 Vali Loss: 0.5422300 Test Loss: 1.4524114
Validation loss decreased (inf --> 0.542230).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3073754
	speed: 0.0168s/iter; left time: 27.6553s
Epoch: 2 cost time: 3.287201404571533
Epoch: 2, Steps: 194 | Train Loss: 1.2187614 Vali Loss: 0.6423002 Test Loss: 1.3608853
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2275118
	speed: 0.0127s/iter; left time: 18.4835s
Epoch: 3 cost time: 2.3406150341033936
Epoch: 3, Steps: 194 | Train Loss: 1.1967718 Vali Loss: 0.5900008 Test Loss: 1.3812262
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.3166759
	speed: 0.0168s/iter; left time: 21.0986s
Epoch: 4 cost time: 3.0062193870544434
Epoch: 4, Steps: 194 | Train Loss: 1.1812388 Vali Loss: 0.6061378 Test Loss: 1.3539443
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.3290496
	speed: 0.0207s/iter; left time: 22.0886s
Epoch: 5 cost time: 3.3371083736419678
Epoch: 5, Steps: 194 | Train Loss: 1.1698084 Vali Loss: 0.6043811 Test Loss: 1.3782012
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.3218352
	speed: 0.0219s/iter; left time: 19.0896s
Epoch: 6 cost time: 4.5345659255981445
Epoch: 6, Steps: 194 | Train Loss: 1.1640885 Vali Loss: 0.6054500 Test Loss: 1.3799398
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4524112939834595, mae:0.9393259882926941
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5136669
	speed: 0.0270s/iter; left time: 54.7706s
	iters: 200, epoch: 1 | loss: 0.4647203
	speed: 0.0229s/iter; left time: 44.1622s
Epoch: 1 cost time: 4.860111236572266
Epoch: 1, Steps: 213 | Train Loss: 0.5479082 Vali Loss: 0.5044698 Test Loss: 0.6011823
Validation loss decreased (inf --> 0.504470).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5238146
	speed: 0.0198s/iter; left time: 36.0444s
	iters: 200, epoch: 2 | loss: 0.4754101
	speed: 0.0188s/iter; left time: 32.2973s
Epoch: 2 cost time: 4.0245044231414795
Epoch: 2, Steps: 213 | Train Loss: 0.5302183 Vali Loss: 0.5102103 Test Loss: 0.6251699
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4857333
	speed: 0.0185s/iter; left time: 29.6646s
	iters: 200, epoch: 3 | loss: 0.5171131
	speed: 0.0150s/iter; left time: 22.6434s
Epoch: 3 cost time: 3.311544895172119
Epoch: 3, Steps: 213 | Train Loss: 0.5184442 Vali Loss: 0.5173885 Test Loss: 0.6270916
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5393722
	speed: 0.0174s/iter; left time: 24.2219s
	iters: 200, epoch: 4 | loss: 0.4811352
	speed: 0.0196s/iter; left time: 25.3738s
Epoch: 4 cost time: 4.230939865112305
Epoch: 4, Steps: 213 | Train Loss: 0.5117078 Vali Loss: 0.5214684 Test Loss: 0.6309764
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5302247
	speed: 0.0160s/iter; left time: 18.8662s
	iters: 200, epoch: 5 | loss: 0.5351956
	speed: 0.0136s/iter; left time: 14.6311s
Epoch: 5 cost time: 2.9665911197662354
Epoch: 5, Steps: 213 | Train Loss: 0.5076121 Vali Loss: 0.5241657 Test Loss: 0.6324426
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4595142
	speed: 0.0156s/iter; left time: 15.0716s
	iters: 200, epoch: 6 | loss: 0.5132687
	speed: 0.0132s/iter; left time: 11.4023s
Epoch: 6 cost time: 2.8576788902282715
Epoch: 6, Steps: 213 | Train Loss: 0.5049716 Vali Loss: 0.5288007 Test Loss: 0.6310607
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6011823415756226, mae:0.6136912107467651
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6088526
	speed: 0.0110s/iter; left time: 22.3091s
	iters: 200, epoch: 1 | loss: 0.5784683
	speed: 0.0102s/iter; left time: 19.7443s
Epoch: 1 cost time: 2.317727565765381
Epoch: 1, Steps: 213 | Train Loss: 0.5466345 Vali Loss: 0.5071567 Test Loss: 0.6000332
Validation loss decreased (inf --> 0.507157).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5586770
	speed: 0.0155s/iter; left time: 28.2437s
	iters: 200, epoch: 2 | loss: 0.4748666
	speed: 0.0156s/iter; left time: 26.8057s
Epoch: 2 cost time: 3.447197914123535
Epoch: 2, Steps: 213 | Train Loss: 0.5298844 Vali Loss: 0.5010696 Test Loss: 0.6007444
Validation loss decreased (0.507157 --> 0.501070).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5229999
	speed: 0.0180s/iter; left time: 28.8323s
	iters: 200, epoch: 3 | loss: 0.4692974
	speed: 0.0166s/iter; left time: 24.9881s
Epoch: 3 cost time: 3.5717122554779053
Epoch: 3, Steps: 213 | Train Loss: 0.5191450 Vali Loss: 0.5192875 Test Loss: 0.6152357
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5367895
	speed: 0.0177s/iter; left time: 24.6559s
	iters: 200, epoch: 4 | loss: 0.5275062
	speed: 0.0158s/iter; left time: 20.4433s
Epoch: 4 cost time: 3.3759701251983643
Epoch: 4, Steps: 213 | Train Loss: 0.5123664 Vali Loss: 0.5172599 Test Loss: 0.6212270
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4934910
	speed: 0.0138s/iter; left time: 16.2439s
	iters: 200, epoch: 5 | loss: 0.4777687
	speed: 0.0110s/iter; left time: 11.9174s
Epoch: 5 cost time: 2.446667432785034
Epoch: 5, Steps: 213 | Train Loss: 0.5072531 Vali Loss: 0.5300336 Test Loss: 0.6269581
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4824143
	speed: 0.0146s/iter; left time: 14.1225s
	iters: 200, epoch: 6 | loss: 0.5228009
	speed: 0.0138s/iter; left time: 11.9162s
Epoch: 6 cost time: 2.958800792694092
Epoch: 6, Steps: 213 | Train Loss: 0.5046775 Vali Loss: 0.5349217 Test Loss: 0.6252825
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4517468
	speed: 0.0144s/iter; left time: 10.8463s
	iters: 200, epoch: 7 | loss: 0.4770522
	speed: 0.0125s/iter; left time: 8.1324s
Epoch: 7 cost time: 2.721726894378662
Epoch: 7, Steps: 213 | Train Loss: 0.5031738 Vali Loss: 0.5361506 Test Loss: 0.6259248
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6007444262504578, mae:0.6135508418083191
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6280262
	speed: 0.0166s/iter; left time: 33.6643s
	iters: 200, epoch: 1 | loss: 0.5287019
	speed: 0.0154s/iter; left time: 29.8022s
Epoch: 1 cost time: 3.3884530067443848
Epoch: 1, Steps: 213 | Train Loss: 0.5473363 Vali Loss: 0.5056307 Test Loss: 0.6257204
Validation loss decreased (inf --> 0.505631).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5065719
	speed: 0.0144s/iter; left time: 26.0973s
	iters: 200, epoch: 2 | loss: 0.5551552
	speed: 0.0116s/iter; left time: 19.8762s
Epoch: 2 cost time: 2.454927682876587
Epoch: 2, Steps: 213 | Train Loss: 0.5303162 Vali Loss: 0.5046125 Test Loss: 0.6255932
Validation loss decreased (0.505631 --> 0.504613).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4999382
	speed: 0.0167s/iter; left time: 26.7595s
	iters: 200, epoch: 3 | loss: 0.5038545
	speed: 0.0147s/iter; left time: 22.1976s
Epoch: 3 cost time: 3.1718623638153076
Epoch: 3, Steps: 213 | Train Loss: 0.5182609 Vali Loss: 0.5161693 Test Loss: 0.6168060
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5095910
	speed: 0.0179s/iter; left time: 24.9695s
	iters: 200, epoch: 4 | loss: 0.5276793
	speed: 0.0155s/iter; left time: 20.0576s
Epoch: 4 cost time: 3.3415582180023193
Epoch: 4, Steps: 213 | Train Loss: 0.5119687 Vali Loss: 0.5188186 Test Loss: 0.6147968
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5062760
	speed: 0.0179s/iter; left time: 21.0900s
	iters: 200, epoch: 5 | loss: 0.5247773
	speed: 0.0154s/iter; left time: 16.5958s
Epoch: 5 cost time: 3.3314096927642822
Epoch: 5, Steps: 213 | Train Loss: 0.5073235 Vali Loss: 0.5212379 Test Loss: 0.6197007
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5046798
	speed: 0.0131s/iter; left time: 12.6336s
	iters: 200, epoch: 6 | loss: 0.5071156
	speed: 0.0104s/iter; left time: 8.9938s
Epoch: 6 cost time: 2.232440948486328
Epoch: 6, Steps: 213 | Train Loss: 0.5054414 Vali Loss: 0.5216381 Test Loss: 0.6209921
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4685342
	speed: 0.0129s/iter; left time: 9.6860s
	iters: 200, epoch: 7 | loss: 0.4936423
	speed: 0.0120s/iter; left time: 7.8138s
Epoch: 7 cost time: 2.630739212036133
Epoch: 7, Steps: 213 | Train Loss: 0.5040837 Vali Loss: 0.5256343 Test Loss: 0.6222246
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6255933046340942, mae:0.6266290545463562
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7732493
	speed: 0.0224s/iter; left time: 44.7728s
	iters: 200, epoch: 1 | loss: 0.6289846
	speed: 0.0170s/iter; left time: 32.2508s
Epoch: 1 cost time: 3.5704615116119385
Epoch: 1, Steps: 210 | Train Loss: 0.6765024 Vali Loss: 0.6106214 Test Loss: 0.8997317
Validation loss decreased (inf --> 0.610621).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7923228
	speed: 0.0137s/iter; left time: 24.5371s
	iters: 200, epoch: 2 | loss: 0.7522383
	speed: 0.0120s/iter; left time: 20.3401s
Epoch: 2 cost time: 2.621396780014038
Epoch: 2, Steps: 210 | Train Loss: 0.6587172 Vali Loss: 0.6103062 Test Loss: 0.9056749
Validation loss decreased (0.610621 --> 0.610306).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6699052
	speed: 0.0101s/iter; left time: 15.9026s
	iters: 200, epoch: 3 | loss: 0.7051503
	speed: 0.0089s/iter; left time: 13.2342s
Epoch: 3 cost time: 1.9470117092132568
Epoch: 3, Steps: 210 | Train Loss: 0.6451492 Vali Loss: 0.6384634 Test Loss: 0.9278166
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6453692
	speed: 0.0128s/iter; left time: 17.5181s
	iters: 200, epoch: 4 | loss: 0.6544907
	speed: 0.0118s/iter; left time: 14.9547s
Epoch: 4 cost time: 2.5299923419952393
Epoch: 4, Steps: 210 | Train Loss: 0.6348935 Vali Loss: 0.6367404 Test Loss: 0.9162723
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6077234
	speed: 0.0125s/iter; left time: 14.5653s
	iters: 200, epoch: 5 | loss: 0.6362426
	speed: 0.0111s/iter; left time: 11.7629s
Epoch: 5 cost time: 2.3815267086029053
Epoch: 5, Steps: 210 | Train Loss: 0.6276562 Vali Loss: 0.6321281 Test Loss: 0.9364613
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6298544
	speed: 0.0140s/iter; left time: 13.3310s
	iters: 200, epoch: 6 | loss: 0.5843644
	speed: 0.0123s/iter; left time: 10.4302s
Epoch: 6 cost time: 2.588627815246582
Epoch: 6, Steps: 210 | Train Loss: 0.6236077 Vali Loss: 0.6502516 Test Loss: 0.9380919
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6069128
	speed: 0.0104s/iter; left time: 7.6763s
	iters: 200, epoch: 7 | loss: 0.5354149
	speed: 0.0094s/iter; left time: 6.0276s
Epoch: 7 cost time: 2.045947551727295
Epoch: 7, Steps: 210 | Train Loss: 0.6220303 Vali Loss: 0.6454149 Test Loss: 0.9379273
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9056746959686279, mae:0.7493169903755188
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5882332
	speed: 0.0135s/iter; left time: 27.0081s
	iters: 200, epoch: 1 | loss: 0.6943125
	speed: 0.0117s/iter; left time: 22.2103s
Epoch: 1 cost time: 2.542532205581665
Epoch: 1, Steps: 210 | Train Loss: 0.6763484 Vali Loss: 0.6134874 Test Loss: 0.9010094
Validation loss decreased (inf --> 0.613487).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6734370
	speed: 0.0137s/iter; left time: 24.5659s
	iters: 200, epoch: 2 | loss: 0.6264068
	speed: 0.0119s/iter; left time: 20.0728s
Epoch: 2 cost time: 2.5612502098083496
Epoch: 2, Steps: 210 | Train Loss: 0.6580056 Vali Loss: 0.6131361 Test Loss: 0.9106147
Validation loss decreased (0.613487 --> 0.613136).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5967098
	speed: 0.0136s/iter; left time: 21.5731s
	iters: 200, epoch: 3 | loss: 0.5462226
	speed: 0.0119s/iter; left time: 17.6297s
Epoch: 3 cost time: 2.545103073120117
Epoch: 3, Steps: 210 | Train Loss: 0.6461647 Vali Loss: 0.6253803 Test Loss: 0.9428066
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6016237
	speed: 0.0097s/iter; left time: 13.3392s
	iters: 200, epoch: 4 | loss: 0.7328649
	speed: 0.0083s/iter; left time: 10.5487s
Epoch: 4 cost time: 1.8306200504302979
Epoch: 4, Steps: 210 | Train Loss: 0.6357848 Vali Loss: 0.6479532 Test Loss: 0.9210019
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5804325
	speed: 0.0108s/iter; left time: 12.5550s
	iters: 200, epoch: 5 | loss: 0.6100527
	speed: 0.0101s/iter; left time: 10.6712s
Epoch: 5 cost time: 2.1520068645477295
Epoch: 5, Steps: 210 | Train Loss: 0.6283059 Vali Loss: 0.6533267 Test Loss: 0.9355441
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5826999
	speed: 0.0109s/iter; left time: 10.4088s
	iters: 200, epoch: 6 | loss: 0.6340171
	speed: 0.0101s/iter; left time: 8.6109s
Epoch: 6 cost time: 2.1770517826080322
Epoch: 6, Steps: 210 | Train Loss: 0.6242736 Vali Loss: 0.6466006 Test Loss: 0.9319176
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7118217
	speed: 0.0140s/iter; left time: 10.3772s
	iters: 200, epoch: 7 | loss: 0.6306630
	speed: 0.0130s/iter; left time: 8.3580s
Epoch: 7 cost time: 2.786939859390259
Epoch: 7, Steps: 210 | Train Loss: 0.6225687 Vali Loss: 0.6545982 Test Loss: 0.9341981
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9106148481369019, mae:0.7511917948722839
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8034534
	speed: 0.0111s/iter; left time: 22.1172s
	iters: 200, epoch: 1 | loss: 0.6586413
	speed: 0.0094s/iter; left time: 17.9516s
Epoch: 1 cost time: 2.0527491569519043
Epoch: 1, Steps: 210 | Train Loss: 0.6767213 Vali Loss: 0.6229222 Test Loss: 0.8927091
Validation loss decreased (inf --> 0.622922).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5890242
	speed: 0.0139s/iter; left time: 24.8784s
	iters: 200, epoch: 2 | loss: 0.6118729
	speed: 0.0127s/iter; left time: 21.4902s
Epoch: 2 cost time: 2.7106473445892334
Epoch: 2, Steps: 210 | Train Loss: 0.6587281 Vali Loss: 0.6150413 Test Loss: 0.8857856
Validation loss decreased (0.622922 --> 0.615041).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5964662
	speed: 0.0139s/iter; left time: 21.9394s
	iters: 200, epoch: 3 | loss: 0.6866654
	speed: 0.0124s/iter; left time: 18.3522s
Epoch: 3 cost time: 2.6512820720672607
Epoch: 3, Steps: 210 | Train Loss: 0.6480727 Vali Loss: 0.6349956 Test Loss: 0.9091265
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6957487
	speed: 0.0139s/iter; left time: 18.9983s
	iters: 200, epoch: 4 | loss: 0.6615893
	speed: 0.0120s/iter; left time: 15.2470s
Epoch: 4 cost time: 2.5428926944732666
Epoch: 4, Steps: 210 | Train Loss: 0.6395079 Vali Loss: 0.6423158 Test Loss: 0.9046877
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6358571
	speed: 0.0121s/iter; left time: 14.0784s
	iters: 200, epoch: 5 | loss: 0.6389167
	speed: 0.0096s/iter; left time: 10.1584s
Epoch: 5 cost time: 2.073889970779419
Epoch: 5, Steps: 210 | Train Loss: 0.6344178 Vali Loss: 0.6399393 Test Loss: 0.9160309
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5982740
	speed: 0.0117s/iter; left time: 11.1283s
	iters: 200, epoch: 6 | loss: 0.6891769
	speed: 0.0120s/iter; left time: 10.2033s
Epoch: 6 cost time: 2.6125028133392334
Epoch: 6, Steps: 210 | Train Loss: 0.6298656 Vali Loss: 0.6512616 Test Loss: 0.9181156
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7072678
	speed: 0.0139s/iter; left time: 10.2984s
	iters: 200, epoch: 7 | loss: 0.5487028
	speed: 0.0131s/iter; left time: 8.3890s
Epoch: 7 cost time: 2.792372941970825
Epoch: 7, Steps: 210 | Train Loss: 0.6286569 Vali Loss: 0.6506396 Test Loss: 0.9192476
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8857857584953308, mae:0.7401354908943176
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7785313
	speed: 0.0178s/iter; left time: 34.8374s
	iters: 200, epoch: 1 | loss: 0.8646226
	speed: 0.0133s/iter; left time: 24.8256s
Epoch: 1 cost time: 2.7860231399536133
Epoch: 1, Steps: 206 | Train Loss: 0.8564689 Vali Loss: 0.7371380 Test Loss: 1.2610109
Validation loss decreased (inf --> 0.737138).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8870224
	speed: 0.0131s/iter; left time: 23.0613s
	iters: 200, epoch: 2 | loss: 0.7943092
	speed: 0.0127s/iter; left time: 21.0292s
Epoch: 2 cost time: 2.6619226932525635
Epoch: 2, Steps: 206 | Train Loss: 0.8355472 Vali Loss: 0.7272657 Test Loss: 1.2560925
Validation loss decreased (0.737138 --> 0.727266).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7698101
	speed: 0.0128s/iter; left time: 19.8267s
	iters: 200, epoch: 3 | loss: 0.8603394
	speed: 0.0125s/iter; left time: 18.1543s
Epoch: 3 cost time: 2.6375949382781982
Epoch: 3, Steps: 206 | Train Loss: 0.8225628 Vali Loss: 0.7341289 Test Loss: 1.2569366
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8233474
	speed: 0.0120s/iter; left time: 16.1688s
	iters: 200, epoch: 4 | loss: 0.8761424
	speed: 0.0121s/iter; left time: 15.1010s
Epoch: 4 cost time: 2.5686442852020264
Epoch: 4, Steps: 206 | Train Loss: 0.8123318 Vali Loss: 0.7324673 Test Loss: 1.2634568
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8697810
	speed: 0.0095s/iter; left time: 10.8180s
	iters: 200, epoch: 5 | loss: 0.8704892
	speed: 0.0080s/iter; left time: 8.3363s
Epoch: 5 cost time: 1.6977720260620117
Epoch: 5, Steps: 206 | Train Loss: 0.8056115 Vali Loss: 0.7334846 Test Loss: 1.2650332
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9916335
	speed: 0.0112s/iter; left time: 10.4443s
	iters: 200, epoch: 6 | loss: 0.7700705
	speed: 0.0107s/iter; left time: 8.8744s
Epoch: 6 cost time: 2.2963454723358154
Epoch: 6, Steps: 206 | Train Loss: 0.8017838 Vali Loss: 0.7361619 Test Loss: 1.2782246
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9387612
	speed: 0.0137s/iter; left time: 9.9164s
	iters: 200, epoch: 7 | loss: 0.6610066
	speed: 0.0122s/iter; left time: 7.6167s
Epoch: 7 cost time: 2.546501874923706
Epoch: 7, Steps: 206 | Train Loss: 0.7968312 Vali Loss: 0.7412693 Test Loss: 1.2889163
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2560925483703613, mae:0.8765986561775208
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7448729
	speed: 0.0140s/iter; left time: 27.4046s
	iters: 200, epoch: 1 | loss: 0.7744520
	speed: 0.0120s/iter; left time: 22.3892s
Epoch: 1 cost time: 2.5443837642669678
Epoch: 1, Steps: 206 | Train Loss: 0.8565883 Vali Loss: 0.7273079 Test Loss: 1.2527128
Validation loss decreased (inf --> 0.727308).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8227811
	speed: 0.0139s/iter; left time: 24.4190s
	iters: 200, epoch: 2 | loss: 0.7298018
	speed: 0.0115s/iter; left time: 19.0346s
Epoch: 2 cost time: 2.408295154571533
Epoch: 2, Steps: 206 | Train Loss: 0.8341961 Vali Loss: 0.7330359 Test Loss: 1.2694869
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6972973
	speed: 0.0108s/iter; left time: 16.6991s
	iters: 200, epoch: 3 | loss: 0.8127759
	speed: 0.0094s/iter; left time: 13.6020s
Epoch: 3 cost time: 1.9708778858184814
Epoch: 3, Steps: 206 | Train Loss: 0.8189047 Vali Loss: 0.7333397 Test Loss: 1.2748616
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6653320
	speed: 0.0139s/iter; left time: 18.6537s
	iters: 200, epoch: 4 | loss: 0.7612448
	speed: 0.0126s/iter; left time: 15.6419s
Epoch: 4 cost time: 2.617372989654541
Epoch: 4, Steps: 206 | Train Loss: 0.8064469 Vali Loss: 0.7341685 Test Loss: 1.3079237
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7449882
	speed: 0.0138s/iter; left time: 15.6437s
	iters: 200, epoch: 5 | loss: 0.8615232
	speed: 0.0126s/iter; left time: 13.1019s
Epoch: 5 cost time: 2.646331787109375
Epoch: 5, Steps: 206 | Train Loss: 0.7974596 Vali Loss: 0.7410098 Test Loss: 1.3245878
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7679772
	speed: 0.0139s/iter; left time: 12.9196s
	iters: 200, epoch: 6 | loss: 0.9081712
	speed: 0.0130s/iter; left time: 10.8020s
Epoch: 6 cost time: 2.7298085689544678
Epoch: 6, Steps: 206 | Train Loss: 0.7919678 Vali Loss: 0.7448942 Test Loss: 1.3310331
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2527129650115967, mae:0.8754937052726746
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8917309
	speed: 0.0084s/iter; left time: 16.3895s
	iters: 200, epoch: 1 | loss: 0.8070719
	speed: 0.0077s/iter; left time: 14.3525s
Epoch: 1 cost time: 1.6411185264587402
Epoch: 1, Steps: 206 | Train Loss: 0.8552368 Vali Loss: 0.6844665 Test Loss: 1.2488114
Validation loss decreased (inf --> 0.684467).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1300715
	speed: 0.0104s/iter; left time: 18.2587s
	iters: 200, epoch: 2 | loss: 0.9216560
	speed: 0.0098s/iter; left time: 16.2979s
Epoch: 2 cost time: 2.08970046043396
Epoch: 2, Steps: 206 | Train Loss: 0.8338303 Vali Loss: 0.7124323 Test Loss: 1.2655878
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7944334
	speed: 0.0107s/iter; left time: 16.6246s
	iters: 200, epoch: 3 | loss: 0.7207191
	speed: 0.0114s/iter; left time: 16.5394s
Epoch: 3 cost time: 2.4060957431793213
Epoch: 3, Steps: 206 | Train Loss: 0.8208588 Vali Loss: 0.7175668 Test Loss: 1.2650974
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7357541
	speed: 0.0137s/iter; left time: 18.4122s
	iters: 200, epoch: 4 | loss: 0.8587067
	speed: 0.0119s/iter; left time: 14.7920s
Epoch: 4 cost time: 2.5097436904907227
Epoch: 4, Steps: 206 | Train Loss: 0.8134745 Vali Loss: 0.7513223 Test Loss: 1.2628356
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7967368
	speed: 0.0136s/iter; left time: 15.5045s
	iters: 200, epoch: 5 | loss: 0.7252104
	speed: 0.0123s/iter; left time: 12.7845s
Epoch: 5 cost time: 2.550473213195801
Epoch: 5, Steps: 206 | Train Loss: 0.8074212 Vali Loss: 0.7420891 Test Loss: 1.2707310
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7303205
	speed: 0.0104s/iter; left time: 9.7269s
	iters: 200, epoch: 6 | loss: 0.7700999
	speed: 0.0089s/iter; left time: 7.3769s
Epoch: 6 cost time: 1.9470152854919434
Epoch: 6, Steps: 206 | Train Loss: 0.8033519 Vali Loss: 0.7397497 Test Loss: 1.2764465
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2488113641738892, mae:0.8725576996803284
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0386903
	speed: 0.0209s/iter; left time: 38.4808s
Epoch: 1 cost time: 3.172041893005371
Epoch: 1, Steps: 194 | Train Loss: 1.2390140 Vali Loss: 0.5796474 Test Loss: 1.3984927
Validation loss decreased (inf --> 0.579647).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3401335
	speed: 0.0136s/iter; left time: 22.3548s
Epoch: 2 cost time: 2.5742692947387695
Epoch: 2, Steps: 194 | Train Loss: 1.2121613 Vali Loss: 0.5973979 Test Loss: 1.3610139
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1417015
	speed: 0.0118s/iter; left time: 17.1989s
Epoch: 3 cost time: 2.4064249992370605
Epoch: 3, Steps: 194 | Train Loss: 1.1911286 Vali Loss: 0.6099090 Test Loss: 1.3249270
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.4109215
	speed: 0.0120s/iter; left time: 15.1233s
Epoch: 4 cost time: 2.364959239959717
Epoch: 4, Steps: 194 | Train Loss: 1.1677071 Vali Loss: 0.6445395 Test Loss: 1.3410161
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.3154770
	speed: 0.0122s/iter; left time: 13.0370s
Epoch: 5 cost time: 2.017500638961792
Epoch: 5, Steps: 194 | Train Loss: 1.1509878 Vali Loss: 0.6347331 Test Loss: 1.3557805
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.3227922
	speed: 0.0104s/iter; left time: 9.0892s
Epoch: 6 cost time: 1.8094878196716309
Epoch: 6, Steps: 194 | Train Loss: 1.1422617 Vali Loss: 0.6406769 Test Loss: 1.3564469
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3984925746917725, mae:0.9278191924095154
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.3223106
	speed: 0.0142s/iter; left time: 26.0835s
Epoch: 1 cost time: 2.442305326461792
Epoch: 1, Steps: 194 | Train Loss: 1.2371752 Vali Loss: 0.5935072 Test Loss: 1.3748002
Validation loss decreased (inf --> 0.593507).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2995427
	speed: 0.0143s/iter; left time: 23.5542s
Epoch: 2 cost time: 2.4778783321380615
Epoch: 2, Steps: 194 | Train Loss: 1.2124570 Vali Loss: 0.6294376 Test Loss: 1.3548779
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0470859
	speed: 0.0140s/iter; left time: 20.3427s
Epoch: 3 cost time: 2.560772180557251
Epoch: 3, Steps: 194 | Train Loss: 1.1914828 Vali Loss: 0.5872474 Test Loss: 1.3848974
Validation loss decreased (0.593507 --> 0.587247).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.3746142
	speed: 0.0124s/iter; left time: 15.6422s
Epoch: 4 cost time: 2.083057165145874
Epoch: 4, Steps: 194 | Train Loss: 1.1735368 Vali Loss: 0.6298013 Test Loss: 1.3602979
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.2496325
	speed: 0.0104s/iter; left time: 11.1194s
Epoch: 5 cost time: 2.0437517166137695
Epoch: 5, Steps: 194 | Train Loss: 1.1599215 Vali Loss: 0.6247919 Test Loss: 1.3751611
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2173135
	speed: 0.0142s/iter; left time: 12.3401s
Epoch: 6 cost time: 2.637458324432373
Epoch: 6, Steps: 194 | Train Loss: 1.1552869 Vali Loss: 0.6403543 Test Loss: 1.3610320
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0839401
	speed: 0.0129s/iter; left time: 8.7257s
Epoch: 7 cost time: 2.5030739307403564
Epoch: 7, Steps: 194 | Train Loss: 1.1522417 Vali Loss: 0.6390446 Test Loss: 1.3697706
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.2580855
	speed: 0.0125s/iter; left time: 6.0349s
Epoch: 8 cost time: 2.46010160446167
Epoch: 8, Steps: 194 | Train Loss: 1.1479341 Vali Loss: 0.6376193 Test Loss: 1.3732167
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3848974704742432, mae:0.9212139248847961
Use GPU: cuda:0
no_skip True
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.3159051
	speed: 0.0087s/iter; left time: 16.0374s
Epoch: 1 cost time: 1.6864769458770752
Epoch: 1, Steps: 194 | Train Loss: 1.2373916 Vali Loss: 0.5923520 Test Loss: 1.4015429
Validation loss decreased (inf --> 0.592352).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1620556
	speed: 0.0094s/iter; left time: 15.4116s
Epoch: 2 cost time: 2.0345113277435303
Epoch: 2, Steps: 194 | Train Loss: 1.2093540 Vali Loss: 0.5608029 Test Loss: 1.3958577
Validation loss decreased (0.592352 --> 0.560803).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0413942
	speed: 0.0129s/iter; left time: 18.6785s
Epoch: 3 cost time: 2.2834253311157227
Epoch: 3, Steps: 194 | Train Loss: 1.1870056 Vali Loss: 0.5637672 Test Loss: 1.3954195
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1201644
	speed: 0.0138s/iter; left time: 17.4350s
Epoch: 4 cost time: 2.420304536819458
Epoch: 4, Steps: 194 | Train Loss: 1.1714965 Vali Loss: 0.6290298 Test Loss: 1.3728032
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0190822
	speed: 0.0139s/iter; left time: 14.8024s
Epoch: 5 cost time: 2.5360379219055176
Epoch: 5, Steps: 194 | Train Loss: 1.1543092 Vali Loss: 0.6361856 Test Loss: 1.3779130
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2308543
	speed: 0.0117s/iter; left time: 10.2154s
Epoch: 6 cost time: 1.9517416954040527
Epoch: 6, Steps: 194 | Train Loss: 1.1502774 Vali Loss: 0.6515101 Test Loss: 1.3620949
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.1830835
	speed: 0.0100s/iter; left time: 6.7995s
Epoch: 7 cost time: 2.224147319793701
Epoch: 7, Steps: 194 | Train Loss: 1.1464943 Vali Loss: 0.6486040 Test Loss: 1.3749511
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3958576917648315, mae:0.9216621518135071
