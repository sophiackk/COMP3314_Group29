nohup: ignoring input
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0381064
	speed: 0.0544s/iter; left time: 110.4313s
	iters: 200, epoch: 1 | loss: 1.0210400
	speed: 0.0341s/iter; left time: 65.9018s
Epoch: 1 cost time: 6.983141660690308
Epoch: 1, Steps: 213 | Train Loss: 1.0805549 Vali Loss: 1.0431441 Test Loss: 1.0246595
Validation loss decreased (inf --> 1.043144).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0554163
	speed: 0.0246s/iter; left time: 44.7194s
	iters: 200, epoch: 2 | loss: 1.0368254
	speed: 0.0204s/iter; left time: 35.1177s
Epoch: 2 cost time: 4.329900503158569
Epoch: 2, Steps: 213 | Train Loss: 1.0375008 Vali Loss: 1.0453751 Test Loss: 1.0237234
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9978609
	speed: 0.0240s/iter; left time: 38.5927s
	iters: 200, epoch: 3 | loss: 1.0133293
	speed: 0.0186s/iter; left time: 28.0622s
Epoch: 3 cost time: 3.9550249576568604
Epoch: 3, Steps: 213 | Train Loss: 1.0303554 Vali Loss: 1.0420870 Test Loss: 1.0208074
Validation loss decreased (1.043144 --> 1.042087).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0248159
	speed: 0.0177s/iter; left time: 24.6063s
	iters: 200, epoch: 4 | loss: 1.0165300
	speed: 0.0154s/iter; left time: 19.9391s
Epoch: 4 cost time: 3.3952341079711914
Epoch: 4, Steps: 213 | Train Loss: 1.0267139 Vali Loss: 1.0413944 Test Loss: 1.0204359
Validation loss decreased (1.042087 --> 1.041394).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0260308
	speed: 0.0132s/iter; left time: 15.5383s
	iters: 200, epoch: 5 | loss: 1.0715221
	speed: 0.0110s/iter; left time: 11.8657s
Epoch: 5 cost time: 2.42965030670166
Epoch: 5, Steps: 213 | Train Loss: 1.0244993 Vali Loss: 1.0413495 Test Loss: 1.0197959
Validation loss decreased (1.041394 --> 1.041350).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0277979
	speed: 0.0173s/iter; left time: 16.6914s
	iters: 200, epoch: 6 | loss: 1.0331423
	speed: 0.0141s/iter; left time: 12.1709s
Epoch: 6 cost time: 2.987273693084717
Epoch: 6, Steps: 213 | Train Loss: 1.0237578 Vali Loss: 1.0398487 Test Loss: 1.0198023
Validation loss decreased (1.041350 --> 1.039849).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9906103
	speed: 0.0212s/iter; left time: 15.9629s
	iters: 200, epoch: 7 | loss: 1.0049787
	speed: 0.0196s/iter; left time: 12.7694s
Epoch: 7 cost time: 4.088000059127808
Epoch: 7, Steps: 213 | Train Loss: 1.0226060 Vali Loss: 1.0402839 Test Loss: 1.0197862
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0205727
	speed: 0.0224s/iter; left time: 12.0844s
	iters: 200, epoch: 8 | loss: 1.0312225
	speed: 0.0182s/iter; left time: 8.0052s
Epoch: 8 cost time: 3.9342551231384277
Epoch: 8, Steps: 213 | Train Loss: 1.0223955 Vali Loss: 1.0410517 Test Loss: 1.0198077
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0583959
	speed: 0.0195s/iter; left time: 6.3901s
	iters: 200, epoch: 9 | loss: 1.0308702
	speed: 0.0157s/iter; left time: 3.5736s
Epoch: 9 cost time: 3.3457190990448
Epoch: 9, Steps: 213 | Train Loss: 1.0218947 Vali Loss: 1.0397904 Test Loss: 1.0198065
Validation loss decreased (1.039849 --> 1.039790).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9911305
	speed: 0.0124s/iter; left time: 1.4169s
	iters: 200, epoch: 10 | loss: 1.0356262
	speed: 0.0124s/iter; left time: 0.1732s
Epoch: 10 cost time: 2.8185982704162598
Epoch: 10, Steps: 213 | Train Loss: 1.0218577 Vali Loss: 1.0409588 Test Loss: 1.0198170
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0198065042495728, mae:0.8056820631027222
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0359346
	speed: 0.0162s/iter; left time: 32.9228s
	iters: 200, epoch: 1 | loss: 1.0452092
	speed: 0.0154s/iter; left time: 29.7950s
Epoch: 1 cost time: 3.3714559078216553
Epoch: 1, Steps: 213 | Train Loss: 1.0790373 Vali Loss: 1.0453674 Test Loss: 1.0258399
Validation loss decreased (inf --> 1.045367).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0345435
	speed: 0.0156s/iter; left time: 28.3648s
	iters: 200, epoch: 2 | loss: 1.0652981
	speed: 0.0144s/iter; left time: 24.7968s
Epoch: 2 cost time: 3.1931934356689453
Epoch: 2, Steps: 213 | Train Loss: 1.0379004 Vali Loss: 1.0432997 Test Loss: 1.0223997
Validation loss decreased (1.045367 --> 1.043300).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0579853
	speed: 0.0114s/iter; left time: 18.3187s
	iters: 200, epoch: 3 | loss: 0.9951113
	speed: 0.0107s/iter; left time: 16.1600s
Epoch: 3 cost time: 2.3710811138153076
Epoch: 3, Steps: 213 | Train Loss: 1.0310397 Vali Loss: 1.0418472 Test Loss: 1.0214657
Validation loss decreased (1.043300 --> 1.041847).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0095795
	speed: 0.0165s/iter; left time: 23.0191s
	iters: 200, epoch: 4 | loss: 1.0362835
	speed: 0.0152s/iter; left time: 19.6386s
Epoch: 4 cost time: 3.5222883224487305
Epoch: 4, Steps: 213 | Train Loss: 1.0267437 Vali Loss: 1.0399009 Test Loss: 1.0204972
Validation loss decreased (1.041847 --> 1.039901).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0034993
	speed: 0.0143s/iter; left time: 16.9030s
	iters: 200, epoch: 5 | loss: 1.0079098
	speed: 0.0144s/iter; left time: 15.4890s
Epoch: 5 cost time: 3.1767995357513428
Epoch: 5, Steps: 213 | Train Loss: 1.0251667 Vali Loss: 1.0416542 Test Loss: 1.0200988
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0099742
	speed: 0.0164s/iter; left time: 15.8724s
	iters: 200, epoch: 6 | loss: 1.0048918
	speed: 0.0216s/iter; left time: 18.7104s
Epoch: 6 cost time: 4.837473630905151
Epoch: 6, Steps: 213 | Train Loss: 1.0232035 Vali Loss: 1.0402070 Test Loss: 1.0199964
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0044286
	speed: 0.0127s/iter; left time: 9.5928s
	iters: 200, epoch: 7 | loss: 1.0121338
	speed: 0.0146s/iter; left time: 9.5119s
Epoch: 7 cost time: 3.3209073543548584
Epoch: 7, Steps: 213 | Train Loss: 1.0226290 Vali Loss: 1.0407698 Test Loss: 1.0199571
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0109711
	speed: 0.0147s/iter; left time: 7.9333s
	iters: 200, epoch: 8 | loss: 1.0607718
	speed: 0.0149s/iter; left time: 6.5534s
Epoch: 8 cost time: 3.258993625640869
Epoch: 8, Steps: 213 | Train Loss: 1.0221939 Vali Loss: 1.0406370 Test Loss: 1.0199467
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0058250
	speed: 0.0145s/iter; left time: 4.7348s
	iters: 200, epoch: 9 | loss: 1.0221537
	speed: 0.0154s/iter; left time: 3.4864s
Epoch: 9 cost time: 3.4579412937164307
Epoch: 9, Steps: 213 | Train Loss: 1.0225266 Vali Loss: 1.0403956 Test Loss: 1.0199590
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.02049720287323, mae:0.8059794306755066
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0472186
	speed: 0.0167s/iter; left time: 33.9842s
	iters: 200, epoch: 1 | loss: 1.0393336
	speed: 0.0156s/iter; left time: 30.1998s
Epoch: 1 cost time: 3.390892267227173
Epoch: 1, Steps: 213 | Train Loss: 1.0779235 Vali Loss: 1.0431535 Test Loss: 1.0241002
Validation loss decreased (inf --> 1.043154).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0676756
	speed: 0.0153s/iter; left time: 27.8280s
	iters: 200, epoch: 2 | loss: 1.0126441
	speed: 0.0132s/iter; left time: 22.7133s
Epoch: 2 cost time: 2.891037940979004
Epoch: 2, Steps: 213 | Train Loss: 1.0382019 Vali Loss: 1.0398339 Test Loss: 1.0230172
Validation loss decreased (1.043154 --> 1.039834).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0555490
	speed: 0.0198s/iter; left time: 31.7975s
	iters: 200, epoch: 3 | loss: 1.0217531
	speed: 0.0172s/iter; left time: 25.8861s
Epoch: 3 cost time: 3.7539455890655518
Epoch: 3, Steps: 213 | Train Loss: 1.0309629 Vali Loss: 1.0404477 Test Loss: 1.0212994
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0396376
	speed: 0.0180s/iter; left time: 25.0858s
	iters: 200, epoch: 4 | loss: 1.0165843
	speed: 0.0165s/iter; left time: 21.3710s
Epoch: 4 cost time: 3.6077332496643066
Epoch: 4, Steps: 213 | Train Loss: 1.0269959 Vali Loss: 1.0403355 Test Loss: 1.0206200
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0350542
	speed: 0.0174s/iter; left time: 20.5732s
	iters: 200, epoch: 5 | loss: 1.0567858
	speed: 0.0165s/iter; left time: 17.8292s
Epoch: 5 cost time: 3.6104280948638916
Epoch: 5, Steps: 213 | Train Loss: 1.0251022 Vali Loss: 1.0401273 Test Loss: 1.0198792
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0320877
	speed: 0.0186s/iter; left time: 17.9576s
	iters: 200, epoch: 6 | loss: 0.9988003
	speed: 0.0161s/iter; left time: 13.9514s
Epoch: 6 cost time: 3.531181573867798
Epoch: 6, Steps: 213 | Train Loss: 1.0236335 Vali Loss: 1.0412310 Test Loss: 1.0198276
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0533431
	speed: 0.0184s/iter; left time: 13.8438s
	iters: 200, epoch: 7 | loss: 1.0427215
	speed: 0.0153s/iter; left time: 9.9796s
Epoch: 7 cost time: 3.2833614349365234
Epoch: 7, Steps: 213 | Train Loss: 1.0227807 Vali Loss: 1.0408996 Test Loss: 1.0197523
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0230172872543335, mae:0.8071578145027161
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0439663
	speed: 0.0342s/iter; left time: 68.3665s
	iters: 200, epoch: 1 | loss: 1.0505025
	speed: 0.0277s/iter; left time: 52.7362s
Epoch: 1 cost time: 5.751864910125732
Epoch: 1, Steps: 210 | Train Loss: 1.0824670 Vali Loss: 1.0500296 Test Loss: 1.0252613
Validation loss decreased (inf --> 1.050030).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0525243
	speed: 0.0161s/iter; left time: 28.7897s
	iters: 200, epoch: 2 | loss: 1.0383037
	speed: 0.0187s/iter; left time: 31.5421s
Epoch: 2 cost time: 4.0712034702301025
Epoch: 2, Steps: 210 | Train Loss: 1.0439934 Vali Loss: 1.0510648 Test Loss: 1.0252404
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0384729
	speed: 0.0152s/iter; left time: 24.0856s
	iters: 200, epoch: 3 | loss: 1.0333313
	speed: 0.0136s/iter; left time: 20.0842s
Epoch: 3 cost time: 2.964707374572754
Epoch: 3, Steps: 210 | Train Loss: 1.0378234 Vali Loss: 1.0481811 Test Loss: 1.0218863
Validation loss decreased (1.050030 --> 1.048181).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0473152
	speed: 0.0249s/iter; left time: 34.0953s
	iters: 200, epoch: 4 | loss: 1.0321013
	speed: 0.0194s/iter; left time: 24.6978s
Epoch: 4 cost time: 4.086079835891724
Epoch: 4, Steps: 210 | Train Loss: 1.0348185 Vali Loss: 1.0473022 Test Loss: 1.0216013
Validation loss decreased (1.048181 --> 1.047302).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0167443
	speed: 0.0177s/iter; left time: 20.5478s
	iters: 200, epoch: 5 | loss: 1.0240386
	speed: 0.0162s/iter; left time: 17.2193s
Epoch: 5 cost time: 3.4943597316741943
Epoch: 5, Steps: 210 | Train Loss: 1.0330247 Vali Loss: 1.0472884 Test Loss: 1.0207162
Validation loss decreased (1.047302 --> 1.047288).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0394995
	speed: 0.0210s/iter; left time: 19.9449s
	iters: 200, epoch: 6 | loss: 1.0244751
	speed: 0.0173s/iter; left time: 14.7591s
Epoch: 6 cost time: 3.730025053024292
Epoch: 6, Steps: 210 | Train Loss: 1.0320734 Vali Loss: 1.0488575 Test Loss: 1.0203546
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0404027
	speed: 0.0144s/iter; left time: 10.6996s
	iters: 200, epoch: 7 | loss: 1.0190718
	speed: 0.0129s/iter; left time: 8.2613s
Epoch: 7 cost time: 2.7910778522491455
Epoch: 7, Steps: 210 | Train Loss: 1.0314099 Vali Loss: 1.0469303 Test Loss: 1.0205564
Validation loss decreased (1.047288 --> 1.046930).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0589628
	speed: 0.0229s/iter; left time: 12.1532s
	iters: 200, epoch: 8 | loss: 1.0271215
	speed: 0.0203s/iter; left time: 8.7627s
Epoch: 8 cost time: 4.287823438644409
Epoch: 8, Steps: 210 | Train Loss: 1.0312226 Vali Loss: 1.0469420 Test Loss: 1.0203412
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0374473
	speed: 0.0202s/iter; left time: 6.4895s
	iters: 200, epoch: 9 | loss: 1.0587109
	speed: 0.0164s/iter; left time: 3.6197s
Epoch: 9 cost time: 3.5057356357574463
Epoch: 9, Steps: 210 | Train Loss: 1.0311351 Vali Loss: 1.0484827 Test Loss: 1.0203348
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0582635
	speed: 0.0232s/iter; left time: 2.5769s
	iters: 200, epoch: 10 | loss: 1.0258249
	speed: 0.0165s/iter; left time: 0.1820s
Epoch: 10 cost time: 3.5020363330841064
Epoch: 10, Steps: 210 | Train Loss: 1.0310376 Vali Loss: 1.0479631 Test Loss: 1.0203546
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0205564498901367, mae:0.8051655888557434
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0569739
	speed: 0.0135s/iter; left time: 27.0538s
	iters: 200, epoch: 1 | loss: 1.0188940
	speed: 0.0133s/iter; left time: 25.2498s
Epoch: 1 cost time: 2.8579187393188477
Epoch: 1, Steps: 210 | Train Loss: 1.0829410 Vali Loss: 1.0540168 Test Loss: 1.0261681
Validation loss decreased (inf --> 1.054017).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0379499
	speed: 0.0148s/iter; left time: 26.4439s
	iters: 200, epoch: 2 | loss: 1.0185540
	speed: 0.0138s/iter; left time: 23.3278s
Epoch: 2 cost time: 3.037302255630493
Epoch: 2, Steps: 210 | Train Loss: 1.0438263 Vali Loss: 1.0486846 Test Loss: 1.0247053
Validation loss decreased (1.054017 --> 1.048685).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0561595
	speed: 0.0172s/iter; left time: 27.2483s
	iters: 200, epoch: 3 | loss: 1.0346973
	speed: 0.0151s/iter; left time: 22.3790s
Epoch: 3 cost time: 3.216909408569336
Epoch: 3, Steps: 210 | Train Loss: 1.0380154 Vali Loss: 1.0506585 Test Loss: 1.0219582
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0179434
	speed: 0.0192s/iter; left time: 26.3658s
	iters: 200, epoch: 4 | loss: 1.0434889
	speed: 0.0169s/iter; left time: 21.4170s
Epoch: 4 cost time: 3.6632020473480225
Epoch: 4, Steps: 210 | Train Loss: 1.0347015 Vali Loss: 1.0477496 Test Loss: 1.0209513
Validation loss decreased (1.048685 --> 1.047750).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0204175
	speed: 0.0184s/iter; left time: 21.3397s
	iters: 200, epoch: 5 | loss: 1.0658398
	speed: 0.0187s/iter; left time: 19.8618s
Epoch: 5 cost time: 4.215799808502197
Epoch: 5, Steps: 210 | Train Loss: 1.0329353 Vali Loss: 1.0495116 Test Loss: 1.0206721
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0452360
	speed: 0.0158s/iter; left time: 15.0466s
	iters: 200, epoch: 6 | loss: 1.0377941
	speed: 0.0160s/iter; left time: 13.6089s
Epoch: 6 cost time: 3.411121129989624
Epoch: 6, Steps: 210 | Train Loss: 1.0323322 Vali Loss: 1.0479000 Test Loss: 1.0203687
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0198376
	speed: 0.0182s/iter; left time: 13.4498s
	iters: 200, epoch: 7 | loss: 1.0154550
	speed: 0.0149s/iter; left time: 9.5365s
Epoch: 7 cost time: 3.13673734664917
Epoch: 7, Steps: 210 | Train Loss: 1.0317608 Vali Loss: 1.0477687 Test Loss: 1.0202187
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0535445
	speed: 0.0182s/iter; left time: 9.6643s
	iters: 200, epoch: 8 | loss: 1.0237336
	speed: 0.0160s/iter; left time: 6.9019s
Epoch: 8 cost time: 3.3959078788757324
Epoch: 8, Steps: 210 | Train Loss: 1.0313330 Vali Loss: 1.0469267 Test Loss: 1.0203490
Validation loss decreased (1.047750 --> 1.046927).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0436192
	speed: 0.0166s/iter; left time: 5.3235s
	iters: 200, epoch: 9 | loss: 1.0416303
	speed: 0.0159s/iter; left time: 3.5051s
Epoch: 9 cost time: 3.4045190811157227
Epoch: 9, Steps: 210 | Train Loss: 1.0311037 Vali Loss: 1.0470154 Test Loss: 1.0202990
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0305493
	speed: 0.0214s/iter; left time: 2.3787s
	iters: 200, epoch: 10 | loss: 1.0463022
	speed: 0.0173s/iter; left time: 0.1907s
Epoch: 10 cost time: 3.8228230476379395
Epoch: 10, Steps: 210 | Train Loss: 1.0311474 Vali Loss: 1.0472705 Test Loss: 1.0202861
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0203489065170288, mae:0.8050057291984558
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0393610
	speed: 0.0167s/iter; left time: 33.4173s
	iters: 200, epoch: 1 | loss: 1.0639999
	speed: 0.0131s/iter; left time: 24.9871s
Epoch: 1 cost time: 2.8435821533203125
Epoch: 1, Steps: 210 | Train Loss: 1.0817535 Vali Loss: 1.0521845 Test Loss: 1.0249734
Validation loss decreased (inf --> 1.052184).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0358442
	speed: 0.0147s/iter; left time: 26.2597s
	iters: 200, epoch: 2 | loss: 1.0315075
	speed: 0.0149s/iter; left time: 25.2783s
Epoch: 2 cost time: 3.185804605484009
Epoch: 2, Steps: 210 | Train Loss: 1.0441522 Vali Loss: 1.0509608 Test Loss: 1.0244881
Validation loss decreased (1.052184 --> 1.050961).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0329969
	speed: 0.0209s/iter; left time: 32.9938s
	iters: 200, epoch: 3 | loss: 1.0280240
	speed: 0.0170s/iter; left time: 25.2177s
Epoch: 3 cost time: 3.6118974685668945
Epoch: 3, Steps: 210 | Train Loss: 1.0383625 Vali Loss: 1.0501393 Test Loss: 1.0216801
Validation loss decreased (1.050961 --> 1.050139).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0238209
	speed: 0.0262s/iter; left time: 35.9413s
	iters: 200, epoch: 4 | loss: 1.0345525
	speed: 0.0213s/iter; left time: 27.0337s
Epoch: 4 cost time: 4.549865484237671
Epoch: 4, Steps: 210 | Train Loss: 1.0350314 Vali Loss: 1.0480961 Test Loss: 1.0210323
Validation loss decreased (1.050139 --> 1.048096).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0147851
	speed: 0.0193s/iter; left time: 22.4012s
	iters: 200, epoch: 5 | loss: 1.0262914
	speed: 0.0145s/iter; left time: 15.3546s
Epoch: 5 cost time: 3.06874942779541
Epoch: 5, Steps: 210 | Train Loss: 1.0332922 Vali Loss: 1.0487481 Test Loss: 1.0206243
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0180683
	speed: 0.0197s/iter; left time: 18.7624s
	iters: 200, epoch: 6 | loss: 1.0463178
	speed: 0.0166s/iter; left time: 14.0855s
Epoch: 6 cost time: 3.5061864852905273
Epoch: 6, Steps: 210 | Train Loss: 1.0323730 Vali Loss: 1.0466371 Test Loss: 1.0206580
Validation loss decreased (1.048096 --> 1.046637).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0641217
	speed: 0.0202s/iter; left time: 14.9582s
	iters: 200, epoch: 7 | loss: 1.0484778
	speed: 0.0181s/iter; left time: 11.6285s
Epoch: 7 cost time: 4.0393664836883545
Epoch: 7, Steps: 210 | Train Loss: 1.0318288 Vali Loss: 1.0472190 Test Loss: 1.0203757
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0355095
	speed: 0.0203s/iter; left time: 10.7858s
	iters: 200, epoch: 8 | loss: 1.0846007
	speed: 0.0166s/iter; left time: 7.1527s
Epoch: 8 cost time: 3.5867326259613037
Epoch: 8, Steps: 210 | Train Loss: 1.0314917 Vali Loss: 1.0470532 Test Loss: 1.0203530
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0637306
	speed: 0.0179s/iter; left time: 5.7444s
	iters: 200, epoch: 9 | loss: 1.0480117
	speed: 0.0161s/iter; left time: 3.5566s
Epoch: 9 cost time: 3.418902635574341
Epoch: 9, Steps: 210 | Train Loss: 1.0312745 Vali Loss: 1.0474824 Test Loss: 1.0203198
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0099061
	speed: 0.0231s/iter; left time: 2.5655s
	iters: 200, epoch: 10 | loss: 1.0385814
	speed: 0.0238s/iter; left time: 0.2621s
Epoch: 10 cost time: 5.046564817428589
Epoch: 10, Steps: 210 | Train Loss: 1.0312089 Vali Loss: 1.0479676 Test Loss: 1.0203352
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.020658254623413, mae:0.805184543132782
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0582157
	speed: 0.0263s/iter; left time: 51.5444s
	iters: 200, epoch: 1 | loss: 1.0455118
	speed: 0.0196s/iter; left time: 36.4486s
Epoch: 1 cost time: 4.125863552093506
Epoch: 1, Steps: 206 | Train Loss: 1.0812995 Vali Loss: 1.0600978 Test Loss: 1.0399394
Validation loss decreased (inf --> 1.060098).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0545207
	speed: 0.0204s/iter; left time: 35.7206s
	iters: 200, epoch: 2 | loss: 1.0394758
	speed: 0.0200s/iter; left time: 33.0560s
Epoch: 2 cost time: 4.2932586669921875
Epoch: 2, Steps: 206 | Train Loss: 1.0441096 Vali Loss: 1.0592463 Test Loss: 1.0394735
Validation loss decreased (1.060098 --> 1.059246).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0518225
	speed: 0.0171s/iter; left time: 26.4192s
	iters: 200, epoch: 3 | loss: 1.0330099
	speed: 0.0160s/iter; left time: 23.2291s
Epoch: 3 cost time: 3.4584600925445557
Epoch: 3, Steps: 206 | Train Loss: 1.0394049 Vali Loss: 1.0611055 Test Loss: 1.0360715
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0440811
	speed: 0.0194s/iter; left time: 26.0021s
	iters: 200, epoch: 4 | loss: 1.0215102
	speed: 0.0175s/iter; left time: 21.7115s
Epoch: 4 cost time: 3.686782121658325
Epoch: 4, Steps: 206 | Train Loss: 1.0368149 Vali Loss: 1.0567136 Test Loss: 1.0357639
Validation loss decreased (1.059246 --> 1.056714).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0132571
	speed: 0.0151s/iter; left time: 17.1146s
	iters: 200, epoch: 5 | loss: 1.0362464
	speed: 0.0148s/iter; left time: 15.3697s
Epoch: 5 cost time: 3.153862237930298
Epoch: 5, Steps: 206 | Train Loss: 1.0354645 Vali Loss: 1.0562981 Test Loss: 1.0354540
Validation loss decreased (1.056714 --> 1.056298).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0294201
	speed: 0.0186s/iter; left time: 17.3209s
	iters: 200, epoch: 6 | loss: 1.0364771
	speed: 0.0167s/iter; left time: 13.8668s
Epoch: 6 cost time: 3.530137538909912
Epoch: 6, Steps: 206 | Train Loss: 1.0345919 Vali Loss: 1.0558336 Test Loss: 1.0354048
Validation loss decreased (1.056298 --> 1.055834).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0389379
	speed: 0.0168s/iter; left time: 12.1738s
	iters: 200, epoch: 7 | loss: 1.0286939
	speed: 0.0153s/iter; left time: 9.5677s
Epoch: 7 cost time: 3.307166337966919
Epoch: 7, Steps: 206 | Train Loss: 1.0342487 Vali Loss: 1.0560939 Test Loss: 1.0350850
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0160669
	speed: 0.0177s/iter; left time: 9.1848s
	iters: 200, epoch: 8 | loss: 1.0467745
	speed: 0.0145s/iter; left time: 6.0758s
Epoch: 8 cost time: 3.1510369777679443
Epoch: 8, Steps: 206 | Train Loss: 1.0343244 Vali Loss: 1.0559880 Test Loss: 1.0350134
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0219041
	speed: 0.0129s/iter; left time: 4.0262s
	iters: 200, epoch: 9 | loss: 1.0542125
	speed: 0.0110s/iter; left time: 2.3453s
Epoch: 9 cost time: 2.3542022705078125
Epoch: 9, Steps: 206 | Train Loss: 1.0342011 Vali Loss: 1.0558006 Test Loss: 1.0350665
Validation loss decreased (1.055834 --> 1.055801).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0376906
	speed: 0.0178s/iter; left time: 1.9048s
	iters: 200, epoch: 10 | loss: 1.0439731
	speed: 0.0147s/iter; left time: 0.1026s
Epoch: 10 cost time: 3.108534336090088
Epoch: 10, Steps: 206 | Train Loss: 1.0340471 Vali Loss: 1.0559038 Test Loss: 1.0351111
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0350666046142578, mae:0.8090624213218689
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0565681
	speed: 0.0188s/iter; left time: 36.9485s
	iters: 200, epoch: 1 | loss: 1.0486156
	speed: 0.0170s/iter; left time: 31.5899s
Epoch: 1 cost time: 3.564401149749756
Epoch: 1, Steps: 206 | Train Loss: 1.0822478 Vali Loss: 1.0616604 Test Loss: 1.0391556
Validation loss decreased (inf --> 1.061660).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0563445
	speed: 0.0230s/iter; left time: 40.3725s
	iters: 200, epoch: 2 | loss: 1.0452101
	speed: 0.0189s/iter; left time: 31.3313s
Epoch: 2 cost time: 3.976830244064331
Epoch: 2, Steps: 206 | Train Loss: 1.0445502 Vali Loss: 1.0602945 Test Loss: 1.0381688
Validation loss decreased (1.061660 --> 1.060295).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0253150
	speed: 0.0149s/iter; left time: 23.0467s
	iters: 200, epoch: 3 | loss: 1.0360754
	speed: 0.0129s/iter; left time: 18.6941s
Epoch: 3 cost time: 2.7613840103149414
Epoch: 3, Steps: 206 | Train Loss: 1.0392938 Vali Loss: 1.0572373 Test Loss: 1.0372816
Validation loss decreased (1.060295 --> 1.057237).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0440538
	speed: 0.0161s/iter; left time: 21.6264s
	iters: 200, epoch: 4 | loss: 1.0429002
	speed: 0.0187s/iter; left time: 23.2602s
Epoch: 4 cost time: 3.9750945568084717
Epoch: 4, Steps: 206 | Train Loss: 1.0369148 Vali Loss: 1.0568254 Test Loss: 1.0357536
Validation loss decreased (1.057237 --> 1.056825).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0386716
	speed: 0.0237s/iter; left time: 26.9139s
	iters: 200, epoch: 5 | loss: 1.0425266
	speed: 0.0194s/iter; left time: 20.1494s
Epoch: 5 cost time: 4.146921396255493
Epoch: 5, Steps: 206 | Train Loss: 1.0354625 Vali Loss: 1.0558527 Test Loss: 1.0356928
Validation loss decreased (1.056825 --> 1.055853).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0286726
	speed: 0.0221s/iter; left time: 20.5976s
	iters: 200, epoch: 6 | loss: 1.0407192
	speed: 0.0202s/iter; left time: 16.8122s
Epoch: 6 cost time: 4.332978010177612
Epoch: 6, Steps: 206 | Train Loss: 1.0349817 Vali Loss: 1.0558459 Test Loss: 1.0354346
Validation loss decreased (1.055853 --> 1.055846).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0377120
	speed: 0.0195s/iter; left time: 14.1139s
	iters: 200, epoch: 7 | loss: 1.0337828
	speed: 0.0196s/iter; left time: 12.2607s
Epoch: 7 cost time: 4.101128578186035
Epoch: 7, Steps: 206 | Train Loss: 1.0343769 Vali Loss: 1.0557510 Test Loss: 1.0353121
Validation loss decreased (1.055846 --> 1.055751).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0463555
	speed: 0.0178s/iter; left time: 9.2123s
	iters: 200, epoch: 8 | loss: 1.0483458
	speed: 0.0151s/iter; left time: 6.3390s
Epoch: 8 cost time: 3.176715135574341
Epoch: 8, Steps: 206 | Train Loss: 1.0343520 Vali Loss: 1.0556142 Test Loss: 1.0351727
Validation loss decreased (1.055751 --> 1.055614).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0242296
	speed: 0.0157s/iter; left time: 4.9165s
	iters: 200, epoch: 9 | loss: 1.0253123
	speed: 0.0133s/iter; left time: 2.8270s
Epoch: 9 cost time: 2.8338937759399414
Epoch: 9, Steps: 206 | Train Loss: 1.0342373 Vali Loss: 1.0558082 Test Loss: 1.0351793
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0299120
	speed: 0.0204s/iter; left time: 2.1866s
	iters: 200, epoch: 10 | loss: 1.0314189
	speed: 0.0173s/iter; left time: 0.1210s
Epoch: 10 cost time: 3.6562275886535645
Epoch: 10, Steps: 206 | Train Loss: 1.0340671 Vali Loss: 1.0556889 Test Loss: 1.0351582
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.035172939300537, mae:0.8091126084327698
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0482336
	speed: 0.0234s/iter; left time: 45.7993s
	iters: 200, epoch: 1 | loss: 1.0403466
	speed: 0.0192s/iter; left time: 35.7399s
Epoch: 1 cost time: 4.024718999862671
Epoch: 1, Steps: 206 | Train Loss: 1.0805622 Vali Loss: 1.0602071 Test Loss: 1.0418462
Validation loss decreased (inf --> 1.060207).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0375326
	speed: 0.0191s/iter; left time: 33.5598s
	iters: 200, epoch: 2 | loss: 1.0307263
	speed: 0.0180s/iter; left time: 29.7611s
Epoch: 2 cost time: 3.8099286556243896
Epoch: 2, Steps: 206 | Train Loss: 1.0443925 Vali Loss: 1.0581263 Test Loss: 1.0384674
Validation loss decreased (1.060207 --> 1.058126).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0429645
	speed: 0.0145s/iter; left time: 22.4038s
	iters: 200, epoch: 3 | loss: 1.0332246
	speed: 0.0136s/iter; left time: 19.6359s
Epoch: 3 cost time: 2.8795435428619385
Epoch: 3, Steps: 206 | Train Loss: 1.0397166 Vali Loss: 1.0572392 Test Loss: 1.0372844
Validation loss decreased (1.058126 --> 1.057239).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0476485
	speed: 0.0188s/iter; left time: 25.2352s
	iters: 200, epoch: 4 | loss: 1.0554826
	speed: 0.0165s/iter; left time: 20.5379s
Epoch: 4 cost time: 3.5251240730285645
Epoch: 4, Steps: 206 | Train Loss: 1.0369386 Vali Loss: 1.0567633 Test Loss: 1.0357192
Validation loss decreased (1.057239 --> 1.056763).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0287420
	speed: 0.0209s/iter; left time: 23.7509s
	iters: 200, epoch: 5 | loss: 1.0719481
	speed: 0.0205s/iter; left time: 21.2564s
Epoch: 5 cost time: 4.260268211364746
Epoch: 5, Steps: 206 | Train Loss: 1.0355872 Vali Loss: 1.0566330 Test Loss: 1.0353277
Validation loss decreased (1.056763 --> 1.056633).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0279673
	speed: 0.0257s/iter; left time: 23.9084s
	iters: 200, epoch: 6 | loss: 1.0529077
	speed: 0.0206s/iter; left time: 17.1116s
Epoch: 6 cost time: 4.265491724014282
Epoch: 6, Steps: 206 | Train Loss: 1.0348212 Vali Loss: 1.0560324 Test Loss: 1.0351429
Validation loss decreased (1.056633 --> 1.056032).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0477059
	speed: 0.0177s/iter; left time: 12.8409s
	iters: 200, epoch: 7 | loss: 1.0326080
	speed: 0.0150s/iter; left time: 9.3869s
Epoch: 7 cost time: 3.143162727355957
Epoch: 7, Steps: 206 | Train Loss: 1.0346612 Vali Loss: 1.0560182 Test Loss: 1.0349907
Validation loss decreased (1.056032 --> 1.056018).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0293925
	speed: 0.0184s/iter; left time: 9.5619s
	iters: 200, epoch: 8 | loss: 1.0117606
	speed: 0.0160s/iter; left time: 6.7190s
Epoch: 8 cost time: 3.3839190006256104
Epoch: 8, Steps: 206 | Train Loss: 1.0341901 Vali Loss: 1.0557691 Test Loss: 1.0350043
Validation loss decreased (1.056018 --> 1.055769).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0323066
	speed: 0.0239s/iter; left time: 7.4910s
	iters: 200, epoch: 9 | loss: 1.0365324
	speed: 0.0187s/iter; left time: 3.9746s
Epoch: 9 cost time: 3.8725008964538574
Epoch: 9, Steps: 206 | Train Loss: 1.0341307 Vali Loss: 1.0558035 Test Loss: 1.0349917
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0469469
	speed: 0.0200s/iter; left time: 2.1449s
	iters: 200, epoch: 10 | loss: 1.0430030
	speed: 0.0185s/iter; left time: 0.1296s
Epoch: 10 cost time: 3.8712351322174072
Epoch: 10, Steps: 206 | Train Loss: 1.0341709 Vali Loss: 1.0557854 Test Loss: 1.0349991
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0350044965744019, mae:0.8090887665748596
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0597771
	speed: 0.0319s/iter; left time: 58.6450s
Epoch: 1 cost time: 5.30890417098999
Epoch: 1, Steps: 194 | Train Loss: 1.0832146 Vali Loss: 1.0607631 Test Loss: 1.0321064
Validation loss decreased (inf --> 1.060763).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0563724
	speed: 0.0187s/iter; left time: 30.8249s
Epoch: 2 cost time: 3.086562395095825
Epoch: 2, Steps: 194 | Train Loss: 1.0464975 Vali Loss: 1.0599198 Test Loss: 1.0311862
Validation loss decreased (1.060763 --> 1.059920).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0453950
	speed: 0.0129s/iter; left time: 18.7553s
Epoch: 3 cost time: 2.5242984294891357
Epoch: 3, Steps: 194 | Train Loss: 1.0424169 Vali Loss: 1.0565848 Test Loss: 1.0297942
Validation loss decreased (1.059920 --> 1.056585).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0255778
	speed: 0.0198s/iter; left time: 24.8796s
Epoch: 4 cost time: 3.2309622764587402
Epoch: 4, Steps: 194 | Train Loss: 1.0403127 Vali Loss: 1.0576246 Test Loss: 1.0286653
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0362488
	speed: 0.0200s/iter; left time: 21.2596s
Epoch: 5 cost time: 3.304839611053467
Epoch: 5, Steps: 194 | Train Loss: 1.0394214 Vali Loss: 1.0553550 Test Loss: 1.0284152
Validation loss decreased (1.056585 --> 1.055355).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0415481
	speed: 0.0200s/iter; left time: 17.4233s
Epoch: 6 cost time: 3.462428092956543
Epoch: 6, Steps: 194 | Train Loss: 1.0389897 Vali Loss: 1.0552422 Test Loss: 1.0282031
Validation loss decreased (1.055355 --> 1.055242).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0332791
	speed: 0.0209s/iter; left time: 14.1265s
Epoch: 7 cost time: 3.330904245376587
Epoch: 7, Steps: 194 | Train Loss: 1.0386808 Vali Loss: 1.0552114 Test Loss: 1.0281299
Validation loss decreased (1.055242 --> 1.055211).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0338529
	speed: 0.0162s/iter; left time: 7.8265s
Epoch: 8 cost time: 3.060950994491577
Epoch: 8, Steps: 194 | Train Loss: 1.0385955 Vali Loss: 1.0552070 Test Loss: 1.0280814
Validation loss decreased (1.055211 --> 1.055207).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0230044
	speed: 0.0209s/iter; left time: 6.0519s
Epoch: 9 cost time: 3.8336644172668457
Epoch: 9, Steps: 194 | Train Loss: 1.0384982 Vali Loss: 1.0551183 Test Loss: 1.0280647
Validation loss decreased (1.055207 --> 1.055118).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0405667
	speed: 0.0170s/iter; left time: 1.6171s
Epoch: 10 cost time: 3.393941879272461
Epoch: 10, Steps: 194 | Train Loss: 1.0382998 Vali Loss: 1.0551096 Test Loss: 1.0280547
Validation loss decreased (1.055118 --> 1.055110).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0280548334121704, mae:0.8047229051589966
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0493945
	speed: 0.0142s/iter; left time: 26.1933s
Epoch: 1 cost time: 2.688836097717285
Epoch: 1, Steps: 194 | Train Loss: 1.0839264 Vali Loss: 1.0592183 Test Loss: 1.0317270
Validation loss decreased (inf --> 1.059218).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0408800
	speed: 0.0149s/iter; left time: 24.5764s
Epoch: 2 cost time: 3.195373296737671
Epoch: 2, Steps: 194 | Train Loss: 1.0461178 Vali Loss: 1.0590355 Test Loss: 1.0312747
Validation loss decreased (1.059218 --> 1.059036).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0364387
	speed: 0.0199s/iter; left time: 28.9787s
Epoch: 3 cost time: 3.4748318195343018
Epoch: 3, Steps: 194 | Train Loss: 1.0424706 Vali Loss: 1.0573363 Test Loss: 1.0293294
Validation loss decreased (1.059036 --> 1.057336).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0306110
	speed: 0.0184s/iter; left time: 23.2168s
Epoch: 4 cost time: 3.2254528999328613
Epoch: 4, Steps: 194 | Train Loss: 1.0402523 Vali Loss: 1.0560918 Test Loss: 1.0284761
Validation loss decreased (1.057336 --> 1.056092).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0312253
	speed: 0.0213s/iter; left time: 22.6657s
Epoch: 5 cost time: 3.9223461151123047
Epoch: 5, Steps: 194 | Train Loss: 1.0390821 Vali Loss: 1.0555100 Test Loss: 1.0283153
Validation loss decreased (1.056092 --> 1.055510).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0441108
	speed: 0.0166s/iter; left time: 14.4457s
Epoch: 6 cost time: 2.8298499584198
Epoch: 6, Steps: 194 | Train Loss: 1.0387074 Vali Loss: 1.0550903 Test Loss: 1.0281370
Validation loss decreased (1.055510 --> 1.055090).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0337917
	speed: 0.0205s/iter; left time: 13.8686s
Epoch: 7 cost time: 3.443704605102539
Epoch: 7, Steps: 194 | Train Loss: 1.0385208 Vali Loss: 1.0552542 Test Loss: 1.0279956
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0268977
	speed: 0.0161s/iter; left time: 7.7607s
Epoch: 8 cost time: 2.945410966873169
Epoch: 8, Steps: 194 | Train Loss: 1.0384233 Vali Loss: 1.0549529 Test Loss: 1.0279917
Validation loss decreased (1.055090 --> 1.054953).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0340992
	speed: 0.0178s/iter; left time: 5.1586s
Epoch: 9 cost time: 3.0481481552124023
Epoch: 9, Steps: 194 | Train Loss: 1.0382534 Vali Loss: 1.0549681 Test Loss: 1.0279506
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0391568
	speed: 0.0176s/iter; left time: 1.6707s
Epoch: 10 cost time: 3.192072868347168
Epoch: 10, Steps: 194 | Train Loss: 1.0381707 Vali Loss: 1.0549139 Test Loss: 1.0279450
Validation loss decreased (1.054953 --> 1.054914).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0279450416564941, mae:0.8046458959579468
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0493351
	speed: 0.0173s/iter; left time: 31.8439s
Epoch: 1 cost time: 2.755624532699585
Epoch: 1, Steps: 194 | Train Loss: 1.0827113 Vali Loss: 1.0586215 Test Loss: 1.0319186
Validation loss decreased (inf --> 1.058622).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0528452
	speed: 0.0207s/iter; left time: 34.0497s
Epoch: 2 cost time: 3.5478875637054443
Epoch: 2, Steps: 194 | Train Loss: 1.0466236 Vali Loss: 1.0586934 Test Loss: 1.0307056
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0498652
	speed: 0.0165s/iter; left time: 23.9059s
Epoch: 3 cost time: 3.7316160202026367
Epoch: 3, Steps: 194 | Train Loss: 1.0421411 Vali Loss: 1.0571519 Test Loss: 1.0293120
Validation loss decreased (1.058622 --> 1.057152).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0473723
	speed: 0.0184s/iter; left time: 23.2018s
Epoch: 4 cost time: 3.4642653465270996
Epoch: 4, Steps: 194 | Train Loss: 1.0402372 Vali Loss: 1.0557530 Test Loss: 1.0285413
Validation loss decreased (1.057152 --> 1.055753).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0485594
	speed: 0.0233s/iter; left time: 24.7650s
Epoch: 5 cost time: 3.4330904483795166
Epoch: 5, Steps: 194 | Train Loss: 1.0393579 Vali Loss: 1.0549667 Test Loss: 1.0282018
Validation loss decreased (1.055753 --> 1.054967).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0266842
	speed: 0.0180s/iter; left time: 15.7082s
Epoch: 6 cost time: 3.0590991973876953
Epoch: 6, Steps: 194 | Train Loss: 1.0388382 Vali Loss: 1.0551405 Test Loss: 1.0281415
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0377767
	speed: 0.0200s/iter; left time: 13.5324s
Epoch: 7 cost time: 3.3600571155548096
Epoch: 7, Steps: 194 | Train Loss: 1.0384843 Vali Loss: 1.0546552 Test Loss: 1.0280322
Validation loss decreased (1.054967 --> 1.054655).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0310981
	speed: 0.0177s/iter; left time: 8.5288s
Epoch: 8 cost time: 2.9918296337127686
Epoch: 8, Steps: 194 | Train Loss: 1.0382650 Vali Loss: 1.0548806 Test Loss: 1.0279517
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0372264
	speed: 0.0244s/iter; left time: 7.0652s
Epoch: 9 cost time: 4.041754245758057
Epoch: 9, Steps: 194 | Train Loss: 1.0381457 Vali Loss: 1.0551155 Test Loss: 1.0279170
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0355892
	speed: 0.0153s/iter; left time: 1.4505s
Epoch: 10 cost time: 2.814832925796509
Epoch: 10, Steps: 194 | Train Loss: 1.0381737 Vali Loss: 1.0550091 Test Loss: 1.0279075
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0280319452285767, mae:0.8047026991844177
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0157071
	speed: 0.0359s/iter; left time: 73.0067s
	iters: 200, epoch: 1 | loss: 1.0510944
	speed: 0.0246s/iter; left time: 47.4462s
Epoch: 1 cost time: 5.0774993896484375
Epoch: 1, Steps: 213 | Train Loss: 1.0787206 Vali Loss: 1.0432229 Test Loss: 1.0250938
Validation loss decreased (inf --> 1.043223).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0205691
	speed: 0.0173s/iter; left time: 31.3632s
	iters: 200, epoch: 2 | loss: 1.0364001
	speed: 0.0137s/iter; left time: 23.5694s
Epoch: 2 cost time: 2.917833089828491
Epoch: 2, Steps: 213 | Train Loss: 1.0389165 Vali Loss: 1.0455012 Test Loss: 1.0239173
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0159147
	speed: 0.0182s/iter; left time: 29.2201s
	iters: 200, epoch: 3 | loss: 1.0446954
	speed: 0.0154s/iter; left time: 23.2261s
Epoch: 3 cost time: 3.3565659523010254
Epoch: 3, Steps: 213 | Train Loss: 1.0312622 Vali Loss: 1.0422080 Test Loss: 1.0206181
Validation loss decreased (1.043223 --> 1.042208).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0477060
	speed: 0.0212s/iter; left time: 29.5684s
	iters: 200, epoch: 4 | loss: 0.9995977
	speed: 0.0174s/iter; left time: 22.5159s
Epoch: 4 cost time: 3.931675672531128
Epoch: 4, Steps: 213 | Train Loss: 1.0273334 Vali Loss: 1.0398757 Test Loss: 1.0203980
Validation loss decreased (1.042208 --> 1.039876).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0486994
	speed: 0.0173s/iter; left time: 20.3581s
	iters: 200, epoch: 5 | loss: 1.0267061
	speed: 0.0155s/iter; left time: 16.7649s
Epoch: 5 cost time: 3.347879409790039
Epoch: 5, Steps: 213 | Train Loss: 1.0253856 Vali Loss: 1.0413550 Test Loss: 1.0199788
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0588317
	speed: 0.0157s/iter; left time: 15.2106s
	iters: 200, epoch: 6 | loss: 1.0265707
	speed: 0.0138s/iter; left time: 11.9528s
Epoch: 6 cost time: 2.957742691040039
Epoch: 6, Steps: 213 | Train Loss: 1.0243413 Vali Loss: 1.0407774 Test Loss: 1.0198548
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0020169
	speed: 0.0216s/iter; left time: 16.2440s
	iters: 200, epoch: 7 | loss: 1.0320837
	speed: 0.0185s/iter; left time: 12.0713s
Epoch: 7 cost time: 3.970855474472046
Epoch: 7, Steps: 213 | Train Loss: 1.0234076 Vali Loss: 1.0413603 Test Loss: 1.0198159
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0252579
	speed: 0.0189s/iter; left time: 10.2039s
	iters: 200, epoch: 8 | loss: 1.0224766
	speed: 0.0173s/iter; left time: 7.6018s
Epoch: 8 cost time: 3.800469160079956
Epoch: 8, Steps: 213 | Train Loss: 1.0230352 Vali Loss: 1.0407814 Test Loss: 1.0197862
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0132991
	speed: 0.0238s/iter; left time: 7.7898s
	iters: 200, epoch: 9 | loss: 1.0242891
	speed: 0.0211s/iter; left time: 4.7787s
Epoch: 9 cost time: 4.605616807937622
Epoch: 9, Steps: 213 | Train Loss: 1.0227046 Vali Loss: 1.0404890 Test Loss: 1.0197960
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0203980207443237, mae:0.8059539794921875
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9920669
	speed: 0.0162s/iter; left time: 32.8420s
	iters: 200, epoch: 1 | loss: 1.0209615
	speed: 0.0128s/iter; left time: 24.7648s
Epoch: 1 cost time: 2.7725329399108887
Epoch: 1, Steps: 213 | Train Loss: 1.0811777 Vali Loss: 1.0429733 Test Loss: 1.0238618
Validation loss decreased (inf --> 1.042973).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0143708
	speed: 0.0209s/iter; left time: 38.0846s
	iters: 200, epoch: 2 | loss: 1.0445361
	speed: 0.0162s/iter; left time: 27.8290s
Epoch: 2 cost time: 3.55328106880188
Epoch: 2, Steps: 213 | Train Loss: 1.0374338 Vali Loss: 1.0430061 Test Loss: 1.0231822
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0167611
	speed: 0.0186s/iter; left time: 29.9134s
	iters: 200, epoch: 3 | loss: 1.0383930
	speed: 0.0175s/iter; left time: 26.3838s
Epoch: 3 cost time: 3.7382359504699707
Epoch: 3, Steps: 213 | Train Loss: 1.0309268 Vali Loss: 1.0408757 Test Loss: 1.0207353
Validation loss decreased (1.042973 --> 1.040876).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0412667
	speed: 0.0273s/iter; left time: 38.0304s
	iters: 200, epoch: 4 | loss: 1.0103024
	speed: 0.0208s/iter; left time: 26.8173s
Epoch: 4 cost time: 4.389374256134033
Epoch: 4, Steps: 213 | Train Loss: 1.0268640 Vali Loss: 1.0406699 Test Loss: 1.0204118
Validation loss decreased (1.040876 --> 1.040670).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0333270
	speed: 0.0183s/iter; left time: 21.5458s
	iters: 200, epoch: 5 | loss: 1.0063117
	speed: 0.0174s/iter; left time: 18.8144s
Epoch: 5 cost time: 3.6592369079589844
Epoch: 5, Steps: 213 | Train Loss: 1.0244428 Vali Loss: 1.0407299 Test Loss: 1.0200208
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9710085
	speed: 0.0214s/iter; left time: 20.6916s
	iters: 200, epoch: 6 | loss: 1.0146480
	speed: 0.0172s/iter; left time: 14.9145s
Epoch: 6 cost time: 3.7150139808654785
Epoch: 6, Steps: 213 | Train Loss: 1.0232523 Vali Loss: 1.0418290 Test Loss: 1.0198973
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0177732
	speed: 0.0273s/iter; left time: 20.5606s
	iters: 200, epoch: 7 | loss: 1.0364885
	speed: 0.0218s/iter; left time: 14.2416s
Epoch: 7 cost time: 4.587601184844971
Epoch: 7, Steps: 213 | Train Loss: 1.0226915 Vali Loss: 1.0410726 Test Loss: 1.0197543
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0231056
	speed: 0.0207s/iter; left time: 11.1822s
	iters: 200, epoch: 8 | loss: 1.0244513
	speed: 0.0168s/iter; left time: 7.3760s
Epoch: 8 cost time: 3.567814826965332
Epoch: 8, Steps: 213 | Train Loss: 1.0223923 Vali Loss: 1.0399957 Test Loss: 1.0197837
Validation loss decreased (1.040670 --> 1.039996).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9990794
	speed: 0.0124s/iter; left time: 4.0512s
	iters: 200, epoch: 9 | loss: 1.0480251
	speed: 0.0114s/iter; left time: 2.5875s
Epoch: 9 cost time: 2.484671115875244
Epoch: 9, Steps: 213 | Train Loss: 1.0217733 Vali Loss: 1.0408492 Test Loss: 1.0197880
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0327418
	speed: 0.0193s/iter; left time: 2.1961s
	iters: 200, epoch: 10 | loss: 1.0137399
	speed: 0.0150s/iter; left time: 0.2095s
Epoch: 10 cost time: 3.215264081954956
Epoch: 10, Steps: 213 | Train Loss: 1.0216771 Vali Loss: 1.0408865 Test Loss: 1.0197963
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.019783854484558, mae:0.80556321144104
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0593836
	speed: 0.0184s/iter; left time: 37.3993s
	iters: 200, epoch: 1 | loss: 1.0425888
	speed: 0.0161s/iter; left time: 31.1384s
Epoch: 1 cost time: 3.5249288082122803
Epoch: 1, Steps: 213 | Train Loss: 1.0809565 Vali Loss: 1.0437793 Test Loss: 1.0240110
Validation loss decreased (inf --> 1.043779).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0345335
	speed: 0.0193s/iter; left time: 35.1402s
	iters: 200, epoch: 2 | loss: 1.0250142
	speed: 0.0147s/iter; left time: 25.3341s
Epoch: 2 cost time: 3.127194881439209
Epoch: 2, Steps: 213 | Train Loss: 1.0379211 Vali Loss: 1.0440406 Test Loss: 1.0238446
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0557777
	speed: 0.0150s/iter; left time: 24.1533s
	iters: 200, epoch: 3 | loss: 1.0494108
	speed: 0.0158s/iter; left time: 23.8412s
Epoch: 3 cost time: 3.4730472564697266
Epoch: 3, Steps: 213 | Train Loss: 1.0305681 Vali Loss: 1.0404178 Test Loss: 1.0209013
Validation loss decreased (1.043779 --> 1.040418).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0020251
	speed: 0.0158s/iter; left time: 21.9638s
	iters: 200, epoch: 4 | loss: 1.0238280
	speed: 0.0145s/iter; left time: 18.6985s
Epoch: 4 cost time: 3.1936588287353516
Epoch: 4, Steps: 213 | Train Loss: 1.0266309 Vali Loss: 1.0427973 Test Loss: 1.0205963
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0186647
	speed: 0.0191s/iter; left time: 22.5759s
	iters: 200, epoch: 5 | loss: 1.0422039
	speed: 0.0169s/iter; left time: 18.2770s
Epoch: 5 cost time: 3.8251256942749023
Epoch: 5, Steps: 213 | Train Loss: 1.0246097 Vali Loss: 1.0403974 Test Loss: 1.0203851
Validation loss decreased (1.040418 --> 1.040397).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0212965
	speed: 0.0146s/iter; left time: 14.1012s
	iters: 200, epoch: 6 | loss: 1.0179620
	speed: 0.0124s/iter; left time: 10.7489s
Epoch: 6 cost time: 2.7256059646606445
Epoch: 6, Steps: 213 | Train Loss: 1.0233207 Vali Loss: 1.0409086 Test Loss: 1.0201077
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0476356
	speed: 0.0163s/iter; left time: 12.2677s
	iters: 200, epoch: 7 | loss: 1.0063404
	speed: 0.0153s/iter; left time: 9.9711s
Epoch: 7 cost time: 3.365140199661255
Epoch: 7, Steps: 213 | Train Loss: 1.0221754 Vali Loss: 1.0414139 Test Loss: 1.0201190
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0164874
	speed: 0.0164s/iter; left time: 8.8542s
	iters: 200, epoch: 8 | loss: 1.0085624
	speed: 0.0176s/iter; left time: 7.7244s
Epoch: 8 cost time: 3.8500733375549316
Epoch: 8, Steps: 213 | Train Loss: 1.0222027 Vali Loss: 1.0400428 Test Loss: 1.0201365
Validation loss decreased (1.040397 --> 1.040043).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0357044
	speed: 0.0172s/iter; left time: 5.6304s
	iters: 200, epoch: 9 | loss: 1.0196862
	speed: 0.0164s/iter; left time: 3.7118s
Epoch: 9 cost time: 3.5857977867126465
Epoch: 9, Steps: 213 | Train Loss: 1.0218819 Vali Loss: 1.0398656 Test Loss: 1.0201529
Validation loss decreased (1.040043 --> 1.039866).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0111794
	speed: 0.0130s/iter; left time: 1.4811s
	iters: 200, epoch: 10 | loss: 1.0077428
	speed: 0.0114s/iter; left time: 0.1597s
Epoch: 10 cost time: 2.5515129566192627
Epoch: 10, Steps: 213 | Train Loss: 1.0216707 Vali Loss: 1.0403539 Test Loss: 1.0201634
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0201530456542969, mae:0.8057507276535034
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0690086
	speed: 0.0331s/iter; left time: 66.3261s
	iters: 200, epoch: 1 | loss: 1.0295075
	speed: 0.0245s/iter; left time: 46.4982s
Epoch: 1 cost time: 5.082291603088379
Epoch: 1, Steps: 210 | Train Loss: 1.0805363 Vali Loss: 1.0528374 Test Loss: 1.0251257
Validation loss decreased (inf --> 1.052837).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0778005
	speed: 0.0174s/iter; left time: 31.1631s
	iters: 200, epoch: 2 | loss: 1.0401267
	speed: 0.0143s/iter; left time: 24.2354s
Epoch: 2 cost time: 3.08416748046875
Epoch: 2, Steps: 210 | Train Loss: 1.0442863 Vali Loss: 1.0499316 Test Loss: 1.0240829
Validation loss decreased (1.052837 --> 1.049932).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0204329
	speed: 0.0198s/iter; left time: 31.3750s
	iters: 200, epoch: 3 | loss: 1.0498259
	speed: 0.0172s/iter; left time: 25.4291s
Epoch: 3 cost time: 3.6985509395599365
Epoch: 3, Steps: 210 | Train Loss: 1.0384024 Vali Loss: 1.0470445 Test Loss: 1.0231929
Validation loss decreased (1.049932 --> 1.047045).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0247676
	speed: 0.0165s/iter; left time: 22.6676s
	iters: 200, epoch: 4 | loss: 1.0158414
	speed: 0.0159s/iter; left time: 20.2258s
Epoch: 4 cost time: 3.4726650714874268
Epoch: 4, Steps: 210 | Train Loss: 1.0351006 Vali Loss: 1.0488784 Test Loss: 1.0207812
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0290254
	speed: 0.0195s/iter; left time: 22.6098s
	iters: 200, epoch: 5 | loss: 1.0313809
	speed: 0.0181s/iter; left time: 19.2193s
Epoch: 5 cost time: 3.888411521911621
Epoch: 5, Steps: 210 | Train Loss: 1.0332938 Vali Loss: 1.0473568 Test Loss: 1.0204270
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0546777
	speed: 0.0137s/iter; left time: 13.0572s
	iters: 200, epoch: 6 | loss: 1.0307429
	speed: 0.0120s/iter; left time: 10.1786s
Epoch: 6 cost time: 2.600811004638672
Epoch: 6, Steps: 210 | Train Loss: 1.0323945 Vali Loss: 1.0470334 Test Loss: 1.0202265
Validation loss decreased (1.047045 --> 1.047033).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0300380
	speed: 0.0217s/iter; left time: 16.0934s
	iters: 200, epoch: 7 | loss: 1.0034823
	speed: 0.0178s/iter; left time: 11.4141s
Epoch: 7 cost time: 3.782914400100708
Epoch: 7, Steps: 210 | Train Loss: 1.0319699 Vali Loss: 1.0477707 Test Loss: 1.0199840
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0132272
	speed: 0.0186s/iter; left time: 9.8721s
	iters: 200, epoch: 8 | loss: 1.0618615
	speed: 0.0172s/iter; left time: 7.4195s
Epoch: 8 cost time: 3.711665630340576
Epoch: 8, Steps: 210 | Train Loss: 1.0313517 Vali Loss: 1.0467108 Test Loss: 1.0200675
Validation loss decreased (1.047033 --> 1.046711).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0433948
	speed: 0.0183s/iter; left time: 5.8621s
	iters: 200, epoch: 9 | loss: 1.0360059
	speed: 0.0163s/iter; left time: 3.6105s
Epoch: 9 cost time: 3.546224594116211
Epoch: 9, Steps: 210 | Train Loss: 1.0316093 Vali Loss: 1.0482367 Test Loss: 1.0200340
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0222099
	speed: 0.0126s/iter; left time: 1.3945s
	iters: 200, epoch: 10 | loss: 1.0238595
	speed: 0.0118s/iter; left time: 0.1300s
Epoch: 10 cost time: 2.5729141235351562
Epoch: 10, Steps: 210 | Train Loss: 1.0313471 Vali Loss: 1.0478275 Test Loss: 1.0200465
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0200674533843994, mae:0.80491042137146
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0478742
	speed: 0.0125s/iter; left time: 25.0673s
	iters: 200, epoch: 1 | loss: 1.0380470
	speed: 0.0108s/iter; left time: 20.5171s
Epoch: 1 cost time: 2.3301584720611572
Epoch: 1, Steps: 210 | Train Loss: 1.0812524 Vali Loss: 1.0513060 Test Loss: 1.0239935
Validation loss decreased (inf --> 1.051306).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0533928
	speed: 0.0143s/iter; left time: 25.5634s
	iters: 200, epoch: 2 | loss: 1.0130031
	speed: 0.0123s/iter; left time: 20.8514s
Epoch: 2 cost time: 2.6404428482055664
Epoch: 2, Steps: 210 | Train Loss: 1.0436044 Vali Loss: 1.0493611 Test Loss: 1.0242770
Validation loss decreased (1.051306 --> 1.049361).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0483636
	speed: 0.0150s/iter; left time: 23.6592s
	iters: 200, epoch: 3 | loss: 1.0275096
	speed: 0.0150s/iter; left time: 22.2878s
Epoch: 3 cost time: 3.2628636360168457
Epoch: 3, Steps: 210 | Train Loss: 1.0380620 Vali Loss: 1.0482905 Test Loss: 1.0219979
Validation loss decreased (1.049361 --> 1.048290).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0533073
	speed: 0.0288s/iter; left time: 39.5491s
	iters: 200, epoch: 4 | loss: 1.0269492
	speed: 0.0207s/iter; left time: 26.2897s
Epoch: 4 cost time: 4.3998706340789795
Epoch: 4, Steps: 210 | Train Loss: 1.0349934 Vali Loss: 1.0475703 Test Loss: 1.0209961
Validation loss decreased (1.048290 --> 1.047570).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0335160
	speed: 0.0217s/iter; left time: 25.2449s
	iters: 200, epoch: 5 | loss: 1.0332637
	speed: 0.0198s/iter; left time: 21.0205s
Epoch: 5 cost time: 4.245551109313965
Epoch: 5, Steps: 210 | Train Loss: 1.0330737 Vali Loss: 1.0493338 Test Loss: 1.0200503
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0297401
	speed: 0.0177s/iter; left time: 16.7863s
	iters: 200, epoch: 6 | loss: 1.0200188
	speed: 0.0150s/iter; left time: 12.7454s
Epoch: 6 cost time: 3.182945966720581
Epoch: 6, Steps: 210 | Train Loss: 1.0322185 Vali Loss: 1.0474509 Test Loss: 1.0199295
Validation loss decreased (1.047570 --> 1.047451).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0147152
	speed: 0.0135s/iter; left time: 10.0095s
	iters: 200, epoch: 7 | loss: 1.0492141
	speed: 0.0142s/iter; left time: 9.0907s
Epoch: 7 cost time: 3.121001958847046
Epoch: 7, Steps: 210 | Train Loss: 1.0315431 Vali Loss: 1.0475113 Test Loss: 1.0199840
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0329373
	speed: 0.0193s/iter; left time: 10.2251s
	iters: 200, epoch: 8 | loss: 1.0105071
	speed: 0.0175s/iter; left time: 7.5288s
Epoch: 8 cost time: 3.752011775970459
Epoch: 8, Steps: 210 | Train Loss: 1.0312962 Vali Loss: 1.0469823 Test Loss: 1.0198835
Validation loss decreased (1.047451 --> 1.046982).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0198119
	speed: 0.0257s/iter; left time: 8.2383s
	iters: 200, epoch: 9 | loss: 1.0285923
	speed: 0.0217s/iter; left time: 4.7851s
Epoch: 9 cost time: 4.551764249801636
Epoch: 9, Steps: 210 | Train Loss: 1.0309835 Vali Loss: 1.0470437 Test Loss: 1.0198565
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0031114
	speed: 0.0172s/iter; left time: 1.9077s
	iters: 200, epoch: 10 | loss: 1.0447569
	speed: 0.0136s/iter; left time: 0.1499s
Epoch: 10 cost time: 2.899235725402832
Epoch: 10, Steps: 210 | Train Loss: 1.0309654 Vali Loss: 1.0465258 Test Loss: 1.0198679
Validation loss decreased (1.046982 --> 1.046526).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0198677778244019, mae:0.8048432469367981
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0440983
	speed: 0.0199s/iter; left time: 39.9105s
	iters: 200, epoch: 1 | loss: 1.0385498
	speed: 0.0173s/iter; left time: 32.9126s
Epoch: 1 cost time: 3.701744794845581
Epoch: 1, Steps: 210 | Train Loss: 1.0808790 Vali Loss: 1.0512658 Test Loss: 1.0248709
Validation loss decreased (inf --> 1.051266).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0656161
	speed: 0.0168s/iter; left time: 30.1293s
	iters: 200, epoch: 2 | loss: 1.0348375
	speed: 0.0160s/iter; left time: 27.0036s
Epoch: 2 cost time: 3.4694652557373047
Epoch: 2, Steps: 210 | Train Loss: 1.0440607 Vali Loss: 1.0520873 Test Loss: 1.0242271
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0188265
	speed: 0.0179s/iter; left time: 28.2237s
	iters: 200, epoch: 3 | loss: 1.0272630
	speed: 0.0159s/iter; left time: 23.5121s
Epoch: 3 cost time: 3.4186654090881348
Epoch: 3, Steps: 210 | Train Loss: 1.0382547 Vali Loss: 1.0491968 Test Loss: 1.0216209
Validation loss decreased (1.051266 --> 1.049197).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0141445
	speed: 0.0142s/iter; left time: 19.4474s
	iters: 200, epoch: 4 | loss: 1.0420755
	speed: 0.0118s/iter; left time: 14.9846s
Epoch: 4 cost time: 2.5413825511932373
Epoch: 4, Steps: 210 | Train Loss: 1.0351259 Vali Loss: 1.0484376 Test Loss: 1.0208269
Validation loss decreased (1.049197 --> 1.048438).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0105095
	speed: 0.0178s/iter; left time: 20.6939s
	iters: 200, epoch: 5 | loss: 1.0483038
	speed: 0.0158s/iter; left time: 16.7460s
Epoch: 5 cost time: 3.4243669509887695
Epoch: 5, Steps: 210 | Train Loss: 1.0328116 Vali Loss: 1.0472252 Test Loss: 1.0210413
Validation loss decreased (1.048438 --> 1.047225).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0165167
	speed: 0.0265s/iter; left time: 25.2488s
	iters: 200, epoch: 6 | loss: 1.0475954
	speed: 0.0193s/iter; left time: 16.4259s
Epoch: 6 cost time: 4.063708305358887
Epoch: 6, Steps: 210 | Train Loss: 1.0321045 Vali Loss: 1.0471324 Test Loss: 1.0205075
Validation loss decreased (1.047225 --> 1.047132).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0373305
	speed: 0.0202s/iter; left time: 14.9581s
	iters: 200, epoch: 7 | loss: 1.0089916
	speed: 0.0158s/iter; left time: 10.0986s
Epoch: 7 cost time: 3.426870107650757
Epoch: 7, Steps: 210 | Train Loss: 1.0316852 Vali Loss: 1.0484091 Test Loss: 1.0202472
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0617278
	speed: 0.0156s/iter; left time: 8.2953s
	iters: 200, epoch: 8 | loss: 1.0360842
	speed: 0.0149s/iter; left time: 6.4324s
Epoch: 8 cost time: 3.122572660446167
Epoch: 8, Steps: 210 | Train Loss: 1.0312201 Vali Loss: 1.0465013 Test Loss: 1.0203170
Validation loss decreased (1.047132 --> 1.046501).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0313729
	speed: 0.0200s/iter; left time: 6.4163s
	iters: 200, epoch: 9 | loss: 1.0639635
	speed: 0.0172s/iter; left time: 3.8064s
Epoch: 9 cost time: 3.8101847171783447
Epoch: 9, Steps: 210 | Train Loss: 1.0311325 Vali Loss: 1.0479486 Test Loss: 1.0203176
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0565591
	speed: 0.0212s/iter; left time: 2.3482s
	iters: 200, epoch: 10 | loss: 1.0287066
	speed: 0.0174s/iter; left time: 0.1910s
Epoch: 10 cost time: 3.7013938426971436
Epoch: 10, Steps: 210 | Train Loss: 1.0310154 Vali Loss: 1.0473388 Test Loss: 1.0203246
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0203168392181396, mae:0.8050540685653687
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0458792
	speed: 0.0331s/iter; left time: 64.9919s
	iters: 200, epoch: 1 | loss: 1.0354575
	speed: 0.0266s/iter; left time: 49.5270s
Epoch: 1 cost time: 5.467164516448975
Epoch: 1, Steps: 206 | Train Loss: 1.0791375 Vali Loss: 1.0608615 Test Loss: 1.0405935
Validation loss decreased (inf --> 1.060861).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0257672
	speed: 0.0166s/iter; left time: 29.1624s
	iters: 200, epoch: 2 | loss: 1.0352429
	speed: 0.0148s/iter; left time: 24.4292s
Epoch: 2 cost time: 3.077357292175293
Epoch: 2, Steps: 206 | Train Loss: 1.0448437 Vali Loss: 1.0606754 Test Loss: 1.0382706
Validation loss decreased (1.060861 --> 1.060675).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0343348
	speed: 0.0166s/iter; left time: 25.6934s
	iters: 200, epoch: 3 | loss: 1.0379806
	speed: 0.0123s/iter; left time: 17.8557s
Epoch: 3 cost time: 2.565734386444092
Epoch: 3, Steps: 206 | Train Loss: 1.0398062 Vali Loss: 1.0581079 Test Loss: 1.0362562
Validation loss decreased (1.060675 --> 1.058108).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0454233
	speed: 0.0145s/iter; left time: 19.4799s
	iters: 200, epoch: 4 | loss: 1.0468494
	speed: 0.0129s/iter; left time: 16.0455s
Epoch: 4 cost time: 2.79174542427063
Epoch: 4, Steps: 206 | Train Loss: 1.0375237 Vali Loss: 1.0568933 Test Loss: 1.0358812
Validation loss decreased (1.058108 --> 1.056893).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0193869
	speed: 0.0197s/iter; left time: 22.4004s
	iters: 200, epoch: 5 | loss: 1.0346824
	speed: 0.0175s/iter; left time: 18.0985s
Epoch: 5 cost time: 3.7417469024658203
Epoch: 5, Steps: 206 | Train Loss: 1.0357929 Vali Loss: 1.0559835 Test Loss: 1.0357542
Validation loss decreased (1.056893 --> 1.055984).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0505662
	speed: 0.0164s/iter; left time: 15.2451s
	iters: 200, epoch: 6 | loss: 1.0445567
	speed: 0.0146s/iter; left time: 12.1047s
Epoch: 6 cost time: 3.0877742767333984
Epoch: 6, Steps: 206 | Train Loss: 1.0353677 Vali Loss: 1.0557572 Test Loss: 1.0354733
Validation loss decreased (1.055984 --> 1.055757).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0323020
	speed: 0.0165s/iter; left time: 11.9271s
	iters: 200, epoch: 7 | loss: 1.0265914
	speed: 0.0142s/iter; left time: 8.8538s
Epoch: 7 cost time: 2.997072219848633
Epoch: 7, Steps: 206 | Train Loss: 1.0347116 Vali Loss: 1.0553728 Test Loss: 1.0354099
Validation loss decreased (1.055757 --> 1.055373).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0491194
	speed: 0.0134s/iter; left time: 6.9383s
	iters: 200, epoch: 8 | loss: 1.0545821
	speed: 0.0122s/iter; left time: 5.0957s
Epoch: 8 cost time: 2.589657783508301
Epoch: 8, Steps: 206 | Train Loss: 1.0345555 Vali Loss: 1.0558733 Test Loss: 1.0350773
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0243583
	speed: 0.0189s/iter; left time: 5.9099s
	iters: 200, epoch: 9 | loss: 1.0178527
	speed: 0.0160s/iter; left time: 3.4008s
Epoch: 9 cost time: 3.342942714691162
Epoch: 9, Steps: 206 | Train Loss: 1.0345101 Vali Loss: 1.0557090 Test Loss: 1.0351020
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0317463
	speed: 0.0194s/iter; left time: 2.0746s
	iters: 200, epoch: 10 | loss: 1.0291908
	speed: 0.0159s/iter; left time: 0.1116s
Epoch: 10 cost time: 3.3793113231658936
Epoch: 10, Steps: 206 | Train Loss: 1.0341181 Vali Loss: 1.0559754 Test Loss: 1.0350991
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0354100465774536, mae:0.8092145323753357
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0636215
	speed: 0.0165s/iter; left time: 32.4033s
	iters: 200, epoch: 1 | loss: 1.0417457
	speed: 0.0145s/iter; left time: 26.9125s
Epoch: 1 cost time: 3.0428824424743652
Epoch: 1, Steps: 206 | Train Loss: 1.0810033 Vali Loss: 1.0599843 Test Loss: 1.0387850
Validation loss decreased (inf --> 1.059984).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0295129
	speed: 0.0141s/iter; left time: 24.6705s
	iters: 200, epoch: 2 | loss: 1.0392052
	speed: 0.0118s/iter; left time: 19.4559s
Epoch: 2 cost time: 2.499037981033325
Epoch: 2, Steps: 206 | Train Loss: 1.0443196 Vali Loss: 1.0591395 Test Loss: 1.0377271
Validation loss decreased (1.059984 --> 1.059139).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0304801
	speed: 0.0154s/iter; left time: 23.8073s
	iters: 200, epoch: 3 | loss: 1.0574139
	speed: 0.0138s/iter; left time: 20.0421s
Epoch: 3 cost time: 2.952657699584961
Epoch: 3, Steps: 206 | Train Loss: 1.0394222 Vali Loss: 1.0569305 Test Loss: 1.0370371
Validation loss decreased (1.059139 --> 1.056931).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0504154
	speed: 0.0152s/iter; left time: 20.4213s
	iters: 200, epoch: 4 | loss: 1.0299639
	speed: 0.0152s/iter; left time: 18.8466s
Epoch: 4 cost time: 3.2598297595977783
Epoch: 4, Steps: 206 | Train Loss: 1.0369967 Vali Loss: 1.0561544 Test Loss: 1.0356245
Validation loss decreased (1.056931 --> 1.056154).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0306853
	speed: 0.0183s/iter; left time: 20.8612s
	iters: 200, epoch: 5 | loss: 1.0316801
	speed: 0.0159s/iter; left time: 16.5109s
Epoch: 5 cost time: 3.3924143314361572
Epoch: 5, Steps: 206 | Train Loss: 1.0355678 Vali Loss: 1.0556498 Test Loss: 1.0354005
Validation loss decreased (1.056154 --> 1.055650).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0336981
	speed: 0.0175s/iter; left time: 16.3207s
	iters: 200, epoch: 6 | loss: 1.0343677
	speed: 0.0157s/iter; left time: 13.0706s
Epoch: 6 cost time: 3.35213041305542
Epoch: 6, Steps: 206 | Train Loss: 1.0346714 Vali Loss: 1.0558336 Test Loss: 1.0347978
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0219125
	speed: 0.0124s/iter; left time: 9.0086s
	iters: 200, epoch: 7 | loss: 1.0349593
	speed: 0.0123s/iter; left time: 7.6850s
Epoch: 7 cost time: 2.6634416580200195
Epoch: 7, Steps: 206 | Train Loss: 1.0344635 Vali Loss: 1.0558537 Test Loss: 1.0346543
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0178536
	speed: 0.0155s/iter; left time: 8.0600s
	iters: 200, epoch: 8 | loss: 1.0129869
	speed: 0.0127s/iter; left time: 5.3204s
Epoch: 8 cost time: 2.680201768875122
Epoch: 8, Steps: 206 | Train Loss: 1.0342663 Vali Loss: 1.0555162 Test Loss: 1.0347700
Validation loss decreased (1.055650 --> 1.055516).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0260909
	speed: 0.0201s/iter; left time: 6.2828s
	iters: 200, epoch: 9 | loss: 1.0429476
	speed: 0.0169s/iter; left time: 3.6002s
Epoch: 9 cost time: 3.5711543560028076
Epoch: 9, Steps: 206 | Train Loss: 1.0339752 Vali Loss: 1.0554653 Test Loss: 1.0347638
Validation loss decreased (1.055516 --> 1.055465).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0186152
	speed: 0.0165s/iter; left time: 1.7686s
	iters: 200, epoch: 10 | loss: 1.0210074
	speed: 0.0154s/iter; left time: 0.1079s
Epoch: 10 cost time: 3.279970407485962
Epoch: 10, Steps: 206 | Train Loss: 1.0340541 Vali Loss: 1.0556495 Test Loss: 1.0347271
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0347638130187988, mae:0.8089872598648071
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0661762
	speed: 0.0173s/iter; left time: 33.9504s
	iters: 200, epoch: 1 | loss: 1.0576324
	speed: 0.0153s/iter; left time: 28.4911s
Epoch: 1 cost time: 3.283403158187866
Epoch: 1, Steps: 206 | Train Loss: 1.0828190 Vali Loss: 1.0615703 Test Loss: 1.0388068
Validation loss decreased (inf --> 1.061570).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0277631
	speed: 0.0165s/iter; left time: 28.9484s
	iters: 200, epoch: 2 | loss: 1.0516268
	speed: 0.0141s/iter; left time: 23.2578s
Epoch: 2 cost time: 2.966310739517212
Epoch: 2, Steps: 206 | Train Loss: 1.0440562 Vali Loss: 1.0578325 Test Loss: 1.0386457
Validation loss decreased (1.061570 --> 1.057832).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0423874
	speed: 0.0187s/iter; left time: 29.0056s
	iters: 200, epoch: 3 | loss: 1.0341824
	speed: 0.0184s/iter; left time: 26.6404s
Epoch: 3 cost time: 3.8077566623687744
Epoch: 3, Steps: 206 | Train Loss: 1.0393469 Vali Loss: 1.0585153 Test Loss: 1.0360130
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0261716
	speed: 0.0240s/iter; left time: 32.2533s
	iters: 200, epoch: 4 | loss: 1.0386242
	speed: 0.0181s/iter; left time: 22.4752s
Epoch: 4 cost time: 3.7277796268463135
Epoch: 4, Steps: 206 | Train Loss: 1.0367914 Vali Loss: 1.0564255 Test Loss: 1.0361096
Validation loss decreased (1.057832 --> 1.056425).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0353658
	speed: 0.0235s/iter; left time: 26.6779s
	iters: 200, epoch: 5 | loss: 1.0437858
	speed: 0.0186s/iter; left time: 19.3329s
Epoch: 5 cost time: 3.950289487838745
Epoch: 5, Steps: 206 | Train Loss: 1.0356005 Vali Loss: 1.0559117 Test Loss: 1.0353253
Validation loss decreased (1.056425 --> 1.055912).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0206057
	speed: 0.0144s/iter; left time: 13.3655s
	iters: 200, epoch: 6 | loss: 1.0309494
	speed: 0.0135s/iter; left time: 11.1849s
Epoch: 6 cost time: 2.8875350952148438
Epoch: 6, Steps: 206 | Train Loss: 1.0345868 Vali Loss: 1.0559621 Test Loss: 1.0350461
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0197212
	speed: 0.0161s/iter; left time: 11.6682s
	iters: 200, epoch: 7 | loss: 1.0219274
	speed: 0.0155s/iter; left time: 9.7133s
Epoch: 7 cost time: 3.267636299133301
Epoch: 7, Steps: 206 | Train Loss: 1.0340926 Vali Loss: 1.0559266 Test Loss: 1.0348892
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0437160
	speed: 0.0160s/iter; left time: 8.2931s
	iters: 200, epoch: 8 | loss: 1.0247554
	speed: 0.0152s/iter; left time: 6.3848s
Epoch: 8 cost time: 3.2152156829833984
Epoch: 8, Steps: 206 | Train Loss: 1.0342847 Vali Loss: 1.0555508 Test Loss: 1.0349593
Validation loss decreased (1.055912 --> 1.055551).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0231053
	speed: 0.0182s/iter; left time: 5.6925s
	iters: 200, epoch: 9 | loss: 1.0505016
	speed: 0.0159s/iter; left time: 3.3841s
Epoch: 9 cost time: 3.435234308242798
Epoch: 9, Steps: 206 | Train Loss: 1.0340753 Vali Loss: 1.0557293 Test Loss: 1.0349329
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0359812
	speed: 0.0172s/iter; left time: 1.8428s
	iters: 200, epoch: 10 | loss: 1.0288547
	speed: 0.0137s/iter; left time: 0.0959s
Epoch: 10 cost time: 2.9341862201690674
Epoch: 10, Steps: 206 | Train Loss: 1.0337506 Vali Loss: 1.0556910 Test Loss: 1.0349274
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0349591970443726, mae:0.8090683817863464
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0565025
	speed: 0.0314s/iter; left time: 57.7323s
Epoch: 1 cost time: 4.340394020080566
Epoch: 1, Steps: 194 | Train Loss: 1.0814655 Vali Loss: 1.0602117 Test Loss: 1.0320880
Validation loss decreased (inf --> 1.060212).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0476491
	speed: 0.0154s/iter; left time: 25.3013s
Epoch: 2 cost time: 2.8616459369659424
Epoch: 2, Steps: 194 | Train Loss: 1.0466126 Vali Loss: 1.0577757 Test Loss: 1.0311821
Validation loss decreased (1.060212 --> 1.057776).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0541500
	speed: 0.0201s/iter; left time: 29.2236s
Epoch: 3 cost time: 3.4565982818603516
Epoch: 3, Steps: 194 | Train Loss: 1.0424847 Vali Loss: 1.0569894 Test Loss: 1.0296242
Validation loss decreased (1.057776 --> 1.056989).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0385903
	speed: 0.0200s/iter; left time: 25.2221s
Epoch: 4 cost time: 3.3489491939544678
Epoch: 4, Steps: 194 | Train Loss: 1.0405006 Vali Loss: 1.0559130 Test Loss: 1.0289040
Validation loss decreased (1.056989 --> 1.055913).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0455582
	speed: 0.0167s/iter; left time: 17.7915s
Epoch: 5 cost time: 2.9022750854492188
Epoch: 5, Steps: 194 | Train Loss: 1.0396811 Vali Loss: 1.0548339 Test Loss: 1.0285499
Validation loss decreased (1.055913 --> 1.054834).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0378467
	speed: 0.0171s/iter; left time: 14.8623s
Epoch: 6 cost time: 2.8981690406799316
Epoch: 6, Steps: 194 | Train Loss: 1.0388889 Vali Loss: 1.0544715 Test Loss: 1.0283879
Validation loss decreased (1.054834 --> 1.054471).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0475352
	speed: 0.0164s/iter; left time: 11.1220s
Epoch: 7 cost time: 2.8975605964660645
Epoch: 7, Steps: 194 | Train Loss: 1.0386973 Vali Loss: 1.0547403 Test Loss: 1.0280964
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0312629
	speed: 0.0173s/iter; left time: 8.3786s
Epoch: 8 cost time: 2.994480609893799
Epoch: 8, Steps: 194 | Train Loss: 1.0387702 Vali Loss: 1.0550958 Test Loss: 1.0280519
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0441973
	speed: 0.0171s/iter; left time: 4.9522s
Epoch: 9 cost time: 2.9686834812164307
Epoch: 9, Steps: 194 | Train Loss: 1.0385534 Vali Loss: 1.0550823 Test Loss: 1.0280553
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0318152
	speed: 0.0238s/iter; left time: 2.2584s
Epoch: 10 cost time: 3.5712649822235107
Epoch: 10, Steps: 194 | Train Loss: 1.0386136 Vali Loss: 1.0546004 Test Loss: 1.0280619
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0283877849578857, mae:0.8048341870307922
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0531094
	speed: 0.0165s/iter; left time: 30.2885s
Epoch: 1 cost time: 2.8145174980163574
Epoch: 1, Steps: 194 | Train Loss: 1.0838335 Vali Loss: 1.0601417 Test Loss: 1.0319991
Validation loss decreased (inf --> 1.060142).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0477812
	speed: 0.0143s/iter; left time: 23.4967s
Epoch: 2 cost time: 2.5381393432617188
Epoch: 2, Steps: 194 | Train Loss: 1.0464617 Vali Loss: 1.0581537 Test Loss: 1.0316116
Validation loss decreased (1.060142 --> 1.058154).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0282445
	speed: 0.0194s/iter; left time: 28.1676s
Epoch: 3 cost time: 3.2446093559265137
Epoch: 3, Steps: 194 | Train Loss: 1.0422866 Vali Loss: 1.0561528 Test Loss: 1.0299505
Validation loss decreased (1.058154 --> 1.056153).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0500547
	speed: 0.0222s/iter; left time: 27.8943s
Epoch: 4 cost time: 3.4545462131500244
Epoch: 4, Steps: 194 | Train Loss: 1.0402046 Vali Loss: 1.0553031 Test Loss: 1.0287690
Validation loss decreased (1.056153 --> 1.055303).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0475789
	speed: 0.0173s/iter; left time: 18.3891s
Epoch: 5 cost time: 3.6839001178741455
Epoch: 5, Steps: 194 | Train Loss: 1.0392784 Vali Loss: 1.0554162 Test Loss: 1.0281665
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0478421
	speed: 0.0177s/iter; left time: 15.4408s
Epoch: 6 cost time: 2.9070708751678467
Epoch: 6, Steps: 194 | Train Loss: 1.0387593 Vali Loss: 1.0544647 Test Loss: 1.0280800
Validation loss decreased (1.055303 --> 1.054465).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0481005
	speed: 0.0138s/iter; left time: 9.3403s
Epoch: 7 cost time: 3.4204413890838623
Epoch: 7, Steps: 194 | Train Loss: 1.0383974 Vali Loss: 1.0545964 Test Loss: 1.0278101
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0408354
	speed: 0.0191s/iter; left time: 9.2400s
Epoch: 8 cost time: 3.2109806537628174
Epoch: 8, Steps: 194 | Train Loss: 1.0382758 Vali Loss: 1.0549387 Test Loss: 1.0276983
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0427895
	speed: 0.0177s/iter; left time: 5.1057s
Epoch: 9 cost time: 3.4832282066345215
Epoch: 9, Steps: 194 | Train Loss: 1.0382095 Vali Loss: 1.0547242 Test Loss: 1.0277057
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0466310
	speed: 0.0221s/iter; left time: 2.1027s
Epoch: 10 cost time: 3.5408337116241455
Epoch: 10, Steps: 194 | Train Loss: 1.0381563 Vali Loss: 1.0542717 Test Loss: 1.0277101
Validation loss decreased (1.054465 --> 1.054272).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0277099609375, mae:0.8045961856842041
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0496752
	speed: 0.0125s/iter; left time: 22.9461s
Epoch: 1 cost time: 2.5961039066314697
Epoch: 1, Steps: 194 | Train Loss: 1.0832131 Vali Loss: 1.0587584 Test Loss: 1.0325134
Validation loss decreased (inf --> 1.058758).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0520400
	speed: 0.0181s/iter; left time: 29.8800s
Epoch: 2 cost time: 3.1495890617370605
Epoch: 2, Steps: 194 | Train Loss: 1.0466777 Vali Loss: 1.0572605 Test Loss: 1.0319134
Validation loss decreased (1.058758 --> 1.057261).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0425713
	speed: 0.0232s/iter; left time: 33.6850s
Epoch: 3 cost time: 3.6499619483947754
Epoch: 3, Steps: 194 | Train Loss: 1.0425578 Vali Loss: 1.0566672 Test Loss: 1.0300621
Validation loss decreased (1.057261 --> 1.056667).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0363233
	speed: 0.0231s/iter; left time: 29.0882s
Epoch: 4 cost time: 3.408073902130127
Epoch: 4, Steps: 194 | Train Loss: 1.0403102 Vali Loss: 1.0560141 Test Loss: 1.0286927
Validation loss decreased (1.056667 --> 1.056014).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0365845
	speed: 0.0198s/iter; left time: 21.0399s
Epoch: 5 cost time: 2.8573036193847656
Epoch: 5, Steps: 194 | Train Loss: 1.0393560 Vali Loss: 1.0553674 Test Loss: 1.0283762
Validation loss decreased (1.056014 --> 1.055367).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0367906
	speed: 0.0148s/iter; left time: 12.8557s
Epoch: 6 cost time: 2.352022647857666
Epoch: 6, Steps: 194 | Train Loss: 1.0390585 Vali Loss: 1.0549475 Test Loss: 1.0281913
Validation loss decreased (1.055367 --> 1.054947).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0361512
	speed: 0.0169s/iter; left time: 11.4691s
Epoch: 7 cost time: 3.070683002471924
Epoch: 7, Steps: 194 | Train Loss: 1.0386353 Vali Loss: 1.0552270 Test Loss: 1.0280820
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0430415
	speed: 0.0176s/iter; left time: 8.4841s
Epoch: 8 cost time: 2.9989311695098877
Epoch: 8, Steps: 194 | Train Loss: 1.0385342 Vali Loss: 1.0547311 Test Loss: 1.0280137
Validation loss decreased (1.054947 --> 1.054731).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0300354
	speed: 0.0189s/iter; left time: 5.4571s
Epoch: 9 cost time: 3.235762357711792
Epoch: 9, Steps: 194 | Train Loss: 1.0382611 Vali Loss: 1.0548545 Test Loss: 1.0279897
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0361308
	speed: 0.0180s/iter; left time: 1.7135s
Epoch: 10 cost time: 3.1090264320373535
Epoch: 10, Steps: 194 | Train Loss: 1.0383835 Vali Loss: 1.0548116 Test Loss: 1.0279840
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0280134677886963, mae:0.8046627044677734
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0211995
	speed: 0.0331s/iter; left time: 67.2095s
	iters: 200, epoch: 1 | loss: 1.0323579
	speed: 0.0239s/iter; left time: 46.2221s
Epoch: 1 cost time: 5.036132335662842
Epoch: 1, Steps: 213 | Train Loss: 1.0814711 Vali Loss: 1.0443295 Test Loss: 1.0252755
Validation loss decreased (inf --> 1.044330).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0107484
	speed: 0.0150s/iter; left time: 27.2484s
	iters: 200, epoch: 2 | loss: 1.0357621
	speed: 0.0152s/iter; left time: 26.0513s
Epoch: 2 cost time: 3.322766065597534
Epoch: 2, Steps: 213 | Train Loss: 1.0381408 Vali Loss: 1.0420327 Test Loss: 1.0237551
Validation loss decreased (1.044330 --> 1.042033).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0165994
	speed: 0.0123s/iter; left time: 19.6880s
	iters: 200, epoch: 3 | loss: 1.0264748
	speed: 0.0105s/iter; left time: 15.8719s
Epoch: 3 cost time: 2.3325259685516357
Epoch: 3, Steps: 213 | Train Loss: 1.0308081 Vali Loss: 1.0418108 Test Loss: 1.0219539
Validation loss decreased (1.042033 --> 1.041811).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0112799
	speed: 0.0137s/iter; left time: 19.1239s
	iters: 200, epoch: 4 | loss: 1.0162147
	speed: 0.0135s/iter; left time: 17.4281s
Epoch: 4 cost time: 3.012141466140747
Epoch: 4, Steps: 213 | Train Loss: 1.0268961 Vali Loss: 1.0416721 Test Loss: 1.0205700
Validation loss decreased (1.041811 --> 1.041672).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9943942
	speed: 0.0171s/iter; left time: 20.1705s
	iters: 200, epoch: 5 | loss: 0.9953189
	speed: 0.0151s/iter; left time: 16.3077s
Epoch: 5 cost time: 3.3321704864501953
Epoch: 5, Steps: 213 | Train Loss: 1.0245669 Vali Loss: 1.0415971 Test Loss: 1.0202652
Validation loss decreased (1.041672 --> 1.041597).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0312855
	speed: 0.0179s/iter; left time: 17.3085s
	iters: 200, epoch: 6 | loss: 1.0078858
	speed: 0.0156s/iter; left time: 13.5143s
Epoch: 6 cost time: 3.4243247509002686
Epoch: 6, Steps: 213 | Train Loss: 1.0234430 Vali Loss: 1.0401762 Test Loss: 1.0201243
Validation loss decreased (1.041597 --> 1.040176).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0333267
	speed: 0.0152s/iter; left time: 11.4189s
	iters: 200, epoch: 7 | loss: 1.0117314
	speed: 0.0126s/iter; left time: 8.2115s
Epoch: 7 cost time: 2.8218815326690674
Epoch: 7, Steps: 213 | Train Loss: 1.0231831 Vali Loss: 1.0404717 Test Loss: 1.0200684
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0149164
	speed: 0.0179s/iter; left time: 9.6796s
	iters: 200, epoch: 8 | loss: 1.0184258
	speed: 0.0161s/iter; left time: 7.0713s
Epoch: 8 cost time: 3.479677677154541
Epoch: 8, Steps: 213 | Train Loss: 1.0219955 Vali Loss: 1.0402799 Test Loss: 1.0200514
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0255270
	speed: 0.0238s/iter; left time: 7.7849s
	iters: 200, epoch: 9 | loss: 1.0120742
	speed: 0.0192s/iter; left time: 4.3677s
Epoch: 9 cost time: 4.1403913497924805
Epoch: 9, Steps: 213 | Train Loss: 1.0218348 Vali Loss: 1.0401371 Test Loss: 1.0200695
Validation loss decreased (1.040176 --> 1.040137).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0477247
	speed: 0.0166s/iter; left time: 1.8907s
	iters: 200, epoch: 10 | loss: 1.0172894
	speed: 0.0144s/iter; left time: 0.2009s
Epoch: 10 cost time: 3.2636702060699463
Epoch: 10, Steps: 213 | Train Loss: 1.0218831 Vali Loss: 1.0407256 Test Loss: 1.0200788
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0200693607330322, mae:0.8058061003684998
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0386248
	speed: 0.0153s/iter; left time: 31.0782s
	iters: 200, epoch: 1 | loss: 1.0751777
	speed: 0.0128s/iter; left time: 24.8076s
Epoch: 1 cost time: 2.833040952682495
Epoch: 1, Steps: 213 | Train Loss: 1.0802827 Vali Loss: 1.0448180 Test Loss: 1.0246089
Validation loss decreased (inf --> 1.044818).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0350288
	speed: 0.0227s/iter; left time: 41.2033s
	iters: 200, epoch: 2 | loss: 1.0472202
	speed: 0.0176s/iter; left time: 30.2280s
Epoch: 2 cost time: 3.809173345565796
Epoch: 2, Steps: 213 | Train Loss: 1.0380701 Vali Loss: 1.0444834 Test Loss: 1.0241355
Validation loss decreased (1.044818 --> 1.044483).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0209714
	speed: 0.0278s/iter; left time: 44.5735s
	iters: 200, epoch: 3 | loss: 1.0664352
	speed: 0.0204s/iter; left time: 30.7273s
Epoch: 3 cost time: 4.419186592102051
Epoch: 3, Steps: 213 | Train Loss: 1.0309152 Vali Loss: 1.0405813 Test Loss: 1.0207452
Validation loss decreased (1.044483 --> 1.040581).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0470605
	speed: 0.0241s/iter; left time: 33.5525s
	iters: 200, epoch: 4 | loss: 0.9972092
	speed: 0.0163s/iter; left time: 21.1039s
Epoch: 4 cost time: 3.4468908309936523
Epoch: 4, Steps: 213 | Train Loss: 1.0269887 Vali Loss: 1.0410304 Test Loss: 1.0199776
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0168579
	speed: 0.0152s/iter; left time: 17.9780s
	iters: 200, epoch: 5 | loss: 1.0547712
	speed: 0.0126s/iter; left time: 13.5995s
Epoch: 5 cost time: 2.7277681827545166
Epoch: 5, Steps: 213 | Train Loss: 1.0247397 Vali Loss: 1.0401555 Test Loss: 1.0200629
Validation loss decreased (1.040581 --> 1.040156).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0457225
	speed: 0.0286s/iter; left time: 27.6331s
	iters: 200, epoch: 6 | loss: 1.0348452
	speed: 0.0206s/iter; left time: 17.8210s
Epoch: 6 cost time: 4.343547821044922
Epoch: 6, Steps: 213 | Train Loss: 1.0236299 Vali Loss: 1.0407171 Test Loss: 1.0197498
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0288920
	speed: 0.0236s/iter; left time: 17.7529s
	iters: 200, epoch: 7 | loss: 1.0680821
	speed: 0.0181s/iter; left time: 11.8292s
Epoch: 7 cost time: 3.883148193359375
Epoch: 7, Steps: 213 | Train Loss: 1.0228062 Vali Loss: 1.0399524 Test Loss: 1.0197710
Validation loss decreased (1.040156 --> 1.039952).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0595937
	speed: 0.0183s/iter; left time: 9.8624s
	iters: 200, epoch: 8 | loss: 1.0133009
	speed: 0.0139s/iter; left time: 6.1355s
Epoch: 8 cost time: 2.9447426795959473
Epoch: 8, Steps: 213 | Train Loss: 1.0227782 Vali Loss: 1.0407553 Test Loss: 1.0197729
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0285454
	speed: 0.0125s/iter; left time: 4.0795s
	iters: 200, epoch: 9 | loss: 0.9993005
	speed: 0.0131s/iter; left time: 2.9774s
Epoch: 9 cost time: 2.921018362045288
Epoch: 9, Steps: 213 | Train Loss: 1.0224123 Vali Loss: 1.0395733 Test Loss: 1.0197997
Validation loss decreased (1.039952 --> 1.039573).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0106094
	speed: 0.0173s/iter; left time: 1.9688s
	iters: 200, epoch: 10 | loss: 1.0140053
	speed: 0.0174s/iter; left time: 0.2441s
Epoch: 10 cost time: 3.693058490753174
Epoch: 10, Steps: 213 | Train Loss: 1.0220099 Vali Loss: 1.0400888 Test Loss: 1.0198106
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.019799828529358, mae:0.8057267069816589
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0243775
	speed: 0.0182s/iter; left time: 36.8715s
	iters: 200, epoch: 1 | loss: 1.0301454
	speed: 0.0192s/iter; left time: 37.0191s
Epoch: 1 cost time: 4.1768999099731445
Epoch: 1, Steps: 213 | Train Loss: 1.0798528 Vali Loss: 1.0425045 Test Loss: 1.0237943
Validation loss decreased (inf --> 1.042505).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0579726
	speed: 0.0201s/iter; left time: 36.5626s
	iters: 200, epoch: 2 | loss: 1.0640850
	speed: 0.0157s/iter; left time: 26.9794s
Epoch: 2 cost time: 3.3673696517944336
Epoch: 2, Steps: 213 | Train Loss: 1.0378098 Vali Loss: 1.0441475 Test Loss: 1.0231049
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0202851
	speed: 0.0144s/iter; left time: 23.0784s
	iters: 200, epoch: 3 | loss: 1.0378832
	speed: 0.0137s/iter; left time: 20.6354s
Epoch: 3 cost time: 3.0603442192077637
Epoch: 3, Steps: 213 | Train Loss: 1.0306754 Vali Loss: 1.0425103 Test Loss: 1.0206697
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0305090
	speed: 0.0191s/iter; left time: 26.5944s
	iters: 200, epoch: 4 | loss: 0.9962289
	speed: 0.0173s/iter; left time: 22.4124s
Epoch: 4 cost time: 3.767458915710449
Epoch: 4, Steps: 213 | Train Loss: 1.0263261 Vali Loss: 1.0394965 Test Loss: 1.0202357
Validation loss decreased (1.042505 --> 1.039497).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0228901
	speed: 0.0263s/iter; left time: 31.0274s
	iters: 200, epoch: 5 | loss: 1.0465374
	speed: 0.0226s/iter; left time: 24.3329s
Epoch: 5 cost time: 4.860191106796265
Epoch: 5, Steps: 213 | Train Loss: 1.0241862 Vali Loss: 1.0409310 Test Loss: 1.0198793
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0072206
	speed: 0.0257s/iter; left time: 24.8034s
	iters: 200, epoch: 6 | loss: 1.0264561
	speed: 0.0189s/iter; left time: 16.3800s
Epoch: 6 cost time: 4.071451425552368
Epoch: 6, Steps: 213 | Train Loss: 1.0230911 Vali Loss: 1.0412447 Test Loss: 1.0199578
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0486465
	speed: 0.0134s/iter; left time: 10.0748s
	iters: 200, epoch: 7 | loss: 1.0381140
	speed: 0.0117s/iter; left time: 7.6727s
Epoch: 7 cost time: 2.613740921020508
Epoch: 7, Steps: 213 | Train Loss: 1.0224068 Vali Loss: 1.0402826 Test Loss: 1.0198194
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0167687
	speed: 0.0172s/iter; left time: 9.2937s
	iters: 200, epoch: 8 | loss: 1.0390506
	speed: 0.0145s/iter; left time: 6.4012s
Epoch: 8 cost time: 3.227297067642212
Epoch: 8, Steps: 213 | Train Loss: 1.0222658 Vali Loss: 1.0412505 Test Loss: 1.0198166
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0463265
	speed: 0.0179s/iter; left time: 5.8540s
	iters: 200, epoch: 9 | loss: 1.0350728
	speed: 0.0163s/iter; left time: 3.7070s
Epoch: 9 cost time: 3.4883594512939453
Epoch: 9, Steps: 213 | Train Loss: 1.0218990 Vali Loss: 1.0404264 Test Loss: 1.0198355
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.020235538482666, mae:0.8059000372886658
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0604246
	speed: 0.0262s/iter; left time: 52.3378s
	iters: 200, epoch: 1 | loss: 1.0514452
	speed: 0.0207s/iter; left time: 39.3795s
Epoch: 1 cost time: 4.4014623165130615
Epoch: 1, Steps: 210 | Train Loss: 1.0816226 Vali Loss: 1.0508001 Test Loss: 1.0256592
Validation loss decreased (inf --> 1.050800).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0487518
	speed: 0.0164s/iter; left time: 29.3075s
	iters: 200, epoch: 2 | loss: 1.0558690
	speed: 0.0156s/iter; left time: 26.3020s
Epoch: 2 cost time: 3.292227268218994
Epoch: 2, Steps: 210 | Train Loss: 1.0437064 Vali Loss: 1.0505781 Test Loss: 1.0238041
Validation loss decreased (1.050800 --> 1.050578).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0415744
	speed: 0.0210s/iter; left time: 33.1321s
	iters: 200, epoch: 3 | loss: 1.0258253
	speed: 0.0157s/iter; left time: 23.2625s
Epoch: 3 cost time: 3.378479242324829
Epoch: 3, Steps: 210 | Train Loss: 1.0379992 Vali Loss: 1.0480509 Test Loss: 1.0223433
Validation loss decreased (1.050578 --> 1.048051).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0159276
	speed: 0.0163s/iter; left time: 22.3871s
	iters: 200, epoch: 4 | loss: 1.0334153
	speed: 0.0132s/iter; left time: 16.8199s
Epoch: 4 cost time: 2.8979885578155518
Epoch: 4, Steps: 210 | Train Loss: 1.0348895 Vali Loss: 1.0500854 Test Loss: 1.0209830
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0462255
	speed: 0.0168s/iter; left time: 19.4517s
	iters: 200, epoch: 5 | loss: 1.0339878
	speed: 0.0142s/iter; left time: 15.0869s
Epoch: 5 cost time: 3.0089428424835205
Epoch: 5, Steps: 210 | Train Loss: 1.0329793 Vali Loss: 1.0471165 Test Loss: 1.0211436
Validation loss decreased (1.048051 --> 1.047117).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0328443
	speed: 0.0155s/iter; left time: 14.7119s
	iters: 200, epoch: 6 | loss: 1.0133629
	speed: 0.0138s/iter; left time: 11.7369s
Epoch: 6 cost time: 3.0631463527679443
Epoch: 6, Steps: 210 | Train Loss: 1.0318951 Vali Loss: 1.0492692 Test Loss: 1.0204208
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0119405
	speed: 0.0288s/iter; left time: 21.3399s
	iters: 200, epoch: 7 | loss: 1.0204816
	speed: 0.0219s/iter; left time: 14.0378s
Epoch: 7 cost time: 4.578898906707764
Epoch: 7, Steps: 210 | Train Loss: 1.0316649 Vali Loss: 1.0463058 Test Loss: 1.0205564
Validation loss decreased (1.047117 --> 1.046306).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0260885
	speed: 0.0236s/iter; left time: 12.5312s
	iters: 200, epoch: 8 | loss: 1.0373869
	speed: 0.0182s/iter; left time: 7.8543s
Epoch: 8 cost time: 3.866243839263916
Epoch: 8, Steps: 210 | Train Loss: 1.0309862 Vali Loss: 1.0470017 Test Loss: 1.0204365
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0313987
	speed: 0.0197s/iter; left time: 6.3383s
	iters: 200, epoch: 9 | loss: 1.0316324
	speed: 0.0156s/iter; left time: 3.4492s
Epoch: 9 cost time: 3.410562038421631
Epoch: 9, Steps: 210 | Train Loss: 1.0310209 Vali Loss: 1.0477650 Test Loss: 1.0204238
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0295138
	speed: 0.0150s/iter; left time: 1.6623s
	iters: 200, epoch: 10 | loss: 1.0154095
	speed: 0.0134s/iter; left time: 0.1470s
Epoch: 10 cost time: 2.9212141036987305
Epoch: 10, Steps: 210 | Train Loss: 1.0309234 Vali Loss: 1.0477607 Test Loss: 1.0204316
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0205565690994263, mae:0.8051519393920898
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0607796
	speed: 0.0269s/iter; left time: 53.7978s
	iters: 200, epoch: 1 | loss: 1.0501326
	speed: 0.0192s/iter; left time: 36.5400s
Epoch: 1 cost time: 4.032965898513794
Epoch: 1, Steps: 210 | Train Loss: 1.0817216 Vali Loss: 1.0525663 Test Loss: 1.0249401
Validation loss decreased (inf --> 1.052566).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0482644
	speed: 0.0186s/iter; left time: 33.3505s
	iters: 200, epoch: 2 | loss: 1.0480788
	speed: 0.0156s/iter; left time: 26.3122s
Epoch: 2 cost time: 3.322859287261963
Epoch: 2, Steps: 210 | Train Loss: 1.0439419 Vali Loss: 1.0498585 Test Loss: 1.0242765
Validation loss decreased (1.052566 --> 1.049858).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0502015
	speed: 0.0193s/iter; left time: 30.5177s
	iters: 200, epoch: 3 | loss: 1.0013518
	speed: 0.0180s/iter; left time: 26.7155s
Epoch: 3 cost time: 3.7606089115142822
Epoch: 3, Steps: 210 | Train Loss: 1.0381254 Vali Loss: 1.0468493 Test Loss: 1.0224874
Validation loss decreased (1.049858 --> 1.046849).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0488386
	speed: 0.0181s/iter; left time: 24.7765s
	iters: 200, epoch: 4 | loss: 1.0467260
	speed: 0.0145s/iter; left time: 18.4297s
Epoch: 4 cost time: 3.140634298324585
Epoch: 4, Steps: 210 | Train Loss: 1.0349879 Vali Loss: 1.0486789 Test Loss: 1.0210775
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0342722
	speed: 0.0195s/iter; left time: 22.6484s
	iters: 200, epoch: 5 | loss: 1.0394820
	speed: 0.0168s/iter; left time: 17.8364s
Epoch: 5 cost time: 3.6920812129974365
Epoch: 5, Steps: 210 | Train Loss: 1.0332153 Vali Loss: 1.0475348 Test Loss: 1.0210460
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0493915
	speed: 0.0237s/iter; left time: 22.5273s
	iters: 200, epoch: 6 | loss: 1.0382023
	speed: 0.0224s/iter; left time: 19.0710s
Epoch: 6 cost time: 4.858002662658691
Epoch: 6, Steps: 210 | Train Loss: 1.0323087 Vali Loss: 1.0471478 Test Loss: 1.0205088
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0036987
	speed: 0.0198s/iter; left time: 14.6451s
	iters: 200, epoch: 7 | loss: 1.0096985
	speed: 0.0156s/iter; left time: 9.9945s
Epoch: 7 cost time: 3.3560407161712646
Epoch: 7, Steps: 210 | Train Loss: 1.0317306 Vali Loss: 1.0485148 Test Loss: 1.0205549
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0316362
	speed: 0.0152s/iter; left time: 8.0466s
	iters: 200, epoch: 8 | loss: 1.0209254
	speed: 0.0132s/iter; left time: 5.6795s
Epoch: 8 cost time: 2.8494880199432373
Epoch: 8, Steps: 210 | Train Loss: 1.0314751 Vali Loss: 1.0475936 Test Loss: 1.0204688
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0224872827529907, mae:0.8059620261192322
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0756127
	speed: 0.0205s/iter; left time: 41.0176s
	iters: 200, epoch: 1 | loss: 1.0435092
	speed: 0.0189s/iter; left time: 35.9250s
Epoch: 1 cost time: 4.007710933685303
Epoch: 1, Steps: 210 | Train Loss: 1.0827491 Vali Loss: 1.0516862 Test Loss: 1.0249752
Validation loss decreased (inf --> 1.051686).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0409129
	speed: 0.0259s/iter; left time: 46.4018s
	iters: 200, epoch: 2 | loss: 1.0640013
	speed: 0.0209s/iter; left time: 35.4127s
Epoch: 2 cost time: 4.420215129852295
Epoch: 2, Steps: 210 | Train Loss: 1.0438750 Vali Loss: 1.0515854 Test Loss: 1.0241940
Validation loss decreased (1.051686 --> 1.051585).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0326637
	speed: 0.0214s/iter; left time: 33.8787s
	iters: 200, epoch: 3 | loss: 1.0332015
	speed: 0.0170s/iter; left time: 25.1559s
Epoch: 3 cost time: 3.633720636367798
Epoch: 3, Steps: 210 | Train Loss: 1.0379188 Vali Loss: 1.0466568 Test Loss: 1.0228913
Validation loss decreased (1.051585 --> 1.046657).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0188360
	speed: 0.0201s/iter; left time: 27.5382s
	iters: 200, epoch: 4 | loss: 1.0177245
	speed: 0.0170s/iter; left time: 21.6176s
Epoch: 4 cost time: 3.6273891925811768
Epoch: 4, Steps: 210 | Train Loss: 1.0344807 Vali Loss: 1.0485409 Test Loss: 1.0209892
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0405064
	speed: 0.0179s/iter; left time: 20.7617s
	iters: 200, epoch: 5 | loss: 1.0358801
	speed: 0.0147s/iter; left time: 15.5664s
Epoch: 5 cost time: 3.1967883110046387
Epoch: 5, Steps: 210 | Train Loss: 1.0327983 Vali Loss: 1.0471475 Test Loss: 1.0208876
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0335630
	speed: 0.0208s/iter; left time: 19.7413s
	iters: 200, epoch: 6 | loss: 1.0372269
	speed: 0.0163s/iter; left time: 13.8961s
Epoch: 6 cost time: 3.513301134109497
Epoch: 6, Steps: 210 | Train Loss: 1.0319104 Vali Loss: 1.0476081 Test Loss: 1.0204248
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0384237
	speed: 0.0164s/iter; left time: 12.1165s
	iters: 200, epoch: 7 | loss: 1.0123065
	speed: 0.0130s/iter; left time: 8.3416s
Epoch: 7 cost time: 2.7945361137390137
Epoch: 7, Steps: 210 | Train Loss: 1.0313802 Vali Loss: 1.0471752 Test Loss: 1.0204825
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0509224
	speed: 0.0183s/iter; left time: 9.7008s
	iters: 200, epoch: 8 | loss: 1.0323012
	speed: 0.0145s/iter; left time: 6.2440s
Epoch: 8 cost time: 3.06415057182312
Epoch: 8, Steps: 210 | Train Loss: 1.0310898 Vali Loss: 1.0475675 Test Loss: 1.0204599
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0228911638259888, mae:0.8060749173164368
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0344678
	speed: 0.0261s/iter; left time: 51.1417s
	iters: 200, epoch: 1 | loss: 1.0379345
	speed: 0.0184s/iter; left time: 34.2645s
Epoch: 1 cost time: 3.8652424812316895
Epoch: 1, Steps: 206 | Train Loss: 1.0809604 Vali Loss: 1.0594002 Test Loss: 1.0403329
Validation loss decreased (inf --> 1.059400).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0495421
	speed: 0.0142s/iter; left time: 25.0043s
	iters: 200, epoch: 2 | loss: 1.0359490
	speed: 0.0130s/iter; left time: 21.5428s
Epoch: 2 cost time: 2.740924596786499
Epoch: 2, Steps: 206 | Train Loss: 1.0441918 Vali Loss: 1.0609957 Test Loss: 1.0379899
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0324320
	speed: 0.0181s/iter; left time: 28.0814s
	iters: 200, epoch: 3 | loss: 1.0330551
	speed: 0.0149s/iter; left time: 21.5288s
Epoch: 3 cost time: 3.178234815597534
Epoch: 3, Steps: 206 | Train Loss: 1.0396599 Vali Loss: 1.0586476 Test Loss: 1.0362576
Validation loss decreased (1.059400 --> 1.058648).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0482436
	speed: 0.0220s/iter; left time: 29.5819s
	iters: 200, epoch: 4 | loss: 1.0313275
	speed: 0.0181s/iter; left time: 22.5188s
Epoch: 4 cost time: 3.8001677989959717
Epoch: 4, Steps: 206 | Train Loss: 1.0371058 Vali Loss: 1.0563055 Test Loss: 1.0358955
Validation loss decreased (1.058648 --> 1.056306).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0450450
	speed: 0.0208s/iter; left time: 23.6551s
	iters: 200, epoch: 5 | loss: 1.0466350
	speed: 0.0179s/iter; left time: 18.6074s
Epoch: 5 cost time: 3.804839849472046
Epoch: 5, Steps: 206 | Train Loss: 1.0358877 Vali Loss: 1.0565844 Test Loss: 1.0353084
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0241631
	speed: 0.0125s/iter; left time: 11.6634s
	iters: 200, epoch: 6 | loss: 1.0532525
	speed: 0.0112s/iter; left time: 9.3223s
Epoch: 6 cost time: 2.385169744491577
Epoch: 6, Steps: 206 | Train Loss: 1.0347250 Vali Loss: 1.0559351 Test Loss: 1.0352224
Validation loss decreased (1.056306 --> 1.055935).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0426047
	speed: 0.0149s/iter; left time: 10.7869s
	iters: 200, epoch: 7 | loss: 1.0419101
	speed: 0.0140s/iter; left time: 8.7372s
Epoch: 7 cost time: 3.0130438804626465
Epoch: 7, Steps: 206 | Train Loss: 1.0343389 Vali Loss: 1.0560215 Test Loss: 1.0350157
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0374850
	speed: 0.0156s/iter; left time: 8.0949s
	iters: 200, epoch: 8 | loss: 1.0313970
	speed: 0.0140s/iter; left time: 5.8683s
Epoch: 8 cost time: 2.947511672973633
Epoch: 8, Steps: 206 | Train Loss: 1.0344212 Vali Loss: 1.0557268 Test Loss: 1.0350786
Validation loss decreased (1.055935 --> 1.055727).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0606815
	speed: 0.0222s/iter; left time: 6.9502s
	iters: 200, epoch: 9 | loss: 1.0056901
	speed: 0.0175s/iter; left time: 3.7226s
Epoch: 9 cost time: 3.6345174312591553
Epoch: 9, Steps: 206 | Train Loss: 1.0343098 Vali Loss: 1.0556660 Test Loss: 1.0350530
Validation loss decreased (1.055727 --> 1.055666).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0087523
	speed: 0.0156s/iter; left time: 1.6686s
	iters: 200, epoch: 10 | loss: 1.0266197
	speed: 0.0145s/iter; left time: 0.1017s
Epoch: 10 cost time: 3.0438191890716553
Epoch: 10, Steps: 206 | Train Loss: 1.0341326 Vali Loss: 1.0556810 Test Loss: 1.0350394
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0350531339645386, mae:0.8091132044792175
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0628152
	speed: 0.0143s/iter; left time: 28.0240s
	iters: 200, epoch: 1 | loss: 1.0501595
	speed: 0.0129s/iter; left time: 24.0954s
Epoch: 1 cost time: 2.7752768993377686
Epoch: 1, Steps: 206 | Train Loss: 1.0793203 Vali Loss: 1.0612618 Test Loss: 1.0382266
Validation loss decreased (inf --> 1.061262).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0568258
	speed: 0.0168s/iter; left time: 29.4666s
	iters: 200, epoch: 2 | loss: 1.0447648
	speed: 0.0157s/iter; left time: 26.0381s
Epoch: 2 cost time: 3.364640951156616
Epoch: 2, Steps: 206 | Train Loss: 1.0442315 Vali Loss: 1.0600001 Test Loss: 1.0379725
Validation loss decreased (1.061262 --> 1.060000).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0464041
	speed: 0.0210s/iter; left time: 32.5852s
	iters: 200, epoch: 3 | loss: 1.0545361
	speed: 0.0179s/iter; left time: 26.0038s
Epoch: 3 cost time: 3.742319345474243
Epoch: 3, Steps: 206 | Train Loss: 1.0398774 Vali Loss: 1.0577322 Test Loss: 1.0361208
Validation loss decreased (1.060000 --> 1.057732).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0390561
	speed: 0.0178s/iter; left time: 23.8416s
	iters: 200, epoch: 4 | loss: 1.0225142
	speed: 0.0159s/iter; left time: 19.7220s
Epoch: 4 cost time: 3.317307233810425
Epoch: 4, Steps: 206 | Train Loss: 1.0373512 Vali Loss: 1.0563372 Test Loss: 1.0359854
Validation loss decreased (1.057732 --> 1.056337).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0285374
	speed: 0.0134s/iter; left time: 15.2503s
	iters: 200, epoch: 5 | loss: 1.0330027
	speed: 0.0119s/iter; left time: 12.3281s
Epoch: 5 cost time: 2.524380683898926
Epoch: 5, Steps: 206 | Train Loss: 1.0359302 Vali Loss: 1.0562019 Test Loss: 1.0352352
Validation loss decreased (1.056337 --> 1.056202).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0391690
	speed: 0.0168s/iter; left time: 15.6857s
	iters: 200, epoch: 6 | loss: 1.0302665
	speed: 0.0151s/iter; left time: 12.5199s
Epoch: 6 cost time: 3.206705331802368
Epoch: 6, Steps: 206 | Train Loss: 1.0351780 Vali Loss: 1.0562429 Test Loss: 1.0348382
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0392865
	speed: 0.0178s/iter; left time: 12.9187s
	iters: 200, epoch: 7 | loss: 1.0362064
	speed: 0.0159s/iter; left time: 9.9533s
Epoch: 7 cost time: 3.3471994400024414
Epoch: 7, Steps: 206 | Train Loss: 1.0345610 Vali Loss: 1.0560071 Test Loss: 1.0348953
Validation loss decreased (1.056202 --> 1.056007).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0346187
	speed: 0.0229s/iter; left time: 11.8598s
	iters: 200, epoch: 8 | loss: 1.0355387
	speed: 0.0182s/iter; left time: 7.6140s
Epoch: 8 cost time: 3.8300795555114746
Epoch: 8, Steps: 206 | Train Loss: 1.0345963 Vali Loss: 1.0557128 Test Loss: 1.0349602
Validation loss decreased (1.056007 --> 1.055713).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0367030
	speed: 0.0209s/iter; left time: 6.5272s
	iters: 200, epoch: 9 | loss: 1.0483689
	speed: 0.0191s/iter; left time: 4.0788s
Epoch: 9 cost time: 3.935681104660034
Epoch: 9, Steps: 206 | Train Loss: 1.0339093 Vali Loss: 1.0557039 Test Loss: 1.0349706
Validation loss decreased (1.055713 --> 1.055704).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0184226
	speed: 0.0156s/iter; left time: 1.6668s
	iters: 200, epoch: 10 | loss: 1.0345498
	speed: 0.0140s/iter; left time: 0.0977s
Epoch: 10 cost time: 2.9198198318481445
Epoch: 10, Steps: 206 | Train Loss: 1.0343758 Vali Loss: 1.0555307 Test Loss: 1.0349530
Validation loss decreased (1.055704 --> 1.055531).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.034952998161316, mae:0.8090417385101318
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0655032
	speed: 0.0251s/iter; left time: 49.2812s
	iters: 200, epoch: 1 | loss: 1.0273131
	speed: 0.0191s/iter; left time: 35.5715s
Epoch: 1 cost time: 3.9560418128967285
Epoch: 1, Steps: 206 | Train Loss: 1.0818429 Vali Loss: 1.0609850 Test Loss: 1.0382239
Validation loss decreased (inf --> 1.060985).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0360243
	speed: 0.0306s/iter; left time: 53.7104s
	iters: 200, epoch: 2 | loss: 1.0295663
	speed: 0.0218s/iter; left time: 36.0750s
Epoch: 2 cost time: 4.5315446853637695
Epoch: 2, Steps: 206 | Train Loss: 1.0443310 Vali Loss: 1.0594794 Test Loss: 1.0386667
Validation loss decreased (1.060985 --> 1.059479).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0406229
	speed: 0.0287s/iter; left time: 44.4986s
	iters: 200, epoch: 3 | loss: 1.0582682
	speed: 0.0192s/iter; left time: 27.7550s
Epoch: 3 cost time: 3.9898765087127686
Epoch: 3, Steps: 206 | Train Loss: 1.0393101 Vali Loss: 1.0581181 Test Loss: 1.0361681
Validation loss decreased (1.059479 --> 1.058118).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0391895
	speed: 0.0206s/iter; left time: 27.6481s
	iters: 200, epoch: 4 | loss: 1.0486383
	speed: 0.0164s/iter; left time: 20.4023s
Epoch: 4 cost time: 3.457956552505493
Epoch: 4, Steps: 206 | Train Loss: 1.0370355 Vali Loss: 1.0561007 Test Loss: 1.0366555
Validation loss decreased (1.058118 --> 1.056101).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0453326
	speed: 0.0209s/iter; left time: 23.7724s
	iters: 200, epoch: 5 | loss: 1.0388538
	speed: 0.0191s/iter; left time: 19.8573s
Epoch: 5 cost time: 4.037295579910278
Epoch: 5, Steps: 206 | Train Loss: 1.0357088 Vali Loss: 1.0556409 Test Loss: 1.0355326
Validation loss decreased (1.056101 --> 1.055641).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0378937
	speed: 0.0151s/iter; left time: 14.0314s
	iters: 200, epoch: 6 | loss: 1.0566878
	speed: 0.0150s/iter; left time: 12.4770s
Epoch: 6 cost time: 3.2241833209991455
Epoch: 6, Steps: 206 | Train Loss: 1.0347164 Vali Loss: 1.0556836 Test Loss: 1.0351714
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0278033
	speed: 0.0147s/iter; left time: 10.6502s
	iters: 200, epoch: 7 | loss: 1.0272642
	speed: 0.0140s/iter; left time: 8.7729s
Epoch: 7 cost time: 3.010852575302124
Epoch: 7, Steps: 206 | Train Loss: 1.0344075 Vali Loss: 1.0559174 Test Loss: 1.0349994
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0337098
	speed: 0.0118s/iter; left time: 6.1020s
	iters: 200, epoch: 8 | loss: 1.0373633
	speed: 0.0098s/iter; left time: 4.0905s
Epoch: 8 cost time: 2.0629074573516846
Epoch: 8, Steps: 206 | Train Loss: 1.0340544 Vali Loss: 1.0557256 Test Loss: 1.0349661
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0305572
	speed: 0.0157s/iter; left time: 4.9268s
	iters: 200, epoch: 9 | loss: 1.0355029
	speed: 0.0134s/iter; left time: 2.8606s
Epoch: 9 cost time: 2.841539144515991
Epoch: 9, Steps: 206 | Train Loss: 1.0340515 Vali Loss: 1.0556707 Test Loss: 1.0349755
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0338529
	speed: 0.0175s/iter; left time: 1.8774s
	iters: 200, epoch: 10 | loss: 1.0406505
	speed: 0.0179s/iter; left time: 0.1251s
Epoch: 10 cost time: 3.8443045616149902
Epoch: 10, Steps: 206 | Train Loss: 1.0341582 Vali Loss: 1.0556856 Test Loss: 1.0349642
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0355324745178223, mae:0.8092547655105591
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0508691
	speed: 0.0324s/iter; left time: 59.6660s
Epoch: 1 cost time: 4.873085021972656
Epoch: 1, Steps: 194 | Train Loss: 1.0836946 Vali Loss: 1.0581889 Test Loss: 1.0319269
Validation loss decreased (inf --> 1.058189).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0397964
	speed: 0.0191s/iter; left time: 31.5244s
Epoch: 2 cost time: 3.1155874729156494
Epoch: 2, Steps: 194 | Train Loss: 1.0467711 Vali Loss: 1.0592664 Test Loss: 1.0312552
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0496167
	speed: 0.0241s/iter; left time: 35.0301s
Epoch: 3 cost time: 3.750769853591919
Epoch: 3, Steps: 194 | Train Loss: 1.0424577 Vali Loss: 1.0567580 Test Loss: 1.0300800
Validation loss decreased (1.058189 --> 1.056758).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0423546
	speed: 0.0213s/iter; left time: 26.8179s
Epoch: 4 cost time: 3.437532663345337
Epoch: 4, Steps: 194 | Train Loss: 1.0404807 Vali Loss: 1.0559698 Test Loss: 1.0287434
Validation loss decreased (1.056758 --> 1.055970).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0292790
	speed: 0.0154s/iter; left time: 16.3961s
Epoch: 5 cost time: 2.7759602069854736
Epoch: 5, Steps: 194 | Train Loss: 1.0393510 Vali Loss: 1.0560148 Test Loss: 1.0282985
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0367030
	speed: 0.0159s/iter; left time: 13.8711s
Epoch: 6 cost time: 2.987905502319336
Epoch: 6, Steps: 194 | Train Loss: 1.0388930 Vali Loss: 1.0548947 Test Loss: 1.0280972
Validation loss decreased (1.055970 --> 1.054895).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0490245
	speed: 0.0142s/iter; left time: 9.6329s
Epoch: 7 cost time: 2.4148480892181396
Epoch: 7, Steps: 194 | Train Loss: 1.0386353 Vali Loss: 1.0549392 Test Loss: 1.0281241
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0394043
	speed: 0.0226s/iter; left time: 10.8944s
Epoch: 8 cost time: 3.6634984016418457
Epoch: 8, Steps: 194 | Train Loss: 1.0384916 Vali Loss: 1.0546581 Test Loss: 1.0280094
Validation loss decreased (1.054895 --> 1.054658).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0367879
	speed: 0.0180s/iter; left time: 5.2080s
Epoch: 9 cost time: 3.3142330646514893
Epoch: 9, Steps: 194 | Train Loss: 1.0382836 Vali Loss: 1.0547189 Test Loss: 1.0279646
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0279485
	speed: 0.0178s/iter; left time: 1.6909s
Epoch: 10 cost time: 3.044386148452759
Epoch: 10, Steps: 194 | Train Loss: 1.0382748 Vali Loss: 1.0552394 Test Loss: 1.0279601
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.028009295463562, mae:0.80470210313797
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0516181
	speed: 0.0149s/iter; left time: 27.3772s
Epoch: 1 cost time: 3.113727331161499
Epoch: 1, Steps: 194 | Train Loss: 1.0833756 Vali Loss: 1.0585185 Test Loss: 1.0326116
Validation loss decreased (inf --> 1.058519).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0474221
	speed: 0.0175s/iter; left time: 28.7912s
Epoch: 2 cost time: 4.171493291854858
Epoch: 2, Steps: 194 | Train Loss: 1.0464350 Vali Loss: 1.0585607 Test Loss: 1.0312693
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0398078
	speed: 0.0161s/iter; left time: 23.3461s
Epoch: 3 cost time: 3.801854133605957
Epoch: 3, Steps: 194 | Train Loss: 1.0423269 Vali Loss: 1.0553354 Test Loss: 1.0301974
Validation loss decreased (1.058519 --> 1.055335).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0355629
	speed: 0.0235s/iter; left time: 29.5678s
Epoch: 4 cost time: 3.509376049041748
Epoch: 4, Steps: 194 | Train Loss: 1.0402728 Vali Loss: 1.0554188 Test Loss: 1.0289742
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0412974
	speed: 0.0158s/iter; left time: 16.8755s
Epoch: 5 cost time: 2.7180049419403076
Epoch: 5, Steps: 194 | Train Loss: 1.0393096 Vali Loss: 1.0556327 Test Loss: 1.0280595
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0407284
	speed: 0.0223s/iter; left time: 19.4004s
Epoch: 6 cost time: 3.4605023860931396
Epoch: 6, Steps: 194 | Train Loss: 1.0388796 Vali Loss: 1.0548254 Test Loss: 1.0281661
Validation loss decreased (1.055335 --> 1.054825).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0379092
	speed: 0.0220s/iter; left time: 14.8914s
Epoch: 7 cost time: 3.6520612239837646
Epoch: 7, Steps: 194 | Train Loss: 1.0386306 Vali Loss: 1.0549846 Test Loss: 1.0280010
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0400208
	speed: 0.0179s/iter; left time: 8.6591s
Epoch: 8 cost time: 3.0743465423583984
Epoch: 8, Steps: 194 | Train Loss: 1.0383967 Vali Loss: 1.0550905 Test Loss: 1.0279580
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0254691
	speed: 0.0230s/iter; left time: 6.6406s
Epoch: 9 cost time: 3.561450481414795
Epoch: 9, Steps: 194 | Train Loss: 1.0382924 Vali Loss: 1.0551386 Test Loss: 1.0279461
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0384400
	speed: 0.0194s/iter; left time: 1.8459s
Epoch: 10 cost time: 2.8831660747528076
Epoch: 10, Steps: 194 | Train Loss: 1.0383956 Vali Loss: 1.0544832 Test Loss: 1.0279468
Validation loss decreased (1.054825 --> 1.054483).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0279467105865479, mae:0.8046627044677734
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0535132
	speed: 0.0129s/iter; left time: 23.8246s
Epoch: 1 cost time: 2.451934337615967
Epoch: 1, Steps: 194 | Train Loss: 1.0864888 Vali Loss: 1.0583786 Test Loss: 1.0328671
Validation loss decreased (inf --> 1.058379).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0375930
	speed: 0.0184s/iter; left time: 30.3348s
Epoch: 2 cost time: 3.206571102142334
Epoch: 2, Steps: 194 | Train Loss: 1.0463515 Vali Loss: 1.0596603 Test Loss: 1.0312366
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0313215
	speed: 0.0164s/iter; left time: 23.8190s
Epoch: 3 cost time: 3.0430989265441895
Epoch: 3, Steps: 194 | Train Loss: 1.0421329 Vali Loss: 1.0549302 Test Loss: 1.0304505
Validation loss decreased (1.058379 --> 1.054930).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0393101
	speed: 0.0223s/iter; left time: 28.0995s
Epoch: 4 cost time: 3.5697174072265625
Epoch: 4, Steps: 194 | Train Loss: 1.0400944 Vali Loss: 1.0559220 Test Loss: 1.0285696
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0256519
	speed: 0.0194s/iter; left time: 20.6618s
Epoch: 5 cost time: 2.989863634109497
Epoch: 5, Steps: 194 | Train Loss: 1.0392355 Vali Loss: 1.0546587 Test Loss: 1.0286130
Validation loss decreased (1.054930 --> 1.054659).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0421357
	speed: 0.0177s/iter; left time: 15.4360s
Epoch: 6 cost time: 3.119241714477539
Epoch: 6, Steps: 194 | Train Loss: 1.0387931 Vali Loss: 1.0544289 Test Loss: 1.0282419
Validation loss decreased (1.054659 --> 1.054429).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0357848
	speed: 0.0177s/iter; left time: 11.9755s
Epoch: 7 cost time: 3.2851979732513428
Epoch: 7, Steps: 194 | Train Loss: 1.0384837 Vali Loss: 1.0549264 Test Loss: 1.0280310
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0461709
	speed: 0.0143s/iter; left time: 6.9089s
Epoch: 8 cost time: 2.637836456298828
Epoch: 8, Steps: 194 | Train Loss: 1.0383498 Vali Loss: 1.0548234 Test Loss: 1.0279868
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0409911
	speed: 0.0172s/iter; left time: 4.9706s
Epoch: 9 cost time: 2.8141024112701416
Epoch: 9, Steps: 194 | Train Loss: 1.0382798 Vali Loss: 1.0548545 Test Loss: 1.0279726
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0200011
	speed: 0.0182s/iter; left time: 1.7301s
Epoch: 10 cost time: 2.6801326274871826
Epoch: 10, Steps: 194 | Train Loss: 1.0381442 Vali Loss: 1.0547340 Test Loss: 1.0279702
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0282419919967651, mae:0.804828405380249
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6987423
	speed: 0.0266s/iter; left time: 53.9321s
	iters: 200, epoch: 1 | loss: 0.6905122
	speed: 0.0208s/iter; left time: 40.1140s
Epoch: 1 cost time: 4.4111008644104
Epoch: 1, Steps: 213 | Train Loss: 0.7328692 Vali Loss: 0.6482778 Test Loss: 0.6482286
Validation loss decreased (inf --> 0.648278).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7167999
	speed: 0.0154s/iter; left time: 27.9351s
	iters: 200, epoch: 2 | loss: 0.7251900
	speed: 0.0146s/iter; left time: 25.1175s
Epoch: 2 cost time: 3.216327428817749
Epoch: 2, Steps: 213 | Train Loss: 0.6932888 Vali Loss: 0.6967858 Test Loss: 0.6574500
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7107438
	speed: 0.0132s/iter; left time: 21.2037s
	iters: 200, epoch: 3 | loss: 0.6589311
	speed: 0.0156s/iter; left time: 23.5258s
Epoch: 3 cost time: 3.4798569679260254
Epoch: 3, Steps: 213 | Train Loss: 0.6758662 Vali Loss: 0.7038975 Test Loss: 0.6587723
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6858493
	speed: 0.0189s/iter; left time: 26.3532s
	iters: 200, epoch: 4 | loss: 0.6351312
	speed: 0.0169s/iter; left time: 21.8263s
Epoch: 4 cost time: 3.6249518394470215
Epoch: 4, Steps: 213 | Train Loss: 0.6653525 Vali Loss: 0.7182293 Test Loss: 0.6646926
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6086103
	speed: 0.0163s/iter; left time: 19.2086s
	iters: 200, epoch: 5 | loss: 0.6581122
	speed: 0.0152s/iter; left time: 16.3614s
Epoch: 5 cost time: 3.3169972896575928
Epoch: 5, Steps: 213 | Train Loss: 0.6588387 Vali Loss: 0.7418656 Test Loss: 0.6688011
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6563748
	speed: 0.0146s/iter; left time: 14.0995s
	iters: 200, epoch: 6 | loss: 0.6379964
	speed: 0.0166s/iter; left time: 14.3356s
Epoch: 6 cost time: 3.6967036724090576
Epoch: 6, Steps: 213 | Train Loss: 0.6557179 Vali Loss: 0.7440076 Test Loss: 0.6690127
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.648228645324707, mae:0.647162914276123
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6707723
	speed: 0.0253s/iter; left time: 51.4633s
	iters: 200, epoch: 1 | loss: 0.7045309
	speed: 0.0199s/iter; left time: 38.3861s
Epoch: 1 cost time: 4.2996861934661865
Epoch: 1, Steps: 213 | Train Loss: 0.7327210 Vali Loss: 0.6611901 Test Loss: 0.6462849
Validation loss decreased (inf --> 0.661190).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6704353
	speed: 0.0166s/iter; left time: 30.0911s
	iters: 200, epoch: 2 | loss: 0.6984686
	speed: 0.0165s/iter; left time: 28.3020s
Epoch: 2 cost time: 3.6360244750976562
Epoch: 2, Steps: 213 | Train Loss: 0.6949998 Vali Loss: 0.6803473 Test Loss: 0.6561000
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6629909
	speed: 0.0178s/iter; left time: 28.4944s
	iters: 200, epoch: 3 | loss: 0.6811554
	speed: 0.0150s/iter; left time: 22.5835s
Epoch: 3 cost time: 3.253434658050537
Epoch: 3, Steps: 213 | Train Loss: 0.6785141 Vali Loss: 0.7647591 Test Loss: 0.6776958
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6625719
	speed: 0.0140s/iter; left time: 19.4631s
	iters: 200, epoch: 4 | loss: 0.6675493
	speed: 0.0127s/iter; left time: 16.3930s
Epoch: 4 cost time: 2.8529179096221924
Epoch: 4, Steps: 213 | Train Loss: 0.6689839 Vali Loss: 0.7468858 Test Loss: 0.6725484
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6603789
	speed: 0.0165s/iter; left time: 19.4963s
	iters: 200, epoch: 5 | loss: 0.6800994
	speed: 0.0176s/iter; left time: 18.9525s
Epoch: 5 cost time: 3.8148434162139893
Epoch: 5, Steps: 213 | Train Loss: 0.6623596 Vali Loss: 0.7172315 Test Loss: 0.6632059
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6277409
	speed: 0.0173s/iter; left time: 16.7424s
	iters: 200, epoch: 6 | loss: 0.6304154
	speed: 0.0192s/iter; left time: 16.5944s
Epoch: 6 cost time: 4.34895396232605
Epoch: 6, Steps: 213 | Train Loss: 0.6586469 Vali Loss: 0.7389077 Test Loss: 0.6670749
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6462846994400024, mae:0.6449265480041504
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7268302
	speed: 0.0179s/iter; left time: 36.4127s
	iters: 200, epoch: 1 | loss: 0.6662204
	speed: 0.0149s/iter; left time: 28.8512s
Epoch: 1 cost time: 3.2131338119506836
Epoch: 1, Steps: 213 | Train Loss: 0.7334556 Vali Loss: 0.6840879 Test Loss: 0.6513681
Validation loss decreased (inf --> 0.684088).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7011834
	speed: 0.0218s/iter; left time: 39.6519s
	iters: 200, epoch: 2 | loss: 0.7082495
	speed: 0.0187s/iter; left time: 32.1917s
Epoch: 2 cost time: 3.9710066318511963
Epoch: 2, Steps: 213 | Train Loss: 0.6960153 Vali Loss: 0.6909694 Test Loss: 0.6572692
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6751868
	speed: 0.0162s/iter; left time: 25.9484s
	iters: 200, epoch: 3 | loss: 0.6649613
	speed: 0.0171s/iter; left time: 25.7177s
Epoch: 3 cost time: 3.656134843826294
Epoch: 3, Steps: 213 | Train Loss: 0.6783282 Vali Loss: 0.7043461 Test Loss: 0.6586598
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6413827
	speed: 0.0143s/iter; left time: 19.8657s
	iters: 200, epoch: 4 | loss: 0.6337962
	speed: 0.0130s/iter; left time: 16.7374s
Epoch: 4 cost time: 2.809943437576294
Epoch: 4, Steps: 213 | Train Loss: 0.6678728 Vali Loss: 0.7290152 Test Loss: 0.6695200
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6471345
	speed: 0.0312s/iter; left time: 36.7407s
	iters: 200, epoch: 5 | loss: 0.6467738
	speed: 0.0208s/iter; left time: 22.4846s
Epoch: 5 cost time: 4.314064979553223
Epoch: 5, Steps: 213 | Train Loss: 0.6615469 Vali Loss: 0.7581885 Test Loss: 0.6757962
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6732807
	speed: 0.0143s/iter; left time: 13.8405s
	iters: 200, epoch: 6 | loss: 0.6475629
	speed: 0.0121s/iter; left time: 10.5096s
Epoch: 6 cost time: 2.727667808532715
Epoch: 6, Steps: 213 | Train Loss: 0.6578357 Vali Loss: 0.7391648 Test Loss: 0.6698017
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6513681411743164, mae:0.6469910144805908
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7460575
	speed: 0.0338s/iter; left time: 67.6689s
	iters: 200, epoch: 1 | loss: 0.7788461
	speed: 0.0231s/iter; left time: 43.9804s
Epoch: 1 cost time: 4.851374864578247
Epoch: 1, Steps: 210 | Train Loss: 0.8355298 Vali Loss: 0.8803756 Test Loss: 0.7383935
Validation loss decreased (inf --> 0.880376).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7963569
	speed: 0.0164s/iter; left time: 29.4440s
	iters: 200, epoch: 2 | loss: 0.8399569
	speed: 0.0136s/iter; left time: 22.9703s
Epoch: 2 cost time: 2.8904151916503906
Epoch: 2, Steps: 210 | Train Loss: 0.7900326 Vali Loss: 0.9451507 Test Loss: 0.7522597
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7473598
	speed: 0.0159s/iter; left time: 25.1676s
	iters: 200, epoch: 3 | loss: 0.7359478
	speed: 0.0143s/iter; left time: 21.1689s
Epoch: 3 cost time: 3.006894588470459
Epoch: 3, Steps: 210 | Train Loss: 0.7671010 Vali Loss: 0.9494091 Test Loss: 0.7639945
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7225561
	speed: 0.0165s/iter; left time: 22.6229s
	iters: 200, epoch: 4 | loss: 0.7818655
	speed: 0.0134s/iter; left time: 16.9858s
Epoch: 4 cost time: 2.8419902324676514
Epoch: 4, Steps: 210 | Train Loss: 0.7508805 Vali Loss: 0.9765112 Test Loss: 0.7869459
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7688200
	speed: 0.0146s/iter; left time: 16.9641s
	iters: 200, epoch: 5 | loss: 0.7377483
	speed: 0.0120s/iter; left time: 12.7569s
Epoch: 5 cost time: 2.672147750854492
Epoch: 5, Steps: 210 | Train Loss: 0.7430912 Vali Loss: 1.0035975 Test Loss: 0.8007019
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7019390
	speed: 0.0151s/iter; left time: 14.3825s
	iters: 200, epoch: 6 | loss: 0.7707338
	speed: 0.0137s/iter; left time: 11.6463s
Epoch: 6 cost time: 2.9367871284484863
Epoch: 6, Steps: 210 | Train Loss: 0.7393542 Vali Loss: 0.9880939 Test Loss: 0.7954783
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7383935451507568, mae:0.6868414282798767
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8228037
	speed: 0.0203s/iter; left time: 40.6555s
	iters: 200, epoch: 1 | loss: 0.7927088
	speed: 0.0187s/iter; left time: 35.4735s
Epoch: 1 cost time: 4.0751941204071045
Epoch: 1, Steps: 210 | Train Loss: 0.8357568 Vali Loss: 0.9751742 Test Loss: 0.7811176
Validation loss decreased (inf --> 0.975174).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7691006
	speed: 0.0146s/iter; left time: 26.0748s
	iters: 200, epoch: 2 | loss: 0.7908545
	speed: 0.0167s/iter; left time: 28.2601s
Epoch: 2 cost time: 3.614922523498535
Epoch: 2, Steps: 210 | Train Loss: 0.7930438 Vali Loss: 0.9689881 Test Loss: 0.7691381
Validation loss decreased (0.975174 --> 0.968988).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7778693
	speed: 0.0131s/iter; left time: 20.7661s
	iters: 200, epoch: 3 | loss: 0.7430922
	speed: 0.0140s/iter; left time: 20.7127s
Epoch: 3 cost time: 3.026512622833252
Epoch: 3, Steps: 210 | Train Loss: 0.7728035 Vali Loss: 0.9841496 Test Loss: 0.7838832
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7748771
	speed: 0.0247s/iter; left time: 33.7952s
	iters: 200, epoch: 4 | loss: 0.7253167
	speed: 0.0218s/iter; left time: 27.6547s
Epoch: 4 cost time: 4.596710443496704
Epoch: 4, Steps: 210 | Train Loss: 0.7593547 Vali Loss: 0.9614679 Test Loss: 0.8048395
Validation loss decreased (0.968988 --> 0.961468).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7531995
	speed: 0.0195s/iter; left time: 22.6570s
	iters: 200, epoch: 5 | loss: 0.8171446
	speed: 0.0182s/iter; left time: 19.3031s
Epoch: 5 cost time: 3.866446018218994
Epoch: 5, Steps: 210 | Train Loss: 0.7492625 Vali Loss: 0.9642115 Test Loss: 0.7994871
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7637135
	speed: 0.0198s/iter; left time: 18.8606s
	iters: 200, epoch: 6 | loss: 0.7447833
	speed: 0.0156s/iter; left time: 13.3075s
Epoch: 6 cost time: 3.3000600337982178
Epoch: 6, Steps: 210 | Train Loss: 0.7431613 Vali Loss: 0.9660524 Test Loss: 0.8057551
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6752213
	speed: 0.0185s/iter; left time: 13.7025s
	iters: 200, epoch: 7 | loss: 0.7468609
	speed: 0.0143s/iter; left time: 9.1820s
Epoch: 7 cost time: 3.0620479583740234
Epoch: 7, Steps: 210 | Train Loss: 0.7419099 Vali Loss: 0.9585279 Test Loss: 0.8074073
Validation loss decreased (0.961468 --> 0.958528).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8543177
	speed: 0.0199s/iter; left time: 10.5514s
	iters: 200, epoch: 8 | loss: 0.6977080
	speed: 0.0169s/iter; left time: 7.2866s
Epoch: 8 cost time: 3.6288604736328125
Epoch: 8, Steps: 210 | Train Loss: 0.7404520 Vali Loss: 0.9627667 Test Loss: 0.8081264
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6835880
	speed: 0.0152s/iter; left time: 4.8643s
	iters: 200, epoch: 9 | loss: 0.7568638
	speed: 0.0151s/iter; left time: 3.3314s
Epoch: 9 cost time: 3.3258330821990967
Epoch: 9, Steps: 210 | Train Loss: 0.7398804 Vali Loss: 0.9617243 Test Loss: 0.8062617
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7413175
	speed: 0.0143s/iter; left time: 1.5893s
	iters: 200, epoch: 10 | loss: 0.7300406
	speed: 0.0127s/iter; left time: 0.1396s
Epoch: 10 cost time: 2.766941547393799
Epoch: 10, Steps: 210 | Train Loss: 0.7399758 Vali Loss: 0.9659755 Test Loss: 0.8073327
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8074072599411011, mae:0.7155954241752625
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7862715
	speed: 0.0150s/iter; left time: 29.9766s
	iters: 200, epoch: 1 | loss: 0.7844151
	speed: 0.0174s/iter; left time: 32.9833s
Epoch: 1 cost time: 3.6142208576202393
Epoch: 1, Steps: 210 | Train Loss: 0.8364266 Vali Loss: 0.8948462 Test Loss: 0.7417560
Validation loss decreased (inf --> 0.894846).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7417052
	speed: 0.0207s/iter; left time: 37.0093s
	iters: 200, epoch: 2 | loss: 0.8124999
	speed: 0.0172s/iter; left time: 29.0290s
Epoch: 2 cost time: 3.6320641040802
Epoch: 2, Steps: 210 | Train Loss: 0.7916521 Vali Loss: 0.9609868 Test Loss: 0.7600734
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7798924
	speed: 0.0171s/iter; left time: 27.0124s
	iters: 200, epoch: 3 | loss: 0.8244276
	speed: 0.0164s/iter; left time: 24.2547s
Epoch: 3 cost time: 3.5276806354522705
Epoch: 3, Steps: 210 | Train Loss: 0.7712529 Vali Loss: 0.9856315 Test Loss: 0.7893090
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7425272
	speed: 0.0172s/iter; left time: 23.5562s
	iters: 200, epoch: 4 | loss: 0.7566416
	speed: 0.0146s/iter; left time: 18.5806s
Epoch: 4 cost time: 3.161749839782715
Epoch: 4, Steps: 210 | Train Loss: 0.7556822 Vali Loss: 0.9911216 Test Loss: 0.7969164
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7219898
	speed: 0.0162s/iter; left time: 18.7930s
	iters: 200, epoch: 5 | loss: 0.7388217
	speed: 0.0152s/iter; left time: 16.0962s
Epoch: 5 cost time: 3.2743923664093018
Epoch: 5, Steps: 210 | Train Loss: 0.7455790 Vali Loss: 0.9790001 Test Loss: 0.8116911
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7776822
	speed: 0.0195s/iter; left time: 18.5467s
	iters: 200, epoch: 6 | loss: 0.7200963
	speed: 0.0175s/iter; left time: 14.8525s
Epoch: 6 cost time: 3.838818311691284
Epoch: 6, Steps: 210 | Train Loss: 0.7416485 Vali Loss: 0.9759783 Test Loss: 0.8101089
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.741756021976471, mae:0.6878490447998047
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9076323
	speed: 0.0340s/iter; left time: 66.6497s
	iters: 200, epoch: 1 | loss: 0.9180606
	speed: 0.0238s/iter; left time: 44.3065s
Epoch: 1 cost time: 4.926713943481445
Epoch: 1, Steps: 206 | Train Loss: 0.9538660 Vali Loss: 1.1100574 Test Loss: 0.8369655
Validation loss decreased (inf --> 1.110057).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8846135
	speed: 0.0167s/iter; left time: 29.3958s
	iters: 200, epoch: 2 | loss: 0.8738949
	speed: 0.0144s/iter; left time: 23.8217s
Epoch: 2 cost time: 3.3697609901428223
Epoch: 2, Steps: 206 | Train Loss: 0.9002642 Vali Loss: 1.0900615 Test Loss: 0.8373953
Validation loss decreased (1.110057 --> 1.090062).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9083690
	speed: 0.0144s/iter; left time: 22.2583s
	iters: 200, epoch: 3 | loss: 0.8700173
	speed: 0.0142s/iter; left time: 20.5726s
Epoch: 3 cost time: 3.0020387172698975
Epoch: 3, Steps: 206 | Train Loss: 0.8725748 Vali Loss: 1.0572642 Test Loss: 0.8398825
Validation loss decreased (1.090062 --> 1.057264).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8257679
	speed: 0.0172s/iter; left time: 23.0957s
	iters: 200, epoch: 4 | loss: 0.9156130
	speed: 0.0142s/iter; left time: 17.6580s
Epoch: 4 cost time: 2.9813597202301025
Epoch: 4, Steps: 206 | Train Loss: 0.8521799 Vali Loss: 1.0759764 Test Loss: 0.8512233
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8781042
	speed: 0.0243s/iter; left time: 27.6291s
	iters: 200, epoch: 5 | loss: 0.8080725
	speed: 0.0190s/iter; left time: 19.7149s
Epoch: 5 cost time: 3.981959819793701
Epoch: 5, Steps: 206 | Train Loss: 0.8416643 Vali Loss: 1.1134270 Test Loss: 0.8691731
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8499218
	speed: 0.0270s/iter; left time: 25.1144s
	iters: 200, epoch: 6 | loss: 0.8146858
	speed: 0.0209s/iter; left time: 17.3381s
Epoch: 6 cost time: 4.426735162734985
Epoch: 6, Steps: 206 | Train Loss: 0.8360647 Vali Loss: 1.1073303 Test Loss: 0.8706840
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8174158
	speed: 0.0171s/iter; left time: 12.3927s
	iters: 200, epoch: 7 | loss: 0.8616228
	speed: 0.0152s/iter; left time: 9.5264s
Epoch: 7 cost time: 3.2536935806274414
Epoch: 7, Steps: 206 | Train Loss: 0.8321734 Vali Loss: 1.1162169 Test Loss: 0.8796101
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8306091
	speed: 0.0156s/iter; left time: 8.0835s
	iters: 200, epoch: 8 | loss: 0.7983785
	speed: 0.0140s/iter; left time: 5.8579s
Epoch: 8 cost time: 2.901787519454956
Epoch: 8, Steps: 206 | Train Loss: 0.8316543 Vali Loss: 1.1166704 Test Loss: 0.8788573
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8398825526237488, mae:0.7336865663528442
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8871847
	speed: 0.0204s/iter; left time: 40.0185s
	iters: 200, epoch: 1 | loss: 0.8291754
	speed: 0.0175s/iter; left time: 32.4777s
Epoch: 1 cost time: 3.7062532901763916
Epoch: 1, Steps: 206 | Train Loss: 0.9530087 Vali Loss: 1.0455669 Test Loss: 0.8209630
Validation loss decreased (inf --> 1.045567).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8219173
	speed: 0.0265s/iter; left time: 46.5039s
	iters: 200, epoch: 2 | loss: 0.8874647
	speed: 0.0196s/iter; left time: 32.4506s
Epoch: 2 cost time: 4.123773097991943
Epoch: 2, Steps: 206 | Train Loss: 0.9010099 Vali Loss: 1.0916405 Test Loss: 0.8496673
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9080800
	speed: 0.0245s/iter; left time: 37.9059s
	iters: 200, epoch: 3 | loss: 0.9156597
	speed: 0.0198s/iter; left time: 28.6898s
Epoch: 3 cost time: 4.150429964065552
Epoch: 3, Steps: 206 | Train Loss: 0.8739269 Vali Loss: 1.1002105 Test Loss: 0.8711764
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8149249
	speed: 0.0168s/iter; left time: 22.5591s
	iters: 200, epoch: 4 | loss: 0.8247828
	speed: 0.0139s/iter; left time: 17.2902s
Epoch: 4 cost time: 2.955949306488037
Epoch: 4, Steps: 206 | Train Loss: 0.8529287 Vali Loss: 1.0827065 Test Loss: 0.8598577
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9011248
	speed: 0.0195s/iter; left time: 22.1997s
	iters: 200, epoch: 5 | loss: 0.8277711
	speed: 0.0183s/iter; left time: 18.9351s
Epoch: 5 cost time: 3.788465976715088
Epoch: 5, Steps: 206 | Train Loss: 0.8421172 Vali Loss: 1.1069332 Test Loss: 0.8667737
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8582233
	speed: 0.0189s/iter; left time: 17.5818s
	iters: 200, epoch: 6 | loss: 0.8081988
	speed: 0.0158s/iter; left time: 13.0977s
Epoch: 6 cost time: 3.2924580574035645
Epoch: 6, Steps: 206 | Train Loss: 0.8352164 Vali Loss: 1.1008142 Test Loss: 0.8729383
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8209629654884338, mae:0.7247370481491089
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9276155
	speed: 0.0171s/iter; left time: 33.5598s
	iters: 200, epoch: 1 | loss: 0.8916166
	speed: 0.0148s/iter; left time: 27.5728s
Epoch: 1 cost time: 3.1607015132904053
Epoch: 1, Steps: 206 | Train Loss: 0.9547106 Vali Loss: 1.0146141 Test Loss: 0.8187508
Validation loss decreased (inf --> 1.014614).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8710943
	speed: 0.0164s/iter; left time: 28.7253s
	iters: 200, epoch: 2 | loss: 0.9453054
	speed: 0.0134s/iter; left time: 22.2447s
Epoch: 2 cost time: 2.845661163330078
Epoch: 2, Steps: 206 | Train Loss: 0.9019869 Vali Loss: 1.0395027 Test Loss: 0.8278406
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8330667
	speed: 0.0140s/iter; left time: 21.7023s
	iters: 200, epoch: 3 | loss: 0.8598106
	speed: 0.0126s/iter; left time: 18.2329s
Epoch: 3 cost time: 2.7076337337493896
Epoch: 3, Steps: 206 | Train Loss: 0.8783470 Vali Loss: 1.0973730 Test Loss: 0.8589879
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8731310
	speed: 0.0180s/iter; left time: 24.1164s
	iters: 200, epoch: 4 | loss: 0.8689935
	speed: 0.0161s/iter; left time: 20.0225s
Epoch: 4 cost time: 3.378216505050659
Epoch: 4, Steps: 206 | Train Loss: 0.8601232 Vali Loss: 1.0964037 Test Loss: 0.8612099
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8624333
	speed: 0.0212s/iter; left time: 24.0534s
	iters: 200, epoch: 5 | loss: 0.8335513
	speed: 0.0184s/iter; left time: 19.1151s
Epoch: 5 cost time: 3.901665449142456
Epoch: 5, Steps: 206 | Train Loss: 0.8479490 Vali Loss: 1.0906013 Test Loss: 0.8615181
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7500823
	speed: 0.0173s/iter; left time: 16.1220s
	iters: 200, epoch: 6 | loss: 0.8443159
	speed: 0.0163s/iter; left time: 13.5241s
Epoch: 6 cost time: 3.4733879566192627
Epoch: 6, Steps: 206 | Train Loss: 0.8433471 Vali Loss: 1.1186923 Test Loss: 0.8788698
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.81875079870224, mae:0.7255454063415527
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0717762
	speed: 0.0333s/iter; left time: 61.3682s
Epoch: 1 cost time: 4.624890089035034
Epoch: 1, Steps: 194 | Train Loss: 1.1527717 Vali Loss: 1.6516846 Test Loss: 0.9105724
Validation loss decreased (inf --> 1.651685).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9812899
	speed: 0.0186s/iter; left time: 30.7088s
Epoch: 2 cost time: 3.308163642883301
Epoch: 2, Steps: 194 | Train Loss: 1.0633054 Vali Loss: 1.7458682 Test Loss: 0.9194033
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0441628
	speed: 0.0202s/iter; left time: 29.3033s
Epoch: 3 cost time: 3.51946759223938
Epoch: 3, Steps: 194 | Train Loss: 0.9975368 Vali Loss: 1.8651975 Test Loss: 0.9074412
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9441549
	speed: 0.0142s/iter; left time: 17.9167s
Epoch: 4 cost time: 2.7466812133789062
Epoch: 4, Steps: 194 | Train Loss: 0.9738590 Vali Loss: 1.9279870 Test Loss: 0.9164894
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0093166
	speed: 0.0165s/iter; left time: 17.5854s
Epoch: 5 cost time: 3.0796589851379395
Epoch: 5, Steps: 194 | Train Loss: 0.9638554 Vali Loss: 1.8442903 Test Loss: 0.9028065
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0037893
	speed: 0.0163s/iter; left time: 14.1729s
Epoch: 6 cost time: 2.9265153408050537
Epoch: 6, Steps: 194 | Train Loss: 0.9588411 Vali Loss: 1.8718376 Test Loss: 0.9054794
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9105722904205322, mae:0.7654635906219482
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0530463
	speed: 0.0160s/iter; left time: 29.3644s
Epoch: 1 cost time: 3.515826940536499
Epoch: 1, Steps: 194 | Train Loss: 1.1531893 Vali Loss: 1.5534347 Test Loss: 0.8993164
Validation loss decreased (inf --> 1.553435).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0833206
	speed: 0.0217s/iter; left time: 35.7271s
Epoch: 2 cost time: 3.4232277870178223
Epoch: 2, Steps: 194 | Train Loss: 1.0656967 Vali Loss: 1.7027712 Test Loss: 0.8957022
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9708778
	speed: 0.0172s/iter; left time: 24.9312s
Epoch: 3 cost time: 2.908698081970215
Epoch: 3, Steps: 194 | Train Loss: 0.9980889 Vali Loss: 1.7849021 Test Loss: 0.9001957
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9809365
	speed: 0.0249s/iter; left time: 31.3941s
Epoch: 4 cost time: 4.904610872268677
Epoch: 4, Steps: 194 | Train Loss: 0.9748445 Vali Loss: 1.9041971 Test Loss: 0.9182041
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9657498
	speed: 0.0183s/iter; left time: 19.4790s
Epoch: 5 cost time: 3.4061830043792725
Epoch: 5, Steps: 194 | Train Loss: 0.9651734 Vali Loss: 1.9363656 Test Loss: 0.9114277
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9444828
	speed: 0.0165s/iter; left time: 14.3282s
Epoch: 6 cost time: 3.2196247577667236
Epoch: 6, Steps: 194 | Train Loss: 0.9598882 Vali Loss: 1.9276587 Test Loss: 0.9118783
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8993163108825684, mae:0.7613030672073364
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0329798
	speed: 0.0177s/iter; left time: 32.5569s
Epoch: 1 cost time: 2.8168256282806396
Epoch: 1, Steps: 194 | Train Loss: 1.1538174 Vali Loss: 1.7450634 Test Loss: 0.9180706
Validation loss decreased (inf --> 1.745063).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0061759
	speed: 0.0144s/iter; left time: 23.6403s
Epoch: 2 cost time: 2.7511680126190186
Epoch: 2, Steps: 194 | Train Loss: 1.0750918 Vali Loss: 1.7950480 Test Loss: 0.9200990
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9734083
	speed: 0.0147s/iter; left time: 21.3268s
Epoch: 3 cost time: 2.7264511585235596
Epoch: 3, Steps: 194 | Train Loss: 0.9996370 Vali Loss: 1.9577250 Test Loss: 0.9169185
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9252771
	speed: 0.0176s/iter; left time: 22.2166s
Epoch: 4 cost time: 3.302762508392334
Epoch: 4, Steps: 194 | Train Loss: 0.9742429 Vali Loss: 1.8804785 Test Loss: 0.9010915
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9512925
	speed: 0.0191s/iter; left time: 20.3594s
Epoch: 5 cost time: 3.2961044311523438
Epoch: 5, Steps: 194 | Train Loss: 0.9633819 Vali Loss: 1.9460847 Test Loss: 0.9071247
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9029244
	speed: 0.0146s/iter; left time: 12.7415s
Epoch: 6 cost time: 2.3787331581115723
Epoch: 6, Steps: 194 | Train Loss: 0.9575385 Vali Loss: 1.9779983 Test Loss: 0.9115995
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9180706739425659, mae:0.7672902345657349
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6937631
	speed: 0.0308s/iter; left time: 62.5149s
	iters: 200, epoch: 1 | loss: 0.7165139
	speed: 0.0239s/iter; left time: 46.1185s
Epoch: 1 cost time: 5.051998615264893
Epoch: 1, Steps: 213 | Train Loss: 0.7316930 Vali Loss: 0.6536014 Test Loss: 0.6449102
Validation loss decreased (inf --> 0.653601).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7102157
	speed: 0.0163s/iter; left time: 29.7010s
	iters: 200, epoch: 2 | loss: 0.6947708
	speed: 0.0125s/iter; left time: 21.5423s
Epoch: 2 cost time: 2.721323013305664
Epoch: 2, Steps: 213 | Train Loss: 0.6938873 Vali Loss: 0.7077892 Test Loss: 0.6648939
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7050890
	speed: 0.0201s/iter; left time: 32.1899s
	iters: 200, epoch: 3 | loss: 0.6885170
	speed: 0.0185s/iter; left time: 27.7963s
Epoch: 3 cost time: 3.9648940563201904
Epoch: 3, Steps: 213 | Train Loss: 0.6773064 Vali Loss: 0.7547348 Test Loss: 0.6756281
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7195144
	speed: 0.0218s/iter; left time: 30.3555s
	iters: 200, epoch: 4 | loss: 0.6509125
	speed: 0.0183s/iter; left time: 23.5936s
Epoch: 4 cost time: 3.9228241443634033
Epoch: 4, Steps: 213 | Train Loss: 0.6671456 Vali Loss: 0.7243495 Test Loss: 0.6686583
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6072967
	speed: 0.0286s/iter; left time: 33.7673s
	iters: 200, epoch: 5 | loss: 0.6806790
	speed: 0.0212s/iter; left time: 22.9218s
Epoch: 5 cost time: 4.477649450302124
Epoch: 5, Steps: 213 | Train Loss: 0.6614381 Vali Loss: 0.7497355 Test Loss: 0.6736882
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5832419
	speed: 0.0147s/iter; left time: 14.2001s
	iters: 200, epoch: 6 | loss: 0.6614779
	speed: 0.0114s/iter; left time: 9.8887s
Epoch: 6 cost time: 2.4588260650634766
Epoch: 6, Steps: 213 | Train Loss: 0.6574202 Vali Loss: 0.7438897 Test Loss: 0.6753687
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6449102759361267, mae:0.6447373628616333
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7307500
	speed: 0.0154s/iter; left time: 31.3382s
	iters: 200, epoch: 1 | loss: 0.7415842
	speed: 0.0150s/iter; left time: 29.0567s
Epoch: 1 cost time: 3.214366912841797
Epoch: 1, Steps: 213 | Train Loss: 0.7329388 Vali Loss: 0.6596756 Test Loss: 0.6487912
Validation loss decreased (inf --> 0.659676).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7000551
	speed: 0.0127s/iter; left time: 23.1760s
	iters: 200, epoch: 2 | loss: 0.6589403
	speed: 0.0128s/iter; left time: 21.9870s
Epoch: 2 cost time: 2.834954023361206
Epoch: 2, Steps: 213 | Train Loss: 0.6950019 Vali Loss: 0.7542608 Test Loss: 0.6779267
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6837850
	speed: 0.0155s/iter; left time: 24.9084s
	iters: 200, epoch: 3 | loss: 0.6537094
	speed: 0.0151s/iter; left time: 22.7987s
Epoch: 3 cost time: 3.3109092712402344
Epoch: 3, Steps: 213 | Train Loss: 0.6777255 Vali Loss: 0.7679495 Test Loss: 0.6719119
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6478491
	speed: 0.0169s/iter; left time: 23.5594s
	iters: 200, epoch: 4 | loss: 0.7084381
	speed: 0.0132s/iter; left time: 17.0884s
Epoch: 4 cost time: 2.827871322631836
Epoch: 4, Steps: 213 | Train Loss: 0.6675193 Vali Loss: 0.7481635 Test Loss: 0.6715957
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6701758
	speed: 0.0164s/iter; left time: 19.3145s
	iters: 200, epoch: 5 | loss: 0.6696266
	speed: 0.0153s/iter; left time: 16.4675s
Epoch: 5 cost time: 3.3392322063446045
Epoch: 5, Steps: 213 | Train Loss: 0.6619965 Vali Loss: 0.7442836 Test Loss: 0.6735988
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6435966
	speed: 0.0186s/iter; left time: 18.0017s
	iters: 200, epoch: 6 | loss: 0.6194968
	speed: 0.0172s/iter; left time: 14.9329s
Epoch: 6 cost time: 3.8105924129486084
Epoch: 6, Steps: 213 | Train Loss: 0.6588436 Vali Loss: 0.7413247 Test Loss: 0.6727836
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6487911343574524, mae:0.6463395953178406
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7096151
	speed: 0.0194s/iter; left time: 39.3866s
	iters: 200, epoch: 1 | loss: 0.6248928
	speed: 0.0175s/iter; left time: 33.7472s
Epoch: 1 cost time: 3.7745378017425537
Epoch: 1, Steps: 213 | Train Loss: 0.7321047 Vali Loss: 0.6709434 Test Loss: 0.6486627
Validation loss decreased (inf --> 0.670943).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7120800
	speed: 0.0187s/iter; left time: 34.0080s
	iters: 200, epoch: 2 | loss: 0.6705832
	speed: 0.0143s/iter; left time: 24.6458s
Epoch: 2 cost time: 3.0772809982299805
Epoch: 2, Steps: 213 | Train Loss: 0.6946227 Vali Loss: 0.6743051 Test Loss: 0.6557791
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6465582
	speed: 0.0165s/iter; left time: 26.5174s
	iters: 200, epoch: 3 | loss: 0.7303559
	speed: 0.0161s/iter; left time: 24.1745s
Epoch: 3 cost time: 3.4474165439605713
Epoch: 3, Steps: 213 | Train Loss: 0.6768847 Vali Loss: 0.7241417 Test Loss: 0.6668037
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7093238
	speed: 0.0163s/iter; left time: 22.7430s
	iters: 200, epoch: 4 | loss: 0.6954303
	speed: 0.0155s/iter; left time: 20.0889s
Epoch: 4 cost time: 3.4202959537506104
Epoch: 4, Steps: 213 | Train Loss: 0.6668701 Vali Loss: 0.7746854 Test Loss: 0.6771438
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6384533
	speed: 0.0312s/iter; left time: 36.8292s
	iters: 200, epoch: 5 | loss: 0.6383952
	speed: 0.0241s/iter; left time: 26.0410s
Epoch: 5 cost time: 5.123658180236816
Epoch: 5, Steps: 213 | Train Loss: 0.6610586 Vali Loss: 0.7483622 Test Loss: 0.6706648
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6219361
	speed: 0.0180s/iter; left time: 17.3482s
	iters: 200, epoch: 6 | loss: 0.6422254
	speed: 0.0151s/iter; left time: 13.1032s
Epoch: 6 cost time: 3.283757448196411
Epoch: 6, Steps: 213 | Train Loss: 0.6575087 Vali Loss: 0.7460085 Test Loss: 0.6710311
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6486627459526062, mae:0.645742654800415
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8171841
	speed: 0.0316s/iter; left time: 63.1829s
	iters: 200, epoch: 1 | loss: 0.7698754
	speed: 0.0229s/iter; left time: 43.5670s
Epoch: 1 cost time: 4.786972999572754
Epoch: 1, Steps: 210 | Train Loss: 0.8326901 Vali Loss: 0.9984713 Test Loss: 0.7822621
Validation loss decreased (inf --> 0.998471).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7778060
	speed: 0.0160s/iter; left time: 28.7059s
	iters: 200, epoch: 2 | loss: 0.7938759
	speed: 0.0138s/iter; left time: 23.3238s
Epoch: 2 cost time: 2.8782870769500732
Epoch: 2, Steps: 210 | Train Loss: 0.7904151 Vali Loss: 1.0527953 Test Loss: 0.7913479
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7724022
	speed: 0.0176s/iter; left time: 27.7923s
	iters: 200, epoch: 3 | loss: 0.7002071
	speed: 0.0159s/iter; left time: 23.4863s
Epoch: 3 cost time: 3.382770538330078
Epoch: 3, Steps: 210 | Train Loss: 0.7701033 Vali Loss: 1.0341990 Test Loss: 0.8077839
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7783197
	speed: 0.0182s/iter; left time: 25.0130s
	iters: 200, epoch: 4 | loss: 0.7745882
	speed: 0.0165s/iter; left time: 20.9898s
Epoch: 4 cost time: 3.55983304977417
Epoch: 4, Steps: 210 | Train Loss: 0.7550536 Vali Loss: 0.9959602 Test Loss: 0.8068795
Validation loss decreased (0.998471 --> 0.995960).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7432903
	speed: 0.0181s/iter; left time: 21.0233s
	iters: 200, epoch: 5 | loss: 0.7480404
	speed: 0.0154s/iter; left time: 16.3029s
Epoch: 5 cost time: 3.4005985260009766
Epoch: 5, Steps: 210 | Train Loss: 0.7454870 Vali Loss: 0.9708842 Test Loss: 0.8025936
Validation loss decreased (0.995960 --> 0.970884).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7065661
	speed: 0.0177s/iter; left time: 16.8427s
	iters: 200, epoch: 6 | loss: 0.7670538
	speed: 0.0142s/iter; left time: 12.0795s
Epoch: 6 cost time: 3.0098650455474854
Epoch: 6, Steps: 210 | Train Loss: 0.7421342 Vali Loss: 0.9883918 Test Loss: 0.8156278
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7290132
	speed: 0.0235s/iter; left time: 17.4415s
	iters: 200, epoch: 7 | loss: 0.7695539
	speed: 0.0178s/iter; left time: 11.3808s
Epoch: 7 cost time: 3.7563304901123047
Epoch: 7, Steps: 210 | Train Loss: 0.7398356 Vali Loss: 1.0000298 Test Loss: 0.8181999
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7311882
	speed: 0.0204s/iter; left time: 10.8424s
	iters: 200, epoch: 8 | loss: 0.6882448
	speed: 0.0179s/iter; left time: 7.7208s
Epoch: 8 cost time: 3.8569300174713135
Epoch: 8, Steps: 210 | Train Loss: 0.7384360 Vali Loss: 0.9885226 Test Loss: 0.8147391
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6798115
	speed: 0.0159s/iter; left time: 5.1132s
	iters: 200, epoch: 9 | loss: 0.7431154
	speed: 0.0143s/iter; left time: 3.1691s
Epoch: 9 cost time: 3.0488016605377197
Epoch: 9, Steps: 210 | Train Loss: 0.7386302 Vali Loss: 0.9898599 Test Loss: 0.8169404
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7109956
	speed: 0.0126s/iter; left time: 1.3944s
	iters: 200, epoch: 10 | loss: 0.7568902
	speed: 0.0116s/iter; left time: 0.1271s
Epoch: 10 cost time: 2.5222725868225098
Epoch: 10, Steps: 210 | Train Loss: 0.7381176 Vali Loss: 0.9928946 Test Loss: 0.8175699
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8025932908058167, mae:0.7139295935630798
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9191887
	speed: 0.0150s/iter; left time: 30.0902s
	iters: 200, epoch: 1 | loss: 0.8429843
	speed: 0.0140s/iter; left time: 26.5478s
Epoch: 1 cost time: 3.0254082679748535
Epoch: 1, Steps: 210 | Train Loss: 0.8350078 Vali Loss: 0.9868803 Test Loss: 0.7759562
Validation loss decreased (inf --> 0.986880).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7792727
	speed: 0.0188s/iter; left time: 33.7120s
	iters: 200, epoch: 2 | loss: 0.8685691
	speed: 0.0161s/iter; left time: 27.1628s
Epoch: 2 cost time: 3.4261865615844727
Epoch: 2, Steps: 210 | Train Loss: 0.7927390 Vali Loss: 1.0143090 Test Loss: 0.7889385
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7286877
	speed: 0.0175s/iter; left time: 27.6403s
	iters: 200, epoch: 3 | loss: 0.8022180
	speed: 0.0165s/iter; left time: 24.3995s
Epoch: 3 cost time: 3.5266377925872803
Epoch: 3, Steps: 210 | Train Loss: 0.7728174 Vali Loss: 0.9463676 Test Loss: 0.7736290
Validation loss decreased (0.986880 --> 0.946368).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7471012
	speed: 0.0181s/iter; left time: 24.8609s
	iters: 200, epoch: 4 | loss: 0.7347944
	speed: 0.0143s/iter; left time: 18.1936s
Epoch: 4 cost time: 3.0564138889312744
Epoch: 4, Steps: 210 | Train Loss: 0.7594960 Vali Loss: 0.9811051 Test Loss: 0.8147087
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6928377
	speed: 0.0173s/iter; left time: 20.0389s
	iters: 200, epoch: 5 | loss: 0.8113496
	speed: 0.0145s/iter; left time: 15.4181s
Epoch: 5 cost time: 3.112205982208252
Epoch: 5, Steps: 210 | Train Loss: 0.7505422 Vali Loss: 0.9788247 Test Loss: 0.8120637
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8464160
	speed: 0.0188s/iter; left time: 17.9190s
	iters: 200, epoch: 6 | loss: 0.6942037
	speed: 0.0167s/iter; left time: 14.1893s
Epoch: 6 cost time: 3.6087186336517334
Epoch: 6, Steps: 210 | Train Loss: 0.7468813 Vali Loss: 0.9849449 Test Loss: 0.8161418
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7212684
	speed: 0.0170s/iter; left time: 12.6106s
	iters: 200, epoch: 7 | loss: 0.7893623
	speed: 0.0164s/iter; left time: 10.5030s
Epoch: 7 cost time: 3.5574724674224854
Epoch: 7, Steps: 210 | Train Loss: 0.7439183 Vali Loss: 0.9917770 Test Loss: 0.8205489
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7432129
	speed: 0.0202s/iter; left time: 10.7031s
	iters: 200, epoch: 8 | loss: 0.8247542
	speed: 0.0152s/iter; left time: 6.5725s
Epoch: 8 cost time: 3.292487382888794
Epoch: 8, Steps: 210 | Train Loss: 0.7438833 Vali Loss: 0.9893092 Test Loss: 0.8193685
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.773628830909729, mae:0.7027658224105835
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7925003
	speed: 0.0131s/iter; left time: 26.2741s
	iters: 200, epoch: 1 | loss: 0.7874746
	speed: 0.0175s/iter; left time: 33.3238s
Epoch: 1 cost time: 3.9112985134124756
Epoch: 1, Steps: 210 | Train Loss: 0.8347685 Vali Loss: 0.9069144 Test Loss: 0.7514063
Validation loss decreased (inf --> 0.906914).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7989799
	speed: 0.0170s/iter; left time: 30.4578s
	iters: 200, epoch: 2 | loss: 0.8012049
	speed: 0.0221s/iter; left time: 37.3425s
Epoch: 2 cost time: 4.896740674972534
Epoch: 2, Steps: 210 | Train Loss: 0.7907346 Vali Loss: 0.9946641 Test Loss: 0.7716146
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8164552
	speed: 0.0151s/iter; left time: 23.8665s
	iters: 200, epoch: 3 | loss: 0.8336742
	speed: 0.0152s/iter; left time: 22.5843s
Epoch: 3 cost time: 3.3158318996429443
Epoch: 3, Steps: 210 | Train Loss: 0.7709058 Vali Loss: 0.9835653 Test Loss: 0.7907366
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7498019
	speed: 0.0156s/iter; left time: 21.3797s
	iters: 200, epoch: 4 | loss: 0.7453038
	speed: 0.0134s/iter; left time: 16.9990s
Epoch: 4 cost time: 2.990061044692993
Epoch: 4, Steps: 210 | Train Loss: 0.7564425 Vali Loss: 1.0045707 Test Loss: 0.8159211
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7956614
	speed: 0.0198s/iter; left time: 22.9303s
	iters: 200, epoch: 5 | loss: 0.7089025
	speed: 0.0178s/iter; left time: 18.9343s
Epoch: 5 cost time: 3.9142446517944336
Epoch: 5, Steps: 210 | Train Loss: 0.7475055 Vali Loss: 1.0144945 Test Loss: 0.8259439
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6934417
	speed: 0.0173s/iter; left time: 16.4889s
	iters: 200, epoch: 6 | loss: 0.7372267
	speed: 0.0177s/iter; left time: 15.1006s
Epoch: 6 cost time: 3.7714273929595947
Epoch: 6, Steps: 210 | Train Loss: 0.7439218 Vali Loss: 1.0029519 Test Loss: 0.8150427
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7514061331748962, mae:0.6918331384658813
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9373287
	speed: 0.0307s/iter; left time: 60.2499s
	iters: 200, epoch: 1 | loss: 0.8413411
	speed: 0.0229s/iter; left time: 42.5481s
Epoch: 1 cost time: 4.762222766876221
Epoch: 1, Steps: 206 | Train Loss: 0.9549991 Vali Loss: 1.0914085 Test Loss: 0.8359141
Validation loss decreased (inf --> 1.091408).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9049483
	speed: 0.0207s/iter; left time: 36.2601s
	iters: 200, epoch: 2 | loss: 0.9455608
	speed: 0.0198s/iter; left time: 32.8339s
Epoch: 2 cost time: 4.177107334136963
Epoch: 2, Steps: 206 | Train Loss: 0.9008745 Vali Loss: 1.0329199 Test Loss: 0.8393881
Validation loss decreased (1.091408 --> 1.032920).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8616473
	speed: 0.0161s/iter; left time: 24.9436s
	iters: 200, epoch: 3 | loss: 0.8234251
	speed: 0.0149s/iter; left time: 21.6292s
Epoch: 3 cost time: 3.16013765335083
Epoch: 3, Steps: 206 | Train Loss: 0.8741411 Vali Loss: 1.0848497 Test Loss: 0.8647002
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8230914
	speed: 0.0147s/iter; left time: 19.7166s
	iters: 200, epoch: 4 | loss: 0.7732651
	speed: 0.0128s/iter; left time: 15.9413s
Epoch: 4 cost time: 2.7109460830688477
Epoch: 4, Steps: 206 | Train Loss: 0.8548604 Vali Loss: 1.1050894 Test Loss: 0.8757259
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8408917
	speed: 0.0251s/iter; left time: 28.5010s
	iters: 200, epoch: 5 | loss: 0.8642080
	speed: 0.0197s/iter; left time: 20.4718s
Epoch: 5 cost time: 4.150900363922119
Epoch: 5, Steps: 206 | Train Loss: 0.8437715 Vali Loss: 1.0978355 Test Loss: 0.8778320
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8389450
	speed: 0.0178s/iter; left time: 16.5746s
	iters: 200, epoch: 6 | loss: 0.8521875
	speed: 0.0161s/iter; left time: 13.3387s
Epoch: 6 cost time: 3.426724433898926
Epoch: 6, Steps: 206 | Train Loss: 0.8386217 Vali Loss: 1.1041025 Test Loss: 0.8816130
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8243748
	speed: 0.0172s/iter; left time: 12.4498s
	iters: 200, epoch: 7 | loss: 0.8228622
	speed: 0.0157s/iter; left time: 9.8196s
Epoch: 7 cost time: 3.2920711040496826
Epoch: 7, Steps: 206 | Train Loss: 0.8361796 Vali Loss: 1.1009831 Test Loss: 0.8789143
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8393880128860474, mae:0.7336178421974182
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8484532
	speed: 0.0134s/iter; left time: 26.2462s
	iters: 200, epoch: 1 | loss: 0.9093679
	speed: 0.0144s/iter; left time: 26.8210s
Epoch: 1 cost time: 3.035703182220459
Epoch: 1, Steps: 206 | Train Loss: 0.9528706 Vali Loss: 1.0516431 Test Loss: 0.8215810
Validation loss decreased (inf --> 1.051643).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8910167
	speed: 0.0132s/iter; left time: 23.0833s
	iters: 200, epoch: 2 | loss: 0.8524895
	speed: 0.0119s/iter; left time: 19.6221s
Epoch: 2 cost time: 2.526449203491211
Epoch: 2, Steps: 206 | Train Loss: 0.8994437 Vali Loss: 1.1511514 Test Loss: 0.8698281
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8613191
	speed: 0.0157s/iter; left time: 24.3080s
	iters: 200, epoch: 3 | loss: 0.8519592
	speed: 0.0128s/iter; left time: 18.4861s
Epoch: 3 cost time: 2.661177635192871
Epoch: 3, Steps: 206 | Train Loss: 0.8746651 Vali Loss: 1.0733080 Test Loss: 0.8520089
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8597823
	speed: 0.0145s/iter; left time: 19.4989s
	iters: 200, epoch: 4 | loss: 0.9342548
	speed: 0.0121s/iter; left time: 14.9789s
Epoch: 4 cost time: 2.5545175075531006
Epoch: 4, Steps: 206 | Train Loss: 0.8560832 Vali Loss: 1.1115763 Test Loss: 0.8601083
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8386385
	speed: 0.0204s/iter; left time: 23.2168s
	iters: 200, epoch: 5 | loss: 0.8805606
	speed: 0.0196s/iter; left time: 20.3059s
Epoch: 5 cost time: 4.112509250640869
Epoch: 5, Steps: 206 | Train Loss: 0.8448403 Vali Loss: 1.0973046 Test Loss: 0.8690920
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8725723
	speed: 0.0211s/iter; left time: 19.6850s
	iters: 200, epoch: 6 | loss: 0.8224967
	speed: 0.0180s/iter; left time: 14.9418s
Epoch: 6 cost time: 3.7935805320739746
Epoch: 6, Steps: 206 | Train Loss: 0.8383370 Vali Loss: 1.1038440 Test Loss: 0.8710815
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8215810656547546, mae:0.7256232500076294
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9954975
	speed: 0.0192s/iter; left time: 37.7257s
	iters: 200, epoch: 1 | loss: 0.9056203
	speed: 0.0173s/iter; left time: 32.1283s
Epoch: 1 cost time: 3.5558502674102783
Epoch: 1, Steps: 206 | Train Loss: 0.9553718 Vali Loss: 1.0449530 Test Loss: 0.8193803
Validation loss decreased (inf --> 1.044953).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8714496
	speed: 0.0160s/iter; left time: 28.1291s
	iters: 200, epoch: 2 | loss: 0.8509109
	speed: 0.0131s/iter; left time: 21.6805s
Epoch: 2 cost time: 2.812997579574585
Epoch: 2, Steps: 206 | Train Loss: 0.9006144 Vali Loss: 1.0727792 Test Loss: 0.8386260
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8281763
	speed: 0.0177s/iter; left time: 27.3939s
	iters: 200, epoch: 3 | loss: 0.8784670
	speed: 0.0171s/iter; left time: 24.7242s
Epoch: 3 cost time: 3.6210110187530518
Epoch: 3, Steps: 206 | Train Loss: 0.8770158 Vali Loss: 1.1112295 Test Loss: 0.8678805
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8669100
	speed: 0.0169s/iter; left time: 22.7034s
	iters: 200, epoch: 4 | loss: 0.8854926
	speed: 0.0166s/iter; left time: 20.6924s
Epoch: 4 cost time: 3.552600383758545
Epoch: 4, Steps: 206 | Train Loss: 0.8594957 Vali Loss: 1.1012319 Test Loss: 0.8574086
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8355175
	speed: 0.0233s/iter; left time: 26.4486s
	iters: 200, epoch: 5 | loss: 0.8255107
	speed: 0.0189s/iter; left time: 19.5996s
Epoch: 5 cost time: 3.9734418392181396
Epoch: 5, Steps: 206 | Train Loss: 0.8498371 Vali Loss: 1.0842986 Test Loss: 0.8660240
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8958029
	speed: 0.0133s/iter; left time: 12.3639s
	iters: 200, epoch: 6 | loss: 0.8335930
	speed: 0.0122s/iter; left time: 10.1644s
Epoch: 6 cost time: 2.6114745140075684
Epoch: 6, Steps: 206 | Train Loss: 0.8444984 Vali Loss: 1.0995600 Test Loss: 0.8718500
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8193802833557129, mae:0.7243569493293762
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2445593
	speed: 0.0333s/iter; left time: 61.3887s
Epoch: 1 cost time: 5.406826972961426
Epoch: 1, Steps: 194 | Train Loss: 1.1542300 Vali Loss: 1.7181106 Test Loss: 0.9174815
Validation loss decreased (inf --> 1.718111).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0734549
	speed: 0.0151s/iter; left time: 24.9398s
Epoch: 2 cost time: 2.839977979660034
Epoch: 2, Steps: 194 | Train Loss: 1.0674396 Vali Loss: 1.7483287 Test Loss: 0.9007842
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9624198
	speed: 0.0130s/iter; left time: 18.8568s
Epoch: 3 cost time: 2.5076913833618164
Epoch: 3, Steps: 194 | Train Loss: 0.9978462 Vali Loss: 1.8718554 Test Loss: 0.9092608
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9647130
	speed: 0.0187s/iter; left time: 23.5242s
Epoch: 4 cost time: 3.233966588973999
Epoch: 4, Steps: 194 | Train Loss: 0.9741562 Vali Loss: 1.9316934 Test Loss: 0.9107445
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9300743
	speed: 0.0173s/iter; left time: 18.4536s
Epoch: 5 cost time: 3.2226243019104004
Epoch: 5, Steps: 194 | Train Loss: 0.9625376 Vali Loss: 1.9539905 Test Loss: 0.9110354
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9508401
	speed: 0.0156s/iter; left time: 13.5864s
Epoch: 6 cost time: 2.949643611907959
Epoch: 6, Steps: 194 | Train Loss: 0.9577992 Vali Loss: 1.9618144 Test Loss: 0.9129611
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9174814820289612, mae:0.7671293616294861
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1051518
	speed: 0.0123s/iter; left time: 22.6031s
Epoch: 1 cost time: 2.2431657314300537
Epoch: 1, Steps: 194 | Train Loss: 1.1531867 Vali Loss: 1.6199899 Test Loss: 0.9020483
Validation loss decreased (inf --> 1.619990).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1278971
	speed: 0.0153s/iter; left time: 25.1750s
Epoch: 2 cost time: 2.7245819568634033
Epoch: 2, Steps: 194 | Train Loss: 1.0678108 Vali Loss: 1.7868322 Test Loss: 0.9075881
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9665642
	speed: 0.0184s/iter; left time: 26.7244s
Epoch: 3 cost time: 2.9142560958862305
Epoch: 3, Steps: 194 | Train Loss: 0.9969601 Vali Loss: 1.8737504 Test Loss: 0.9063467
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9465780
	speed: 0.0288s/iter; left time: 36.2838s
Epoch: 4 cost time: 4.904534578323364
Epoch: 4, Steps: 194 | Train Loss: 0.9728581 Vali Loss: 1.9255246 Test Loss: 0.9097341
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9545703
	speed: 0.0178s/iter; left time: 18.9658s
Epoch: 5 cost time: 3.420976400375366
Epoch: 5, Steps: 194 | Train Loss: 0.9631059 Vali Loss: 1.8768885 Test Loss: 0.8995078
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9665216
	speed: 0.0205s/iter; left time: 17.8611s
Epoch: 6 cost time: 2.983792304992676
Epoch: 6, Steps: 194 | Train Loss: 0.9553572 Vali Loss: 1.8921763 Test Loss: 0.9050831
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9020482301712036, mae:0.761198103427887
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1421853
	speed: 0.0180s/iter; left time: 33.1867s
Epoch: 1 cost time: 2.9970014095306396
Epoch: 1, Steps: 194 | Train Loss: 1.1536144 Vali Loss: 1.6500108 Test Loss: 0.9057906
Validation loss decreased (inf --> 1.650011).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0783010
	speed: 0.0249s/iter; left time: 41.0354s
Epoch: 2 cost time: 3.7272772789001465
Epoch: 2, Steps: 194 | Train Loss: 1.0682776 Vali Loss: 1.8480352 Test Loss: 0.9216130
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9743797
	speed: 0.0290s/iter; left time: 42.1150s
Epoch: 3 cost time: 4.4576263427734375
Epoch: 3, Steps: 194 | Train Loss: 0.9989261 Vali Loss: 1.9196523 Test Loss: 0.9097757
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0095276
	speed: 0.0183s/iter; left time: 23.0375s
Epoch: 4 cost time: 2.8928322792053223
Epoch: 4, Steps: 194 | Train Loss: 0.9765122 Vali Loss: 1.9326297 Test Loss: 0.9147139
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9749711
	speed: 0.0157s/iter; left time: 16.7360s
Epoch: 5 cost time: 2.7083330154418945
Epoch: 5, Steps: 194 | Train Loss: 0.9675491 Vali Loss: 1.8562497 Test Loss: 0.9012308
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9338503
	speed: 0.0198s/iter; left time: 17.2437s
Epoch: 6 cost time: 3.2426493167877197
Epoch: 6, Steps: 194 | Train Loss: 0.9619522 Vali Loss: 1.9359826 Test Loss: 0.9142359
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9057905077934265, mae:0.7630823850631714
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7333211
	speed: 0.0263s/iter; left time: 53.3456s
	iters: 200, epoch: 1 | loss: 0.6630368
	speed: 0.0186s/iter; left time: 35.8696s
Epoch: 1 cost time: 3.968787431716919
Epoch: 1, Steps: 213 | Train Loss: 0.7332146 Vali Loss: 0.6756533 Test Loss: 0.6513202
Validation loss decreased (inf --> 0.675653).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7299921
	speed: 0.0168s/iter; left time: 30.5392s
	iters: 200, epoch: 2 | loss: 0.6746889
	speed: 0.0153s/iter; left time: 26.2964s
Epoch: 2 cost time: 3.3729588985443115
Epoch: 2, Steps: 213 | Train Loss: 0.6931823 Vali Loss: 0.7022757 Test Loss: 0.6597821
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6463779
	speed: 0.0171s/iter; left time: 27.3658s
	iters: 200, epoch: 3 | loss: 0.6927850
	speed: 0.0162s/iter; left time: 24.4552s
Epoch: 3 cost time: 3.4664087295532227
Epoch: 3, Steps: 213 | Train Loss: 0.6755657 Vali Loss: 0.7296872 Test Loss: 0.6668628
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6538405
	speed: 0.0216s/iter; left time: 30.0062s
	iters: 200, epoch: 4 | loss: 0.6640518
	speed: 0.0177s/iter; left time: 22.8491s
Epoch: 4 cost time: 3.8445887565612793
Epoch: 4, Steps: 213 | Train Loss: 0.6650996 Vali Loss: 0.7168910 Test Loss: 0.6643963
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6929656
	speed: 0.0140s/iter; left time: 16.5641s
	iters: 200, epoch: 5 | loss: 0.6680460
	speed: 0.0122s/iter; left time: 13.1881s
Epoch: 5 cost time: 2.7097737789154053
Epoch: 5, Steps: 213 | Train Loss: 0.6586250 Vali Loss: 0.7464579 Test Loss: 0.6736094
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6416361
	speed: 0.0168s/iter; left time: 16.2557s
	iters: 200, epoch: 6 | loss: 0.6278160
	speed: 0.0152s/iter; left time: 13.1638s
Epoch: 6 cost time: 3.3754470348358154
Epoch: 6, Steps: 213 | Train Loss: 0.6547440 Vali Loss: 0.7373485 Test Loss: 0.6698235
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.651320219039917, mae:0.6468865871429443
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7046542
	speed: 0.0190s/iter; left time: 38.6770s
	iters: 200, epoch: 1 | loss: 0.6925742
	speed: 0.0163s/iter; left time: 31.5085s
Epoch: 1 cost time: 3.565537452697754
Epoch: 1, Steps: 213 | Train Loss: 0.7323127 Vali Loss: 0.6590438 Test Loss: 0.6484094
Validation loss decreased (inf --> 0.659044).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6582912
	speed: 0.0266s/iter; left time: 48.3731s
	iters: 200, epoch: 2 | loss: 0.6979458
	speed: 0.0210s/iter; left time: 36.0502s
Epoch: 2 cost time: 4.4538774490356445
Epoch: 2, Steps: 213 | Train Loss: 0.6960674 Vali Loss: 0.6909186 Test Loss: 0.6620643
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6933485
	speed: 0.0177s/iter; left time: 28.3825s
	iters: 200, epoch: 3 | loss: 0.6779479
	speed: 0.0138s/iter; left time: 20.7408s
Epoch: 3 cost time: 2.980618953704834
Epoch: 3, Steps: 213 | Train Loss: 0.6799379 Vali Loss: 0.7153820 Test Loss: 0.6660219
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6953167
	speed: 0.0156s/iter; left time: 21.7647s
	iters: 200, epoch: 4 | loss: 0.6618037
	speed: 0.0136s/iter; left time: 17.5704s
Epoch: 4 cost time: 2.9619853496551514
Epoch: 4, Steps: 213 | Train Loss: 0.6688060 Vali Loss: 0.7380277 Test Loss: 0.6681827
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6640414
	speed: 0.0169s/iter; left time: 19.8715s
	iters: 200, epoch: 5 | loss: 0.6723690
	speed: 0.0146s/iter; left time: 15.7192s
Epoch: 5 cost time: 3.4774043560028076
Epoch: 5, Steps: 213 | Train Loss: 0.6631027 Vali Loss: 0.7420093 Test Loss: 0.6684879
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6293827
	speed: 0.0239s/iter; left time: 23.1351s
	iters: 200, epoch: 6 | loss: 0.6352302
	speed: 0.0203s/iter; left time: 17.5870s
Epoch: 6 cost time: 4.300812005996704
Epoch: 6, Steps: 213 | Train Loss: 0.6603290 Vali Loss: 0.7418259 Test Loss: 0.6718986
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6484094858169556, mae:0.6460158228874207
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7978603
	speed: 0.0154s/iter; left time: 31.2558s
	iters: 200, epoch: 1 | loss: 0.6911079
	speed: 0.0129s/iter; left time: 24.8142s
Epoch: 1 cost time: 2.798654794692993
Epoch: 1, Steps: 213 | Train Loss: 0.7328642 Vali Loss: 0.6473124 Test Loss: 0.6465784
Validation loss decreased (inf --> 0.647312).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6753876
	speed: 0.0172s/iter; left time: 31.3496s
	iters: 200, epoch: 2 | loss: 0.6609358
	speed: 0.0135s/iter; left time: 23.2175s
Epoch: 2 cost time: 2.9740071296691895
Epoch: 2, Steps: 213 | Train Loss: 0.6968371 Vali Loss: 0.6902723 Test Loss: 0.6585859
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6598467
	speed: 0.0280s/iter; left time: 45.0027s
	iters: 200, epoch: 3 | loss: 0.6628196
	speed: 0.0219s/iter; left time: 32.8844s
Epoch: 3 cost time: 4.60476279258728
Epoch: 3, Steps: 213 | Train Loss: 0.6810139 Vali Loss: 0.6945884 Test Loss: 0.6563938
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6650857
	speed: 0.0207s/iter; left time: 28.7818s
	iters: 200, epoch: 4 | loss: 0.6668915
	speed: 0.0178s/iter; left time: 22.9563s
Epoch: 4 cost time: 3.8762691020965576
Epoch: 4, Steps: 213 | Train Loss: 0.6706780 Vali Loss: 0.7448308 Test Loss: 0.6662784
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6272621
	speed: 0.0144s/iter; left time: 16.9325s
	iters: 200, epoch: 5 | loss: 0.6566516
	speed: 0.0122s/iter; left time: 13.1836s
Epoch: 5 cost time: 2.7201104164123535
Epoch: 5, Steps: 213 | Train Loss: 0.6641835 Vali Loss: 0.7441329 Test Loss: 0.6680540
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6765988
	speed: 0.0167s/iter; left time: 16.1109s
	iters: 200, epoch: 6 | loss: 0.6285920
	speed: 0.0155s/iter; left time: 13.3903s
Epoch: 6 cost time: 3.4843499660491943
Epoch: 6, Steps: 213 | Train Loss: 0.6612248 Vali Loss: 0.7677897 Test Loss: 0.6775944
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6465784311294556, mae:0.645824134349823
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8598536
	speed: 0.0298s/iter; left time: 59.6235s
	iters: 200, epoch: 1 | loss: 0.8121585
	speed: 0.0208s/iter; left time: 39.4552s
Epoch: 1 cost time: 4.357755422592163
Epoch: 1, Steps: 210 | Train Loss: 0.8355863 Vali Loss: 0.9696331 Test Loss: 0.7713633
Validation loss decreased (inf --> 0.969633).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7518064
	speed: 0.0161s/iter; left time: 28.9141s
	iters: 200, epoch: 2 | loss: 0.7956551
	speed: 0.0176s/iter; left time: 29.8406s
Epoch: 2 cost time: 3.8145456314086914
Epoch: 2, Steps: 210 | Train Loss: 0.7911319 Vali Loss: 0.9741926 Test Loss: 0.7593407
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7984642
	speed: 0.0209s/iter; left time: 33.0187s
	iters: 200, epoch: 3 | loss: 0.7762403
	speed: 0.0184s/iter; left time: 27.2879s
Epoch: 3 cost time: 3.928532361984253
Epoch: 3, Steps: 210 | Train Loss: 0.7689889 Vali Loss: 0.9712402 Test Loss: 0.8032094
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7918296
	speed: 0.0172s/iter; left time: 23.5858s
	iters: 200, epoch: 4 | loss: 0.7675141
	speed: 0.0160s/iter; left time: 20.3667s
Epoch: 4 cost time: 3.485112428665161
Epoch: 4, Steps: 210 | Train Loss: 0.7532351 Vali Loss: 0.9742385 Test Loss: 0.8084373
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7604487
	speed: 0.0171s/iter; left time: 19.8222s
	iters: 200, epoch: 5 | loss: 0.7742214
	speed: 0.0147s/iter; left time: 15.5620s
Epoch: 5 cost time: 3.1070005893707275
Epoch: 5, Steps: 210 | Train Loss: 0.7441798 Vali Loss: 0.9596621 Test Loss: 0.8078140
Validation loss decreased (0.969633 --> 0.959662).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7280976
	speed: 0.0168s/iter; left time: 15.9639s
	iters: 200, epoch: 6 | loss: 0.8138791
	speed: 0.0152s/iter; left time: 12.9756s
Epoch: 6 cost time: 3.2091009616851807
Epoch: 6, Steps: 210 | Train Loss: 0.7401554 Vali Loss: 0.9894803 Test Loss: 0.8179390
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7889031
	speed: 0.0226s/iter; left time: 16.7333s
	iters: 200, epoch: 7 | loss: 0.7008826
	speed: 0.0198s/iter; left time: 12.6760s
Epoch: 7 cost time: 4.212339639663696
Epoch: 7, Steps: 210 | Train Loss: 0.7382824 Vali Loss: 0.9750563 Test Loss: 0.8156994
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7657017
	speed: 0.0183s/iter; left time: 9.6997s
	iters: 200, epoch: 8 | loss: 0.7308816
	speed: 0.0184s/iter; left time: 7.9233s
Epoch: 8 cost time: 3.9053292274475098
Epoch: 8, Steps: 210 | Train Loss: 0.7369068 Vali Loss: 0.9812235 Test Loss: 0.8182429
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7890821
	speed: 0.0180s/iter; left time: 5.7833s
	iters: 200, epoch: 9 | loss: 0.7734067
	speed: 0.0146s/iter; left time: 3.2339s
Epoch: 9 cost time: 3.105984926223755
Epoch: 9, Steps: 210 | Train Loss: 0.7359185 Vali Loss: 0.9833289 Test Loss: 0.8179396
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6750392
	speed: 0.0162s/iter; left time: 1.7943s
	iters: 200, epoch: 10 | loss: 0.7170157
	speed: 0.0151s/iter; left time: 0.1666s
Epoch: 10 cost time: 3.2999861240386963
Epoch: 10, Steps: 210 | Train Loss: 0.7356186 Vali Loss: 0.9768097 Test Loss: 0.8185893
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.807813823223114, mae:0.7162203192710876
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8341298
	speed: 0.0200s/iter; left time: 40.0454s
	iters: 200, epoch: 1 | loss: 0.7968439
	speed: 0.0179s/iter; left time: 34.0475s
Epoch: 1 cost time: 3.850050687789917
Epoch: 1, Steps: 210 | Train Loss: 0.8341094 Vali Loss: 0.9766346 Test Loss: 0.7784160
Validation loss decreased (inf --> 0.976635).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7318208
	speed: 0.0178s/iter; left time: 31.8402s
	iters: 200, epoch: 2 | loss: 0.7480197
	speed: 0.0154s/iter; left time: 26.0432s
Epoch: 2 cost time: 3.3054609298706055
Epoch: 2, Steps: 210 | Train Loss: 0.7907990 Vali Loss: 0.9470114 Test Loss: 0.7567072
Validation loss decreased (0.976635 --> 0.947011).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7148361
	speed: 0.0155s/iter; left time: 24.5464s
	iters: 200, epoch: 3 | loss: 0.7209510
	speed: 0.0136s/iter; left time: 20.1623s
Epoch: 3 cost time: 2.9293627738952637
Epoch: 3, Steps: 210 | Train Loss: 0.7685867 Vali Loss: 1.0187190 Test Loss: 0.7937403
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7141113
	speed: 0.0173s/iter; left time: 23.6946s
	iters: 200, epoch: 4 | loss: 0.6955795
	speed: 0.0162s/iter; left time: 20.6516s
Epoch: 4 cost time: 3.5103139877319336
Epoch: 4, Steps: 210 | Train Loss: 0.7536493 Vali Loss: 1.0006689 Test Loss: 0.8080595
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7809093
	speed: 0.0175s/iter; left time: 20.3365s
	iters: 200, epoch: 5 | loss: 0.7575512
	speed: 0.0162s/iter; left time: 17.1832s
Epoch: 5 cost time: 3.5915322303771973
Epoch: 5, Steps: 210 | Train Loss: 0.7457036 Vali Loss: 0.9888732 Test Loss: 0.8029767
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7413421
	speed: 0.0206s/iter; left time: 19.5507s
	iters: 200, epoch: 6 | loss: 0.7677273
	speed: 0.0178s/iter; left time: 15.1494s
Epoch: 6 cost time: 3.7846410274505615
Epoch: 6, Steps: 210 | Train Loss: 0.7410218 Vali Loss: 0.9927883 Test Loss: 0.8035545
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7321687
	speed: 0.0156s/iter; left time: 11.5857s
	iters: 200, epoch: 7 | loss: 0.7296461
	speed: 0.0157s/iter; left time: 10.0380s
Epoch: 7 cost time: 3.3455770015716553
Epoch: 7, Steps: 210 | Train Loss: 0.7397291 Vali Loss: 1.0030459 Test Loss: 0.8106936
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7567072510719299, mae:0.6941173076629639
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7471952
	speed: 0.0181s/iter; left time: 36.1728s
	iters: 200, epoch: 1 | loss: 0.8683114
	speed: 0.0205s/iter; left time: 38.9186s
Epoch: 1 cost time: 4.27360725402832
Epoch: 1, Steps: 210 | Train Loss: 0.8354223 Vali Loss: 0.8696515 Test Loss: 0.7349846
Validation loss decreased (inf --> 0.869651).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8005278
	speed: 0.0183s/iter; left time: 32.7411s
	iters: 200, epoch: 2 | loss: 0.7449777
	speed: 0.0154s/iter; left time: 25.9666s
Epoch: 2 cost time: 3.3522555828094482
Epoch: 2, Steps: 210 | Train Loss: 0.7914004 Vali Loss: 0.9430172 Test Loss: 0.7589591
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7687650
	speed: 0.0235s/iter; left time: 37.1372s
	iters: 200, epoch: 3 | loss: 0.7843338
	speed: 0.0182s/iter; left time: 26.9914s
Epoch: 3 cost time: 3.853506326675415
Epoch: 3, Steps: 210 | Train Loss: 0.7708754 Vali Loss: 1.0116420 Test Loss: 0.8037778
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7134752
	speed: 0.0226s/iter; left time: 31.0313s
	iters: 200, epoch: 4 | loss: 0.7872095
	speed: 0.0169s/iter; left time: 21.4337s
Epoch: 4 cost time: 3.5817317962646484
Epoch: 4, Steps: 210 | Train Loss: 0.7551578 Vali Loss: 0.9763202 Test Loss: 0.7938515
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7774286
	speed: 0.0173s/iter; left time: 20.1332s
	iters: 200, epoch: 5 | loss: 0.7600725
	speed: 0.0157s/iter; left time: 16.6537s
Epoch: 5 cost time: 3.4133293628692627
Epoch: 5, Steps: 210 | Train Loss: 0.7471133 Vali Loss: 0.9894082 Test Loss: 0.7979307
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7317426
	speed: 0.0174s/iter; left time: 16.5689s
	iters: 200, epoch: 6 | loss: 0.7379516
	speed: 0.0177s/iter; left time: 15.0451s
Epoch: 6 cost time: 3.786689043045044
Epoch: 6, Steps: 210 | Train Loss: 0.7434116 Vali Loss: 0.9713811 Test Loss: 0.7952852
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7349845767021179, mae:0.6846671104431152
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8824848
	speed: 0.0274s/iter; left time: 53.6461s
	iters: 200, epoch: 1 | loss: 0.9263737
	speed: 0.0211s/iter; left time: 39.1920s
Epoch: 1 cost time: 4.399568319320679
Epoch: 1, Steps: 206 | Train Loss: 0.9548573 Vali Loss: 1.1499128 Test Loss: 0.8571770
Validation loss decreased (inf --> 1.149913).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9216823
	speed: 0.0192s/iter; left time: 33.7025s
	iters: 200, epoch: 2 | loss: 0.8667482
	speed: 0.0166s/iter; left time: 27.5141s
Epoch: 2 cost time: 3.5466115474700928
Epoch: 2, Steps: 206 | Train Loss: 0.9003295 Vali Loss: 1.0671959 Test Loss: 0.8422124
Validation loss decreased (1.149913 --> 1.067196).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8961505
	speed: 0.0185s/iter; left time: 28.6311s
	iters: 200, epoch: 3 | loss: 0.8435650
	speed: 0.0162s/iter; left time: 23.4584s
Epoch: 3 cost time: 3.4313502311706543
Epoch: 3, Steps: 206 | Train Loss: 0.8749187 Vali Loss: 1.0746927 Test Loss: 0.8474007
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8751993
	speed: 0.0167s/iter; left time: 22.4158s
	iters: 200, epoch: 4 | loss: 0.8105231
	speed: 0.0138s/iter; left time: 17.2050s
Epoch: 4 cost time: 2.9360504150390625
Epoch: 4, Steps: 206 | Train Loss: 0.8563254 Vali Loss: 1.0769126 Test Loss: 0.8597825
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8824625
	speed: 0.0160s/iter; left time: 18.1989s
	iters: 200, epoch: 5 | loss: 0.7935198
	speed: 0.0126s/iter; left time: 13.0650s
Epoch: 5 cost time: 2.7025017738342285
Epoch: 5, Steps: 206 | Train Loss: 0.8459605 Vali Loss: 1.1106281 Test Loss: 0.8742520
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8415557
	speed: 0.0200s/iter; left time: 18.6553s
	iters: 200, epoch: 6 | loss: 0.8652911
	speed: 0.0168s/iter; left time: 13.9740s
Epoch: 6 cost time: 3.557314872741699
Epoch: 6, Steps: 206 | Train Loss: 0.8394606 Vali Loss: 1.1038631 Test Loss: 0.8669569
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8616194
	speed: 0.0182s/iter; left time: 13.2139s
	iters: 200, epoch: 7 | loss: 0.8477563
	speed: 0.0172s/iter; left time: 10.7781s
Epoch: 7 cost time: 3.6214094161987305
Epoch: 7, Steps: 206 | Train Loss: 0.8359606 Vali Loss: 1.1105008 Test Loss: 0.8715703
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8422123789787292, mae:0.7351577281951904
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9344061
	speed: 0.0153s/iter; left time: 30.0539s
	iters: 200, epoch: 1 | loss: 0.9495966
	speed: 0.0132s/iter; left time: 24.4955s
Epoch: 1 cost time: 2.739079713821411
Epoch: 1, Steps: 206 | Train Loss: 0.9537687 Vali Loss: 1.0961386 Test Loss: 0.8335248
Validation loss decreased (inf --> 1.096139).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8927791
	speed: 0.0141s/iter; left time: 24.6579s
	iters: 200, epoch: 2 | loss: 0.8634962
	speed: 0.0117s/iter; left time: 19.4239s
Epoch: 2 cost time: 2.52758526802063
Epoch: 2, Steps: 206 | Train Loss: 0.8986870 Vali Loss: 1.0643458 Test Loss: 0.8447019
Validation loss decreased (1.096139 --> 1.064346).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8492061
	speed: 0.0173s/iter; left time: 26.8711s
	iters: 200, epoch: 3 | loss: 0.8984241
	speed: 0.0159s/iter; left time: 23.0496s
Epoch: 3 cost time: 3.3859031200408936
Epoch: 3, Steps: 206 | Train Loss: 0.8729232 Vali Loss: 1.1111755 Test Loss: 0.8708278
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8396503
	speed: 0.0166s/iter; left time: 22.2380s
	iters: 200, epoch: 4 | loss: 0.8649409
	speed: 0.0151s/iter; left time: 18.7400s
Epoch: 4 cost time: 3.216266393661499
Epoch: 4, Steps: 206 | Train Loss: 0.8563617 Vali Loss: 1.1055201 Test Loss: 0.8675440
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8542174
	speed: 0.0179s/iter; left time: 20.3784s
	iters: 200, epoch: 5 | loss: 0.8106724
	speed: 0.0177s/iter; left time: 18.3073s
Epoch: 5 cost time: 3.679638624191284
Epoch: 5, Steps: 206 | Train Loss: 0.8472381 Vali Loss: 1.1106150 Test Loss: 0.8771814
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8251626
	speed: 0.0175s/iter; left time: 16.3219s
	iters: 200, epoch: 6 | loss: 0.8345813
	speed: 0.0156s/iter; left time: 12.9643s
Epoch: 6 cost time: 3.2873029708862305
Epoch: 6, Steps: 206 | Train Loss: 0.8412501 Vali Loss: 1.1034153 Test Loss: 0.8753793
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8436553
	speed: 0.0140s/iter; left time: 10.1853s
	iters: 200, epoch: 7 | loss: 0.8331310
	speed: 0.0123s/iter; left time: 7.7033s
Epoch: 7 cost time: 2.6421778202056885
Epoch: 7, Steps: 206 | Train Loss: 0.8384631 Vali Loss: 1.1168793 Test Loss: 0.8837819
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8447016477584839, mae:0.7362794280052185
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8963795
	speed: 0.0177s/iter; left time: 34.7041s
	iters: 200, epoch: 1 | loss: 0.9439397
	speed: 0.0168s/iter; left time: 31.2569s
Epoch: 1 cost time: 3.548570156097412
Epoch: 1, Steps: 206 | Train Loss: 0.9531590 Vali Loss: 1.0929629 Test Loss: 0.8296502
Validation loss decreased (inf --> 1.092963).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8859589
	speed: 0.0217s/iter; left time: 38.1294s
	iters: 200, epoch: 2 | loss: 0.8635649
	speed: 0.0178s/iter; left time: 29.4991s
Epoch: 2 cost time: 3.707014799118042
Epoch: 2, Steps: 206 | Train Loss: 0.9016386 Vali Loss: 1.1435214 Test Loss: 0.8576074
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8584619
	speed: 0.0279s/iter; left time: 43.2300s
	iters: 200, epoch: 3 | loss: 0.8961031
	speed: 0.0209s/iter; left time: 30.3534s
Epoch: 3 cost time: 4.350378751754761
Epoch: 3, Steps: 206 | Train Loss: 0.8758164 Vali Loss: 1.1033803 Test Loss: 0.8515241
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8789172
	speed: 0.0169s/iter; left time: 22.6635s
	iters: 200, epoch: 4 | loss: 0.8792459
	speed: 0.0147s/iter; left time: 18.2799s
Epoch: 4 cost time: 3.0893826484680176
Epoch: 4, Steps: 206 | Train Loss: 0.8585431 Vali Loss: 1.1208539 Test Loss: 0.8581961
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8501302
	speed: 0.0210s/iter; left time: 23.8961s
	iters: 200, epoch: 5 | loss: 0.8130925
	speed: 0.0179s/iter; left time: 18.5376s
Epoch: 5 cost time: 3.7774899005889893
Epoch: 5, Steps: 206 | Train Loss: 0.8475630 Vali Loss: 1.1396666 Test Loss: 0.8696254
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8963239
	speed: 0.0181s/iter; left time: 16.8914s
	iters: 200, epoch: 6 | loss: 0.8370080
	speed: 0.0160s/iter; left time: 13.2570s
Epoch: 6 cost time: 3.3703911304473877
Epoch: 6, Steps: 206 | Train Loss: 0.8425487 Vali Loss: 1.1392035 Test Loss: 0.8751785
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8296501040458679, mae:0.7283701300621033
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1717218
	speed: 0.0317s/iter; left time: 58.4511s
Epoch: 1 cost time: 4.669278383255005
Epoch: 1, Steps: 194 | Train Loss: 1.1546212 Vali Loss: 1.6340656 Test Loss: 0.9089744
Validation loss decreased (inf --> 1.634066).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0443035
	speed: 0.0158s/iter; left time: 26.0341s
Epoch: 2 cost time: 2.7427985668182373
Epoch: 2, Steps: 194 | Train Loss: 1.0620680 Vali Loss: 1.6297396 Test Loss: 0.8962016
Validation loss decreased (1.634066 --> 1.629740).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0581195
	speed: 0.0241s/iter; left time: 35.0578s
Epoch: 3 cost time: 3.684025526046753
Epoch: 3, Steps: 194 | Train Loss: 0.9985882 Vali Loss: 1.6228373 Test Loss: 0.8877847
Validation loss decreased (1.629740 --> 1.622837).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9670315
	speed: 0.0166s/iter; left time: 20.8641s
Epoch: 4 cost time: 2.968086004257202
Epoch: 4, Steps: 194 | Train Loss: 0.9767400 Vali Loss: 1.7215513 Test Loss: 0.8915631
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9497211
	speed: 0.0171s/iter; left time: 18.2109s
Epoch: 5 cost time: 3.166193723678589
Epoch: 5, Steps: 194 | Train Loss: 0.9664096 Vali Loss: 1.7705938 Test Loss: 0.8977376
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0113162
	speed: 0.0142s/iter; left time: 12.3702s
Epoch: 6 cost time: 2.9851245880126953
Epoch: 6, Steps: 194 | Train Loss: 0.9603303 Vali Loss: 1.7631736 Test Loss: 0.8994368
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9507043
	speed: 0.0167s/iter; left time: 11.3325s
Epoch: 7 cost time: 3.1385748386383057
Epoch: 7, Steps: 194 | Train Loss: 0.9563238 Vali Loss: 1.7658664 Test Loss: 0.8975228
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0496621
	speed: 0.0191s/iter; left time: 9.2412s
Epoch: 8 cost time: 3.3178870677948
Epoch: 8, Steps: 194 | Train Loss: 0.9558647 Vali Loss: 1.7712601 Test Loss: 0.8982504
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8877847194671631, mae:0.755160391330719
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1695786
	speed: 0.0110s/iter; left time: 20.2848s
Epoch: 1 cost time: 2.397339344024658
Epoch: 1, Steps: 194 | Train Loss: 1.1532838 Vali Loss: 1.6656376 Test Loss: 0.9078745
Validation loss decreased (inf --> 1.665638).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1458318
	speed: 0.0175s/iter; left time: 28.7628s
Epoch: 2 cost time: 3.3250136375427246
Epoch: 2, Steps: 194 | Train Loss: 1.0623483 Vali Loss: 1.6267700 Test Loss: 0.8886526
Validation loss decreased (1.665638 --> 1.626770).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0261195
	speed: 0.0184s/iter; left time: 26.7289s
Epoch: 3 cost time: 3.205132484436035
Epoch: 3, Steps: 194 | Train Loss: 0.9988799 Vali Loss: 1.7729377 Test Loss: 0.9019545
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8901359
	speed: 0.0167s/iter; left time: 21.0292s
Epoch: 4 cost time: 2.960780620574951
Epoch: 4, Steps: 194 | Train Loss: 0.9768530 Vali Loss: 1.7249919 Test Loss: 0.8954079
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9154319
	speed: 0.0161s/iter; left time: 17.1240s
Epoch: 5 cost time: 2.87084698677063
Epoch: 5, Steps: 194 | Train Loss: 0.9684997 Vali Loss: 1.7680775 Test Loss: 0.8930818
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0013571
	speed: 0.0119s/iter; left time: 10.3294s
Epoch: 6 cost time: 2.6962461471557617
Epoch: 6, Steps: 194 | Train Loss: 0.9619926 Vali Loss: 1.7887865 Test Loss: 0.8958903
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9127719
	speed: 0.0130s/iter; left time: 8.7931s
Epoch: 7 cost time: 2.7484474182128906
Epoch: 7, Steps: 194 | Train Loss: 0.9610119 Vali Loss: 1.8257059 Test Loss: 0.9012119
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8886525630950928, mae:0.7555680871009827
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1687504
	speed: 0.0134s/iter; left time: 24.6677s
Epoch: 1 cost time: 2.61763072013855
Epoch: 1, Steps: 194 | Train Loss: 1.1560514 Vali Loss: 1.7087454 Test Loss: 0.9174283
Validation loss decreased (inf --> 1.708745).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9889700
	speed: 0.0179s/iter; left time: 29.4564s
Epoch: 2 cost time: 2.968775749206543
Epoch: 2, Steps: 194 | Train Loss: 1.0665835 Vali Loss: 1.7631921 Test Loss: 0.8978099
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0154325
	speed: 0.0178s/iter; left time: 25.9247s
Epoch: 3 cost time: 3.678368330001831
Epoch: 3, Steps: 194 | Train Loss: 0.9988133 Vali Loss: 1.8466574 Test Loss: 0.8988428
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9654384
	speed: 0.0130s/iter; left time: 16.4212s
Epoch: 4 cost time: 2.4832983016967773
Epoch: 4, Steps: 194 | Train Loss: 0.9759316 Vali Loss: 1.8207321 Test Loss: 0.8976386
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8842239
	speed: 0.0165s/iter; left time: 17.5685s
Epoch: 5 cost time: 3.4934117794036865
Epoch: 5, Steps: 194 | Train Loss: 0.9643348 Vali Loss: 1.8518952 Test Loss: 0.8998076
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9366420
	speed: 0.0180s/iter; left time: 15.6794s
Epoch: 6 cost time: 3.4389355182647705
Epoch: 6, Steps: 194 | Train Loss: 0.9594198 Vali Loss: 1.8891163 Test Loss: 0.9041272
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9174282550811768, mae:0.7674100399017334
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0528531
	speed: 0.0277s/iter; left time: 56.1933s
	iters: 200, epoch: 1 | loss: 1.0486058
	speed: 0.0209s/iter; left time: 40.4073s
Epoch: 1 cost time: 4.438604831695557
Epoch: 1, Steps: 213 | Train Loss: 1.0886798 Vali Loss: 1.0586677 Test Loss: 1.0479267
Validation loss decreased (inf --> 1.058668).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0366650
	speed: 0.0187s/iter; left time: 33.9069s
	iters: 200, epoch: 2 | loss: 1.0228761
	speed: 0.0173s/iter; left time: 29.6761s
Epoch: 2 cost time: 3.768118381500244
Epoch: 2, Steps: 213 | Train Loss: 1.0343084 Vali Loss: 1.0521631 Test Loss: 1.0468813
Validation loss decreased (1.058668 --> 1.052163).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0354829
	speed: 0.0268s/iter; left time: 42.9885s
	iters: 200, epoch: 3 | loss: 0.9974587
	speed: 0.0245s/iter; left time: 36.8861s
Epoch: 3 cost time: 5.213850259780884
Epoch: 3, Steps: 213 | Train Loss: 1.0255238 Vali Loss: 1.0541198 Test Loss: 1.0471061
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0418463
	speed: 0.0142s/iter; left time: 19.7485s
	iters: 200, epoch: 4 | loss: 1.0462480
	speed: 0.0142s/iter; left time: 18.3624s
Epoch: 4 cost time: 3.0577783584594727
Epoch: 4, Steps: 213 | Train Loss: 1.0204221 Vali Loss: 1.0507855 Test Loss: 1.0453349
Validation loss decreased (1.052163 --> 1.050786).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9899682
	speed: 0.0297s/iter; left time: 35.0215s
	iters: 200, epoch: 5 | loss: 1.0061082
	speed: 0.0247s/iter; left time: 26.6535s
Epoch: 5 cost time: 5.146820783615112
Epoch: 5, Steps: 213 | Train Loss: 1.0178255 Vali Loss: 1.0512998 Test Loss: 1.0459877
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0294865
	speed: 0.0241s/iter; left time: 23.2666s
	iters: 200, epoch: 6 | loss: 1.0114403
	speed: 0.0193s/iter; left time: 16.7445s
Epoch: 6 cost time: 4.3448333740234375
Epoch: 6, Steps: 213 | Train Loss: 1.0154419 Vali Loss: 1.0517411 Test Loss: 1.0460188
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0128453
	speed: 0.0224s/iter; left time: 16.8804s
	iters: 200, epoch: 7 | loss: 1.0080150
	speed: 0.0174s/iter; left time: 11.3539s
Epoch: 7 cost time: 3.751802444458008
Epoch: 7, Steps: 213 | Train Loss: 1.0144706 Vali Loss: 1.0509133 Test Loss: 1.0460063
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0564227
	speed: 0.0141s/iter; left time: 7.6311s
	iters: 200, epoch: 8 | loss: 0.9931374
	speed: 0.0116s/iter; left time: 5.1062s
Epoch: 8 cost time: 2.483311414718628
Epoch: 8, Steps: 213 | Train Loss: 1.0140265 Vali Loss: 1.0506040 Test Loss: 1.0460422
Validation loss decreased (1.050786 --> 1.050604).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0143425
	speed: 0.0141s/iter; left time: 4.6113s
	iters: 200, epoch: 9 | loss: 0.9960598
	speed: 0.0119s/iter; left time: 2.6951s
Epoch: 9 cost time: 2.591218948364258
Epoch: 9, Steps: 213 | Train Loss: 1.0140725 Vali Loss: 1.0519922 Test Loss: 1.0460632
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0532825
	speed: 0.0141s/iter; left time: 1.6061s
	iters: 200, epoch: 10 | loss: 0.9987110
	speed: 0.0120s/iter; left time: 0.1684s
Epoch: 10 cost time: 2.6355860233306885
Epoch: 10, Steps: 213 | Train Loss: 1.0136113 Vali Loss: 1.0521749 Test Loss: 1.0460900
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0460423231124878, mae:0.8209149241447449
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0623205
	speed: 0.0134s/iter; left time: 27.3128s
	iters: 200, epoch: 1 | loss: 1.0435184
	speed: 0.0153s/iter; left time: 29.5492s
Epoch: 1 cost time: 3.3380770683288574
Epoch: 1, Steps: 213 | Train Loss: 1.0861633 Vali Loss: 1.0573158 Test Loss: 1.0479331
Validation loss decreased (inf --> 1.057316).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0152767
	speed: 0.0143s/iter; left time: 25.9178s
	iters: 200, epoch: 2 | loss: 1.0734818
	speed: 0.0138s/iter; left time: 23.6560s
Epoch: 2 cost time: 3.1693804264068604
Epoch: 2, Steps: 213 | Train Loss: 1.0343757 Vali Loss: 1.0538739 Test Loss: 1.0477164
Validation loss decreased (1.057316 --> 1.053874).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0100131
	speed: 0.0184s/iter; left time: 29.5186s
	iters: 200, epoch: 3 | loss: 1.0479969
	speed: 0.0170s/iter; left time: 25.6146s
Epoch: 3 cost time: 3.8865649700164795
Epoch: 3, Steps: 213 | Train Loss: 1.0257213 Vali Loss: 1.0517114 Test Loss: 1.0451208
Validation loss decreased (1.053874 --> 1.051711).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0269151
	speed: 0.0170s/iter; left time: 23.6124s
	iters: 200, epoch: 4 | loss: 0.9674746
	speed: 0.0140s/iter; left time: 18.1094s
Epoch: 4 cost time: 3.1065380573272705
Epoch: 4, Steps: 213 | Train Loss: 1.0205399 Vali Loss: 1.0522981 Test Loss: 1.0457201
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0306869
	speed: 0.0127s/iter; left time: 14.9383s
	iters: 200, epoch: 5 | loss: 1.0563579
	speed: 0.0135s/iter; left time: 14.5254s
Epoch: 5 cost time: 3.00425386428833
Epoch: 5, Steps: 213 | Train Loss: 1.0178394 Vali Loss: 1.0526407 Test Loss: 1.0456756
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0282505
	speed: 0.0225s/iter; left time: 21.7536s
	iters: 200, epoch: 6 | loss: 1.0397729
	speed: 0.0205s/iter; left time: 17.7651s
Epoch: 6 cost time: 4.343988418579102
Epoch: 6, Steps: 213 | Train Loss: 1.0159125 Vali Loss: 1.0521338 Test Loss: 1.0458376
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0039854
	speed: 0.0183s/iter; left time: 13.7569s
	iters: 200, epoch: 7 | loss: 1.0019671
	speed: 0.0196s/iter; left time: 12.8191s
Epoch: 7 cost time: 4.173986434936523
Epoch: 7, Steps: 213 | Train Loss: 1.0148919 Vali Loss: 1.0514281 Test Loss: 1.0458121
Validation loss decreased (1.051711 --> 1.051428).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0016451
	speed: 0.0167s/iter; left time: 9.0120s
	iters: 200, epoch: 8 | loss: 1.0249525
	speed: 0.0147s/iter; left time: 6.4588s
Epoch: 8 cost time: 3.2207319736480713
Epoch: 8, Steps: 213 | Train Loss: 1.0144376 Vali Loss: 1.0528616 Test Loss: 1.0458492
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0033519
	speed: 0.0168s/iter; left time: 5.4841s
	iters: 200, epoch: 9 | loss: 0.9706731
	speed: 0.0152s/iter; left time: 3.4611s
Epoch: 9 cost time: 3.4027984142303467
Epoch: 9, Steps: 213 | Train Loss: 1.0140923 Vali Loss: 1.0537254 Test Loss: 1.0458912
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9799654
	speed: 0.0224s/iter; left time: 2.5509s
	iters: 200, epoch: 10 | loss: 1.0261081
	speed: 0.0188s/iter; left time: 0.2628s
Epoch: 10 cost time: 4.09145712852478
Epoch: 10, Steps: 213 | Train Loss: 1.0138526 Vali Loss: 1.0530719 Test Loss: 1.0459254
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0458121299743652, mae:0.8207997679710388
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0283960
	speed: 0.0257s/iter; left time: 52.2217s
	iters: 200, epoch: 1 | loss: 1.0488007
	speed: 0.0209s/iter; left time: 40.3761s
Epoch: 1 cost time: 4.378298282623291
Epoch: 1, Steps: 213 | Train Loss: 1.0866585 Vali Loss: 1.0602337 Test Loss: 1.0463946
Validation loss decreased (inf --> 1.060234).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0209293
	speed: 0.0163s/iter; left time: 29.6551s
	iters: 200, epoch: 2 | loss: 1.0355512
	speed: 0.0128s/iter; left time: 21.9891s
Epoch: 2 cost time: 2.744987964630127
Epoch: 2, Steps: 213 | Train Loss: 1.0348821 Vali Loss: 1.0545418 Test Loss: 1.0464834
Validation loss decreased (1.060234 --> 1.054542).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0617816
	speed: 0.0137s/iter; left time: 22.0398s
	iters: 200, epoch: 3 | loss: 1.0042357
	speed: 0.0135s/iter; left time: 20.3191s
Epoch: 3 cost time: 2.8930933475494385
Epoch: 3, Steps: 213 | Train Loss: 1.0254084 Vali Loss: 1.0528389 Test Loss: 1.0449349
Validation loss decreased (1.054542 --> 1.052839).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0462315
	speed: 0.0223s/iter; left time: 30.9800s
	iters: 200, epoch: 4 | loss: 1.0385898
	speed: 0.0187s/iter; left time: 24.2096s
Epoch: 4 cost time: 3.9566495418548584
Epoch: 4, Steps: 213 | Train Loss: 1.0202799 Vali Loss: 1.0502286 Test Loss: 1.0445347
Validation loss decreased (1.052839 --> 1.050229).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0674757
	speed: 0.0259s/iter; left time: 30.4898s
	iters: 200, epoch: 5 | loss: 0.9848568
	speed: 0.0183s/iter; left time: 19.7029s
Epoch: 5 cost time: 3.8459432125091553
Epoch: 5, Steps: 213 | Train Loss: 1.0172510 Vali Loss: 1.0518205 Test Loss: 1.0450521
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0120628
	speed: 0.0147s/iter; left time: 14.2018s
	iters: 200, epoch: 6 | loss: 1.0013535
	speed: 0.0114s/iter; left time: 9.8914s
Epoch: 6 cost time: 2.549360752105713
Epoch: 6, Steps: 213 | Train Loss: 1.0155388 Vali Loss: 1.0536346 Test Loss: 1.0448370
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0232196
	speed: 0.0219s/iter; left time: 16.4747s
	iters: 200, epoch: 7 | loss: 1.0759970
	speed: 0.0171s/iter; left time: 11.1685s
Epoch: 7 cost time: 3.7211029529571533
Epoch: 7, Steps: 213 | Train Loss: 1.0151658 Vali Loss: 1.0502957 Test Loss: 1.0449451
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9947798
	speed: 0.0240s/iter; left time: 12.9492s
	iters: 200, epoch: 8 | loss: 1.0176311
	speed: 0.0194s/iter; left time: 8.5401s
Epoch: 8 cost time: 4.187012672424316
Epoch: 8, Steps: 213 | Train Loss: 1.0140958 Vali Loss: 1.0535116 Test Loss: 1.0450062
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0006369
	speed: 0.0163s/iter; left time: 5.3229s
	iters: 200, epoch: 9 | loss: 1.0265670
	speed: 0.0145s/iter; left time: 3.2950s
Epoch: 9 cost time: 3.150498390197754
Epoch: 9, Steps: 213 | Train Loss: 1.0142198 Vali Loss: 1.0504814 Test Loss: 1.0450637
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0445345640182495, mae:0.8202731609344482
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0578735
	speed: 0.0279s/iter; left time: 55.9078s
	iters: 200, epoch: 1 | loss: 1.0697237
	speed: 0.0212s/iter; left time: 40.3506s
Epoch: 1 cost time: 4.453495264053345
Epoch: 1, Steps: 210 | Train Loss: 1.0895145 Vali Loss: 1.0690374 Test Loss: 1.0527846
Validation loss decreased (inf --> 1.069037).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0201607
	speed: 0.0171s/iter; left time: 30.6035s
	iters: 200, epoch: 2 | loss: 1.0300759
	speed: 0.0150s/iter; left time: 25.3876s
Epoch: 2 cost time: 3.2595436573028564
Epoch: 2, Steps: 210 | Train Loss: 1.0422189 Vali Loss: 1.0639498 Test Loss: 1.0537577
Validation loss decreased (1.069037 --> 1.063950).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0554938
	speed: 0.0127s/iter; left time: 20.1456s
	iters: 200, epoch: 3 | loss: 1.0549606
	speed: 0.0111s/iter; left time: 16.4210s
Epoch: 3 cost time: 2.471888542175293
Epoch: 3, Steps: 210 | Train Loss: 1.0348450 Vali Loss: 1.0609199 Test Loss: 1.0524844
Validation loss decreased (1.063950 --> 1.060920).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9931474
	speed: 0.0144s/iter; left time: 19.7817s
	iters: 200, epoch: 4 | loss: 1.0633107
	speed: 0.0133s/iter; left time: 16.9295s
Epoch: 4 cost time: 2.910031795501709
Epoch: 4, Steps: 210 | Train Loss: 1.0305864 Vali Loss: 1.0609015 Test Loss: 1.0523381
Validation loss decreased (1.060920 --> 1.060902).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0236074
	speed: 0.0192s/iter; left time: 22.3047s
	iters: 200, epoch: 5 | loss: 1.0402383
	speed: 0.0159s/iter; left time: 16.8740s
Epoch: 5 cost time: 3.4235923290252686
Epoch: 5, Steps: 210 | Train Loss: 1.0283163 Vali Loss: 1.0585791 Test Loss: 1.0523156
Validation loss decreased (1.060902 --> 1.058579).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0245132
	speed: 0.0277s/iter; left time: 26.3136s
	iters: 200, epoch: 6 | loss: 1.0284990
	speed: 0.0218s/iter; left time: 18.5534s
Epoch: 6 cost time: 4.498075723648071
Epoch: 6, Steps: 210 | Train Loss: 1.0268192 Vali Loss: 1.0606449 Test Loss: 1.0525273
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0263609
	speed: 0.0163s/iter; left time: 12.0725s
	iters: 200, epoch: 7 | loss: 1.0171245
	speed: 0.0132s/iter; left time: 8.4847s
Epoch: 7 cost time: 2.899944305419922
Epoch: 7, Steps: 210 | Train Loss: 1.0266146 Vali Loss: 1.0572295 Test Loss: 1.0520549
Validation loss decreased (1.058579 --> 1.057230).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0221459
	speed: 0.0172s/iter; left time: 9.1101s
	iters: 200, epoch: 8 | loss: 1.0121115
	speed: 0.0160s/iter; left time: 6.8984s
Epoch: 8 cost time: 3.516497850418091
Epoch: 8, Steps: 210 | Train Loss: 1.0258171 Vali Loss: 1.0585442 Test Loss: 1.0520768
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0341610
	speed: 0.0237s/iter; left time: 7.6037s
	iters: 200, epoch: 9 | loss: 1.0384541
	speed: 0.0182s/iter; left time: 4.0241s
Epoch: 9 cost time: 3.816889762878418
Epoch: 9, Steps: 210 | Train Loss: 1.0260238 Vali Loss: 1.0578202 Test Loss: 1.0521423
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0421650
	speed: 0.0327s/iter; left time: 3.6349s
	iters: 200, epoch: 10 | loss: 1.0352957
	speed: 0.0224s/iter; left time: 0.2462s
Epoch: 10 cost time: 4.679011821746826
Epoch: 10, Steps: 210 | Train Loss: 1.0258115 Vali Loss: 1.0586194 Test Loss: 1.0521569
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0520548820495605, mae:0.8228293657302856
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0719255
	speed: 0.0141s/iter; left time: 28.2994s
	iters: 200, epoch: 1 | loss: 1.0592835
	speed: 0.0131s/iter; left time: 24.9971s
Epoch: 1 cost time: 2.7753021717071533
Epoch: 1, Steps: 210 | Train Loss: 1.0895346 Vali Loss: 1.0679677 Test Loss: 1.0540068
Validation loss decreased (inf --> 1.067968).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9952375
	speed: 0.0193s/iter; left time: 34.5898s
	iters: 200, epoch: 2 | loss: 1.0532222
	speed: 0.0171s/iter; left time: 28.9501s
Epoch: 2 cost time: 3.6354074478149414
Epoch: 2, Steps: 210 | Train Loss: 1.0423363 Vali Loss: 1.0648158 Test Loss: 1.0538030
Validation loss decreased (1.067968 --> 1.064816).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0242307
	speed: 0.0208s/iter; left time: 32.9162s
	iters: 200, epoch: 3 | loss: 1.0286317
	speed: 0.0176s/iter; left time: 26.1136s
Epoch: 3 cost time: 3.7700788974761963
Epoch: 3, Steps: 210 | Train Loss: 1.0347242 Vali Loss: 1.0599030 Test Loss: 1.0524845
Validation loss decreased (1.064816 --> 1.059903).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0618448
	speed: 0.0200s/iter; left time: 27.4399s
	iters: 200, epoch: 4 | loss: 1.0427215
	speed: 0.0158s/iter; left time: 20.1097s
Epoch: 4 cost time: 3.321868658065796
Epoch: 4, Steps: 210 | Train Loss: 1.0306201 Vali Loss: 1.0598981 Test Loss: 1.0520598
Validation loss decreased (1.059903 --> 1.059898).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0044141
	speed: 0.0186s/iter; left time: 21.5425s
	iters: 200, epoch: 5 | loss: 1.0461551
	speed: 0.0152s/iter; left time: 16.1158s
Epoch: 5 cost time: 3.2610864639282227
Epoch: 5, Steps: 210 | Train Loss: 1.0284299 Vali Loss: 1.0601442 Test Loss: 1.0519128
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0136274
	speed: 0.0282s/iter; left time: 26.7842s
	iters: 200, epoch: 6 | loss: 0.9987023
	speed: 0.0203s/iter; left time: 17.2700s
Epoch: 6 cost time: 4.274930715560913
Epoch: 6, Steps: 210 | Train Loss: 1.0271035 Vali Loss: 1.0591146 Test Loss: 1.0518740
Validation loss decreased (1.059898 --> 1.059115).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0191027
	speed: 0.0166s/iter; left time: 12.3251s
	iters: 200, epoch: 7 | loss: 1.0360527
	speed: 0.0161s/iter; left time: 10.3139s
Epoch: 7 cost time: 3.424351930618286
Epoch: 7, Steps: 210 | Train Loss: 1.0263892 Vali Loss: 1.0578334 Test Loss: 1.0519367
Validation loss decreased (1.059115 --> 1.057833).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0340720
	speed: 0.0189s/iter; left time: 10.0618s
	iters: 200, epoch: 8 | loss: 1.0160216
	speed: 0.0150s/iter; left time: 6.4492s
Epoch: 8 cost time: 3.1873626708984375
Epoch: 8, Steps: 210 | Train Loss: 1.0261138 Vali Loss: 1.0584172 Test Loss: 1.0518795
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0420938
	speed: 0.0136s/iter; left time: 4.3589s
	iters: 200, epoch: 9 | loss: 1.0031190
	speed: 0.0116s/iter; left time: 2.5703s
Epoch: 9 cost time: 2.5417416095733643
Epoch: 9, Steps: 210 | Train Loss: 1.0256550 Vali Loss: 1.0575337 Test Loss: 1.0519273
Validation loss decreased (1.057833 --> 1.057534).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0288401
	speed: 0.0113s/iter; left time: 1.2531s
	iters: 200, epoch: 10 | loss: 1.0485532
	speed: 0.0109s/iter; left time: 0.1197s
Epoch: 10 cost time: 2.403424024581909
Epoch: 10, Steps: 210 | Train Loss: 1.0259209 Vali Loss: 1.0578710 Test Loss: 1.0519605
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0519273281097412, mae:0.8227936625480652
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0598097
	speed: 0.0143s/iter; left time: 28.6455s
	iters: 200, epoch: 1 | loss: 1.0529875
	speed: 0.0138s/iter; left time: 26.1732s
Epoch: 1 cost time: 3.010615348815918
Epoch: 1, Steps: 210 | Train Loss: 1.0877306 Vali Loss: 1.0649613 Test Loss: 1.0541182
Validation loss decreased (inf --> 1.064961).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0631430
	speed: 0.0176s/iter; left time: 31.5257s
	iters: 200, epoch: 2 | loss: 1.0315757
	speed: 0.0192s/iter; left time: 32.5013s
Epoch: 2 cost time: 4.270705699920654
Epoch: 2, Steps: 210 | Train Loss: 1.0428982 Vali Loss: 1.0663875 Test Loss: 1.0534632
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0597765
	speed: 0.0151s/iter; left time: 23.8340s
	iters: 200, epoch: 3 | loss: 1.0343261
	speed: 0.0151s/iter; left time: 22.3873s
Epoch: 3 cost time: 3.410224676132202
Epoch: 3, Steps: 210 | Train Loss: 1.0353078 Vali Loss: 1.0628318 Test Loss: 1.0530987
Validation loss decreased (1.064961 --> 1.062832).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0328269
	speed: 0.0190s/iter; left time: 26.0772s
	iters: 200, epoch: 4 | loss: 1.0535088
	speed: 0.0172s/iter; left time: 21.9104s
Epoch: 4 cost time: 3.717637777328491
Epoch: 4, Steps: 210 | Train Loss: 1.0308899 Vali Loss: 1.0587032 Test Loss: 1.0521632
Validation loss decreased (1.062832 --> 1.058703).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0503142
	speed: 0.0199s/iter; left time: 23.0492s
	iters: 200, epoch: 5 | loss: 1.0288082
	speed: 0.0200s/iter; left time: 21.1937s
Epoch: 5 cost time: 4.315771579742432
Epoch: 5, Steps: 210 | Train Loss: 1.0288370 Vali Loss: 1.0605719 Test Loss: 1.0519648
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0268434
	speed: 0.0190s/iter; left time: 18.0997s
	iters: 200, epoch: 6 | loss: 1.0362074
	speed: 0.0173s/iter; left time: 14.7483s
Epoch: 6 cost time: 3.745772361755371
Epoch: 6, Steps: 210 | Train Loss: 1.0273761 Vali Loss: 1.0610514 Test Loss: 1.0518293
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0177689
	speed: 0.0192s/iter; left time: 14.2555s
	iters: 200, epoch: 7 | loss: 1.0002315
	speed: 0.0162s/iter; left time: 10.3558s
Epoch: 7 cost time: 3.499584674835205
Epoch: 7, Steps: 210 | Train Loss: 1.0265558 Vali Loss: 1.0592548 Test Loss: 1.0520254
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0524229
	speed: 0.0157s/iter; left time: 8.3172s
	iters: 200, epoch: 8 | loss: 0.9932932
	speed: 0.0164s/iter; left time: 7.0653s
Epoch: 8 cost time: 3.5319817066192627
Epoch: 8, Steps: 210 | Train Loss: 1.0263872 Vali Loss: 1.0588777 Test Loss: 1.0521148
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0576099
	speed: 0.0188s/iter; left time: 6.0218s
	iters: 200, epoch: 9 | loss: 1.0087295
	speed: 0.0162s/iter; left time: 3.5820s
Epoch: 9 cost time: 3.4833433628082275
Epoch: 9, Steps: 210 | Train Loss: 1.0261402 Vali Loss: 1.0610265 Test Loss: 1.0521070
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0521633625030518, mae:0.8227657079696655
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0757258
	speed: 0.0249s/iter; left time: 48.9129s
	iters: 200, epoch: 1 | loss: 1.0382903
	speed: 0.0164s/iter; left time: 30.4412s
Epoch: 1 cost time: 3.386157512664795
Epoch: 1, Steps: 206 | Train Loss: 1.0921812 Vali Loss: 1.0596695 Test Loss: 1.0441524
Validation loss decreased (inf --> 1.059669).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0890495
	speed: 0.0217s/iter; left time: 38.0133s
	iters: 200, epoch: 2 | loss: 1.0424998
	speed: 0.0164s/iter; left time: 27.0647s
Epoch: 2 cost time: 3.4254817962646484
Epoch: 2, Steps: 206 | Train Loss: 1.0478679 Vali Loss: 1.0580447 Test Loss: 1.0439277
Validation loss decreased (1.059669 --> 1.058045).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0706537
	speed: 0.0279s/iter; left time: 43.2438s
	iters: 200, epoch: 3 | loss: 1.0342666
	speed: 0.0197s/iter; left time: 28.5861s
Epoch: 3 cost time: 4.056895971298218
Epoch: 3, Steps: 206 | Train Loss: 1.0419422 Vali Loss: 1.0553893 Test Loss: 1.0425268
Validation loss decreased (1.058045 --> 1.055389).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0252684
	speed: 0.0233s/iter; left time: 31.3074s
	iters: 200, epoch: 4 | loss: 1.0235648
	speed: 0.0170s/iter; left time: 21.1796s
Epoch: 4 cost time: 3.560682535171509
Epoch: 4, Steps: 206 | Train Loss: 1.0384057 Vali Loss: 1.0540669 Test Loss: 1.0414484
Validation loss decreased (1.055389 --> 1.054067).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0404723
	speed: 0.0139s/iter; left time: 15.7718s
	iters: 200, epoch: 5 | loss: 1.0548998
	speed: 0.0118s/iter; left time: 12.2231s
Epoch: 5 cost time: 2.5724706649780273
Epoch: 5, Steps: 206 | Train Loss: 1.0362923 Vali Loss: 1.0531635 Test Loss: 1.0410262
Validation loss decreased (1.054067 --> 1.053164).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0251069
	speed: 0.0231s/iter; left time: 21.5310s
	iters: 200, epoch: 6 | loss: 1.0430197
	speed: 0.0192s/iter; left time: 15.9693s
Epoch: 6 cost time: 4.002359628677368
Epoch: 6, Steps: 206 | Train Loss: 1.0355659 Vali Loss: 1.0529264 Test Loss: 1.0411154
Validation loss decreased (1.053164 --> 1.052926).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0457301
	speed: 0.0173s/iter; left time: 12.5691s
	iters: 200, epoch: 7 | loss: 1.0331696
	speed: 0.0149s/iter; left time: 9.3412s
Epoch: 7 cost time: 3.1950085163116455
Epoch: 7, Steps: 206 | Train Loss: 1.0348774 Vali Loss: 1.0526699 Test Loss: 1.0409060
Validation loss decreased (1.052926 --> 1.052670).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0424002
	speed: 0.0174s/iter; left time: 9.0308s
	iters: 200, epoch: 8 | loss: 1.0267203
	speed: 0.0144s/iter; left time: 6.0495s
Epoch: 8 cost time: 3.0353848934173584
Epoch: 8, Steps: 206 | Train Loss: 1.0347243 Vali Loss: 1.0526208 Test Loss: 1.0409009
Validation loss decreased (1.052670 --> 1.052621).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0638812
	speed: 0.0110s/iter; left time: 3.4416s
	iters: 200, epoch: 9 | loss: 1.0278461
	speed: 0.0099s/iter; left time: 2.1068s
Epoch: 9 cost time: 2.1682968139648438
Epoch: 9, Steps: 206 | Train Loss: 1.0346441 Vali Loss: 1.0525907 Test Loss: 1.0409391
Validation loss decreased (1.052621 --> 1.052591).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0427274
	speed: 0.0137s/iter; left time: 1.4679s
	iters: 200, epoch: 10 | loss: 1.0332023
	speed: 0.0128s/iter; left time: 0.0899s
Epoch: 10 cost time: 2.738318681716919
Epoch: 10, Steps: 206 | Train Loss: 1.0345815 Vali Loss: 1.0527186 Test Loss: 1.0409696
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0409390926361084, mae:0.8193926811218262
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0523573
	speed: 0.0181s/iter; left time: 35.4812s
	iters: 200, epoch: 1 | loss: 1.0549091
	speed: 0.0151s/iter; left time: 28.0922s
Epoch: 1 cost time: 3.155697822570801
Epoch: 1, Steps: 206 | Train Loss: 1.0933894 Vali Loss: 1.0614954 Test Loss: 1.0464591
Validation loss decreased (inf --> 1.061495).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0230842
	speed: 0.0272s/iter; left time: 47.7895s
	iters: 200, epoch: 2 | loss: 1.0598360
	speed: 0.0191s/iter; left time: 31.5480s
Epoch: 2 cost time: 3.983834743499756
Epoch: 2, Steps: 206 | Train Loss: 1.0478296 Vali Loss: 1.0583560 Test Loss: 1.0442019
Validation loss decreased (1.061495 --> 1.058356).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0432063
	speed: 0.0246s/iter; left time: 38.1506s
	iters: 200, epoch: 3 | loss: 1.0459414
	speed: 0.0183s/iter; left time: 26.5066s
Epoch: 3 cost time: 3.831779956817627
Epoch: 3, Steps: 206 | Train Loss: 1.0413851 Vali Loss: 1.0541444 Test Loss: 1.0409545
Validation loss decreased (1.058356 --> 1.054144).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0508975
	speed: 0.0140s/iter; left time: 18.8127s
	iters: 200, epoch: 4 | loss: 1.0438609
	speed: 0.0155s/iter; left time: 19.2144s
Epoch: 4 cost time: 3.388582944869995
Epoch: 4, Steps: 206 | Train Loss: 1.0384528 Vali Loss: 1.0533875 Test Loss: 1.0410144
Validation loss decreased (1.054144 --> 1.053388).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0615813
	speed: 0.0157s/iter; left time: 17.8057s
	iters: 200, epoch: 5 | loss: 1.0361252
	speed: 0.0199s/iter; left time: 20.6246s
Epoch: 5 cost time: 4.191890716552734
Epoch: 5, Steps: 206 | Train Loss: 1.0361898 Vali Loss: 1.0535840 Test Loss: 1.0414531
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0434351
	speed: 0.0130s/iter; left time: 12.1075s
	iters: 200, epoch: 6 | loss: 1.0347353
	speed: 0.0124s/iter; left time: 10.3235s
Epoch: 6 cost time: 2.685762405395508
Epoch: 6, Steps: 206 | Train Loss: 1.0354618 Vali Loss: 1.0527107 Test Loss: 1.0407883
Validation loss decreased (1.053388 --> 1.052711).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0234843
	speed: 0.0155s/iter; left time: 11.2582s
	iters: 200, epoch: 7 | loss: 1.0252138
	speed: 0.0132s/iter; left time: 8.2730s
Epoch: 7 cost time: 2.8198747634887695
Epoch: 7, Steps: 206 | Train Loss: 1.0347647 Vali Loss: 1.0528842 Test Loss: 1.0410172
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0334262
	speed: 0.0118s/iter; left time: 6.1069s
	iters: 200, epoch: 8 | loss: 1.0147535
	speed: 0.0120s/iter; left time: 5.0301s
Epoch: 8 cost time: 2.553588390350342
Epoch: 8, Steps: 206 | Train Loss: 1.0344508 Vali Loss: 1.0527065 Test Loss: 1.0409575
Validation loss decreased (1.052711 --> 1.052706).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0576245
	speed: 0.0167s/iter; left time: 5.2156s
	iters: 200, epoch: 9 | loss: 1.0453970
	speed: 0.0137s/iter; left time: 2.9226s
Epoch: 9 cost time: 2.909959316253662
Epoch: 9, Steps: 206 | Train Loss: 1.0342158 Vali Loss: 1.0527719 Test Loss: 1.0409242
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0252320
	speed: 0.0230s/iter; left time: 2.4641s
	iters: 200, epoch: 10 | loss: 1.0036665
	speed: 0.0184s/iter; left time: 0.1288s
Epoch: 10 cost time: 3.8733482360839844
Epoch: 10, Steps: 206 | Train Loss: 1.0342404 Vali Loss: 1.0526809 Test Loss: 1.0408903
Validation loss decreased (1.052706 --> 1.052681).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0408902168273926, mae:0.8194491863250732
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0162779
	speed: 0.0192s/iter; left time: 37.6562s
	iters: 200, epoch: 1 | loss: 1.0573922
	speed: 0.0181s/iter; left time: 33.6210s
Epoch: 1 cost time: 3.7848386764526367
Epoch: 1, Steps: 206 | Train Loss: 1.0922155 Vali Loss: 1.0584990 Test Loss: 1.0429780
Validation loss decreased (inf --> 1.058499).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0583457
	speed: 0.0131s/iter; left time: 23.0199s
	iters: 200, epoch: 2 | loss: 1.0627604
	speed: 0.0114s/iter; left time: 18.8706s
Epoch: 2 cost time: 2.4061152935028076
Epoch: 2, Steps: 206 | Train Loss: 1.0479364 Vali Loss: 1.0579661 Test Loss: 1.0429621
Validation loss decreased (1.058499 --> 1.057966).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0535711
	speed: 0.0185s/iter; left time: 28.6114s
	iters: 200, epoch: 3 | loss: 1.0516080
	speed: 0.0164s/iter; left time: 23.8016s
Epoch: 3 cost time: 3.4272994995117188
Epoch: 3, Steps: 206 | Train Loss: 1.0417641 Vali Loss: 1.0544428 Test Loss: 1.0414071
Validation loss decreased (1.057966 --> 1.054443).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0606215
	speed: 0.0170s/iter; left time: 22.8586s
	iters: 200, epoch: 4 | loss: 1.0373862
	speed: 0.0148s/iter; left time: 18.4443s
Epoch: 4 cost time: 3.127973794937134
Epoch: 4, Steps: 206 | Train Loss: 1.0383345 Vali Loss: 1.0543916 Test Loss: 1.0415859
Validation loss decreased (1.054443 --> 1.054392).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0171902
	speed: 0.0219s/iter; left time: 24.8713s
	iters: 200, epoch: 5 | loss: 1.0502648
	speed: 0.0180s/iter; left time: 18.6959s
Epoch: 5 cost time: 3.7752127647399902
Epoch: 5, Steps: 206 | Train Loss: 1.0362375 Vali Loss: 1.0531257 Test Loss: 1.0408126
Validation loss decreased (1.054392 --> 1.053126).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0399764
	speed: 0.0227s/iter; left time: 21.1118s
	iters: 200, epoch: 6 | loss: 1.0530999
	speed: 0.0178s/iter; left time: 14.8237s
Epoch: 6 cost time: 3.736521005630493
Epoch: 6, Steps: 206 | Train Loss: 1.0353869 Vali Loss: 1.0529158 Test Loss: 1.0407876
Validation loss decreased (1.053126 --> 1.052916).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0349097
	speed: 0.0217s/iter; left time: 15.7393s
	iters: 200, epoch: 7 | loss: 1.0444014
	speed: 0.0176s/iter; left time: 11.0258s
Epoch: 7 cost time: 3.678009510040283
Epoch: 7, Steps: 206 | Train Loss: 1.0346679 Vali Loss: 1.0531648 Test Loss: 1.0411546
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0513828
	speed: 0.0244s/iter; left time: 12.6872s
	iters: 200, epoch: 8 | loss: 1.0249307
	speed: 0.0195s/iter; left time: 8.1685s
Epoch: 8 cost time: 4.039166688919067
Epoch: 8, Steps: 206 | Train Loss: 1.0345907 Vali Loss: 1.0526270 Test Loss: 1.0409783
Validation loss decreased (1.052916 --> 1.052627).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0517393
	speed: 0.0182s/iter; left time: 5.6923s
	iters: 200, epoch: 9 | loss: 1.0429568
	speed: 0.0159s/iter; left time: 3.3938s
Epoch: 9 cost time: 3.370054244995117
Epoch: 9, Steps: 206 | Train Loss: 1.0343791 Vali Loss: 1.0527184 Test Loss: 1.0410554
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0350912
	speed: 0.0206s/iter; left time: 2.2094s
	iters: 200, epoch: 10 | loss: 1.0415547
	speed: 0.0154s/iter; left time: 0.1080s
Epoch: 10 cost time: 3.226475715637207
Epoch: 10, Steps: 206 | Train Loss: 1.0344600 Vali Loss: 1.0529662 Test Loss: 1.0410473
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040978193283081, mae:0.8193862438201904
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0812825
	speed: 0.0291s/iter; left time: 53.6108s
Epoch: 1 cost time: 4.3634352684021
Epoch: 1, Steps: 194 | Train Loss: 1.0972535 Vali Loss: 1.0473087 Test Loss: 1.0453993
Validation loss decreased (inf --> 1.047309).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0509012
	speed: 0.0244s/iter; left time: 40.1498s
Epoch: 2 cost time: 3.737421751022339
Epoch: 2, Steps: 194 | Train Loss: 1.0537154 Vali Loss: 1.0478090 Test Loss: 1.0463886
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0254371
	speed: 0.0175s/iter; left time: 25.4672s
Epoch: 3 cost time: 2.9249651432037354
Epoch: 3, Steps: 194 | Train Loss: 1.0488508 Vali Loss: 1.0485694 Test Loss: 1.0376165
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0728732
	speed: 0.0171s/iter; left time: 21.4690s
Epoch: 4 cost time: 2.8916096687316895
Epoch: 4, Steps: 194 | Train Loss: 1.0462944 Vali Loss: 1.0441231 Test Loss: 1.0412413
Validation loss decreased (1.047309 --> 1.044123).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0458426
	speed: 0.0183s/iter; left time: 19.4962s
Epoch: 5 cost time: 3.440174102783203
Epoch: 5, Steps: 194 | Train Loss: 1.0449998 Vali Loss: 1.0450209 Test Loss: 1.0400079
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0445268
	speed: 0.0169s/iter; left time: 14.7021s
Epoch: 6 cost time: 3.2204134464263916
Epoch: 6, Steps: 194 | Train Loss: 1.0441071 Vali Loss: 1.0445828 Test Loss: 1.0405420
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0438588
	speed: 0.0160s/iter; left time: 10.8117s
Epoch: 7 cost time: 2.868147373199463
Epoch: 7, Steps: 194 | Train Loss: 1.0437591 Vali Loss: 1.0449589 Test Loss: 1.0399806
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0390930
	speed: 0.0165s/iter; left time: 7.9521s
Epoch: 8 cost time: 2.662961006164551
Epoch: 8, Steps: 194 | Train Loss: 1.0435837 Vali Loss: 1.0444360 Test Loss: 1.0401181
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0359552
	speed: 0.0176s/iter; left time: 5.0933s
Epoch: 9 cost time: 3.1105239391326904
Epoch: 9, Steps: 194 | Train Loss: 1.0432834 Vali Loss: 1.0444537 Test Loss: 1.0401851
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.04124116897583, mae:0.8188357353210449
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0445398
	speed: 0.0197s/iter; left time: 36.3334s
Epoch: 1 cost time: 3.3418312072753906
Epoch: 1, Steps: 194 | Train Loss: 1.0965955 Vali Loss: 1.0500906 Test Loss: 1.0433769
Validation loss decreased (inf --> 1.050091).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0634342
	speed: 0.0159s/iter; left time: 26.2114s
Epoch: 2 cost time: 3.2935221195220947
Epoch: 2, Steps: 194 | Train Loss: 1.0543819 Vali Loss: 1.0489498 Test Loss: 1.0438107
Validation loss decreased (1.050091 --> 1.048950).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0415359
	speed: 0.0195s/iter; left time: 28.3254s
Epoch: 3 cost time: 3.209463357925415
Epoch: 3, Steps: 194 | Train Loss: 1.0490904 Vali Loss: 1.0449870 Test Loss: 1.0423182
Validation loss decreased (1.048950 --> 1.044987).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0515741
	speed: 0.0155s/iter; left time: 19.4928s
Epoch: 4 cost time: 2.990774631500244
Epoch: 4, Steps: 194 | Train Loss: 1.0464532 Vali Loss: 1.0452332 Test Loss: 1.0416608
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0443563
	speed: 0.0194s/iter; left time: 20.7101s
Epoch: 5 cost time: 3.3527109622955322
Epoch: 5, Steps: 194 | Train Loss: 1.0450002 Vali Loss: 1.0443625 Test Loss: 1.0400237
Validation loss decreased (1.044987 --> 1.044363).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0381891
	speed: 0.0143s/iter; left time: 12.4511s
Epoch: 6 cost time: 2.7455835342407227
Epoch: 6, Steps: 194 | Train Loss: 1.0442418 Vali Loss: 1.0440669 Test Loss: 1.0405374
Validation loss decreased (1.044363 --> 1.044067).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0284220
	speed: 0.0198s/iter; left time: 13.3981s
Epoch: 7 cost time: 3.5893213748931885
Epoch: 7, Steps: 194 | Train Loss: 1.0438925 Vali Loss: 1.0442977 Test Loss: 1.0401940
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0518004
	speed: 0.0151s/iter; left time: 7.3081s
Epoch: 8 cost time: 2.6273531913757324
Epoch: 8, Steps: 194 | Train Loss: 1.0434737 Vali Loss: 1.0443954 Test Loss: 1.0402123
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0491347
	speed: 0.0195s/iter; left time: 5.6450s
Epoch: 9 cost time: 3.4288172721862793
Epoch: 9, Steps: 194 | Train Loss: 1.0435012 Vali Loss: 1.0443158 Test Loss: 1.0400795
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0308098
	speed: 0.0174s/iter; left time: 1.6500s
Epoch: 10 cost time: 3.244096279144287
Epoch: 10, Steps: 194 | Train Loss: 1.0434236 Vali Loss: 1.0445920 Test Loss: 1.0400143
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405372381210327, mae:0.8185538053512573
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0584701
	speed: 0.0163s/iter; left time: 30.0398s
Epoch: 1 cost time: 4.1935951709747314
Epoch: 1, Steps: 194 | Train Loss: 1.0969383 Vali Loss: 1.0525264 Test Loss: 1.0456698
Validation loss decreased (inf --> 1.052526).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0534534
	speed: 0.0175s/iter; left time: 28.8459s
Epoch: 2 cost time: 2.8993659019470215
Epoch: 2, Steps: 194 | Train Loss: 1.0538008 Vali Loss: 1.0464189 Test Loss: 1.0516627
Validation loss decreased (1.052526 --> 1.046419).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0584687
	speed: 0.0132s/iter; left time: 19.1296s
Epoch: 3 cost time: 2.484464645385742
Epoch: 3, Steps: 194 | Train Loss: 1.0489013 Vali Loss: 1.0458674 Test Loss: 1.0400957
Validation loss decreased (1.046419 --> 1.045867).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0421643
	speed: 0.0164s/iter; left time: 20.6058s
Epoch: 4 cost time: 3.1107358932495117
Epoch: 4, Steps: 194 | Train Loss: 1.0463855 Vali Loss: 1.0439326 Test Loss: 1.0433230
Validation loss decreased (1.045867 --> 1.043933).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0304359
	speed: 0.0198s/iter; left time: 21.0758s
Epoch: 5 cost time: 3.388477325439453
Epoch: 5, Steps: 194 | Train Loss: 1.0447432 Vali Loss: 1.0453780 Test Loss: 1.0413227
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0189643
	speed: 0.0176s/iter; left time: 15.3288s
Epoch: 6 cost time: 3.584988594055176
Epoch: 6, Steps: 194 | Train Loss: 1.0438542 Vali Loss: 1.0444537 Test Loss: 1.0411835
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0343884
	speed: 0.0133s/iter; left time: 9.0014s
Epoch: 7 cost time: 2.5018105506896973
Epoch: 7, Steps: 194 | Train Loss: 1.0437862 Vali Loss: 1.0453248 Test Loss: 1.0399541
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0243019
	speed: 0.0127s/iter; left time: 6.1445s
Epoch: 8 cost time: 2.5472891330718994
Epoch: 8, Steps: 194 | Train Loss: 1.0435085 Vali Loss: 1.0450993 Test Loss: 1.0400813
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0594816
	speed: 0.0189s/iter; left time: 5.4760s
Epoch: 9 cost time: 3.806421995162964
Epoch: 9, Steps: 194 | Train Loss: 1.0431480 Vali Loss: 1.0451586 Test Loss: 1.0402215
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0433229207992554, mae:0.8197041749954224
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0364404
	speed: 0.0233s/iter; left time: 47.4059s
	iters: 200, epoch: 1 | loss: 1.0127866
	speed: 0.0192s/iter; left time: 37.1081s
Epoch: 1 cost time: 4.158395767211914
Epoch: 1, Steps: 213 | Train Loss: 1.0848278 Vali Loss: 1.0577899 Test Loss: 1.0486034
Validation loss decreased (inf --> 1.057790).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0574870
	speed: 0.0256s/iter; left time: 46.6043s
	iters: 200, epoch: 2 | loss: 1.0166090
	speed: 0.0217s/iter; left time: 37.3324s
Epoch: 2 cost time: 4.575887203216553
Epoch: 2, Steps: 213 | Train Loss: 1.0352104 Vali Loss: 1.0550395 Test Loss: 1.0466179
Validation loss decreased (1.057790 --> 1.055040).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0178823
	speed: 0.0213s/iter; left time: 34.1173s
	iters: 200, epoch: 3 | loss: 1.0380180
	speed: 0.0170s/iter; left time: 25.5345s
Epoch: 3 cost time: 3.712825059890747
Epoch: 3, Steps: 213 | Train Loss: 1.0263416 Vali Loss: 1.0557125 Test Loss: 1.0475931
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9599244
	speed: 0.0279s/iter; left time: 38.7953s
	iters: 200, epoch: 4 | loss: 1.0618896
	speed: 0.0212s/iter; left time: 27.3766s
Epoch: 4 cost time: 4.46071195602417
Epoch: 4, Steps: 213 | Train Loss: 1.0211811 Vali Loss: 1.0503511 Test Loss: 1.0451230
Validation loss decreased (1.055040 --> 1.050351).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0223980
	speed: 0.0166s/iter; left time: 19.5637s
	iters: 200, epoch: 5 | loss: 1.0264190
	speed: 0.0141s/iter; left time: 15.2344s
Epoch: 5 cost time: 3.046349287033081
Epoch: 5, Steps: 213 | Train Loss: 1.0184977 Vali Loss: 1.0548488 Test Loss: 1.0455908
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9600940
	speed: 0.0147s/iter; left time: 14.2092s
	iters: 200, epoch: 6 | loss: 1.0619017
	speed: 0.0176s/iter; left time: 15.2137s
Epoch: 6 cost time: 3.8506650924682617
Epoch: 6, Steps: 213 | Train Loss: 1.0164277 Vali Loss: 1.0511972 Test Loss: 1.0454764
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9860473
	speed: 0.0198s/iter; left time: 14.9332s
	iters: 200, epoch: 7 | loss: 1.0470798
	speed: 0.0176s/iter; left time: 11.5082s
Epoch: 7 cost time: 3.787809133529663
Epoch: 7, Steps: 213 | Train Loss: 1.0155430 Vali Loss: 1.0513626 Test Loss: 1.0453187
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0145500
	speed: 0.0177s/iter; left time: 9.5472s
	iters: 200, epoch: 8 | loss: 1.0053589
	speed: 0.0143s/iter; left time: 6.2931s
Epoch: 8 cost time: 3.0587449073791504
Epoch: 8, Steps: 213 | Train Loss: 1.0150087 Vali Loss: 1.0514930 Test Loss: 1.0454243
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0335827
	speed: 0.0169s/iter; left time: 5.5360s
	iters: 200, epoch: 9 | loss: 1.0548234
	speed: 0.0130s/iter; left time: 2.9535s
Epoch: 9 cost time: 2.7725400924682617
Epoch: 9, Steps: 213 | Train Loss: 1.0149947 Vali Loss: 1.0519265 Test Loss: 1.0454590
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0451231002807617, mae:0.8204923868179321
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0757396
	speed: 0.0126s/iter; left time: 25.6353s
	iters: 200, epoch: 1 | loss: 1.0530472
	speed: 0.0132s/iter; left time: 25.4149s
Epoch: 1 cost time: 2.9103875160217285
Epoch: 1, Steps: 213 | Train Loss: 1.0892404 Vali Loss: 1.0548842 Test Loss: 1.0479516
Validation loss decreased (inf --> 1.054884).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0034051
	speed: 0.0164s/iter; left time: 29.7267s
	iters: 200, epoch: 2 | loss: 1.0128717
	speed: 0.0151s/iter; left time: 25.8815s
Epoch: 2 cost time: 3.328856945037842
Epoch: 2, Steps: 213 | Train Loss: 1.0346648 Vali Loss: 1.0544450 Test Loss: 1.0469257
Validation loss decreased (1.054884 --> 1.054445).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0700107
	speed: 0.0163s/iter; left time: 26.1415s
	iters: 200, epoch: 3 | loss: 1.0471919
	speed: 0.0149s/iter; left time: 22.4840s
Epoch: 3 cost time: 3.1832897663116455
Epoch: 3, Steps: 213 | Train Loss: 1.0251891 Vali Loss: 1.0549123 Test Loss: 1.0456994
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9959687
	speed: 0.0154s/iter; left time: 21.4847s
	iters: 200, epoch: 4 | loss: 1.0397042
	speed: 0.0139s/iter; left time: 17.9926s
Epoch: 4 cost time: 3.061763048171997
Epoch: 4, Steps: 213 | Train Loss: 1.0200789 Vali Loss: 1.0532720 Test Loss: 1.0457920
Validation loss decreased (1.054445 --> 1.053272).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0133554
	speed: 0.0146s/iter; left time: 17.1985s
	iters: 200, epoch: 5 | loss: 1.0373003
	speed: 0.0132s/iter; left time: 14.2344s
Epoch: 5 cost time: 2.8502590656280518
Epoch: 5, Steps: 213 | Train Loss: 1.0168655 Vali Loss: 1.0514334 Test Loss: 1.0452527
Validation loss decreased (1.053272 --> 1.051433).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0056267
	speed: 0.0147s/iter; left time: 14.2119s
	iters: 200, epoch: 6 | loss: 1.0485320
	speed: 0.0129s/iter; left time: 11.2090s
Epoch: 6 cost time: 2.8328230381011963
Epoch: 6, Steps: 213 | Train Loss: 1.0158191 Vali Loss: 1.0510396 Test Loss: 1.0454363
Validation loss decreased (1.051433 --> 1.051040).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9918393
	speed: 0.0161s/iter; left time: 12.1250s
	iters: 200, epoch: 7 | loss: 0.9900691
	speed: 0.0159s/iter; left time: 10.4081s
Epoch: 7 cost time: 3.4929862022399902
Epoch: 7, Steps: 213 | Train Loss: 1.0143238 Vali Loss: 1.0522047 Test Loss: 1.0453943
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0068616
	speed: 0.0183s/iter; left time: 9.9064s
	iters: 200, epoch: 8 | loss: 0.9910153
	speed: 0.0190s/iter; left time: 8.3771s
Epoch: 8 cost time: 4.08513069152832
Epoch: 8, Steps: 213 | Train Loss: 1.0137736 Vali Loss: 1.0523130 Test Loss: 1.0453490
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0270195
	speed: 0.0197s/iter; left time: 6.4259s
	iters: 200, epoch: 9 | loss: 1.0164595
	speed: 0.0168s/iter; left time: 3.8186s
Epoch: 9 cost time: 3.796563148498535
Epoch: 9, Steps: 213 | Train Loss: 1.0134044 Vali Loss: 1.0519333 Test Loss: 1.0454131
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0098557
	speed: 0.0151s/iter; left time: 1.7240s
	iters: 200, epoch: 10 | loss: 1.0168124
	speed: 0.0157s/iter; left time: 0.2192s
Epoch: 10 cost time: 3.3999032974243164
Epoch: 10, Steps: 213 | Train Loss: 1.0131951 Vali Loss: 1.0526434 Test Loss: 1.0454561
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0454363822937012, mae:0.8205888271331787
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0881464
	speed: 0.0197s/iter; left time: 39.9922s
	iters: 200, epoch: 1 | loss: 1.0569625
	speed: 0.0181s/iter; left time: 34.9771s
Epoch: 1 cost time: 3.9540491104125977
Epoch: 1, Steps: 213 | Train Loss: 1.0878733 Vali Loss: 1.0575274 Test Loss: 1.0477730
Validation loss decreased (inf --> 1.057527).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0335870
	speed: 0.0310s/iter; left time: 56.3098s
	iters: 200, epoch: 2 | loss: 1.0502553
	speed: 0.0240s/iter; left time: 41.1564s
Epoch: 2 cost time: 5.024486780166626
Epoch: 2, Steps: 213 | Train Loss: 1.0342225 Vali Loss: 1.0567505 Test Loss: 1.0468062
Validation loss decreased (1.057527 --> 1.056751).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9786173
	speed: 0.0220s/iter; left time: 35.2696s
	iters: 200, epoch: 3 | loss: 1.0471282
	speed: 0.0181s/iter; left time: 27.1665s
Epoch: 3 cost time: 3.90602707862854
Epoch: 3, Steps: 213 | Train Loss: 1.0255999 Vali Loss: 1.0547953 Test Loss: 1.0466584
Validation loss decreased (1.056751 --> 1.054795).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9996270
	speed: 0.0213s/iter; left time: 29.6240s
	iters: 200, epoch: 4 | loss: 0.9714863
	speed: 0.0165s/iter; left time: 21.3640s
Epoch: 4 cost time: 3.5703952312469482
Epoch: 4, Steps: 213 | Train Loss: 1.0201519 Vali Loss: 1.0530269 Test Loss: 1.0456575
Validation loss decreased (1.054795 --> 1.053027).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0562463
	speed: 0.0177s/iter; left time: 20.8308s
	iters: 200, epoch: 5 | loss: 0.9984578
	speed: 0.0187s/iter; left time: 20.1452s
Epoch: 5 cost time: 4.035303115844727
Epoch: 5, Steps: 213 | Train Loss: 1.0169077 Vali Loss: 1.0528697 Test Loss: 1.0461919
Validation loss decreased (1.053027 --> 1.052870).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0597893
	speed: 0.0227s/iter; left time: 21.8983s
	iters: 200, epoch: 6 | loss: 1.0085943
	speed: 0.0204s/iter; left time: 17.6283s
Epoch: 6 cost time: 4.333199501037598
Epoch: 6, Steps: 213 | Train Loss: 1.0150320 Vali Loss: 1.0526967 Test Loss: 1.0459789
Validation loss decreased (1.052870 --> 1.052697).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9963855
	speed: 0.0179s/iter; left time: 13.4462s
	iters: 200, epoch: 7 | loss: 1.0462474
	speed: 0.0163s/iter; left time: 10.6533s
Epoch: 7 cost time: 3.4268364906311035
Epoch: 7, Steps: 213 | Train Loss: 1.0146019 Vali Loss: 1.0531520 Test Loss: 1.0459286
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0016255
	speed: 0.0133s/iter; left time: 7.1604s
	iters: 200, epoch: 8 | loss: 0.9717948
	speed: 0.0121s/iter; left time: 5.3094s
Epoch: 8 cost time: 2.7242815494537354
Epoch: 8, Steps: 213 | Train Loss: 1.0140642 Vali Loss: 1.0544354 Test Loss: 1.0460066
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0197991
	speed: 0.0238s/iter; left time: 7.7869s
	iters: 200, epoch: 9 | loss: 1.0160471
	speed: 0.0183s/iter; left time: 4.1483s
Epoch: 9 cost time: 3.93815279006958
Epoch: 9, Steps: 213 | Train Loss: 1.0131890 Vali Loss: 1.0511378 Test Loss: 1.0460522
Validation loss decreased (1.052697 --> 1.051138).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0111399
	speed: 0.0190s/iter; left time: 2.1641s
	iters: 200, epoch: 10 | loss: 1.0231211
	speed: 0.0173s/iter; left time: 0.2427s
Epoch: 10 cost time: 3.7572453022003174
Epoch: 10, Steps: 213 | Train Loss: 1.0132818 Vali Loss: 1.0510739 Test Loss: 1.0460769
Validation loss decreased (1.051138 --> 1.051074).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.046077013015747, mae:0.8209854364395142
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0360124
	speed: 0.0302s/iter; left time: 60.4053s
	iters: 200, epoch: 1 | loss: 1.0455253
	speed: 0.0215s/iter; left time: 40.8657s
Epoch: 1 cost time: 4.573317289352417
Epoch: 1, Steps: 210 | Train Loss: 1.0859606 Vali Loss: 1.0677485 Test Loss: 1.0540510
Validation loss decreased (inf --> 1.067749).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0475495
	speed: 0.0185s/iter; left time: 33.2228s
	iters: 200, epoch: 2 | loss: 1.0579778
	speed: 0.0160s/iter; left time: 26.9989s
Epoch: 2 cost time: 3.412362813949585
Epoch: 2, Steps: 210 | Train Loss: 1.0426508 Vali Loss: 1.0620909 Test Loss: 1.0557063
Validation loss decreased (1.067749 --> 1.062091).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0290745
	speed: 0.0146s/iter; left time: 23.0595s
	iters: 200, epoch: 3 | loss: 1.0529863
	speed: 0.0141s/iter; left time: 20.8944s
Epoch: 3 cost time: 3.090562105178833
Epoch: 3, Steps: 210 | Train Loss: 1.0354093 Vali Loss: 1.0638711 Test Loss: 1.0524845
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0783179
	speed: 0.0176s/iter; left time: 24.1015s
	iters: 200, epoch: 4 | loss: 1.0222973
	speed: 0.0148s/iter; left time: 18.7882s
Epoch: 4 cost time: 3.140869140625
Epoch: 4, Steps: 210 | Train Loss: 1.0310803 Vali Loss: 1.0636523 Test Loss: 1.0515565
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0422363
	speed: 0.0258s/iter; left time: 29.9083s
	iters: 200, epoch: 5 | loss: 1.0091341
	speed: 0.0184s/iter; left time: 19.5604s
Epoch: 5 cost time: 3.867159366607666
Epoch: 5, Steps: 210 | Train Loss: 1.0290032 Vali Loss: 1.0590037 Test Loss: 1.0518999
Validation loss decreased (1.062091 --> 1.059004).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0597558
	speed: 0.0154s/iter; left time: 14.6045s
	iters: 200, epoch: 6 | loss: 1.0299973
	speed: 0.0155s/iter; left time: 13.1791s
Epoch: 6 cost time: 3.359117269515991
Epoch: 6, Steps: 210 | Train Loss: 1.0275585 Vali Loss: 1.0578012 Test Loss: 1.0518495
Validation loss decreased (1.059004 --> 1.057801).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9931431
	speed: 0.0197s/iter; left time: 14.6037s
	iters: 200, epoch: 7 | loss: 1.0474195
	speed: 0.0153s/iter; left time: 9.7789s
Epoch: 7 cost time: 3.258392095565796
Epoch: 7, Steps: 210 | Train Loss: 1.0268288 Vali Loss: 1.0588726 Test Loss: 1.0519538
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0300913
	speed: 0.0145s/iter; left time: 7.6928s
	iters: 200, epoch: 8 | loss: 0.9976050
	speed: 0.0115s/iter; left time: 4.9459s
Epoch: 8 cost time: 2.4936165809631348
Epoch: 8, Steps: 210 | Train Loss: 1.0266292 Vali Loss: 1.0575147 Test Loss: 1.0518234
Validation loss decreased (1.057801 --> 1.057515).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0189831
	speed: 0.0189s/iter; left time: 6.0592s
	iters: 200, epoch: 9 | loss: 1.0404675
	speed: 0.0171s/iter; left time: 3.7719s
Epoch: 9 cost time: 3.6882874965667725
Epoch: 9, Steps: 210 | Train Loss: 1.0262909 Vali Loss: 1.0597330 Test Loss: 1.0518762
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0357531
	speed: 0.0157s/iter; left time: 1.7480s
	iters: 200, epoch: 10 | loss: 1.0331748
	speed: 0.0153s/iter; left time: 0.1687s
Epoch: 10 cost time: 3.304678201675415
Epoch: 10, Steps: 210 | Train Loss: 1.0262737 Vali Loss: 1.0590670 Test Loss: 1.0519083
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0518232583999634, mae:0.8227738738059998
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0428041
	speed: 0.0249s/iter; left time: 49.8070s
	iters: 200, epoch: 1 | loss: 1.0621129
	speed: 0.0173s/iter; left time: 32.8439s
Epoch: 1 cost time: 3.6016604900360107
Epoch: 1, Steps: 210 | Train Loss: 1.0884173 Vali Loss: 1.0667402 Test Loss: 1.0524377
Validation loss decreased (inf --> 1.066740).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0497317
	speed: 0.0146s/iter; left time: 26.1291s
	iters: 200, epoch: 2 | loss: 1.0544430
	speed: 0.0121s/iter; left time: 20.4881s
Epoch: 2 cost time: 2.5924956798553467
Epoch: 2, Steps: 210 | Train Loss: 1.0417012 Vali Loss: 1.0641500 Test Loss: 1.0534307
Validation loss decreased (1.066740 --> 1.064150).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0730491
	speed: 0.0174s/iter; left time: 27.5469s
	iters: 200, epoch: 3 | loss: 1.0181605
	speed: 0.0167s/iter; left time: 24.8050s
Epoch: 3 cost time: 3.605224370956421
Epoch: 3, Steps: 210 | Train Loss: 1.0343089 Vali Loss: 1.0632732 Test Loss: 1.0519220
Validation loss decreased (1.064150 --> 1.063273).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0258937
	speed: 0.0185s/iter; left time: 25.4240s
	iters: 200, epoch: 4 | loss: 1.0564491
	speed: 0.0165s/iter; left time: 21.0136s
Epoch: 4 cost time: 3.5963497161865234
Epoch: 4, Steps: 210 | Train Loss: 1.0305509 Vali Loss: 1.0599520 Test Loss: 1.0515989
Validation loss decreased (1.063273 --> 1.059952).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0650299
	speed: 0.0219s/iter; left time: 25.4112s
	iters: 200, epoch: 5 | loss: 1.0262372
	speed: 0.0212s/iter; left time: 22.5358s
Epoch: 5 cost time: 4.4379212856292725
Epoch: 5, Steps: 210 | Train Loss: 1.0282947 Vali Loss: 1.0600073 Test Loss: 1.0517751
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0154757
	speed: 0.0134s/iter; left time: 12.7551s
	iters: 200, epoch: 6 | loss: 1.0420808
	speed: 0.0114s/iter; left time: 9.7200s
Epoch: 6 cost time: 2.4525980949401855
Epoch: 6, Steps: 210 | Train Loss: 1.0267274 Vali Loss: 1.0600920 Test Loss: 1.0517381
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0382707
	speed: 0.0156s/iter; left time: 11.5955s
	iters: 200, epoch: 7 | loss: 1.0273964
	speed: 0.0155s/iter; left time: 9.9048s
Epoch: 7 cost time: 3.363884210586548
Epoch: 7, Steps: 210 | Train Loss: 1.0261119 Vali Loss: 1.0589340 Test Loss: 1.0517043
Validation loss decreased (1.059952 --> 1.058934).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0339687
	speed: 0.0186s/iter; left time: 9.8979s
	iters: 200, epoch: 8 | loss: 1.0323299
	speed: 0.0184s/iter; left time: 7.9464s
Epoch: 8 cost time: 3.8623478412628174
Epoch: 8, Steps: 210 | Train Loss: 1.0256975 Vali Loss: 1.0593786 Test Loss: 1.0517156
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0331867
	speed: 0.0233s/iter; left time: 7.4891s
	iters: 200, epoch: 9 | loss: 1.0427637
	speed: 0.0183s/iter; left time: 4.0541s
Epoch: 9 cost time: 3.871359348297119
Epoch: 9, Steps: 210 | Train Loss: 1.0254384 Vali Loss: 1.0591198 Test Loss: 1.0517997
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0619863
	speed: 0.0164s/iter; left time: 1.8203s
	iters: 200, epoch: 10 | loss: 1.0235627
	speed: 0.0137s/iter; left time: 0.1511s
Epoch: 10 cost time: 2.9641051292419434
Epoch: 10, Steps: 210 | Train Loss: 1.0253133 Vali Loss: 1.0565616 Test Loss: 1.0518291
Validation loss decreased (1.058934 --> 1.056562).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0518293380737305, mae:0.8227528929710388
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0344505
	speed: 0.0136s/iter; left time: 27.1739s
	iters: 200, epoch: 1 | loss: 1.0543826
	speed: 0.0153s/iter; left time: 29.0811s
Epoch: 1 cost time: 3.3321151733398438
Epoch: 1, Steps: 210 | Train Loss: 1.0873936 Vali Loss: 1.0649061 Test Loss: 1.0537534
Validation loss decreased (inf --> 1.064906).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0653107
	speed: 0.0184s/iter; left time: 33.0415s
	iters: 200, epoch: 2 | loss: 1.0030221
	speed: 0.0165s/iter; left time: 27.8683s
Epoch: 2 cost time: 3.660975694656372
Epoch: 2, Steps: 210 | Train Loss: 1.0420993 Vali Loss: 1.0652659 Test Loss: 1.0537064
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0490828
	speed: 0.0183s/iter; left time: 28.8640s
	iters: 200, epoch: 3 | loss: 1.0530623
	speed: 0.0179s/iter; left time: 26.4685s
Epoch: 3 cost time: 4.058308362960815
Epoch: 3, Steps: 210 | Train Loss: 1.0345881 Vali Loss: 1.0630815 Test Loss: 1.0524389
Validation loss decreased (1.064906 --> 1.063082).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0175760
	speed: 0.0153s/iter; left time: 21.0416s
	iters: 200, epoch: 4 | loss: 1.0213785
	speed: 0.0141s/iter; left time: 17.9126s
Epoch: 4 cost time: 3.055844306945801
Epoch: 4, Steps: 210 | Train Loss: 1.0306690 Vali Loss: 1.0607429 Test Loss: 1.0531068
Validation loss decreased (1.063082 --> 1.060743).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0304393
	speed: 0.0159s/iter; left time: 18.4557s
	iters: 200, epoch: 5 | loss: 0.9991755
	speed: 0.0168s/iter; left time: 17.7903s
Epoch: 5 cost time: 3.711233615875244
Epoch: 5, Steps: 210 | Train Loss: 1.0283228 Vali Loss: 1.0577598 Test Loss: 1.0523802
Validation loss decreased (1.060743 --> 1.057760).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0225359
	speed: 0.0159s/iter; left time: 15.1375s
	iters: 200, epoch: 6 | loss: 1.0533218
	speed: 0.0146s/iter; left time: 12.4111s
Epoch: 6 cost time: 3.1775240898132324
Epoch: 6, Steps: 210 | Train Loss: 1.0271307 Vali Loss: 1.0594565 Test Loss: 1.0520008
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0089508
	speed: 0.0167s/iter; left time: 12.3665s
	iters: 200, epoch: 7 | loss: 1.0143855
	speed: 0.0145s/iter; left time: 9.2707s
Epoch: 7 cost time: 3.1121280193328857
Epoch: 7, Steps: 210 | Train Loss: 1.0260935 Vali Loss: 1.0570284 Test Loss: 1.0522916
Validation loss decreased (1.057760 --> 1.057028).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0000467
	speed: 0.0265s/iter; left time: 14.0712s
	iters: 200, epoch: 8 | loss: 1.0205708
	speed: 0.0195s/iter; left time: 8.3911s
Epoch: 8 cost time: 4.0428407192230225
Epoch: 8, Steps: 210 | Train Loss: 1.0259564 Vali Loss: 1.0592877 Test Loss: 1.0521665
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9975810
	speed: 0.0146s/iter; left time: 4.6758s
	iters: 200, epoch: 9 | loss: 1.0737569
	speed: 0.0142s/iter; left time: 3.1362s
Epoch: 9 cost time: 3.219712257385254
Epoch: 9, Steps: 210 | Train Loss: 1.0254397 Vali Loss: 1.0585623 Test Loss: 1.0521702
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0196166
	speed: 0.0166s/iter; left time: 1.8444s
	iters: 200, epoch: 10 | loss: 1.0247462
	speed: 0.0138s/iter; left time: 0.1519s
Epoch: 10 cost time: 2.9697532653808594
Epoch: 10, Steps: 210 | Train Loss: 1.0257917 Vali Loss: 1.0601445 Test Loss: 1.0521889
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.052291750907898, mae:0.8229225873947144
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0639409
	speed: 0.0251s/iter; left time: 49.2761s
	iters: 200, epoch: 1 | loss: 1.0420362
	speed: 0.0202s/iter; left time: 37.6168s
Epoch: 1 cost time: 4.299772262573242
Epoch: 1, Steps: 206 | Train Loss: 1.0891995 Vali Loss: 1.0585905 Test Loss: 1.0431129
Validation loss decreased (inf --> 1.058591).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0380218
	speed: 0.0169s/iter; left time: 29.5758s
	iters: 200, epoch: 2 | loss: 1.0505860
	speed: 0.0136s/iter; left time: 22.5272s
Epoch: 2 cost time: 2.953770160675049
Epoch: 2, Steps: 206 | Train Loss: 1.0483008 Vali Loss: 1.0575855 Test Loss: 1.0436232
Validation loss decreased (1.058591 --> 1.057585).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0256495
	speed: 0.0222s/iter; left time: 34.4082s
	iters: 200, epoch: 3 | loss: 1.0659896
	speed: 0.0183s/iter; left time: 26.5427s
Epoch: 3 cost time: 3.8109867572784424
Epoch: 3, Steps: 206 | Train Loss: 1.0420614 Vali Loss: 1.0563741 Test Loss: 1.0428677
Validation loss decreased (1.057585 --> 1.056374).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0782392
	speed: 0.0189s/iter; left time: 25.4094s
	iters: 200, epoch: 4 | loss: 1.0178603
	speed: 0.0149s/iter; left time: 18.5331s
Epoch: 4 cost time: 3.1041979789733887
Epoch: 4, Steps: 206 | Train Loss: 1.0390809 Vali Loss: 1.0537741 Test Loss: 1.0411094
Validation loss decreased (1.056374 --> 1.053774).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0234916
	speed: 0.0145s/iter; left time: 16.5169s
	iters: 200, epoch: 5 | loss: 1.0488436
	speed: 0.0125s/iter; left time: 12.9951s
Epoch: 5 cost time: 2.6622321605682373
Epoch: 5, Steps: 206 | Train Loss: 1.0369904 Vali Loss: 1.0528557 Test Loss: 1.0404451
Validation loss decreased (1.053774 --> 1.052856).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0306495
	speed: 0.0188s/iter; left time: 17.4850s
	iters: 200, epoch: 6 | loss: 1.0326205
	speed: 0.0183s/iter; left time: 15.2079s
Epoch: 6 cost time: 3.8166491985321045
Epoch: 6, Steps: 206 | Train Loss: 1.0359947 Vali Loss: 1.0531054 Test Loss: 1.0407269
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0462213
	speed: 0.0177s/iter; left time: 12.8120s
	iters: 200, epoch: 7 | loss: 1.0167857
	speed: 0.0155s/iter; left time: 9.7025s
Epoch: 7 cost time: 3.3177459239959717
Epoch: 7, Steps: 206 | Train Loss: 1.0353752 Vali Loss: 1.0522459 Test Loss: 1.0404406
Validation loss decreased (1.052856 --> 1.052246).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0019938
	speed: 0.0216s/iter; left time: 11.1936s
	iters: 200, epoch: 8 | loss: 1.0422252
	speed: 0.0180s/iter; left time: 7.5304s
Epoch: 8 cost time: 3.8135013580322266
Epoch: 8, Steps: 206 | Train Loss: 1.0352306 Vali Loss: 1.0526736 Test Loss: 1.0406691
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0359470
	speed: 0.0138s/iter; left time: 4.3155s
	iters: 200, epoch: 9 | loss: 1.0450363
	speed: 0.0115s/iter; left time: 2.4493s
Epoch: 9 cost time: 2.471221446990967
Epoch: 9, Steps: 206 | Train Loss: 1.0350138 Vali Loss: 1.0525700 Test Loss: 1.0405730
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0359149
	speed: 0.0165s/iter; left time: 1.7637s
	iters: 200, epoch: 10 | loss: 1.0325019
	speed: 0.0146s/iter; left time: 0.1022s
Epoch: 10 cost time: 3.068382501602173
Epoch: 10, Steps: 206 | Train Loss: 1.0351224 Vali Loss: 1.0529567 Test Loss: 1.0406473
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0404406785964966, mae:0.8192054629325867
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0530581
	speed: 0.0148s/iter; left time: 29.0287s
	iters: 200, epoch: 1 | loss: 1.0760528
	speed: 0.0155s/iter; left time: 28.7818s
Epoch: 1 cost time: 3.267346143722534
Epoch: 1, Steps: 206 | Train Loss: 1.0922242 Vali Loss: 1.0583814 Test Loss: 1.0431406
Validation loss decreased (inf --> 1.058381).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0639448
	speed: 0.0188s/iter; left time: 33.0523s
	iters: 200, epoch: 2 | loss: 1.0807993
	speed: 0.0159s/iter; left time: 26.3459s
Epoch: 2 cost time: 3.420286178588867
Epoch: 2, Steps: 206 | Train Loss: 1.0475698 Vali Loss: 1.0580556 Test Loss: 1.0445379
Validation loss decreased (1.058381 --> 1.058056).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0587498
	speed: 0.0218s/iter; left time: 33.7355s
	iters: 200, epoch: 3 | loss: 1.0429585
	speed: 0.0160s/iter; left time: 23.1888s
Epoch: 3 cost time: 3.4167213439941406
Epoch: 3, Steps: 206 | Train Loss: 1.0414394 Vali Loss: 1.0541887 Test Loss: 1.0412095
Validation loss decreased (1.058056 --> 1.054189).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0245043
	speed: 0.0140s/iter; left time: 18.7472s
	iters: 200, epoch: 4 | loss: 1.0613844
	speed: 0.0119s/iter; left time: 14.8267s
Epoch: 4 cost time: 2.6168038845062256
Epoch: 4, Steps: 206 | Train Loss: 1.0383812 Vali Loss: 1.0551095 Test Loss: 1.0431356
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0558339
	speed: 0.0162s/iter; left time: 18.4244s
	iters: 200, epoch: 5 | loss: 1.0228490
	speed: 0.0135s/iter; left time: 14.0209s
Epoch: 5 cost time: 2.9154746532440186
Epoch: 5, Steps: 206 | Train Loss: 1.0362196 Vali Loss: 1.0544188 Test Loss: 1.0419229
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0159044
	speed: 0.0207s/iter; left time: 19.2973s
	iters: 200, epoch: 6 | loss: 1.0292491
	speed: 0.0177s/iter; left time: 14.6738s
Epoch: 6 cost time: 3.7121737003326416
Epoch: 6, Steps: 206 | Train Loss: 1.0353390 Vali Loss: 1.0521994 Test Loss: 1.0401030
Validation loss decreased (1.054189 --> 1.052199).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0116514
	speed: 0.0177s/iter; left time: 12.8681s
	iters: 200, epoch: 7 | loss: 1.0239207
	speed: 0.0205s/iter; left time: 12.8230s
Epoch: 7 cost time: 4.379998445510864
Epoch: 7, Steps: 206 | Train Loss: 1.0349453 Vali Loss: 1.0531706 Test Loss: 1.0410721
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0362916
	speed: 0.0154s/iter; left time: 7.9829s
	iters: 200, epoch: 8 | loss: 1.0346808
	speed: 0.0135s/iter; left time: 5.6377s
Epoch: 8 cost time: 2.863740921020508
Epoch: 8, Steps: 206 | Train Loss: 1.0346211 Vali Loss: 1.0525023 Test Loss: 1.0408241
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0345036
	speed: 0.0194s/iter; left time: 6.0689s
	iters: 200, epoch: 9 | loss: 1.0558335
	speed: 0.0169s/iter; left time: 3.6038s
Epoch: 9 cost time: 3.574911594390869
Epoch: 9, Steps: 206 | Train Loss: 1.0347050 Vali Loss: 1.0531235 Test Loss: 1.0407830
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0435663
	speed: 0.0198s/iter; left time: 2.1200s
	iters: 200, epoch: 10 | loss: 1.0142899
	speed: 0.0183s/iter; left time: 0.1280s
Epoch: 10 cost time: 3.835209608078003
Epoch: 10, Steps: 206 | Train Loss: 1.0344001 Vali Loss: 1.0526823 Test Loss: 1.0407536
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0401028394699097, mae:0.8190188407897949
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0476896
	speed: 0.0177s/iter; left time: 34.6711s
	iters: 200, epoch: 1 | loss: 1.0385451
	speed: 0.0163s/iter; left time: 30.3720s
Epoch: 1 cost time: 3.502450704574585
Epoch: 1, Steps: 206 | Train Loss: 1.0931336 Vali Loss: 1.0603132 Test Loss: 1.0449903
Validation loss decreased (inf --> 1.060313).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0711913
	speed: 0.0151s/iter; left time: 26.5362s
	iters: 200, epoch: 2 | loss: 1.0615240
	speed: 0.0149s/iter; left time: 24.6597s
Epoch: 2 cost time: 3.1733920574188232
Epoch: 2, Steps: 206 | Train Loss: 1.0474477 Vali Loss: 1.0567977 Test Loss: 1.0428426
Validation loss decreased (1.060313 --> 1.056798).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0305804
	speed: 0.0236s/iter; left time: 36.5476s
	iters: 200, epoch: 3 | loss: 1.0434469
	speed: 0.0188s/iter; left time: 27.2275s
Epoch: 3 cost time: 3.949239492416382
Epoch: 3, Steps: 206 | Train Loss: 1.0414481 Vali Loss: 1.0555021 Test Loss: 1.0426215
Validation loss decreased (1.056798 --> 1.055502).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0422196
	speed: 0.0185s/iter; left time: 24.7809s
	iters: 200, epoch: 4 | loss: 1.0155005
	speed: 0.0156s/iter; left time: 19.4187s
Epoch: 4 cost time: 3.3287110328674316
Epoch: 4, Steps: 206 | Train Loss: 1.0384172 Vali Loss: 1.0534641 Test Loss: 1.0409777
Validation loss decreased (1.055502 --> 1.053464).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0217158
	speed: 0.0237s/iter; left time: 26.8940s
	iters: 200, epoch: 5 | loss: 1.0310853
	speed: 0.0179s/iter; left time: 18.6113s
Epoch: 5 cost time: 3.74035382270813
Epoch: 5, Steps: 206 | Train Loss: 1.0362134 Vali Loss: 1.0532670 Test Loss: 1.0417136
Validation loss decreased (1.053464 --> 1.053267).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0625104
	speed: 0.0120s/iter; left time: 11.1502s
	iters: 200, epoch: 6 | loss: 1.0277126
	speed: 0.0105s/iter; left time: 8.7014s
Epoch: 6 cost time: 2.291727066040039
Epoch: 6, Steps: 206 | Train Loss: 1.0349170 Vali Loss: 1.0525893 Test Loss: 1.0410117
Validation loss decreased (1.053267 --> 1.052589).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0485934
	speed: 0.0136s/iter; left time: 9.8434s
	iters: 200, epoch: 7 | loss: 1.0193287
	speed: 0.0123s/iter; left time: 7.6609s
Epoch: 7 cost time: 2.7660248279571533
Epoch: 7, Steps: 206 | Train Loss: 1.0346761 Vali Loss: 1.0532107 Test Loss: 1.0410213
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0386183
	speed: 0.0156s/iter; left time: 8.1040s
	iters: 200, epoch: 8 | loss: 1.0337975
	speed: 0.0154s/iter; left time: 6.4422s
Epoch: 8 cost time: 3.247258424758911
Epoch: 8, Steps: 206 | Train Loss: 1.0337555 Vali Loss: 1.0526937 Test Loss: 1.0411805
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0620528
	speed: 0.0207s/iter; left time: 6.4808s
	iters: 200, epoch: 9 | loss: 1.0388328
	speed: 0.0183s/iter; left time: 3.8944s
Epoch: 9 cost time: 3.872897148132324
Epoch: 9, Steps: 206 | Train Loss: 1.0341169 Vali Loss: 1.0527563 Test Loss: 1.0412468
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0499431
	speed: 0.0169s/iter; left time: 1.8116s
	iters: 200, epoch: 10 | loss: 1.0164123
	speed: 0.0183s/iter; left time: 0.1280s
Epoch: 10 cost time: 3.8615338802337646
Epoch: 10, Steps: 206 | Train Loss: 1.0340161 Vali Loss: 1.0529894 Test Loss: 1.0412605
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0410115718841553, mae:0.8194045424461365
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0420560
	speed: 0.0294s/iter; left time: 54.1062s
Epoch: 1 cost time: 4.705276012420654
Epoch: 1, Steps: 194 | Train Loss: 1.0940599 Vali Loss: 1.0515321 Test Loss: 1.0420943
Validation loss decreased (inf --> 1.051532).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0639017
	speed: 0.0226s/iter; left time: 37.2824s
Epoch: 2 cost time: 3.891012668609619
Epoch: 2, Steps: 194 | Train Loss: 1.0540143 Vali Loss: 1.0503699 Test Loss: 1.0449970
Validation loss decreased (1.051532 --> 1.050370).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0360423
	speed: 0.0144s/iter; left time: 20.9554s
Epoch: 3 cost time: 2.386589288711548
Epoch: 3, Steps: 194 | Train Loss: 1.0492864 Vali Loss: 1.0473026 Test Loss: 1.0411592
Validation loss decreased (1.050370 --> 1.047303).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0568260
	speed: 0.0176s/iter; left time: 22.1201s
Epoch: 4 cost time: 2.7193095684051514
Epoch: 4, Steps: 194 | Train Loss: 1.0463695 Vali Loss: 1.0453454 Test Loss: 1.0411816
Validation loss decreased (1.047303 --> 1.045345).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0442140
	speed: 0.0223s/iter; left time: 23.7983s
Epoch: 5 cost time: 3.633244514465332
Epoch: 5, Steps: 194 | Train Loss: 1.0449533 Vali Loss: 1.0464958 Test Loss: 1.0388260
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0349824
	speed: 0.0183s/iter; left time: 15.9311s
Epoch: 6 cost time: 3.009866237640381
Epoch: 6, Steps: 194 | Train Loss: 1.0445128 Vali Loss: 1.0451518 Test Loss: 1.0406508
Validation loss decreased (1.045345 --> 1.045152).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0376248
	speed: 0.0263s/iter; left time: 17.8080s
Epoch: 7 cost time: 4.110810995101929
Epoch: 7, Steps: 194 | Train Loss: 1.0438557 Vali Loss: 1.0450848 Test Loss: 1.0399954
Validation loss decreased (1.045152 --> 1.045085).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0476195
	speed: 0.0178s/iter; left time: 8.6002s
Epoch: 8 cost time: 3.0385661125183105
Epoch: 8, Steps: 194 | Train Loss: 1.0437168 Vali Loss: 1.0449030 Test Loss: 1.0399777
Validation loss decreased (1.045085 --> 1.044903).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0147473
	speed: 0.0186s/iter; left time: 5.3734s
Epoch: 9 cost time: 3.5032999515533447
Epoch: 9, Steps: 194 | Train Loss: 1.0436070 Vali Loss: 1.0451264 Test Loss: 1.0399938
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0401756
	speed: 0.0201s/iter; left time: 1.9055s
Epoch: 10 cost time: 3.307168960571289
Epoch: 10, Steps: 194 | Train Loss: 1.0434652 Vali Loss: 1.0449224 Test Loss: 1.0399718
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0399776697158813, mae:0.8183430433273315
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0352318
	speed: 0.0194s/iter; left time: 35.6562s
Epoch: 1 cost time: 3.2660393714904785
Epoch: 1, Steps: 194 | Train Loss: 1.0970114 Vali Loss: 1.0503795 Test Loss: 1.0480001
Validation loss decreased (inf --> 1.050380).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0654316
	speed: 0.0143s/iter; left time: 23.4930s
Epoch: 2 cost time: 2.9676642417907715
Epoch: 2, Steps: 194 | Train Loss: 1.0537007 Vali Loss: 1.0495019 Test Loss: 1.0438937
Validation loss decreased (1.050380 --> 1.049502).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0851158
	speed: 0.0150s/iter; left time: 21.7676s
Epoch: 3 cost time: 2.6526846885681152
Epoch: 3, Steps: 194 | Train Loss: 1.0486382 Vali Loss: 1.0458444 Test Loss: 1.0429720
Validation loss decreased (1.049502 --> 1.045844).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0658188
	speed: 0.0224s/iter; left time: 28.2240s
Epoch: 4 cost time: 3.8030447959899902
Epoch: 4, Steps: 194 | Train Loss: 1.0461703 Vali Loss: 1.0455556 Test Loss: 1.0416050
Validation loss decreased (1.045844 --> 1.045556).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0470022
	speed: 0.0260s/iter; left time: 27.7055s
Epoch: 5 cost time: 4.040913343429565
Epoch: 5, Steps: 194 | Train Loss: 1.0444919 Vali Loss: 1.0441493 Test Loss: 1.0413878
Validation loss decreased (1.045556 --> 1.044149).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0478921
	speed: 0.0239s/iter; left time: 20.8099s
Epoch: 6 cost time: 3.4925620555877686
Epoch: 6, Steps: 194 | Train Loss: 1.0437980 Vali Loss: 1.0458925 Test Loss: 1.0394239
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0549750
	speed: 0.0182s/iter; left time: 12.3458s
Epoch: 7 cost time: 2.7837469577789307
Epoch: 7, Steps: 194 | Train Loss: 1.0434159 Vali Loss: 1.0444753 Test Loss: 1.0403551
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0423154
	speed: 0.0144s/iter; left time: 6.9688s
Epoch: 8 cost time: 2.763875961303711
Epoch: 8, Steps: 194 | Train Loss: 1.0434212 Vali Loss: 1.0442665 Test Loss: 1.0401508
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0530111
	speed: 0.0226s/iter; left time: 6.5337s
Epoch: 9 cost time: 3.998852014541626
Epoch: 9, Steps: 194 | Train Loss: 1.0430108 Vali Loss: 1.0446544 Test Loss: 1.0401076
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0165431
	speed: 0.0157s/iter; left time: 1.4941s
Epoch: 10 cost time: 2.855494260787964
Epoch: 10, Steps: 194 | Train Loss: 1.0430936 Vali Loss: 1.0448012 Test Loss: 1.0400722
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.041387677192688, mae:0.8188908100128174
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0392219
	speed: 0.0176s/iter; left time: 32.4421s
Epoch: 1 cost time: 3.164895534515381
Epoch: 1, Steps: 194 | Train Loss: 1.0967717 Vali Loss: 1.0523769 Test Loss: 1.0443393
Validation loss decreased (inf --> 1.052377).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0623071
	speed: 0.0150s/iter; left time: 24.6757s
Epoch: 2 cost time: 2.566945791244507
Epoch: 2, Steps: 194 | Train Loss: 1.0536342 Vali Loss: 1.0488194 Test Loss: 1.0416219
Validation loss decreased (1.052377 --> 1.048819).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0344466
	speed: 0.0230s/iter; left time: 33.3581s
Epoch: 3 cost time: 3.9917960166931152
Epoch: 3, Steps: 194 | Train Loss: 1.0487398 Vali Loss: 1.0460067 Test Loss: 1.0433182
Validation loss decreased (1.048819 --> 1.046007).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0740343
	speed: 0.0193s/iter; left time: 24.3298s
Epoch: 4 cost time: 3.6292903423309326
Epoch: 4, Steps: 194 | Train Loss: 1.0463432 Vali Loss: 1.0446913 Test Loss: 1.0405941
Validation loss decreased (1.046007 --> 1.044691).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0514624
	speed: 0.0179s/iter; left time: 19.0705s
Epoch: 5 cost time: 3.284668445587158
Epoch: 5, Steps: 194 | Train Loss: 1.0445835 Vali Loss: 1.0454055 Test Loss: 1.0402504
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0395685
	speed: 0.0133s/iter; left time: 11.5773s
Epoch: 6 cost time: 2.3794500827789307
Epoch: 6, Steps: 194 | Train Loss: 1.0440911 Vali Loss: 1.0455767 Test Loss: 1.0396633
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0478826
	speed: 0.0138s/iter; left time: 9.3120s
Epoch: 7 cost time: 2.5475258827209473
Epoch: 7, Steps: 194 | Train Loss: 1.0435891 Vali Loss: 1.0450332 Test Loss: 1.0402471
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0257814
	speed: 0.0244s/iter; left time: 11.7947s
Epoch: 8 cost time: 3.6086769104003906
Epoch: 8, Steps: 194 | Train Loss: 1.0432893 Vali Loss: 1.0452805 Test Loss: 1.0399923
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0513914
	speed: 0.0181s/iter; left time: 5.2333s
Epoch: 9 cost time: 3.3691189289093018
Epoch: 9, Steps: 194 | Train Loss: 1.0432442 Vali Loss: 1.0451350 Test Loss: 1.0399892
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405941009521484, mae:0.818604052066803
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0532343
	speed: 0.0318s/iter; left time: 64.5535s
	iters: 200, epoch: 1 | loss: 1.0476911
	speed: 0.0230s/iter; left time: 44.4493s
Epoch: 1 cost time: 4.874472618103027
Epoch: 1, Steps: 213 | Train Loss: 1.0888462 Vali Loss: 1.0553423 Test Loss: 1.0475277
Validation loss decreased (inf --> 1.055342).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0084976
	speed: 0.0166s/iter; left time: 30.2041s
	iters: 200, epoch: 2 | loss: 1.0374579
	speed: 0.0166s/iter; left time: 28.4383s
Epoch: 2 cost time: 3.572911500930786
Epoch: 2, Steps: 213 | Train Loss: 1.0349421 Vali Loss: 1.0557811 Test Loss: 1.0483351
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0539888
	speed: 0.0208s/iter; left time: 33.3558s
	iters: 200, epoch: 3 | loss: 1.0555041
	speed: 0.0174s/iter; left time: 26.1433s
Epoch: 3 cost time: 3.7347536087036133
Epoch: 3, Steps: 213 | Train Loss: 1.0257565 Vali Loss: 1.0535812 Test Loss: 1.0459440
Validation loss decreased (1.055342 --> 1.053581).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9987551
	speed: 0.0150s/iter; left time: 20.8416s
	iters: 200, epoch: 4 | loss: 1.0450109
	speed: 0.0131s/iter; left time: 16.9001s
Epoch: 4 cost time: 2.8578646183013916
Epoch: 4, Steps: 213 | Train Loss: 1.0202675 Vali Loss: 1.0532024 Test Loss: 1.0461329
Validation loss decreased (1.053581 --> 1.053202).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0549787
	speed: 0.0124s/iter; left time: 14.5853s
	iters: 200, epoch: 5 | loss: 0.9738008
	speed: 0.0149s/iter; left time: 16.0493s
Epoch: 5 cost time: 3.296679735183716
Epoch: 5, Steps: 213 | Train Loss: 1.0174804 Vali Loss: 1.0546949 Test Loss: 1.0458399
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0457132
	speed: 0.0122s/iter; left time: 11.7567s
	iters: 200, epoch: 6 | loss: 1.0092499
	speed: 0.0126s/iter; left time: 10.8903s
Epoch: 6 cost time: 2.7302119731903076
Epoch: 6, Steps: 213 | Train Loss: 1.0154507 Vali Loss: 1.0526615 Test Loss: 1.0458510
Validation loss decreased (1.053202 --> 1.052662).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0151846
	speed: 0.0151s/iter; left time: 11.3505s
	iters: 200, epoch: 7 | loss: 1.0861204
	speed: 0.0166s/iter; left time: 10.8581s
Epoch: 7 cost time: 3.4909160137176514
Epoch: 7, Steps: 213 | Train Loss: 1.0145148 Vali Loss: 1.0545232 Test Loss: 1.0460075
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0227180
	speed: 0.0179s/iter; left time: 9.6878s
	iters: 200, epoch: 8 | loss: 0.9779159
	speed: 0.0156s/iter; left time: 6.8719s
Epoch: 8 cost time: 3.5516419410705566
Epoch: 8, Steps: 213 | Train Loss: 1.0142640 Vali Loss: 1.0532743 Test Loss: 1.0460209
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0109379
	speed: 0.0158s/iter; left time: 5.1793s
	iters: 200, epoch: 9 | loss: 0.9640225
	speed: 0.0152s/iter; left time: 3.4617s
Epoch: 9 cost time: 3.3587770462036133
Epoch: 9, Steps: 213 | Train Loss: 1.0142844 Vali Loss: 1.0537933 Test Loss: 1.0460711
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0232240
	speed: 0.0136s/iter; left time: 1.5546s
	iters: 200, epoch: 10 | loss: 1.0874600
	speed: 0.0122s/iter; left time: 0.1705s
Epoch: 10 cost time: 2.657912254333496
Epoch: 10, Steps: 213 | Train Loss: 1.0135204 Vali Loss: 1.0545473 Test Loss: 1.0460981
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0458511114120483, mae:0.8208395838737488
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0882912
	speed: 0.0202s/iter; left time: 40.9942s
	iters: 200, epoch: 1 | loss: 1.0400721
	speed: 0.0168s/iter; left time: 32.4270s
Epoch: 1 cost time: 3.6501071453094482
Epoch: 1, Steps: 213 | Train Loss: 1.0885004 Vali Loss: 1.0583394 Test Loss: 1.0472091
Validation loss decreased (inf --> 1.058339).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0348730
	speed: 0.0285s/iter; left time: 51.7342s
	iters: 200, epoch: 2 | loss: 1.0839261
	speed: 0.0207s/iter; left time: 35.5424s
Epoch: 2 cost time: 4.3571388721466064
Epoch: 2, Steps: 213 | Train Loss: 1.0348581 Vali Loss: 1.0582408 Test Loss: 1.0497091
Validation loss decreased (1.058339 --> 1.058241).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0463741
	speed: 0.0248s/iter; left time: 39.8198s
	iters: 200, epoch: 3 | loss: 1.0520089
	speed: 0.0197s/iter; left time: 29.6763s
Epoch: 3 cost time: 4.132611513137817
Epoch: 3, Steps: 213 | Train Loss: 1.0252769 Vali Loss: 1.0584236 Test Loss: 1.0475999
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0642787
	speed: 0.0132s/iter; left time: 18.3600s
	iters: 200, epoch: 4 | loss: 1.0308938
	speed: 0.0117s/iter; left time: 15.1620s
Epoch: 4 cost time: 2.780353546142578
Epoch: 4, Steps: 213 | Train Loss: 1.0203332 Vali Loss: 1.0536052 Test Loss: 1.0455270
Validation loss decreased (1.058241 --> 1.053605).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0416125
	speed: 0.0182s/iter; left time: 21.4150s
	iters: 200, epoch: 5 | loss: 1.0106628
	speed: 0.0165s/iter; left time: 17.7619s
Epoch: 5 cost time: 3.592543363571167
Epoch: 5, Steps: 213 | Train Loss: 1.0169612 Vali Loss: 1.0509307 Test Loss: 1.0455220
Validation loss decreased (1.053605 --> 1.050931).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0016545
	speed: 0.0145s/iter; left time: 14.0202s
	iters: 200, epoch: 6 | loss: 0.9851074
	speed: 0.0128s/iter; left time: 11.0432s
Epoch: 6 cost time: 2.822341203689575
Epoch: 6, Steps: 213 | Train Loss: 1.0153912 Vali Loss: 1.0530851 Test Loss: 1.0456457
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9889164
	speed: 0.0177s/iter; left time: 13.3342s
	iters: 200, epoch: 7 | loss: 0.9647040
	speed: 0.0136s/iter; left time: 8.8864s
Epoch: 7 cost time: 2.8864965438842773
Epoch: 7, Steps: 213 | Train Loss: 1.0146587 Vali Loss: 1.0519592 Test Loss: 1.0457052
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9829182
	speed: 0.0227s/iter; left time: 12.2458s
	iters: 200, epoch: 8 | loss: 0.9971385
	speed: 0.0185s/iter; left time: 8.1349s
Epoch: 8 cost time: 4.010770320892334
Epoch: 8, Steps: 213 | Train Loss: 1.0136685 Vali Loss: 1.0543892 Test Loss: 1.0457484
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9886180
	speed: 0.0206s/iter; left time: 6.7389s
	iters: 200, epoch: 9 | loss: 1.0210260
	speed: 0.0189s/iter; left time: 4.2968s
Epoch: 9 cost time: 3.979675054550171
Epoch: 9, Steps: 213 | Train Loss: 1.0132211 Vali Loss: 1.0511048 Test Loss: 1.0458008
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0600781
	speed: 0.0251s/iter; left time: 2.8565s
	iters: 200, epoch: 10 | loss: 0.9924583
	speed: 0.0206s/iter; left time: 0.2881s
Epoch: 10 cost time: 4.449995994567871
Epoch: 10, Steps: 213 | Train Loss: 1.0132984 Vali Loss: 1.0536929 Test Loss: 1.0458270
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0455220937728882, mae:0.8205751180648804
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0725639
	speed: 0.0139s/iter; left time: 28.2459s
	iters: 200, epoch: 1 | loss: 1.0675199
	speed: 0.0131s/iter; left time: 25.2627s
Epoch: 1 cost time: 2.914186954498291
Epoch: 1, Steps: 213 | Train Loss: 1.0884194 Vali Loss: 1.0580516 Test Loss: 1.0484130
Validation loss decreased (inf --> 1.058052).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0457207
	speed: 0.0192s/iter; left time: 34.9712s
	iters: 200, epoch: 2 | loss: 1.0487547
	speed: 0.0188s/iter; left time: 32.2979s
Epoch: 2 cost time: 4.175769090652466
Epoch: 2, Steps: 213 | Train Loss: 1.0340845 Vali Loss: 1.0575125 Test Loss: 1.0485882
Validation loss decreased (1.058052 --> 1.057513).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0213451
	speed: 0.0197s/iter; left time: 31.6786s
	iters: 200, epoch: 3 | loss: 1.0042682
	speed: 0.0171s/iter; left time: 25.7463s
Epoch: 3 cost time: 3.623460292816162
Epoch: 3, Steps: 213 | Train Loss: 1.0252591 Vali Loss: 1.0549932 Test Loss: 1.0466563
Validation loss decreased (1.057513 --> 1.054993).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9850706
	speed: 0.0215s/iter; left time: 29.8673s
	iters: 200, epoch: 4 | loss: 1.0274175
	speed: 0.0186s/iter; left time: 23.9729s
Epoch: 4 cost time: 3.99922251701355
Epoch: 4, Steps: 213 | Train Loss: 1.0198706 Vali Loss: 1.0537043 Test Loss: 1.0457677
Validation loss decreased (1.054993 --> 1.053704).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0591125
	speed: 0.0133s/iter; left time: 15.7106s
	iters: 200, epoch: 5 | loss: 1.0111355
	speed: 0.0108s/iter; left time: 11.6414s
Epoch: 5 cost time: 2.413485288619995
Epoch: 5, Steps: 213 | Train Loss: 1.0167581 Vali Loss: 1.0512991 Test Loss: 1.0454471
Validation loss decreased (1.053704 --> 1.051299).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0166769
	speed: 0.0233s/iter; left time: 22.4910s
	iters: 200, epoch: 6 | loss: 1.0147706
	speed: 0.0199s/iter; left time: 17.2529s
Epoch: 6 cost time: 4.484846591949463
Epoch: 6, Steps: 213 | Train Loss: 1.0152352 Vali Loss: 1.0527099 Test Loss: 1.0456413
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9741032
	speed: 0.0210s/iter; left time: 15.8378s
	iters: 200, epoch: 7 | loss: 0.9909028
	speed: 0.0181s/iter; left time: 11.8212s
Epoch: 7 cost time: 3.940366506576538
Epoch: 7, Steps: 213 | Train Loss: 1.0141986 Vali Loss: 1.0545819 Test Loss: 1.0457016
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0813131
	speed: 0.0212s/iter; left time: 11.4340s
	iters: 200, epoch: 8 | loss: 1.0261724
	speed: 0.0175s/iter; left time: 7.6805s
Epoch: 8 cost time: 3.6876535415649414
Epoch: 8, Steps: 213 | Train Loss: 1.0134066 Vali Loss: 1.0517498 Test Loss: 1.0458181
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0040181
	speed: 0.0214s/iter; left time: 6.9896s
	iters: 200, epoch: 9 | loss: 1.0048798
	speed: 0.0176s/iter; left time: 4.0031s
Epoch: 9 cost time: 3.8243775367736816
Epoch: 9, Steps: 213 | Train Loss: 1.0134115 Vali Loss: 1.0535102 Test Loss: 1.0458544
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0055455
	speed: 0.0167s/iter; left time: 1.9061s
	iters: 200, epoch: 10 | loss: 0.9769148
	speed: 0.0153s/iter; left time: 0.2143s
Epoch: 10 cost time: 3.341362714767456
Epoch: 10, Steps: 213 | Train Loss: 1.0133395 Vali Loss: 1.0517910 Test Loss: 1.0458788
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0454472303390503, mae:0.8205668330192566
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0469515
	speed: 0.0308s/iter; left time: 61.6475s
	iters: 200, epoch: 1 | loss: 1.0081143
	speed: 0.0245s/iter; left time: 46.6503s
Epoch: 1 cost time: 5.145084619522095
Epoch: 1, Steps: 210 | Train Loss: 1.0891977 Vali Loss: 1.0660244 Test Loss: 1.0543334
Validation loss decreased (inf --> 1.066024).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0430797
	speed: 0.0238s/iter; left time: 42.5885s
	iters: 200, epoch: 2 | loss: 1.0330482
	speed: 0.0190s/iter; left time: 32.1087s
Epoch: 2 cost time: 4.01750373840332
Epoch: 2, Steps: 210 | Train Loss: 1.0421758 Vali Loss: 1.0662123 Test Loss: 1.0545290
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0052297
	speed: 0.0165s/iter; left time: 26.0411s
	iters: 200, epoch: 3 | loss: 1.0067608
	speed: 0.0136s/iter; left time: 20.0835s
Epoch: 3 cost time: 2.940586566925049
Epoch: 3, Steps: 210 | Train Loss: 1.0348528 Vali Loss: 1.0635064 Test Loss: 1.0521605
Validation loss decreased (1.066024 --> 1.063506).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0359364
	speed: 0.0155s/iter; left time: 21.1941s
	iters: 200, epoch: 4 | loss: 1.0296134
	speed: 0.0182s/iter; left time: 23.1709s
Epoch: 4 cost time: 3.8762922286987305
Epoch: 4, Steps: 210 | Train Loss: 1.0308243 Vali Loss: 1.0619482 Test Loss: 1.0520992
Validation loss decreased (1.063506 --> 1.061948).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0217470
	speed: 0.0181s/iter; left time: 21.0077s
	iters: 200, epoch: 5 | loss: 1.0335934
	speed: 0.0180s/iter; left time: 19.1482s
Epoch: 5 cost time: 3.9049155712127686
Epoch: 5, Steps: 210 | Train Loss: 1.0282856 Vali Loss: 1.0582650 Test Loss: 1.0522134
Validation loss decreased (1.061948 --> 1.058265).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0173546
	speed: 0.0190s/iter; left time: 18.0609s
	iters: 200, epoch: 6 | loss: 1.0413033
	speed: 0.0178s/iter; left time: 15.1410s
Epoch: 6 cost time: 3.785853147506714
Epoch: 6, Steps: 210 | Train Loss: 1.0270742 Vali Loss: 1.0580990 Test Loss: 1.0517602
Validation loss decreased (1.058265 --> 1.058099).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0288985
	speed: 0.0175s/iter; left time: 12.9679s
	iters: 200, epoch: 7 | loss: 1.0568609
	speed: 0.0160s/iter; left time: 10.2385s
Epoch: 7 cost time: 3.328127384185791
Epoch: 7, Steps: 210 | Train Loss: 1.0262581 Vali Loss: 1.0593921 Test Loss: 1.0517255
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9812214
	speed: 0.0174s/iter; left time: 9.2574s
	iters: 200, epoch: 8 | loss: 0.9805943
	speed: 0.0161s/iter; left time: 6.9208s
Epoch: 8 cost time: 3.9060306549072266
Epoch: 8, Steps: 210 | Train Loss: 1.0256261 Vali Loss: 1.0569904 Test Loss: 1.0518517
Validation loss decreased (1.058099 --> 1.056990).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0363935
	speed: 0.0168s/iter; left time: 5.4056s
	iters: 200, epoch: 9 | loss: 1.0167010
	speed: 0.0154s/iter; left time: 3.3938s
Epoch: 9 cost time: 3.318197250366211
Epoch: 9, Steps: 210 | Train Loss: 1.0258339 Vali Loss: 1.0610503 Test Loss: 1.0519212
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0362614
	speed: 0.0166s/iter; left time: 1.8453s
	iters: 200, epoch: 10 | loss: 1.0336261
	speed: 0.0148s/iter; left time: 0.1633s
Epoch: 10 cost time: 3.1868648529052734
Epoch: 10, Steps: 210 | Train Loss: 1.0257097 Vali Loss: 1.0589694 Test Loss: 1.0519381
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0518519878387451, mae:0.8227430582046509
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0550559
	speed: 0.0152s/iter; left time: 30.4163s
	iters: 200, epoch: 1 | loss: 1.0384173
	speed: 0.0137s/iter; left time: 25.9999s
Epoch: 1 cost time: 2.9287993907928467
Epoch: 1, Steps: 210 | Train Loss: 1.0880740 Vali Loss: 1.0696952 Test Loss: 1.0538751
Validation loss decreased (inf --> 1.069695).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0875732
	speed: 0.0207s/iter; left time: 37.0622s
	iters: 200, epoch: 2 | loss: 1.0278091
	speed: 0.0152s/iter; left time: 25.7224s
Epoch: 2 cost time: 3.2976436614990234
Epoch: 2, Steps: 210 | Train Loss: 1.0427054 Vali Loss: 1.0614711 Test Loss: 1.0529531
Validation loss decreased (1.069695 --> 1.061471).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0376019
	speed: 0.0227s/iter; left time: 35.8821s
	iters: 200, epoch: 3 | loss: 1.0612655
	speed: 0.0176s/iter; left time: 26.1007s
Epoch: 3 cost time: 3.740726947784424
Epoch: 3, Steps: 210 | Train Loss: 1.0346729 Vali Loss: 1.0604403 Test Loss: 1.0524482
Validation loss decreased (1.061471 --> 1.060440).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0047724
	speed: 0.0241s/iter; left time: 33.0751s
	iters: 200, epoch: 4 | loss: 1.0555204
	speed: 0.0195s/iter; left time: 24.8423s
Epoch: 4 cost time: 4.160643577575684
Epoch: 4, Steps: 210 | Train Loss: 1.0306641 Vali Loss: 1.0604738 Test Loss: 1.0527005
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0032382
	speed: 0.0184s/iter; left time: 21.3291s
	iters: 200, epoch: 5 | loss: 1.0346941
	speed: 0.0171s/iter; left time: 18.1693s
Epoch: 5 cost time: 3.677980422973633
Epoch: 5, Steps: 210 | Train Loss: 1.0286221 Vali Loss: 1.0608315 Test Loss: 1.0524094
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0214459
	speed: 0.0175s/iter; left time: 16.6230s
	iters: 200, epoch: 6 | loss: 1.0228913
	speed: 0.0134s/iter; left time: 11.4052s
Epoch: 6 cost time: 2.8374135494232178
Epoch: 6, Steps: 210 | Train Loss: 1.0268886 Vali Loss: 1.0587976 Test Loss: 1.0522288
Validation loss decreased (1.060440 --> 1.058798).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0215440
	speed: 0.0227s/iter; left time: 16.8248s
	iters: 200, epoch: 7 | loss: 1.0242586
	speed: 0.0179s/iter; left time: 11.4955s
Epoch: 7 cost time: 3.9167938232421875
Epoch: 7, Steps: 210 | Train Loss: 1.0263293 Vali Loss: 1.0604867 Test Loss: 1.0521376
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0227166
	speed: 0.0188s/iter; left time: 9.9624s
	iters: 200, epoch: 8 | loss: 1.0057416
	speed: 0.0163s/iter; left time: 7.0395s
Epoch: 8 cost time: 3.4863765239715576
Epoch: 8, Steps: 210 | Train Loss: 1.0257875 Vali Loss: 1.0597336 Test Loss: 1.0521895
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0156590
	speed: 0.0171s/iter; left time: 5.4842s
	iters: 200, epoch: 9 | loss: 1.0258640
	speed: 0.0166s/iter; left time: 3.6652s
Epoch: 9 cost time: 3.552217483520508
Epoch: 9, Steps: 210 | Train Loss: 1.0254849 Vali Loss: 1.0575144 Test Loss: 1.0522584
Validation loss decreased (1.058798 --> 1.057514).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0490980
	speed: 0.0149s/iter; left time: 1.6508s
	iters: 200, epoch: 10 | loss: 1.0412767
	speed: 0.0170s/iter; left time: 0.1868s
Epoch: 10 cost time: 3.661334753036499
Epoch: 10, Steps: 210 | Train Loss: 1.0253021 Vali Loss: 1.0607374 Test Loss: 1.0522772
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0522582530975342, mae:0.8228569030761719
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0445598
	speed: 0.0257s/iter; left time: 51.3877s
	iters: 200, epoch: 1 | loss: 1.0489347
	speed: 0.0183s/iter; left time: 34.7333s
Epoch: 1 cost time: 3.8522729873657227
Epoch: 1, Steps: 210 | Train Loss: 1.0867148 Vali Loss: 1.0675330 Test Loss: 1.0541221
Validation loss decreased (inf --> 1.067533).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0320859
	speed: 0.0161s/iter; left time: 28.7609s
	iters: 200, epoch: 2 | loss: 1.0749427
	speed: 0.0180s/iter; left time: 30.4151s
Epoch: 2 cost time: 3.9723401069641113
Epoch: 2, Steps: 210 | Train Loss: 1.0421191 Vali Loss: 1.0648986 Test Loss: 1.0538143
Validation loss decreased (1.067533 --> 1.064899).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9933056
	speed: 0.0167s/iter; left time: 26.3469s
	iters: 200, epoch: 3 | loss: 1.0406051
	speed: 0.0135s/iter; left time: 20.0178s
Epoch: 3 cost time: 2.9119486808776855
Epoch: 3, Steps: 210 | Train Loss: 1.0350179 Vali Loss: 1.0618485 Test Loss: 1.0522859
Validation loss decreased (1.064899 --> 1.061849).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0237246
	speed: 0.0162s/iter; left time: 22.2239s
	iters: 200, epoch: 4 | loss: 1.0419071
	speed: 0.0147s/iter; left time: 18.6968s
Epoch: 4 cost time: 3.193803548812866
Epoch: 4, Steps: 210 | Train Loss: 1.0306087 Vali Loss: 1.0593545 Test Loss: 1.0518448
Validation loss decreased (1.061849 --> 1.059355).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0693374
	speed: 0.0214s/iter; left time: 24.8849s
	iters: 200, epoch: 5 | loss: 1.0296116
	speed: 0.0178s/iter; left time: 18.8639s
Epoch: 5 cost time: 3.8169612884521484
Epoch: 5, Steps: 210 | Train Loss: 1.0283005 Vali Loss: 1.0583497 Test Loss: 1.0521079
Validation loss decreased (1.059355 --> 1.058350).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0450655
	speed: 0.0179s/iter; left time: 17.0562s
	iters: 200, epoch: 6 | loss: 1.0082107
	speed: 0.0165s/iter; left time: 14.0635s
Epoch: 6 cost time: 3.590428352355957
Epoch: 6, Steps: 210 | Train Loss: 1.0270542 Vali Loss: 1.0583454 Test Loss: 1.0519872
Validation loss decreased (1.058350 --> 1.058345).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0115713
	speed: 0.0154s/iter; left time: 11.4430s
	iters: 200, epoch: 7 | loss: 1.0020422
	speed: 0.0142s/iter; left time: 9.1090s
Epoch: 7 cost time: 3.0973217487335205
Epoch: 7, Steps: 210 | Train Loss: 1.0263728 Vali Loss: 1.0570878 Test Loss: 1.0518446
Validation loss decreased (1.058345 --> 1.057088).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0045235
	speed: 0.0124s/iter; left time: 6.5788s
	iters: 200, epoch: 8 | loss: 1.0089711
	speed: 0.0110s/iter; left time: 4.7345s
Epoch: 8 cost time: 2.4194819927215576
Epoch: 8, Steps: 210 | Train Loss: 1.0261535 Vali Loss: 1.0599016 Test Loss: 1.0520191
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0403185
	speed: 0.0139s/iter; left time: 4.4485s
	iters: 200, epoch: 9 | loss: 1.0373783
	speed: 0.0151s/iter; left time: 3.3361s
Epoch: 9 cost time: 3.261258602142334
Epoch: 9, Steps: 210 | Train Loss: 1.0257467 Vali Loss: 1.0598319 Test Loss: 1.0519717
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0162728
	speed: 0.0225s/iter; left time: 2.4978s
	iters: 200, epoch: 10 | loss: 1.0163945
	speed: 0.0187s/iter; left time: 0.2055s
Epoch: 10 cost time: 3.948028087615967
Epoch: 10, Steps: 210 | Train Loss: 1.0255939 Vali Loss: 1.0598300 Test Loss: 1.0519853
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0518447160720825, mae:0.82274329662323
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0675970
	speed: 0.0347s/iter; left time: 68.0909s
	iters: 200, epoch: 1 | loss: 1.0596000
	speed: 0.0253s/iter; left time: 47.0287s
Epoch: 1 cost time: 5.237651348114014
Epoch: 1, Steps: 206 | Train Loss: 1.0917576 Vali Loss: 1.0576258 Test Loss: 1.0422479
Validation loss decreased (inf --> 1.057626).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0503405
	speed: 0.0131s/iter; left time: 22.9749s
	iters: 200, epoch: 2 | loss: 1.0553161
	speed: 0.0123s/iter; left time: 20.3454s
Epoch: 2 cost time: 2.6274330615997314
Epoch: 2, Steps: 206 | Train Loss: 1.0480015 Vali Loss: 1.0583105 Test Loss: 1.0428798
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0425979
	speed: 0.0186s/iter; left time: 28.7479s
	iters: 200, epoch: 3 | loss: 1.0463265
	speed: 0.0161s/iter; left time: 23.2788s
Epoch: 3 cost time: 3.4320499897003174
Epoch: 3, Steps: 206 | Train Loss: 1.0419302 Vali Loss: 1.0550666 Test Loss: 1.0417244
Validation loss decreased (1.057626 --> 1.055067).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0448107
	speed: 0.0182s/iter; left time: 24.4965s
	iters: 200, epoch: 4 | loss: 1.0350660
	speed: 0.0173s/iter; left time: 21.5383s
Epoch: 4 cost time: 3.636096954345703
Epoch: 4, Steps: 206 | Train Loss: 1.0389442 Vali Loss: 1.0531414 Test Loss: 1.0400889
Validation loss decreased (1.055067 --> 1.053141).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0394082
	speed: 0.0150s/iter; left time: 17.0936s
	iters: 200, epoch: 5 | loss: 1.0146651
	speed: 0.0142s/iter; left time: 14.7256s
Epoch: 5 cost time: 3.000885486602783
Epoch: 5, Steps: 206 | Train Loss: 1.0365048 Vali Loss: 1.0542523 Test Loss: 1.0416659
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0171331
	speed: 0.0157s/iter; left time: 14.5829s
	iters: 200, epoch: 6 | loss: 1.0443201
	speed: 0.0158s/iter; left time: 13.1470s
Epoch: 6 cost time: 3.340928316116333
Epoch: 6, Steps: 206 | Train Loss: 1.0353162 Vali Loss: 1.0529823 Test Loss: 1.0408208
Validation loss decreased (1.053141 --> 1.052982).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0388436
	speed: 0.0201s/iter; left time: 14.5922s
	iters: 200, epoch: 7 | loss: 1.0416731
	speed: 0.0183s/iter; left time: 11.4580s
Epoch: 7 cost time: 3.8797783851623535
Epoch: 7, Steps: 206 | Train Loss: 1.0349943 Vali Loss: 1.0530062 Test Loss: 1.0406415
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0243963
	speed: 0.0157s/iter; left time: 8.1653s
	iters: 200, epoch: 8 | loss: 1.0191892
	speed: 0.0163s/iter; left time: 6.8315s
Epoch: 8 cost time: 3.4984912872314453
Epoch: 8, Steps: 206 | Train Loss: 1.0345682 Vali Loss: 1.0525556 Test Loss: 1.0405740
Validation loss decreased (1.052982 --> 1.052556).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0270900
	speed: 0.0162s/iter; left time: 5.0677s
	iters: 200, epoch: 9 | loss: 1.0560399
	speed: 0.0141s/iter; left time: 2.9946s
Epoch: 9 cost time: 2.984055280685425
Epoch: 9, Steps: 206 | Train Loss: 1.0345447 Vali Loss: 1.0532196 Test Loss: 1.0406388
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0471115
	speed: 0.0141s/iter; left time: 1.5039s
	iters: 200, epoch: 10 | loss: 1.0350922
	speed: 0.0122s/iter; left time: 0.0852s
Epoch: 10 cost time: 2.5920934677124023
Epoch: 10, Steps: 206 | Train Loss: 1.0343561 Vali Loss: 1.0527179 Test Loss: 1.0406740
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0405739545822144, mae:0.8192630410194397
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0534617
	speed: 0.0186s/iter; left time: 36.5611s
	iters: 200, epoch: 1 | loss: 1.0589978
	speed: 0.0174s/iter; left time: 32.3863s
Epoch: 1 cost time: 3.6335065364837646
Epoch: 1, Steps: 206 | Train Loss: 1.0897033 Vali Loss: 1.0584861 Test Loss: 1.0435340
Validation loss decreased (inf --> 1.058486).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0618049
	speed: 0.0159s/iter; left time: 27.8555s
	iters: 200, epoch: 2 | loss: 1.0442735
	speed: 0.0151s/iter; left time: 24.9834s
Epoch: 2 cost time: 3.2187139987945557
Epoch: 2, Steps: 206 | Train Loss: 1.0479133 Vali Loss: 1.0575455 Test Loss: 1.0431126
Validation loss decreased (1.058486 --> 1.057546).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0267061
	speed: 0.0187s/iter; left time: 29.0288s
	iters: 200, epoch: 3 | loss: 1.0223850
	speed: 0.0157s/iter; left time: 22.6781s
Epoch: 3 cost time: 3.3303632736206055
Epoch: 3, Steps: 206 | Train Loss: 1.0418865 Vali Loss: 1.0559310 Test Loss: 1.0418054
Validation loss decreased (1.057546 --> 1.055931).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0169924
	speed: 0.0174s/iter; left time: 23.3334s
	iters: 200, epoch: 4 | loss: 1.0731660
	speed: 0.0130s/iter; left time: 16.1617s
Epoch: 4 cost time: 2.7386746406555176
Epoch: 4, Steps: 206 | Train Loss: 1.0384809 Vali Loss: 1.0542688 Test Loss: 1.0411981
Validation loss decreased (1.055931 --> 1.054269).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0311432
	speed: 0.0164s/iter; left time: 18.6354s
	iters: 200, epoch: 5 | loss: 1.0312167
	speed: 0.0139s/iter; left time: 14.4140s
Epoch: 5 cost time: 2.9313552379608154
Epoch: 5, Steps: 206 | Train Loss: 1.0365326 Vali Loss: 1.0535054 Test Loss: 1.0409111
Validation loss decreased (1.054269 --> 1.053505).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0219396
	speed: 0.0274s/iter; left time: 25.4987s
	iters: 200, epoch: 6 | loss: 1.0542537
	speed: 0.0199s/iter; left time: 16.5078s
Epoch: 6 cost time: 4.112256288528442
Epoch: 6, Steps: 206 | Train Loss: 1.0355110 Vali Loss: 1.0537612 Test Loss: 1.0408955
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0129081
	speed: 0.0276s/iter; left time: 19.9980s
	iters: 200, epoch: 7 | loss: 1.0552839
	speed: 0.0198s/iter; left time: 12.3587s
Epoch: 7 cost time: 4.14331841468811
Epoch: 7, Steps: 206 | Train Loss: 1.0352561 Vali Loss: 1.0535151 Test Loss: 1.0406027
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0608134
	speed: 0.0247s/iter; left time: 12.8205s
	iters: 200, epoch: 8 | loss: 1.0207565
	speed: 0.0171s/iter; left time: 7.1624s
Epoch: 8 cost time: 3.567025899887085
Epoch: 8, Steps: 206 | Train Loss: 1.0347863 Vali Loss: 1.0530347 Test Loss: 1.0407588
Validation loss decreased (1.053505 --> 1.053035).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0254855
	speed: 0.0205s/iter; left time: 6.4132s
	iters: 200, epoch: 9 | loss: 1.0368642
	speed: 0.0151s/iter; left time: 3.2226s
Epoch: 9 cost time: 3.192662000656128
Epoch: 9, Steps: 206 | Train Loss: 1.0344611 Vali Loss: 1.0530090 Test Loss: 1.0407172
Validation loss decreased (1.053035 --> 1.053009).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0175003
	speed: 0.0154s/iter; left time: 1.6444s
	iters: 200, epoch: 10 | loss: 1.0097977
	speed: 0.0122s/iter; left time: 0.0851s
Epoch: 10 cost time: 2.5875980854034424
Epoch: 10, Steps: 206 | Train Loss: 1.0347261 Vali Loss: 1.0531869 Test Loss: 1.0407120
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0407172441482544, mae:0.8193281888961792
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0744309
	speed: 0.0185s/iter; left time: 36.1815s
	iters: 200, epoch: 1 | loss: 1.0307047
	speed: 0.0157s/iter; left time: 29.2012s
Epoch: 1 cost time: 3.4267961978912354
Epoch: 1, Steps: 206 | Train Loss: 1.0932046 Vali Loss: 1.0621338 Test Loss: 1.0465759
Validation loss decreased (inf --> 1.062134).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0512373
	speed: 0.0187s/iter; left time: 32.8391s
	iters: 200, epoch: 2 | loss: 1.0732508
	speed: 0.0189s/iter; left time: 31.2467s
Epoch: 2 cost time: 3.918572425842285
Epoch: 2, Steps: 206 | Train Loss: 1.0480872 Vali Loss: 1.0581338 Test Loss: 1.0442184
Validation loss decreased (1.062134 --> 1.058134).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0409995
	speed: 0.0181s/iter; left time: 28.0209s
	iters: 200, epoch: 3 | loss: 1.0314229
	speed: 0.0152s/iter; left time: 22.0943s
Epoch: 3 cost time: 3.2246909141540527
Epoch: 3, Steps: 206 | Train Loss: 1.0413414 Vali Loss: 1.0554597 Test Loss: 1.0421650
Validation loss decreased (1.058134 --> 1.055460).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0454050
	speed: 0.0152s/iter; left time: 20.4141s
	iters: 200, epoch: 4 | loss: 1.0547090
	speed: 0.0139s/iter; left time: 17.3372s
Epoch: 4 cost time: 2.8947908878326416
Epoch: 4, Steps: 206 | Train Loss: 1.0382183 Vali Loss: 1.0545118 Test Loss: 1.0426382
Validation loss decreased (1.055460 --> 1.054512).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0456339
	speed: 0.0319s/iter; left time: 36.2750s
	iters: 200, epoch: 5 | loss: 1.0559949
	speed: 0.0229s/iter; left time: 23.7267s
Epoch: 5 cost time: 4.712488651275635
Epoch: 5, Steps: 206 | Train Loss: 1.0360999 Vali Loss: 1.0531638 Test Loss: 1.0412964
Validation loss decreased (1.054512 --> 1.053164).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0601449
	speed: 0.0292s/iter; left time: 27.2053s
	iters: 200, epoch: 6 | loss: 1.0526925
	speed: 0.0219s/iter; left time: 18.1981s
Epoch: 6 cost time: 4.537257432937622
Epoch: 6, Steps: 206 | Train Loss: 1.0351471 Vali Loss: 1.0528331 Test Loss: 1.0409168
Validation loss decreased (1.053164 --> 1.052833).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0340626
	speed: 0.0151s/iter; left time: 10.9617s
	iters: 200, epoch: 7 | loss: 1.0134245
	speed: 0.0122s/iter; left time: 7.6504s
Epoch: 7 cost time: 2.592193603515625
Epoch: 7, Steps: 206 | Train Loss: 1.0347727 Vali Loss: 1.0528635 Test Loss: 1.0409831
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0288814
	speed: 0.0126s/iter; left time: 6.5509s
	iters: 200, epoch: 8 | loss: 1.0228039
	speed: 0.0125s/iter; left time: 5.2233s
Epoch: 8 cost time: 2.6791303157806396
Epoch: 8, Steps: 206 | Train Loss: 1.0342734 Vali Loss: 1.0531324 Test Loss: 1.0409027
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0262465
	speed: 0.0257s/iter; left time: 8.0336s
	iters: 200, epoch: 9 | loss: 1.0330551
	speed: 0.0196s/iter; left time: 4.1659s
Epoch: 9 cost time: 4.120169401168823
Epoch: 9, Steps: 206 | Train Loss: 1.0343100 Vali Loss: 1.0527114 Test Loss: 1.0409234
Validation loss decreased (1.052833 --> 1.052711).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0494652
	speed: 0.0163s/iter; left time: 1.7487s
	iters: 200, epoch: 10 | loss: 1.0044712
	speed: 0.0156s/iter; left time: 0.1089s
Epoch: 10 cost time: 3.314716100692749
Epoch: 10, Steps: 206 | Train Loss: 1.0343102 Vali Loss: 1.0526415 Test Loss: 1.0409228
Validation loss decreased (1.052711 --> 1.052642).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0409226417541504, mae:0.8193480372428894
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0607793
	speed: 0.0303s/iter; left time: 55.8339s
Epoch: 1 cost time: 4.512373685836792
Epoch: 1, Steps: 194 | Train Loss: 1.0972690 Vali Loss: 1.0502180 Test Loss: 1.0439484
Validation loss decreased (inf --> 1.050218).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0483447
	speed: 0.0214s/iter; left time: 35.3156s
Epoch: 2 cost time: 4.12258505821228
Epoch: 2, Steps: 194 | Train Loss: 1.0537285 Vali Loss: 1.0468093 Test Loss: 1.0471427
Validation loss decreased (1.050218 --> 1.046809).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0639610
	speed: 0.0169s/iter; left time: 24.5392s
Epoch: 3 cost time: 3.2748141288757324
Epoch: 3, Steps: 194 | Train Loss: 1.0487586 Vali Loss: 1.0467860 Test Loss: 1.0416647
Validation loss decreased (1.046809 --> 1.046786).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0413263
	speed: 0.0123s/iter; left time: 15.4337s
Epoch: 4 cost time: 2.591374397277832
Epoch: 4, Steps: 194 | Train Loss: 1.0463583 Vali Loss: 1.0443389 Test Loss: 1.0430045
Validation loss decreased (1.046786 --> 1.044339).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0466335
	speed: 0.0199s/iter; left time: 21.1576s
Epoch: 5 cost time: 3.361332893371582
Epoch: 5, Steps: 194 | Train Loss: 1.0449570 Vali Loss: 1.0441245 Test Loss: 1.0416626
Validation loss decreased (1.044339 --> 1.044124).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0347815
	speed: 0.0237s/iter; left time: 20.6830s
Epoch: 6 cost time: 3.8326518535614014
Epoch: 6, Steps: 194 | Train Loss: 1.0439913 Vali Loss: 1.0448748 Test Loss: 1.0405546
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0420113
	speed: 0.0204s/iter; left time: 13.8286s
Epoch: 7 cost time: 3.345146656036377
Epoch: 7, Steps: 194 | Train Loss: 1.0437122 Vali Loss: 1.0449256 Test Loss: 1.0400453
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0490056
	speed: 0.0156s/iter; left time: 7.5250s
Epoch: 8 cost time: 2.6190433502197266
Epoch: 8, Steps: 194 | Train Loss: 1.0434925 Vali Loss: 1.0454906 Test Loss: 1.0397754
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0641388
	speed: 0.0119s/iter; left time: 3.4517s
Epoch: 9 cost time: 2.6294121742248535
Epoch: 9, Steps: 194 | Train Loss: 1.0433894 Vali Loss: 1.0451961 Test Loss: 1.0398879
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0372130
	speed: 0.0160s/iter; left time: 1.5161s
Epoch: 10 cost time: 3.5690033435821533
Epoch: 10, Steps: 194 | Train Loss: 1.0432829 Vali Loss: 1.0450666 Test Loss: 1.0399600
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0416624546051025, mae:0.8190021514892578
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0781393
	speed: 0.0197s/iter; left time: 36.2273s
Epoch: 1 cost time: 3.3347384929656982
Epoch: 1, Steps: 194 | Train Loss: 1.0956674 Vali Loss: 1.0524495 Test Loss: 1.0423986
Validation loss decreased (inf --> 1.052449).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0410224
	speed: 0.0194s/iter; left time: 32.0222s
Epoch: 2 cost time: 3.6467769145965576
Epoch: 2, Steps: 194 | Train Loss: 1.0536599 Vali Loss: 1.0492654 Test Loss: 1.0425560
Validation loss decreased (1.052449 --> 1.049265).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0657402
	speed: 0.0160s/iter; left time: 23.3168s
Epoch: 3 cost time: 2.7957544326782227
Epoch: 3, Steps: 194 | Train Loss: 1.0488404 Vali Loss: 1.0495995 Test Loss: 1.0395662
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0287906
	speed: 0.0167s/iter; left time: 21.0571s
Epoch: 4 cost time: 2.9818992614746094
Epoch: 4, Steps: 194 | Train Loss: 1.0463587 Vali Loss: 1.0459063 Test Loss: 1.0418539
Validation loss decreased (1.049265 --> 1.045906).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0514967
	speed: 0.0211s/iter; left time: 22.4191s
Epoch: 5 cost time: 3.1857709884643555
Epoch: 5, Steps: 194 | Train Loss: 1.0449664 Vali Loss: 1.0445111 Test Loss: 1.0398974
Validation loss decreased (1.045906 --> 1.044511).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0544914
	speed: 0.0253s/iter; left time: 22.0137s
Epoch: 6 cost time: 3.662925958633423
Epoch: 6, Steps: 194 | Train Loss: 1.0439176 Vali Loss: 1.0444791 Test Loss: 1.0401721
Validation loss decreased (1.044511 --> 1.044479).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0632166
	speed: 0.0137s/iter; left time: 9.2602s
Epoch: 7 cost time: 2.289745569229126
Epoch: 7, Steps: 194 | Train Loss: 1.0437860 Vali Loss: 1.0447266 Test Loss: 1.0400740
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0439978
	speed: 0.0209s/iter; left time: 10.0843s
Epoch: 8 cost time: 3.611205816268921
Epoch: 8, Steps: 194 | Train Loss: 1.0435227 Vali Loss: 1.0445819 Test Loss: 1.0402404
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0709873
	speed: 0.0173s/iter; left time: 4.9994s
Epoch: 9 cost time: 3.0435967445373535
Epoch: 9, Steps: 194 | Train Loss: 1.0433761 Vali Loss: 1.0446321 Test Loss: 1.0400599
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0318578
	speed: 0.0148s/iter; left time: 1.4093s
Epoch: 10 cost time: 3.112673282623291
Epoch: 10, Steps: 194 | Train Loss: 1.0428796 Vali Loss: 1.0448303 Test Loss: 1.0401185
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0401722192764282, mae:0.8184317946434021
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0623996
	speed: 0.0212s/iter; left time: 39.0779s
Epoch: 1 cost time: 3.5726816654205322
Epoch: 1, Steps: 194 | Train Loss: 1.1004809 Vali Loss: 1.0527656 Test Loss: 1.0459090
Validation loss decreased (inf --> 1.052766).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0382465
	speed: 0.0149s/iter; left time: 24.4761s
Epoch: 2 cost time: 2.6953234672546387
Epoch: 2, Steps: 194 | Train Loss: 1.0535115 Vali Loss: 1.0479188 Test Loss: 1.0434731
Validation loss decreased (1.052766 --> 1.047919).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0602139
	speed: 0.0192s/iter; left time: 27.9480s
Epoch: 3 cost time: 3.4607794284820557
Epoch: 3, Steps: 194 | Train Loss: 1.0485955 Vali Loss: 1.0497499 Test Loss: 1.0403514
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0577904
	speed: 0.0166s/iter; left time: 20.8937s
Epoch: 4 cost time: 3.1117899417877197
Epoch: 4, Steps: 194 | Train Loss: 1.0460820 Vali Loss: 1.0459431 Test Loss: 1.0404929
Validation loss decreased (1.047919 --> 1.045943).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0745941
	speed: 0.0177s/iter; left time: 18.8174s
Epoch: 5 cost time: 3.719482421875
Epoch: 5, Steps: 194 | Train Loss: 1.0446687 Vali Loss: 1.0468212 Test Loss: 1.0397263
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0465903
	speed: 0.0172s/iter; left time: 15.0029s
Epoch: 6 cost time: 3.141728639602661
Epoch: 6, Steps: 194 | Train Loss: 1.0438414 Vali Loss: 1.0455997 Test Loss: 1.0403639
Validation loss decreased (1.045943 --> 1.045600).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0502298
	speed: 0.0218s/iter; left time: 14.7655s
Epoch: 7 cost time: 3.445621967315674
Epoch: 7, Steps: 194 | Train Loss: 1.0433110 Vali Loss: 1.0449830 Test Loss: 1.0400054
Validation loss decreased (1.045600 --> 1.044983).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0625620
	speed: 0.0182s/iter; left time: 8.8106s
Epoch: 8 cost time: 3.185312032699585
Epoch: 8, Steps: 194 | Train Loss: 1.0432896 Vali Loss: 1.0449338 Test Loss: 1.0398859
Validation loss decreased (1.044983 --> 1.044934).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0157145
	speed: 0.0152s/iter; left time: 4.4046s
Epoch: 9 cost time: 2.862980842590332
Epoch: 9, Steps: 194 | Train Loss: 1.0431922 Vali Loss: 1.0448895 Test Loss: 1.0399842
Validation loss decreased (1.044934 --> 1.044889).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0403992
	speed: 0.0187s/iter; left time: 1.7766s
Epoch: 10 cost time: 3.1332850456237793
Epoch: 10, Steps: 194 | Train Loss: 1.0431597 Vali Loss: 1.0450082 Test Loss: 1.0399920
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.039984107017517, mae:0.8183802962303162
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5695729
	speed: 0.0271s/iter; left time: 55.0361s
	iters: 200, epoch: 1 | loss: 0.5329464
	speed: 0.0221s/iter; left time: 42.7646s
Epoch: 1 cost time: 4.702104330062866
Epoch: 1, Steps: 213 | Train Loss: 0.5482086 Vali Loss: 0.4838418 Test Loss: 0.6098158
Validation loss decreased (inf --> 0.483842).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5877775
	speed: 0.0141s/iter; left time: 25.5912s
	iters: 200, epoch: 2 | loss: 0.5616010
	speed: 0.0148s/iter; left time: 25.4241s
Epoch: 2 cost time: 3.2962992191314697
Epoch: 2, Steps: 213 | Train Loss: 0.5100586 Vali Loss: 0.4761645 Test Loss: 0.6390460
Validation loss decreased (0.483842 --> 0.476164).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4702216
	speed: 0.0182s/iter; left time: 29.2209s
	iters: 200, epoch: 3 | loss: 0.4390013
	speed: 0.0163s/iter; left time: 24.5608s
Epoch: 3 cost time: 3.5580296516418457
Epoch: 3, Steps: 213 | Train Loss: 0.4907994 Vali Loss: 0.4819970 Test Loss: 0.6619591
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4196734
	speed: 0.0261s/iter; left time: 36.3429s
	iters: 200, epoch: 4 | loss: 0.4074273
	speed: 0.0214s/iter; left time: 27.5863s
Epoch: 4 cost time: 4.6187193393707275
Epoch: 4, Steps: 213 | Train Loss: 0.4775297 Vali Loss: 0.4770369 Test Loss: 0.6728396
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4960366
	speed: 0.0210s/iter; left time: 24.7242s
	iters: 200, epoch: 5 | loss: 0.4905980
	speed: 0.0189s/iter; left time: 20.3898s
Epoch: 5 cost time: 4.008434057235718
Epoch: 5, Steps: 213 | Train Loss: 0.4705862 Vali Loss: 0.5010762 Test Loss: 0.6939699
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4252025
	speed: 0.0125s/iter; left time: 12.0489s
	iters: 200, epoch: 6 | loss: 0.4577626
	speed: 0.0106s/iter; left time: 9.2041s
Epoch: 6 cost time: 2.433688163757324
Epoch: 6, Steps: 213 | Train Loss: 0.4660881 Vali Loss: 0.4880430 Test Loss: 0.6882479
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4707229
	speed: 0.0159s/iter; left time: 11.9437s
	iters: 200, epoch: 7 | loss: 0.4315952
	speed: 0.0139s/iter; left time: 9.0900s
Epoch: 7 cost time: 3.1150412559509277
Epoch: 7, Steps: 213 | Train Loss: 0.4646390 Vali Loss: 0.4878437 Test Loss: 0.6868252
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6390458941459656, mae:0.6343209743499756
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5132884
	speed: 0.0163s/iter; left time: 33.0938s
	iters: 200, epoch: 1 | loss: 0.5241345
	speed: 0.0156s/iter; left time: 30.2059s
Epoch: 1 cost time: 3.4806556701660156
Epoch: 1, Steps: 213 | Train Loss: 0.5483057 Vali Loss: 0.4973626 Test Loss: 0.6009666
Validation loss decreased (inf --> 0.497363).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5108354
	speed: 0.0166s/iter; left time: 30.1510s
	iters: 200, epoch: 2 | loss: 0.4738830
	speed: 0.0140s/iter; left time: 23.9993s
Epoch: 2 cost time: 2.9882004261016846
Epoch: 2, Steps: 213 | Train Loss: 0.5122690 Vali Loss: 0.5135839 Test Loss: 0.6533461
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5096266
	speed: 0.0119s/iter; left time: 19.1712s
	iters: 200, epoch: 3 | loss: 0.4500412
	speed: 0.0106s/iter; left time: 15.9064s
Epoch: 3 cost time: 2.325194835662842
Epoch: 3, Steps: 213 | Train Loss: 0.4940864 Vali Loss: 0.4969209 Test Loss: 0.6457707
Validation loss decreased (0.497363 --> 0.496921).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4987413
	speed: 0.0234s/iter; left time: 32.6180s
	iters: 200, epoch: 4 | loss: 0.5392436
	speed: 0.0181s/iter; left time: 23.4460s
Epoch: 4 cost time: 3.880955219268799
Epoch: 4, Steps: 213 | Train Loss: 0.4833559 Vali Loss: 0.5090770 Test Loss: 0.6641964
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4385185
	speed: 0.0169s/iter; left time: 19.9087s
	iters: 200, epoch: 5 | loss: 0.4632332
	speed: 0.0162s/iter; left time: 17.5091s
Epoch: 5 cost time: 3.7421727180480957
Epoch: 5, Steps: 213 | Train Loss: 0.4761785 Vali Loss: 0.5146807 Test Loss: 0.6800295
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4575989
	speed: 0.0186s/iter; left time: 17.9636s
	iters: 200, epoch: 6 | loss: 0.4494144
	speed: 0.0154s/iter; left time: 13.3456s
Epoch: 6 cost time: 3.3035337924957275
Epoch: 6, Steps: 213 | Train Loss: 0.4717921 Vali Loss: 0.5044766 Test Loss: 0.6747972
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4701849
	speed: 0.0166s/iter; left time: 12.4684s
	iters: 200, epoch: 7 | loss: 0.5029228
	speed: 0.0153s/iter; left time: 9.9587s
Epoch: 7 cost time: 3.291980266571045
Epoch: 7, Steps: 213 | Train Loss: 0.4695968 Vali Loss: 0.5152815 Test Loss: 0.6791458
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4531851
	speed: 0.0209s/iter; left time: 11.2756s
	iters: 200, epoch: 8 | loss: 0.4565141
	speed: 0.0176s/iter; left time: 7.7266s
Epoch: 8 cost time: 3.837117910385132
Epoch: 8, Steps: 213 | Train Loss: 0.4684323 Vali Loss: 0.5111937 Test Loss: 0.6785019
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6457707285881042, mae:0.6348257660865784
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5477122
	speed: 0.0218s/iter; left time: 44.3511s
	iters: 200, epoch: 1 | loss: 0.5949073
	speed: 0.0203s/iter; left time: 39.2156s
Epoch: 1 cost time: 4.349559545516968
Epoch: 1, Steps: 213 | Train Loss: 0.5474113 Vali Loss: 0.4875790 Test Loss: 0.6130431
Validation loss decreased (inf --> 0.487579).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4856974
	speed: 0.0184s/iter; left time: 33.5075s
	iters: 200, epoch: 2 | loss: 0.4708312
	speed: 0.0155s/iter; left time: 26.6943s
Epoch: 2 cost time: 3.3670670986175537
Epoch: 2, Steps: 213 | Train Loss: 0.5098832 Vali Loss: 0.5315027 Test Loss: 0.6586014
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4254800
	speed: 0.0189s/iter; left time: 30.2887s
	iters: 200, epoch: 3 | loss: 0.5006876
	speed: 0.0171s/iter; left time: 25.7485s
Epoch: 3 cost time: 3.679671049118042
Epoch: 3, Steps: 213 | Train Loss: 0.4913002 Vali Loss: 0.4909177 Test Loss: 0.6522925
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5111911
	speed: 0.0174s/iter; left time: 24.2314s
	iters: 200, epoch: 4 | loss: 0.4368977
	speed: 0.0166s/iter; left time: 21.4072s
Epoch: 4 cost time: 3.5414741039276123
Epoch: 4, Steps: 213 | Train Loss: 0.4764400 Vali Loss: 0.5000924 Test Loss: 0.6568497
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4832124
	speed: 0.0166s/iter; left time: 19.5450s
	iters: 200, epoch: 5 | loss: 0.4516595
	speed: 0.0140s/iter; left time: 15.0845s
Epoch: 5 cost time: 3.0129687786102295
Epoch: 5, Steps: 213 | Train Loss: 0.4681562 Vali Loss: 0.5023235 Test Loss: 0.6686356
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4918200
	speed: 0.0155s/iter; left time: 15.0177s
	iters: 200, epoch: 6 | loss: 0.5252055
	speed: 0.0121s/iter; left time: 10.4567s
Epoch: 6 cost time: 2.6199097633361816
Epoch: 6, Steps: 213 | Train Loss: 0.4643270 Vali Loss: 0.5010841 Test Loss: 0.6693602
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6130432486534119, mae:0.6197364330291748
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7526102
	speed: 0.0280s/iter; left time: 55.9934s
	iters: 200, epoch: 1 | loss: 0.7437929
	speed: 0.0205s/iter; left time: 38.9218s
Epoch: 1 cost time: 4.264517307281494
Epoch: 1, Steps: 210 | Train Loss: 0.6764873 Vali Loss: 0.6319498 Test Loss: 0.9492463
Validation loss decreased (inf --> 0.631950).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6324743
	speed: 0.0128s/iter; left time: 22.8387s
	iters: 200, epoch: 2 | loss: 0.7531242
	speed: 0.0108s/iter; left time: 18.2831s
Epoch: 2 cost time: 2.312190055847168
Epoch: 2, Steps: 210 | Train Loss: 0.6345641 Vali Loss: 0.6099730 Test Loss: 0.9416755
Validation loss decreased (0.631950 --> 0.609973).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6171371
	speed: 0.0178s/iter; left time: 28.1106s
	iters: 200, epoch: 3 | loss: 0.5843887
	speed: 0.0142s/iter; left time: 20.9875s
Epoch: 3 cost time: 3.0283868312835693
Epoch: 3, Steps: 210 | Train Loss: 0.6099783 Vali Loss: 0.6108697 Test Loss: 1.0132613
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5674148
	speed: 0.0145s/iter; left time: 19.8817s
	iters: 200, epoch: 4 | loss: 0.6019337
	speed: 0.0159s/iter; left time: 20.1718s
Epoch: 4 cost time: 3.4145185947418213
Epoch: 4, Steps: 210 | Train Loss: 0.5917826 Vali Loss: 0.5963599 Test Loss: 1.0210700
Validation loss decreased (0.609973 --> 0.596360).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5714856
	speed: 0.0147s/iter; left time: 17.1078s
	iters: 200, epoch: 5 | loss: 0.6132643
	speed: 0.0131s/iter; left time: 13.9446s
Epoch: 5 cost time: 2.770113945007324
Epoch: 5, Steps: 210 | Train Loss: 0.5796979 Vali Loss: 0.6106586 Test Loss: 1.0232426
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5564178
	speed: 0.0188s/iter; left time: 17.8912s
	iters: 200, epoch: 6 | loss: 0.6169283
	speed: 0.0147s/iter; left time: 12.5034s
Epoch: 6 cost time: 3.113074779510498
Epoch: 6, Steps: 210 | Train Loss: 0.5732749 Vali Loss: 0.6088423 Test Loss: 1.0110167
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6431934
	speed: 0.0234s/iter; left time: 17.3574s
	iters: 200, epoch: 7 | loss: 0.6087064
	speed: 0.0196s/iter; left time: 12.5514s
Epoch: 7 cost time: 4.189866304397583
Epoch: 7, Steps: 210 | Train Loss: 0.5695235 Vali Loss: 0.6285625 Test Loss: 1.0160898
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6783285
	speed: 0.0253s/iter; left time: 13.4352s
	iters: 200, epoch: 8 | loss: 0.5543894
	speed: 0.0213s/iter; left time: 9.1883s
Epoch: 8 cost time: 4.536978006362915
Epoch: 8, Steps: 210 | Train Loss: 0.5678903 Vali Loss: 0.6208706 Test Loss: 1.0150932
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5822980
	speed: 0.0241s/iter; left time: 7.7359s
	iters: 200, epoch: 9 | loss: 0.5656650
	speed: 0.0174s/iter; left time: 3.8411s
Epoch: 9 cost time: 3.67117977142334
Epoch: 9, Steps: 210 | Train Loss: 0.5667292 Vali Loss: 0.6213324 Test Loss: 1.0180589
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0210700035095215, mae:0.7930920720100403
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7408159
	speed: 0.0183s/iter; left time: 36.6962s
	iters: 200, epoch: 1 | loss: 0.5727866
	speed: 0.0178s/iter; left time: 33.8703s
Epoch: 1 cost time: 3.729876756668091
Epoch: 1, Steps: 210 | Train Loss: 0.6784049 Vali Loss: 0.5904779 Test Loss: 0.9142079
Validation loss decreased (inf --> 0.590478).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5887799
	speed: 0.0228s/iter; left time: 40.8223s
	iters: 200, epoch: 2 | loss: 0.5913604
	speed: 0.0175s/iter; left time: 29.6581s
Epoch: 2 cost time: 3.6943676471710205
Epoch: 2, Steps: 210 | Train Loss: 0.6339285 Vali Loss: 0.5739598 Test Loss: 0.9611149
Validation loss decreased (0.590478 --> 0.573960).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5839915
	speed: 0.0169s/iter; left time: 26.7364s
	iters: 200, epoch: 3 | loss: 0.5173507
	speed: 0.0172s/iter; left time: 25.4690s
Epoch: 3 cost time: 3.6570465564727783
Epoch: 3, Steps: 210 | Train Loss: 0.6080389 Vali Loss: 0.5627976 Test Loss: 0.9763605
Validation loss decreased (0.573960 --> 0.562798).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5387787
	speed: 0.0135s/iter; left time: 18.5174s
	iters: 200, epoch: 4 | loss: 0.5049379
	speed: 0.0126s/iter; left time: 16.0657s
Epoch: 4 cost time: 2.746522903442383
Epoch: 4, Steps: 210 | Train Loss: 0.5880324 Vali Loss: 0.5857276 Test Loss: 1.0167264
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6057417
	speed: 0.0144s/iter; left time: 16.7244s
	iters: 200, epoch: 5 | loss: 0.4884509
	speed: 0.0137s/iter; left time: 14.5284s
Epoch: 5 cost time: 2.923405408859253
Epoch: 5, Steps: 210 | Train Loss: 0.5746628 Vali Loss: 0.5828655 Test Loss: 1.0050936
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6379802
	speed: 0.0184s/iter; left time: 17.5366s
	iters: 200, epoch: 6 | loss: 0.5161219
	speed: 0.0158s/iter; left time: 13.4488s
Epoch: 6 cost time: 3.3115179538726807
Epoch: 6, Steps: 210 | Train Loss: 0.5665879 Vali Loss: 0.5889539 Test Loss: 0.9984608
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5298952
	speed: 0.0142s/iter; left time: 10.5478s
	iters: 200, epoch: 7 | loss: 0.5907404
	speed: 0.0138s/iter; left time: 8.8598s
Epoch: 7 cost time: 3.0116806030273438
Epoch: 7, Steps: 210 | Train Loss: 0.5629204 Vali Loss: 0.5909105 Test Loss: 1.0113679
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5436338
	speed: 0.0154s/iter; left time: 8.1580s
	iters: 200, epoch: 8 | loss: 0.5730591
	speed: 0.0152s/iter; left time: 6.5458s
Epoch: 8 cost time: 3.357739210128784
Epoch: 8, Steps: 210 | Train Loss: 0.5624731 Vali Loss: 0.5922757 Test Loss: 1.0090733
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9763603806495667, mae:0.7750608921051025
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6628579
	speed: 0.0163s/iter; left time: 32.6931s
	iters: 200, epoch: 1 | loss: 0.5551579
	speed: 0.0145s/iter; left time: 27.5069s
Epoch: 1 cost time: 3.134521961212158
Epoch: 1, Steps: 210 | Train Loss: 0.6757289 Vali Loss: 0.5854891 Test Loss: 0.9372397
Validation loss decreased (inf --> 0.585489).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5686824
	speed: 0.0194s/iter; left time: 34.7607s
	iters: 200, epoch: 2 | loss: 0.5065526
	speed: 0.0188s/iter; left time: 31.8420s
Epoch: 2 cost time: 3.99554181098938
Epoch: 2, Steps: 210 | Train Loss: 0.6328985 Vali Loss: 0.6024396 Test Loss: 0.9710377
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5633472
	speed: 0.0177s/iter; left time: 27.9774s
	iters: 200, epoch: 3 | loss: 0.6129051
	speed: 0.0171s/iter; left time: 25.2948s
Epoch: 3 cost time: 3.681501626968384
Epoch: 3, Steps: 210 | Train Loss: 0.6080700 Vali Loss: 0.5788254 Test Loss: 1.0025650
Validation loss decreased (0.585489 --> 0.578825).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5479003
	speed: 0.0183s/iter; left time: 25.1569s
	iters: 200, epoch: 4 | loss: 0.5302727
	speed: 0.0157s/iter; left time: 19.9679s
Epoch: 4 cost time: 3.454378366470337
Epoch: 4, Steps: 210 | Train Loss: 0.5883532 Vali Loss: 0.6185102 Test Loss: 1.0485442
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5941103
	speed: 0.0141s/iter; left time: 16.3745s
	iters: 200, epoch: 5 | loss: 0.4822825
	speed: 0.0114s/iter; left time: 12.0486s
Epoch: 5 cost time: 2.4803874492645264
Epoch: 5, Steps: 210 | Train Loss: 0.5756092 Vali Loss: 0.6120510 Test Loss: 0.9771605
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5904925
	speed: 0.0171s/iter; left time: 16.2513s
	iters: 200, epoch: 6 | loss: 0.5607749
	speed: 0.0150s/iter; left time: 12.7291s
Epoch: 6 cost time: 3.1592907905578613
Epoch: 6, Steps: 210 | Train Loss: 0.5678736 Vali Loss: 0.6267291 Test Loss: 1.0015104
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4629899
	speed: 0.0182s/iter; left time: 13.4870s
	iters: 200, epoch: 7 | loss: 0.6415462
	speed: 0.0189s/iter; left time: 12.1281s
Epoch: 7 cost time: 4.050945281982422
Epoch: 7, Steps: 210 | Train Loss: 0.5642509 Vali Loss: 0.6231906 Test Loss: 1.0005107
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5810794
	speed: 0.0169s/iter; left time: 8.9536s
	iters: 200, epoch: 8 | loss: 0.5393202
	speed: 0.0155s/iter; left time: 6.6628s
Epoch: 8 cost time: 3.4017882347106934
Epoch: 8, Steps: 210 | Train Loss: 0.5620163 Vali Loss: 0.6261740 Test Loss: 0.9996488
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0025649070739746, mae:0.7848066687583923
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8974197
	speed: 0.0411s/iter; left time: 80.5554s
	iters: 200, epoch: 1 | loss: 0.7367869
	speed: 0.0267s/iter; left time: 49.6494s
Epoch: 1 cost time: 5.4763023853302
Epoch: 1, Steps: 206 | Train Loss: 0.8569909 Vali Loss: 0.6969332 Test Loss: 1.3062420
Validation loss decreased (inf --> 0.696933).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7740622
	speed: 0.0151s/iter; left time: 26.5089s
	iters: 200, epoch: 2 | loss: 0.9176047
	speed: 0.0133s/iter; left time: 22.0541s
Epoch: 2 cost time: 2.811253786087036
Epoch: 2, Steps: 206 | Train Loss: 0.8101838 Vali Loss: 0.6585029 Test Loss: 1.3766437
Validation loss decreased (0.696933 --> 0.658503).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7818983
	speed: 0.0164s/iter; left time: 25.3292s
	iters: 200, epoch: 3 | loss: 0.8253608
	speed: 0.0152s/iter; left time: 21.9980s
Epoch: 3 cost time: 3.190757989883423
Epoch: 3, Steps: 206 | Train Loss: 0.7774387 Vali Loss: 0.6651273 Test Loss: 1.4305407
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8000703
	speed: 0.0179s/iter; left time: 24.0035s
	iters: 200, epoch: 4 | loss: 0.7711189
	speed: 0.0168s/iter; left time: 20.8408s
Epoch: 4 cost time: 3.5527474880218506
Epoch: 4, Steps: 206 | Train Loss: 0.7496496 Vali Loss: 0.6271361 Test Loss: 1.4423225
Validation loss decreased (0.658503 --> 0.627136).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7281864
	speed: 0.0198s/iter; left time: 22.5222s
	iters: 200, epoch: 5 | loss: 0.6809523
	speed: 0.0173s/iter; left time: 17.9509s
Epoch: 5 cost time: 3.6736557483673096
Epoch: 5, Steps: 206 | Train Loss: 0.7329261 Vali Loss: 0.6541604 Test Loss: 1.4582715
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7407600
	speed: 0.0150s/iter; left time: 13.9649s
	iters: 200, epoch: 6 | loss: 0.6457338
	speed: 0.0139s/iter; left time: 11.5404s
Epoch: 6 cost time: 2.96427321434021
Epoch: 6, Steps: 206 | Train Loss: 0.7231692 Vali Loss: 0.6557626 Test Loss: 1.4710333
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6174539
	speed: 0.0186s/iter; left time: 13.4839s
	iters: 200, epoch: 7 | loss: 0.6473368
	speed: 0.0168s/iter; left time: 10.4748s
Epoch: 7 cost time: 3.6384217739105225
Epoch: 7, Steps: 206 | Train Loss: 0.7172351 Vali Loss: 0.6585885 Test Loss: 1.4668676
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7250484
	speed: 0.0181s/iter; left time: 9.3700s
	iters: 200, epoch: 8 | loss: 0.6807253
	speed: 0.0169s/iter; left time: 7.0692s
Epoch: 8 cost time: 3.5832083225250244
Epoch: 8, Steps: 206 | Train Loss: 0.7134449 Vali Loss: 0.6611478 Test Loss: 1.4709703
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7754263
	speed: 0.0144s/iter; left time: 4.5029s
	iters: 200, epoch: 9 | loss: 0.5699109
	speed: 0.0140s/iter; left time: 2.9853s
Epoch: 9 cost time: 3.0111963748931885
Epoch: 9, Steps: 206 | Train Loss: 0.7127848 Vali Loss: 0.6614855 Test Loss: 1.4722775
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4423223733901978, mae:0.9466235637664795
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7649557
	speed: 0.0180s/iter; left time: 35.2219s
	iters: 200, epoch: 1 | loss: 0.8641945
	speed: 0.0152s/iter; left time: 28.3418s
Epoch: 1 cost time: 3.21718430519104
Epoch: 1, Steps: 206 | Train Loss: 0.8557698 Vali Loss: 0.6490933 Test Loss: 1.3283781
Validation loss decreased (inf --> 0.649093).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7488405
	speed: 0.0176s/iter; left time: 30.8072s
	iters: 200, epoch: 2 | loss: 0.9647778
	speed: 0.0154s/iter; left time: 25.4190s
Epoch: 2 cost time: 3.270880699157715
Epoch: 2, Steps: 206 | Train Loss: 0.8109971 Vali Loss: 0.6540613 Test Loss: 1.3643987
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7300807
	speed: 0.0186s/iter; left time: 28.7760s
	iters: 200, epoch: 3 | loss: 0.6534954
	speed: 0.0163s/iter; left time: 23.6905s
Epoch: 3 cost time: 3.4553463459014893
Epoch: 3, Steps: 206 | Train Loss: 0.7789267 Vali Loss: 0.6362029 Test Loss: 1.4342226
Validation loss decreased (0.649093 --> 0.636203).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6778080
	speed: 0.0225s/iter; left time: 30.1522s
	iters: 200, epoch: 4 | loss: 0.6888141
	speed: 0.0214s/iter; left time: 26.5920s
Epoch: 4 cost time: 4.416353464126587
Epoch: 4, Steps: 206 | Train Loss: 0.7489541 Vali Loss: 0.6514878 Test Loss: 1.4471784
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8442769
	speed: 0.0154s/iter; left time: 17.5369s
	iters: 200, epoch: 5 | loss: 0.7571796
	speed: 0.0127s/iter; left time: 13.1360s
Epoch: 5 cost time: 2.748739242553711
Epoch: 5, Steps: 206 | Train Loss: 0.7287665 Vali Loss: 0.6521956 Test Loss: 1.4390439
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6017301
	speed: 0.0221s/iter; left time: 20.5712s
	iters: 200, epoch: 6 | loss: 0.8265107
	speed: 0.0163s/iter; left time: 13.5073s
Epoch: 6 cost time: 3.4549942016601562
Epoch: 6, Steps: 206 | Train Loss: 0.7183251 Vali Loss: 0.6697268 Test Loss: 1.4689325
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7200924
	speed: 0.0172s/iter; left time: 12.4922s
	iters: 200, epoch: 7 | loss: 0.6564666
	speed: 0.0153s/iter; left time: 9.5626s
Epoch: 7 cost time: 3.264716148376465
Epoch: 7, Steps: 206 | Train Loss: 0.7119922 Vali Loss: 0.6650311 Test Loss: 1.4794713
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7721996
	speed: 0.0172s/iter; left time: 8.9328s
	iters: 200, epoch: 8 | loss: 0.6727261
	speed: 0.0154s/iter; left time: 6.4501s
Epoch: 8 cost time: 3.2504801750183105
Epoch: 8, Steps: 206 | Train Loss: 0.7095048 Vali Loss: 0.6625473 Test Loss: 1.4770924
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4342228174209595, mae:0.944275975227356
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7320338
	speed: 0.0213s/iter; left time: 41.8148s
	iters: 200, epoch: 1 | loss: 0.8868318
	speed: 0.0171s/iter; left time: 31.8016s
Epoch: 1 cost time: 3.5956172943115234
Epoch: 1, Steps: 206 | Train Loss: 0.8582091 Vali Loss: 0.6906968 Test Loss: 1.3689585
Validation loss decreased (inf --> 0.690697).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8773852
	speed: 0.0178s/iter; left time: 31.1634s
	iters: 200, epoch: 2 | loss: 0.7380714
	speed: 0.0138s/iter; left time: 22.9216s
Epoch: 2 cost time: 2.9997735023498535
Epoch: 2, Steps: 206 | Train Loss: 0.8107621 Vali Loss: 0.6728063 Test Loss: 1.3732313
Validation loss decreased (0.690697 --> 0.672806).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7487852
	speed: 0.0148s/iter; left time: 22.9846s
	iters: 200, epoch: 3 | loss: 0.8111351
	speed: 0.0151s/iter; left time: 21.8863s
Epoch: 3 cost time: 3.1887660026550293
Epoch: 3, Steps: 206 | Train Loss: 0.7762227 Vali Loss: 0.6598929 Test Loss: 1.3847454
Validation loss decreased (0.672806 --> 0.659893).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6312991
	speed: 0.0181s/iter; left time: 24.3253s
	iters: 200, epoch: 4 | loss: 0.6885051
	speed: 0.0179s/iter; left time: 22.1886s
Epoch: 4 cost time: 3.7308478355407715
Epoch: 4, Steps: 206 | Train Loss: 0.7483334 Vali Loss: 0.6562169 Test Loss: 1.4602288
Validation loss decreased (0.659893 --> 0.656217).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6931720
	speed: 0.0225s/iter; left time: 25.6271s
	iters: 200, epoch: 5 | loss: 0.7340951
	speed: 0.0178s/iter; left time: 18.4442s
Epoch: 5 cost time: 3.7637155055999756
Epoch: 5, Steps: 206 | Train Loss: 0.7276714 Vali Loss: 0.6480607 Test Loss: 1.4218839
Validation loss decreased (0.656217 --> 0.648061).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7427009
	speed: 0.0141s/iter; left time: 13.1454s
	iters: 200, epoch: 6 | loss: 0.6383313
	speed: 0.0138s/iter; left time: 11.4733s
Epoch: 6 cost time: 2.94073486328125
Epoch: 6, Steps: 206 | Train Loss: 0.7160815 Vali Loss: 0.6651231 Test Loss: 1.4508889
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7178685
	speed: 0.0190s/iter; left time: 13.7848s
	iters: 200, epoch: 7 | loss: 0.8403069
	speed: 0.0152s/iter; left time: 9.4914s
Epoch: 7 cost time: 3.165879726409912
Epoch: 7, Steps: 206 | Train Loss: 0.7103018 Vali Loss: 0.6583199 Test Loss: 1.4398575
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7484497
	speed: 0.0189s/iter; left time: 9.7837s
	iters: 200, epoch: 8 | loss: 0.6781455
	speed: 0.0160s/iter; left time: 6.7186s
Epoch: 8 cost time: 3.4161481857299805
Epoch: 8, Steps: 206 | Train Loss: 0.7069899 Vali Loss: 0.6569002 Test Loss: 1.4432361
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7228615
	speed: 0.0198s/iter; left time: 6.2020s
	iters: 200, epoch: 9 | loss: 0.6804893
	speed: 0.0181s/iter; left time: 3.8583s
Epoch: 9 cost time: 3.761434316635132
Epoch: 9, Steps: 206 | Train Loss: 0.7060822 Vali Loss: 0.6566177 Test Loss: 1.4403368
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6766121
	speed: 0.0211s/iter; left time: 2.2597s
	iters: 200, epoch: 10 | loss: 0.8415882
	speed: 0.0177s/iter; left time: 0.1241s
Epoch: 10 cost time: 3.8044021129608154
Epoch: 10, Steps: 206 | Train Loss: 0.7046093 Vali Loss: 0.6571634 Test Loss: 1.4406574
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4218840599060059, mae:0.9408657550811768
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2433170
	speed: 0.0299s/iter; left time: 55.0723s
Epoch: 1 cost time: 4.447784662246704
Epoch: 1, Steps: 194 | Train Loss: 1.2423348 Vali Loss: 0.6397092 Test Loss: 1.4285709
Validation loss decreased (inf --> 0.639709).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3805827
	speed: 0.0194s/iter; left time: 31.9234s
Epoch: 2 cost time: 3.57804012298584
Epoch: 2, Steps: 194 | Train Loss: 1.1828311 Vali Loss: 0.6623042 Test Loss: 1.4269063
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1547842
	speed: 0.0160s/iter; left time: 23.2521s
Epoch: 3 cost time: 3.1906416416168213
Epoch: 3, Steps: 194 | Train Loss: 1.1020615 Vali Loss: 0.8691472 Test Loss: 1.4812806
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1019111
	speed: 0.0144s/iter; left time: 18.0795s
Epoch: 4 cost time: 2.677048921585083
Epoch: 4, Steps: 194 | Train Loss: 1.0353442 Vali Loss: 0.9255245 Test Loss: 1.5463732
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0712050
	speed: 0.0204s/iter; left time: 21.7598s
Epoch: 5 cost time: 3.649019718170166
Epoch: 5, Steps: 194 | Train Loss: 0.9943490 Vali Loss: 1.0516950 Test Loss: 1.5493973
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9326203
	speed: 0.0189s/iter; left time: 16.4995s
Epoch: 6 cost time: 3.605701208114624
Epoch: 6, Steps: 194 | Train Loss: 0.9774015 Vali Loss: 1.0553527 Test Loss: 1.5849500
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4285707473754883, mae:0.9416999220848083
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1345932
	speed: 0.0170s/iter; left time: 31.3117s
Epoch: 1 cost time: 3.1784536838531494
Epoch: 1, Steps: 194 | Train Loss: 1.2432202 Vali Loss: 0.5871930 Test Loss: 1.4317859
Validation loss decreased (inf --> 0.587193).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2574010
	speed: 0.0172s/iter; left time: 28.3896s
Epoch: 2 cost time: 2.7220852375030518
Epoch: 2, Steps: 194 | Train Loss: 1.1816225 Vali Loss: 0.6821568 Test Loss: 1.4224280
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0590434
	speed: 0.0144s/iter; left time: 20.9460s
Epoch: 3 cost time: 2.6314096450805664
Epoch: 3, Steps: 194 | Train Loss: 1.0956138 Vali Loss: 0.7862809 Test Loss: 1.4582063
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9988526
	speed: 0.0173s/iter; left time: 21.8118s
Epoch: 4 cost time: 2.949688673019409
Epoch: 4, Steps: 194 | Train Loss: 1.0243148 Vali Loss: 0.8348966 Test Loss: 1.4737622
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9789022
	speed: 0.0316s/iter; left time: 33.6035s
Epoch: 5 cost time: 4.859481573104858
Epoch: 5, Steps: 194 | Train Loss: 0.9775294 Vali Loss: 0.8663023 Test Loss: 1.5027560
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8824233
	speed: 0.0228s/iter; left time: 19.8821s
Epoch: 6 cost time: 3.68033504486084
Epoch: 6, Steps: 194 | Train Loss: 0.9510842 Vali Loss: 0.9056084 Test Loss: 1.4674314
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4317859411239624, mae:0.9382804036140442
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1883982
	speed: 0.0129s/iter; left time: 23.7446s
Epoch: 1 cost time: 2.5184104442596436
Epoch: 1, Steps: 194 | Train Loss: 1.2432528 Vali Loss: 0.5974932 Test Loss: 1.4439654
Validation loss decreased (inf --> 0.597493).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0479645
	speed: 0.0169s/iter; left time: 27.7738s
Epoch: 2 cost time: 2.893247127532959
Epoch: 2, Steps: 194 | Train Loss: 1.1905577 Vali Loss: 0.6902347 Test Loss: 1.3787131
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1412302
	speed: 0.0145s/iter; left time: 21.1228s
Epoch: 3 cost time: 3.2290947437286377
Epoch: 3, Steps: 194 | Train Loss: 1.1122156 Vali Loss: 0.7485863 Test Loss: 1.5008594
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8378615
	speed: 0.0209s/iter; left time: 26.2691s
Epoch: 4 cost time: 3.428083896636963
Epoch: 4, Steps: 194 | Train Loss: 1.0407445 Vali Loss: 0.8344200 Test Loss: 1.4937128
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9727815
	speed: 0.0228s/iter; left time: 24.2922s
Epoch: 5 cost time: 3.71018385887146
Epoch: 5, Steps: 194 | Train Loss: 0.9841405 Vali Loss: 0.8847759 Test Loss: 1.4802833
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9704899
	speed: 0.0141s/iter; left time: 12.3135s
Epoch: 6 cost time: 2.4327304363250732
Epoch: 6, Steps: 194 | Train Loss: 0.9573200 Vali Loss: 0.9340715 Test Loss: 1.4433688
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4439655542373657, mae:0.9444239139556885
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5116434
	speed: 0.0373s/iter; left time: 75.7437s
	iters: 200, epoch: 1 | loss: 0.5364034
	speed: 0.0264s/iter; left time: 50.9654s
Epoch: 1 cost time: 5.536930561065674
Epoch: 1, Steps: 213 | Train Loss: 0.5494027 Vali Loss: 0.4883791 Test Loss: 0.5989899
Validation loss decreased (inf --> 0.488379).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5296528
	speed: 0.0172s/iter; left time: 31.2167s
	iters: 200, epoch: 2 | loss: 0.5597964
	speed: 0.0170s/iter; left time: 29.2734s
Epoch: 2 cost time: 3.660316228866577
Epoch: 2, Steps: 213 | Train Loss: 0.5122299 Vali Loss: 0.5038257 Test Loss: 0.6479759
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4903544
	speed: 0.0250s/iter; left time: 40.1698s
	iters: 200, epoch: 3 | loss: 0.4751984
	speed: 0.0192s/iter; left time: 28.9554s
Epoch: 3 cost time: 4.1550493240356445
Epoch: 3, Steps: 213 | Train Loss: 0.4933498 Vali Loss: 0.4943329 Test Loss: 0.6501112
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5154881
	speed: 0.0231s/iter; left time: 32.1799s
	iters: 200, epoch: 4 | loss: 0.4399276
	speed: 0.0200s/iter; left time: 25.8127s
Epoch: 4 cost time: 4.274503946304321
Epoch: 4, Steps: 213 | Train Loss: 0.4810783 Vali Loss: 0.4943737 Test Loss: 0.6616753
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4638499
	speed: 0.0195s/iter; left time: 22.9547s
	iters: 200, epoch: 5 | loss: 0.4611574
	speed: 0.0145s/iter; left time: 15.6880s
Epoch: 5 cost time: 3.1997454166412354
Epoch: 5, Steps: 213 | Train Loss: 0.4735305 Vali Loss: 0.5008386 Test Loss: 0.6729898
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4634573
	speed: 0.0151s/iter; left time: 14.6283s
	iters: 200, epoch: 6 | loss: 0.5083663
	speed: 0.0138s/iter; left time: 11.9340s
Epoch: 6 cost time: 2.953864336013794
Epoch: 6, Steps: 213 | Train Loss: 0.4690529 Vali Loss: 0.5052826 Test Loss: 0.6794149
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5989899635314941, mae:0.6123349070549011
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5973119
	speed: 0.0161s/iter; left time: 32.6438s
	iters: 200, epoch: 1 | loss: 0.5703806
	speed: 0.0143s/iter; left time: 27.6687s
Epoch: 1 cost time: 3.1818318367004395
Epoch: 1, Steps: 213 | Train Loss: 0.5472601 Vali Loss: 0.4828852 Test Loss: 0.6210244
Validation loss decreased (inf --> 0.482885).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5149484
	speed: 0.0263s/iter; left time: 47.7536s
	iters: 200, epoch: 2 | loss: 0.5559228
	speed: 0.0188s/iter; left time: 32.3075s
Epoch: 2 cost time: 3.982262134552002
Epoch: 2, Steps: 213 | Train Loss: 0.5094658 Vali Loss: 0.4909100 Test Loss: 0.6244715
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4426040
	speed: 0.0195s/iter; left time: 31.2738s
	iters: 200, epoch: 3 | loss: 0.5458068
	speed: 0.0141s/iter; left time: 21.2208s
Epoch: 3 cost time: 2.9837138652801514
Epoch: 3, Steps: 213 | Train Loss: 0.4898088 Vali Loss: 0.4956264 Test Loss: 0.6607184
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4682275
	speed: 0.0140s/iter; left time: 19.5504s
	iters: 200, epoch: 4 | loss: 0.5116355
	speed: 0.0149s/iter; left time: 19.3009s
Epoch: 4 cost time: 3.2387382984161377
Epoch: 4, Steps: 213 | Train Loss: 0.4764275 Vali Loss: 0.5111619 Test Loss: 0.6742401
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5201466
	speed: 0.0160s/iter; left time: 18.8497s
	iters: 200, epoch: 5 | loss: 0.4846429
	speed: 0.0153s/iter; left time: 16.5303s
Epoch: 5 cost time: 3.5037143230438232
Epoch: 5, Steps: 213 | Train Loss: 0.4679324 Vali Loss: 0.4976706 Test Loss: 0.6775087
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4412273
	speed: 0.0146s/iter; left time: 14.0576s
	iters: 200, epoch: 6 | loss: 0.4218528
	speed: 0.0180s/iter; left time: 15.5965s
Epoch: 6 cost time: 3.860743999481201
Epoch: 6, Steps: 213 | Train Loss: 0.4641637 Vali Loss: 0.5070024 Test Loss: 0.6779798
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6210244297981262, mae:0.6234708428382874
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5301073
	speed: 0.0174s/iter; left time: 35.4381s
	iters: 200, epoch: 1 | loss: 0.5500419
	speed: 0.0154s/iter; left time: 29.7566s
Epoch: 1 cost time: 3.3761532306671143
Epoch: 1, Steps: 213 | Train Loss: 0.5476721 Vali Loss: 0.4857490 Test Loss: 0.6008635
Validation loss decreased (inf --> 0.485749).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5275174
	speed: 0.0150s/iter; left time: 27.2860s
	iters: 200, epoch: 2 | loss: 0.4743991
	speed: 0.0151s/iter; left time: 25.8775s
Epoch: 2 cost time: 3.480006694793701
Epoch: 2, Steps: 213 | Train Loss: 0.5100255 Vali Loss: 0.4937538 Test Loss: 0.6465205
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4360287
	speed: 0.0145s/iter; left time: 23.2326s
	iters: 200, epoch: 3 | loss: 0.4469139
	speed: 0.0137s/iter; left time: 20.6542s
Epoch: 3 cost time: 2.977149724960327
Epoch: 3, Steps: 213 | Train Loss: 0.4889862 Vali Loss: 0.5126430 Test Loss: 0.6651202
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5078189
	speed: 0.0156s/iter; left time: 21.7298s
	iters: 200, epoch: 4 | loss: 0.4451101
	speed: 0.0139s/iter; left time: 17.9372s
Epoch: 4 cost time: 2.9716992378234863
Epoch: 4, Steps: 213 | Train Loss: 0.4754742 Vali Loss: 0.4937694 Test Loss: 0.6701860
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4633965
	speed: 0.0138s/iter; left time: 16.2168s
	iters: 200, epoch: 5 | loss: 0.4794918
	speed: 0.0122s/iter; left time: 13.1699s
Epoch: 5 cost time: 2.6815567016601562
Epoch: 5, Steps: 213 | Train Loss: 0.4685054 Vali Loss: 0.4934432 Test Loss: 0.6693214
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4309185
	speed: 0.0124s/iter; left time: 11.9724s
	iters: 200, epoch: 6 | loss: 0.4502692
	speed: 0.0131s/iter; left time: 11.3756s
Epoch: 6 cost time: 2.8783533573150635
Epoch: 6, Steps: 213 | Train Loss: 0.4642744 Vali Loss: 0.5042661 Test Loss: 0.6813591
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6008633971214294, mae:0.6133482456207275
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7695173
	speed: 0.0273s/iter; left time: 54.5336s
	iters: 200, epoch: 1 | loss: 0.6332481
	speed: 0.0250s/iter; left time: 47.4687s
Epoch: 1 cost time: 5.1635215282440186
Epoch: 1, Steps: 210 | Train Loss: 0.6773133 Vali Loss: 0.6177728 Test Loss: 0.9929198
Validation loss decreased (inf --> 0.617773).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6032385
	speed: 0.0215s/iter; left time: 38.5350s
	iters: 200, epoch: 2 | loss: 0.6820683
	speed: 0.0196s/iter; left time: 33.2184s
Epoch: 2 cost time: 4.202870845794678
Epoch: 2, Steps: 210 | Train Loss: 0.6343388 Vali Loss: 0.5954746 Test Loss: 0.9739525
Validation loss decreased (0.617773 --> 0.595475).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6000003
	speed: 0.0168s/iter; left time: 26.5711s
	iters: 200, epoch: 3 | loss: 0.5964760
	speed: 0.0141s/iter; left time: 20.9396s
Epoch: 3 cost time: 3.0503551959991455
Epoch: 3, Steps: 210 | Train Loss: 0.6095662 Vali Loss: 0.5868608 Test Loss: 1.0197115
Validation loss decreased (0.595475 --> 0.586861).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5431085
	speed: 0.0169s/iter; left time: 23.2169s
	iters: 200, epoch: 4 | loss: 0.6996624
	speed: 0.0153s/iter; left time: 19.4467s
Epoch: 4 cost time: 3.2611143589019775
Epoch: 4, Steps: 210 | Train Loss: 0.5916430 Vali Loss: 0.5985606 Test Loss: 1.0031812
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6296922
	speed: 0.0175s/iter; left time: 20.3059s
	iters: 200, epoch: 5 | loss: 0.5549551
	speed: 0.0161s/iter; left time: 17.0421s
Epoch: 5 cost time: 3.4320268630981445
Epoch: 5, Steps: 210 | Train Loss: 0.5802590 Vali Loss: 0.6160047 Test Loss: 1.0328872
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6523783
	speed: 0.0209s/iter; left time: 19.8945s
	iters: 200, epoch: 6 | loss: 0.5382758
	speed: 0.0176s/iter; left time: 14.9676s
Epoch: 6 cost time: 3.781961679458618
Epoch: 6, Steps: 210 | Train Loss: 0.5717081 Vali Loss: 0.5999051 Test Loss: 1.0223558
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5621805
	speed: 0.0168s/iter; left time: 12.4369s
	iters: 200, epoch: 7 | loss: 0.5424682
	speed: 0.0142s/iter; left time: 9.0759s
Epoch: 7 cost time: 2.988633632659912
Epoch: 7, Steps: 210 | Train Loss: 0.5686189 Vali Loss: 0.6030533 Test Loss: 1.0203633
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7128164
	speed: 0.0161s/iter; left time: 8.5479s
	iters: 200, epoch: 8 | loss: 0.6679256
	speed: 0.0146s/iter; left time: 6.3086s
Epoch: 8 cost time: 3.13737416267395
Epoch: 8, Steps: 210 | Train Loss: 0.5652816 Vali Loss: 0.6039340 Test Loss: 1.0243841
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0197114944458008, mae:0.7918883562088013
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7398741
	speed: 0.0202s/iter; left time: 40.3487s
	iters: 200, epoch: 1 | loss: 0.4870409
	speed: 0.0191s/iter; left time: 36.2258s
Epoch: 1 cost time: 4.057720899581909
Epoch: 1, Steps: 210 | Train Loss: 0.6797223 Vali Loss: 0.6126077 Test Loss: 0.9611736
Validation loss decreased (inf --> 0.612608).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6238881
	speed: 0.0140s/iter; left time: 25.0703s
	iters: 200, epoch: 2 | loss: 0.6636260
	speed: 0.0158s/iter; left time: 26.7835s
Epoch: 2 cost time: 3.445213794708252
Epoch: 2, Steps: 210 | Train Loss: 0.6371600 Vali Loss: 0.5914835 Test Loss: 0.9832855
Validation loss decreased (0.612608 --> 0.591483).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6180806
	speed: 0.0117s/iter; left time: 18.5524s
	iters: 200, epoch: 3 | loss: 0.6098248
	speed: 0.0115s/iter; left time: 17.0613s
Epoch: 3 cost time: 2.5049214363098145
Epoch: 3, Steps: 210 | Train Loss: 0.6125539 Vali Loss: 0.5866852 Test Loss: 0.9981641
Validation loss decreased (0.591483 --> 0.586685).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6028726
	speed: 0.0196s/iter; left time: 26.9003s
	iters: 200, epoch: 4 | loss: 0.5997778
	speed: 0.0198s/iter; left time: 25.2122s
Epoch: 4 cost time: 4.386171102523804
Epoch: 4, Steps: 210 | Train Loss: 0.5966250 Vali Loss: 0.5661892 Test Loss: 1.0363946
Validation loss decreased (0.586685 --> 0.566189).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6019965
	speed: 0.0178s/iter; left time: 20.6621s
	iters: 200, epoch: 5 | loss: 0.5485201
	speed: 0.0160s/iter; left time: 16.9471s
Epoch: 5 cost time: 3.4927968978881836
Epoch: 5, Steps: 210 | Train Loss: 0.5841948 Vali Loss: 0.5789669 Test Loss: 1.0266294
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6105397
	speed: 0.0180s/iter; left time: 17.1206s
	iters: 200, epoch: 6 | loss: 0.4963741
	speed: 0.0185s/iter; left time: 15.7753s
Epoch: 6 cost time: 4.047485113143921
Epoch: 6, Steps: 210 | Train Loss: 0.5771431 Vali Loss: 0.5669754 Test Loss: 1.0291660
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6546037
	speed: 0.0140s/iter; left time: 10.3867s
	iters: 200, epoch: 7 | loss: 0.5475262
	speed: 0.0120s/iter; left time: 7.6677s
Epoch: 7 cost time: 2.6082546710968018
Epoch: 7, Steps: 210 | Train Loss: 0.5737070 Vali Loss: 0.5813144 Test Loss: 1.0226959
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5593209
	speed: 0.0186s/iter; left time: 9.8940s
	iters: 200, epoch: 8 | loss: 0.5521798
	speed: 0.0158s/iter; left time: 6.8129s
Epoch: 8 cost time: 3.4035804271698
Epoch: 8, Steps: 210 | Train Loss: 0.5714129 Vali Loss: 0.5826687 Test Loss: 1.0251342
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5439307
	speed: 0.0172s/iter; left time: 5.5285s
	iters: 200, epoch: 9 | loss: 0.6550890
	speed: 0.0159s/iter; left time: 3.5208s
Epoch: 9 cost time: 3.381258010864258
Epoch: 9, Steps: 210 | Train Loss: 0.5706983 Vali Loss: 0.5807474 Test Loss: 1.0283204
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.036394715309143, mae:0.7955649495124817
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6568102
	speed: 0.0268s/iter; left time: 53.5391s
	iters: 200, epoch: 1 | loss: 0.5783769
	speed: 0.0217s/iter; left time: 41.3016s
Epoch: 1 cost time: 4.5896406173706055
Epoch: 1, Steps: 210 | Train Loss: 0.6761547 Vali Loss: 0.5862549 Test Loss: 0.9312510
Validation loss decreased (inf --> 0.586255).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6250618
	speed: 0.0228s/iter; left time: 40.8358s
	iters: 200, epoch: 2 | loss: 0.7223200
	speed: 0.0165s/iter; left time: 27.9829s
Epoch: 2 cost time: 3.478466510772705
Epoch: 2, Steps: 210 | Train Loss: 0.6333770 Vali Loss: 0.6316360 Test Loss: 0.9720987
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6188697
	speed: 0.0154s/iter; left time: 24.4081s
	iters: 200, epoch: 3 | loss: 0.5973070
	speed: 0.0142s/iter; left time: 21.0062s
Epoch: 3 cost time: 3.0297434329986572
Epoch: 3, Steps: 210 | Train Loss: 0.6085706 Vali Loss: 0.5885778 Test Loss: 0.9400874
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6081614
	speed: 0.0163s/iter; left time: 22.3009s
	iters: 200, epoch: 4 | loss: 0.7219428
	speed: 0.0159s/iter; left time: 20.2265s
Epoch: 4 cost time: 3.4724626541137695
Epoch: 4, Steps: 210 | Train Loss: 0.5887170 Vali Loss: 0.6189331 Test Loss: 0.9640017
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5780398
	speed: 0.0181s/iter; left time: 21.0417s
	iters: 200, epoch: 5 | loss: 0.5862569
	speed: 0.0152s/iter; left time: 16.1495s
Epoch: 5 cost time: 3.2179510593414307
Epoch: 5, Steps: 210 | Train Loss: 0.5762569 Vali Loss: 0.6215053 Test Loss: 0.9982741
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5922353
	speed: 0.0142s/iter; left time: 13.5297s
	iters: 200, epoch: 6 | loss: 0.5346848
	speed: 0.0118s/iter; left time: 10.0736s
Epoch: 6 cost time: 2.5517139434814453
Epoch: 6, Steps: 210 | Train Loss: 0.5682864 Vali Loss: 0.6406963 Test Loss: 0.9933306
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.931251049041748, mae:0.7561890482902527
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9078727
	speed: 0.0288s/iter; left time: 56.4840s
	iters: 200, epoch: 1 | loss: 0.8503026
	speed: 0.0208s/iter; left time: 38.7972s
Epoch: 1 cost time: 4.353647232055664
Epoch: 1, Steps: 206 | Train Loss: 0.8563784 Vali Loss: 0.6701593 Test Loss: 1.3238779
Validation loss decreased (inf --> 0.670159).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7890266
	speed: 0.0131s/iter; left time: 23.0298s
	iters: 200, epoch: 2 | loss: 0.8115241
	speed: 0.0115s/iter; left time: 19.0848s
Epoch: 2 cost time: 2.441950559616089
Epoch: 2, Steps: 206 | Train Loss: 0.8106576 Vali Loss: 0.6509360 Test Loss: 1.3467158
Validation loss decreased (0.670159 --> 0.650936).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8035678
	speed: 0.0218s/iter; left time: 33.7483s
	iters: 200, epoch: 3 | loss: 0.6970205
	speed: 0.0164s/iter; left time: 23.7048s
Epoch: 3 cost time: 3.433948278427124
Epoch: 3, Steps: 206 | Train Loss: 0.7744522 Vali Loss: 0.6302684 Test Loss: 1.4034255
Validation loss decreased (0.650936 --> 0.630268).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7149065
	speed: 0.0291s/iter; left time: 39.0324s
	iters: 200, epoch: 4 | loss: 0.8192171
	speed: 0.0199s/iter; left time: 24.7048s
Epoch: 4 cost time: 4.174740314483643
Epoch: 4, Steps: 206 | Train Loss: 0.7452118 Vali Loss: 0.6703420 Test Loss: 1.4865369
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8396841
	speed: 0.0263s/iter; left time: 29.8737s
	iters: 200, epoch: 5 | loss: 0.7429640
	speed: 0.0197s/iter; left time: 20.4740s
Epoch: 5 cost time: 4.081047773361206
Epoch: 5, Steps: 206 | Train Loss: 0.7254891 Vali Loss: 0.6572700 Test Loss: 1.4632401
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6364994
	speed: 0.0160s/iter; left time: 14.8712s
	iters: 200, epoch: 6 | loss: 0.7644201
	speed: 0.0131s/iter; left time: 10.8534s
Epoch: 6 cost time: 2.774968147277832
Epoch: 6, Steps: 206 | Train Loss: 0.7169775 Vali Loss: 0.6670561 Test Loss: 1.4761137
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7407347
	speed: 0.0158s/iter; left time: 11.4466s
	iters: 200, epoch: 7 | loss: 0.8346954
	speed: 0.0150s/iter; left time: 9.3564s
Epoch: 7 cost time: 3.209094524383545
Epoch: 7, Steps: 206 | Train Loss: 0.7100010 Vali Loss: 0.6663998 Test Loss: 1.4752188
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6743712
	speed: 0.0186s/iter; left time: 9.6430s
	iters: 200, epoch: 8 | loss: 0.7243670
	speed: 0.0168s/iter; left time: 7.0478s
Epoch: 8 cost time: 3.525632381439209
Epoch: 8, Steps: 206 | Train Loss: 0.7079086 Vali Loss: 0.6679456 Test Loss: 1.4753251
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4034252166748047, mae:0.9341347813606262
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8029892
	speed: 0.0233s/iter; left time: 45.7134s
	iters: 200, epoch: 1 | loss: 0.9843990
	speed: 0.0198s/iter; left time: 36.8641s
Epoch: 1 cost time: 4.1747190952301025
Epoch: 1, Steps: 206 | Train Loss: 0.8560513 Vali Loss: 0.6691641 Test Loss: 1.3289211
Validation loss decreased (inf --> 0.669164).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7390367
	speed: 0.0144s/iter; left time: 25.2679s
	iters: 200, epoch: 2 | loss: 0.7125227
	speed: 0.0136s/iter; left time: 22.4525s
Epoch: 2 cost time: 2.9035329818725586
Epoch: 2, Steps: 206 | Train Loss: 0.8084560 Vali Loss: 0.6383613 Test Loss: 1.2896941
Validation loss decreased (0.669164 --> 0.638361).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7267233
	speed: 0.0183s/iter; left time: 28.2724s
	iters: 200, epoch: 3 | loss: 0.6701576
	speed: 0.0148s/iter; left time: 21.4833s
Epoch: 3 cost time: 3.08121657371521
Epoch: 3, Steps: 206 | Train Loss: 0.7763111 Vali Loss: 0.6179946 Test Loss: 1.4257931
Validation loss decreased (0.638361 --> 0.617995).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7912741
	speed: 0.0186s/iter; left time: 25.0302s
	iters: 200, epoch: 4 | loss: 0.7427288
	speed: 0.0159s/iter; left time: 19.7743s
Epoch: 4 cost time: 3.322821617126465
Epoch: 4, Steps: 206 | Train Loss: 0.7474529 Vali Loss: 0.6533414 Test Loss: 1.4756460
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8013076
	speed: 0.0198s/iter; left time: 22.5150s
	iters: 200, epoch: 5 | loss: 0.6361302
	speed: 0.0171s/iter; left time: 17.7198s
Epoch: 5 cost time: 3.5183184146881104
Epoch: 5, Steps: 206 | Train Loss: 0.7209882 Vali Loss: 0.6245614 Test Loss: 1.4800324
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6221942
	speed: 0.0153s/iter; left time: 14.2495s
	iters: 200, epoch: 6 | loss: 0.7319040
	speed: 0.0134s/iter; left time: 11.1720s
Epoch: 6 cost time: 2.881624937057495
Epoch: 6, Steps: 206 | Train Loss: 0.7073257 Vali Loss: 0.6238995 Test Loss: 1.4659173
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6806535
	speed: 0.0169s/iter; left time: 12.2466s
	iters: 200, epoch: 7 | loss: 0.6771752
	speed: 0.0139s/iter; left time: 8.6861s
Epoch: 7 cost time: 2.9580304622650146
Epoch: 7, Steps: 206 | Train Loss: 0.6989446 Vali Loss: 0.6207770 Test Loss: 1.4667976
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7404999
	speed: 0.0141s/iter; left time: 7.3178s
	iters: 200, epoch: 8 | loss: 0.6824907
	speed: 0.0134s/iter; left time: 5.6215s
Epoch: 8 cost time: 2.894545555114746
Epoch: 8, Steps: 206 | Train Loss: 0.6977675 Vali Loss: 0.6239685 Test Loss: 1.4675972
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4257930517196655, mae:0.9413968324661255
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7548921
	speed: 0.0197s/iter; left time: 38.6880s
	iters: 200, epoch: 1 | loss: 0.8084802
	speed: 0.0215s/iter; left time: 39.9585s
Epoch: 1 cost time: 4.509498357772827
Epoch: 1, Steps: 206 | Train Loss: 0.8579189 Vali Loss: 0.7189137 Test Loss: 1.3860520
Validation loss decreased (inf --> 0.718914).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8049745
	speed: 0.0167s/iter; left time: 29.3445s
	iters: 200, epoch: 2 | loss: 0.8622268
	speed: 0.0154s/iter; left time: 25.5040s
Epoch: 2 cost time: 3.291790246963501
Epoch: 2, Steps: 206 | Train Loss: 0.8072317 Vali Loss: 0.6755246 Test Loss: 1.3794435
Validation loss decreased (0.718914 --> 0.675525).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9348302
	speed: 0.0184s/iter; left time: 28.4745s
	iters: 200, epoch: 3 | loss: 0.6651456
	speed: 0.0148s/iter; left time: 21.4775s
Epoch: 3 cost time: 3.151090145111084
Epoch: 3, Steps: 206 | Train Loss: 0.7731729 Vali Loss: 0.6550063 Test Loss: 1.4246925
Validation loss decreased (0.675525 --> 0.655006).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6624532
	speed: 0.0184s/iter; left time: 24.7192s
	iters: 200, epoch: 4 | loss: 0.7006193
	speed: 0.0172s/iter; left time: 21.3977s
Epoch: 4 cost time: 3.603522777557373
Epoch: 4, Steps: 206 | Train Loss: 0.7429412 Vali Loss: 0.6467984 Test Loss: 1.4914920
Validation loss decreased (0.655006 --> 0.646798).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7581349
	speed: 0.0167s/iter; left time: 18.9665s
	iters: 200, epoch: 5 | loss: 0.7177345
	speed: 0.0147s/iter; left time: 15.2100s
Epoch: 5 cost time: 3.096261501312256
Epoch: 5, Steps: 206 | Train Loss: 0.7200635 Vali Loss: 0.6343163 Test Loss: 1.4599311
Validation loss decreased (0.646798 --> 0.634316).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6439744
	speed: 0.0203s/iter; left time: 18.9117s
	iters: 200, epoch: 6 | loss: 0.7928652
	speed: 0.0161s/iter; left time: 13.4032s
Epoch: 6 cost time: 3.419292449951172
Epoch: 6, Steps: 206 | Train Loss: 0.7081205 Vali Loss: 0.6515958 Test Loss: 1.5043111
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6440727
	speed: 0.0205s/iter; left time: 14.8701s
	iters: 200, epoch: 7 | loss: 0.7336214
	speed: 0.0188s/iter; left time: 11.7223s
Epoch: 7 cost time: 3.92098069190979
Epoch: 7, Steps: 206 | Train Loss: 0.7034468 Vali Loss: 0.6446296 Test Loss: 1.4915104
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6881459
	speed: 0.0125s/iter; left time: 6.5037s
	iters: 200, epoch: 8 | loss: 0.7168435
	speed: 0.0117s/iter; left time: 4.9100s
Epoch: 8 cost time: 2.5290582180023193
Epoch: 8, Steps: 206 | Train Loss: 0.7014813 Vali Loss: 0.6468600 Test Loss: 1.4923893
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6036614
	speed: 0.0179s/iter; left time: 5.5900s
	iters: 200, epoch: 9 | loss: 0.7358717
	speed: 0.0162s/iter; left time: 3.4563s
Epoch: 9 cost time: 3.4299943447113037
Epoch: 9, Steps: 206 | Train Loss: 0.6993976 Vali Loss: 0.6472955 Test Loss: 1.4911253
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6555894
	speed: 0.0204s/iter; left time: 2.1818s
	iters: 200, epoch: 10 | loss: 0.7488452
	speed: 0.0175s/iter; left time: 0.1225s
Epoch: 10 cost time: 3.6394896507263184
Epoch: 10, Steps: 206 | Train Loss: 0.6993809 Vali Loss: 0.6471946 Test Loss: 1.4906617
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4599312543869019, mae:0.9539148807525635
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0742636
	speed: 0.0284s/iter; left time: 52.2650s
Epoch: 1 cost time: 4.262900114059448
Epoch: 1, Steps: 194 | Train Loss: 1.2417893 Vali Loss: 0.5479860 Test Loss: 1.4570587
Validation loss decreased (inf --> 0.547986).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0868005
	speed: 0.0197s/iter; left time: 32.4263s
Epoch: 2 cost time: 3.220273733139038
Epoch: 2, Steps: 194 | Train Loss: 1.1832755 Vali Loss: 0.6379426 Test Loss: 1.4520760
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1533892
	speed: 0.0177s/iter; left time: 25.7544s
Epoch: 3 cost time: 3.211585521697998
Epoch: 3, Steps: 194 | Train Loss: 1.1128943 Vali Loss: 0.8133132 Test Loss: 1.6241823
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9269015
	speed: 0.0119s/iter; left time: 15.0015s
Epoch: 4 cost time: 2.144070625305176
Epoch: 4, Steps: 194 | Train Loss: 1.0413882 Vali Loss: 0.8463700 Test Loss: 1.6881551
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0264986
	speed: 0.0134s/iter; left time: 14.2180s
Epoch: 5 cost time: 2.519700050354004
Epoch: 5, Steps: 194 | Train Loss: 0.9974362 Vali Loss: 0.9049714 Test Loss: 1.7207911
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8742719
	speed: 0.0180s/iter; left time: 15.6690s
Epoch: 6 cost time: 3.2817530632019043
Epoch: 6, Steps: 194 | Train Loss: 0.9707613 Vali Loss: 0.9066245 Test Loss: 1.7700019
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4570587873458862, mae:0.9388947486877441
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2771209
	speed: 0.0134s/iter; left time: 24.6624s
Epoch: 1 cost time: 2.6491169929504395
Epoch: 1, Steps: 194 | Train Loss: 1.2415557 Vali Loss: 0.6979932 Test Loss: 1.4265841
Validation loss decreased (inf --> 0.697993).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2412444
	speed: 0.0180s/iter; left time: 29.5805s
Epoch: 2 cost time: 2.954920530319214
Epoch: 2, Steps: 194 | Train Loss: 1.1788537 Vali Loss: 0.7535723 Test Loss: 1.4866031
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9026155
	speed: 0.0167s/iter; left time: 24.2260s
Epoch: 3 cost time: 3.1069326400756836
Epoch: 3, Steps: 194 | Train Loss: 1.0970255 Vali Loss: 0.7532656 Test Loss: 1.5810981
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2022370
	speed: 0.0163s/iter; left time: 20.5678s
Epoch: 4 cost time: 3.3744022846221924
Epoch: 4, Steps: 194 | Train Loss: 1.0342387 Vali Loss: 0.9223950 Test Loss: 1.5841682
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8940520
	speed: 0.0139s/iter; left time: 14.8155s
Epoch: 5 cost time: 3.310647964477539
Epoch: 5, Steps: 194 | Train Loss: 0.9916186 Vali Loss: 0.9490035 Test Loss: 1.6272404
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0584135
	speed: 0.0130s/iter; left time: 11.3379s
Epoch: 6 cost time: 2.8300909996032715
Epoch: 6, Steps: 194 | Train Loss: 0.9646495 Vali Loss: 0.9870261 Test Loss: 1.6480501
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.426584005355835, mae:0.9433808326721191
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1107566
	speed: 0.0129s/iter; left time: 23.6829s
Epoch: 1 cost time: 2.2678651809692383
Epoch: 1, Steps: 194 | Train Loss: 1.2430145 Vali Loss: 0.6032417 Test Loss: 1.4119407
Validation loss decreased (inf --> 0.603242).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1590453
	speed: 0.0126s/iter; left time: 20.7241s
Epoch: 2 cost time: 2.4187967777252197
Epoch: 2, Steps: 194 | Train Loss: 1.1844923 Vali Loss: 0.6484725 Test Loss: 1.3786533
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2106131
	speed: 0.0175s/iter; left time: 25.4815s
Epoch: 3 cost time: 3.006631851196289
Epoch: 3, Steps: 194 | Train Loss: 1.1208130 Vali Loss: 0.7339209 Test Loss: 1.5503284
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2063863
	speed: 0.0186s/iter; left time: 23.3882s
Epoch: 4 cost time: 3.3722984790802
Epoch: 4, Steps: 194 | Train Loss: 1.0533214 Vali Loss: 0.8547023 Test Loss: 1.6634120
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0198431
	speed: 0.0179s/iter; left time: 19.0633s
Epoch: 5 cost time: 3.296565294265747
Epoch: 5, Steps: 194 | Train Loss: 1.0098736 Vali Loss: 0.8888323 Test Loss: 1.7007028
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0609314
	speed: 0.0127s/iter; left time: 11.0779s
Epoch: 6 cost time: 2.418433904647827
Epoch: 6, Steps: 194 | Train Loss: 0.9898189 Vali Loss: 0.9159409 Test Loss: 1.6982926
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4119408130645752, mae:0.9336549639701843
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5069891
	speed: 0.0244s/iter; left time: 49.4788s
	iters: 200, epoch: 1 | loss: 0.4466449
	speed: 0.0193s/iter; left time: 37.2309s
Epoch: 1 cost time: 4.124524354934692
Epoch: 1, Steps: 213 | Train Loss: 0.5504397 Vali Loss: 0.4896376 Test Loss: 0.5954943
Validation loss decreased (inf --> 0.489638).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5091343
	speed: 0.0139s/iter; left time: 25.3461s
	iters: 200, epoch: 2 | loss: 0.4749430
	speed: 0.0128s/iter; left time: 22.0168s
Epoch: 2 cost time: 2.8318891525268555
Epoch: 2, Steps: 213 | Train Loss: 0.5133435 Vali Loss: 0.5014185 Test Loss: 0.6289585
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4661240
	speed: 0.0127s/iter; left time: 20.4304s
	iters: 200, epoch: 3 | loss: 0.4787996
	speed: 0.0139s/iter; left time: 20.8784s
Epoch: 3 cost time: 3.096764087677002
Epoch: 3, Steps: 213 | Train Loss: 0.4969520 Vali Loss: 0.5148210 Test Loss: 0.6509314
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5037604
	speed: 0.0139s/iter; left time: 19.3307s
	iters: 200, epoch: 4 | loss: 0.4642796
	speed: 0.0147s/iter; left time: 19.0034s
Epoch: 4 cost time: 3.255706787109375
Epoch: 4, Steps: 213 | Train Loss: 0.4872745 Vali Loss: 0.5077577 Test Loss: 0.6584016
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5249128
	speed: 0.0146s/iter; left time: 17.2367s
	iters: 200, epoch: 5 | loss: 0.5175438
	speed: 0.0152s/iter; left time: 16.3682s
Epoch: 5 cost time: 3.3078272342681885
Epoch: 5, Steps: 213 | Train Loss: 0.4804853 Vali Loss: 0.5073028 Test Loss: 0.6672184
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4349917
	speed: 0.0157s/iter; left time: 15.1423s
	iters: 200, epoch: 6 | loss: 0.4860458
	speed: 0.0137s/iter; left time: 11.8707s
Epoch: 6 cost time: 2.9232776165008545
Epoch: 6, Steps: 213 | Train Loss: 0.4758791 Vali Loss: 0.5062360 Test Loss: 0.6692079
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5954944491386414, mae:0.610639750957489
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6190096
	speed: 0.0121s/iter; left time: 24.6611s
	iters: 200, epoch: 1 | loss: 0.5734279
	speed: 0.0114s/iter; left time: 21.9582s
Epoch: 1 cost time: 2.551572561264038
Epoch: 1, Steps: 213 | Train Loss: 0.5465868 Vali Loss: 0.4913769 Test Loss: 0.6022434
Validation loss decreased (inf --> 0.491377).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5462024
	speed: 0.0134s/iter; left time: 24.2994s
	iters: 200, epoch: 2 | loss: 0.4727194
	speed: 0.0131s/iter; left time: 22.4632s
Epoch: 2 cost time: 2.8314049243927
Epoch: 2, Steps: 213 | Train Loss: 0.5112237 Vali Loss: 0.4840018 Test Loss: 0.6261118
Validation loss decreased (0.491377 --> 0.484002).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4821332
	speed: 0.0142s/iter; left time: 22.7399s
	iters: 200, epoch: 3 | loss: 0.4518577
	speed: 0.0147s/iter; left time: 22.1456s
Epoch: 3 cost time: 3.2180163860321045
Epoch: 3, Steps: 213 | Train Loss: 0.4923451 Vali Loss: 0.5091490 Test Loss: 0.6514392
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4975356
	speed: 0.0140s/iter; left time: 19.5566s
	iters: 200, epoch: 4 | loss: 0.4610599
	speed: 0.0122s/iter; left time: 15.8185s
Epoch: 4 cost time: 2.660783529281616
Epoch: 4, Steps: 213 | Train Loss: 0.4809830 Vali Loss: 0.5222443 Test Loss: 0.6726245
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4953829
	speed: 0.0101s/iter; left time: 11.9358s
	iters: 200, epoch: 5 | loss: 0.4541553
	speed: 0.0087s/iter; left time: 9.3854s
Epoch: 5 cost time: 1.9145522117614746
Epoch: 5, Steps: 213 | Train Loss: 0.4709107 Vali Loss: 0.5192994 Test Loss: 0.6757198
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4832535
	speed: 0.0107s/iter; left time: 10.3625s
	iters: 200, epoch: 6 | loss: 0.4806951
	speed: 0.0108s/iter; left time: 9.3217s
Epoch: 6 cost time: 2.373520612716675
Epoch: 6, Steps: 213 | Train Loss: 0.4673261 Vali Loss: 0.5242189 Test Loss: 0.6702106
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4326796
	speed: 0.0128s/iter; left time: 9.6754s
	iters: 200, epoch: 7 | loss: 0.4323966
	speed: 0.0117s/iter; left time: 7.6355s
Epoch: 7 cost time: 2.55206561088562
Epoch: 7, Steps: 213 | Train Loss: 0.4644650 Vali Loss: 0.5299732 Test Loss: 0.6767697
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6261119246482849, mae:0.626687228679657
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6152591
	speed: 0.0128s/iter; left time: 25.9529s
	iters: 200, epoch: 1 | loss: 0.5204556
	speed: 0.0126s/iter; left time: 24.2341s
Epoch: 1 cost time: 2.7250537872314453
Epoch: 1, Steps: 213 | Train Loss: 0.5477186 Vali Loss: 0.4877647 Test Loss: 0.6179078
Validation loss decreased (inf --> 0.487765).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4869905
	speed: 0.0103s/iter; left time: 18.6676s
	iters: 200, epoch: 2 | loss: 0.5197049
	speed: 0.0095s/iter; left time: 16.3038s
Epoch: 2 cost time: 2.0762648582458496
Epoch: 2, Steps: 213 | Train Loss: 0.5115971 Vali Loss: 0.4989826 Test Loss: 0.6264126
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4910923
	speed: 0.0121s/iter; left time: 19.4049s
	iters: 200, epoch: 3 | loss: 0.4691438
	speed: 0.0118s/iter; left time: 17.7538s
Epoch: 3 cost time: 2.5720744132995605
Epoch: 3, Steps: 213 | Train Loss: 0.4940150 Vali Loss: 0.5116863 Test Loss: 0.6568350
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4838317
	speed: 0.0119s/iter; left time: 16.6079s
	iters: 200, epoch: 4 | loss: 0.5019679
	speed: 0.0117s/iter; left time: 15.1474s
Epoch: 4 cost time: 2.559586763381958
Epoch: 4, Steps: 213 | Train Loss: 0.4822122 Vali Loss: 0.5254278 Test Loss: 0.6687959
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4842172
	speed: 0.0117s/iter; left time: 13.7663s
	iters: 200, epoch: 5 | loss: 0.5134266
	speed: 0.0116s/iter; left time: 12.5202s
Epoch: 5 cost time: 2.5338728427886963
Epoch: 5, Steps: 213 | Train Loss: 0.4744187 Vali Loss: 0.5178897 Test Loss: 0.6714257
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4855049
	speed: 0.0092s/iter; left time: 8.8888s
	iters: 200, epoch: 6 | loss: 0.4749235
	speed: 0.0088s/iter; left time: 7.6124s
Epoch: 6 cost time: 1.9468715190887451
Epoch: 6, Steps: 213 | Train Loss: 0.4688062 Vali Loss: 0.5190445 Test Loss: 0.6765932
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6179078221321106, mae:0.6219457387924194
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7574949
	speed: 0.0230s/iter; left time: 45.9360s
	iters: 200, epoch: 1 | loss: 0.6093204
	speed: 0.0176s/iter; left time: 33.4813s
Epoch: 1 cost time: 3.6613128185272217
Epoch: 1, Steps: 210 | Train Loss: 0.6779532 Vali Loss: 0.6009994 Test Loss: 0.9355572
Validation loss decreased (inf --> 0.600999).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7251549
	speed: 0.0107s/iter; left time: 19.2067s
	iters: 200, epoch: 2 | loss: 0.7339110
	speed: 0.0098s/iter; left time: 16.6490s
Epoch: 2 cost time: 2.112985849380493
Epoch: 2, Steps: 210 | Train Loss: 0.6348546 Vali Loss: 0.6155120 Test Loss: 0.9480436
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6544280
	speed: 0.0108s/iter; left time: 17.0042s
	iters: 200, epoch: 3 | loss: 0.7151121
	speed: 0.0116s/iter; left time: 17.1429s
Epoch: 3 cost time: 2.4911372661590576
Epoch: 3, Steps: 210 | Train Loss: 0.6108510 Vali Loss: 0.6560897 Test Loss: 1.0398228
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5848333
	speed: 0.0119s/iter; left time: 16.3784s
	iters: 200, epoch: 4 | loss: 0.5839490
	speed: 0.0121s/iter; left time: 15.3944s
Epoch: 4 cost time: 2.5901193618774414
Epoch: 4, Steps: 210 | Train Loss: 0.5914583 Vali Loss: 0.6281611 Test Loss: 0.9931238
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5655395
	speed: 0.0115s/iter; left time: 13.3302s
	iters: 200, epoch: 5 | loss: 0.6081781
	speed: 0.0116s/iter; left time: 12.2949s
Epoch: 5 cost time: 2.516742706298828
Epoch: 5, Steps: 210 | Train Loss: 0.5767607 Vali Loss: 0.6290010 Test Loss: 0.9853198
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5556444
	speed: 0.0120s/iter; left time: 11.4247s
	iters: 200, epoch: 6 | loss: 0.5089005
	speed: 0.0112s/iter; left time: 9.5565s
Epoch: 6 cost time: 2.400294542312622
Epoch: 6, Steps: 210 | Train Loss: 0.5690688 Vali Loss: 0.6454430 Test Loss: 0.9894543
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9355573654174805, mae:0.758529782295227
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6005169
	speed: 0.0124s/iter; left time: 24.7402s
	iters: 200, epoch: 1 | loss: 0.6491230
	speed: 0.0124s/iter; left time: 23.5480s
Epoch: 1 cost time: 2.6886367797851562
Epoch: 1, Steps: 210 | Train Loss: 0.6790509 Vali Loss: 0.6115674 Test Loss: 0.9466388
Validation loss decreased (inf --> 0.611567).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5782526
	speed: 0.0143s/iter; left time: 25.5797s
	iters: 200, epoch: 2 | loss: 0.6474615
	speed: 0.0133s/iter; left time: 22.4605s
Epoch: 2 cost time: 2.8423562049865723
Epoch: 2, Steps: 210 | Train Loss: 0.6351481 Vali Loss: 0.6007170 Test Loss: 0.9900900
Validation loss decreased (0.611567 --> 0.600717).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5915725
	speed: 0.0117s/iter; left time: 18.4730s
	iters: 200, epoch: 3 | loss: 0.5596329
	speed: 0.0106s/iter; left time: 15.6753s
Epoch: 3 cost time: 2.2591850757598877
Epoch: 3, Steps: 210 | Train Loss: 0.6065141 Vali Loss: 0.5823405 Test Loss: 0.9781986
Validation loss decreased (0.600717 --> 0.582340).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4973309
	speed: 0.0138s/iter; left time: 18.9234s
	iters: 200, epoch: 4 | loss: 0.5214379
	speed: 0.0106s/iter; left time: 13.5066s
Epoch: 4 cost time: 2.244163990020752
Epoch: 4, Steps: 210 | Train Loss: 0.5833206 Vali Loss: 0.6167790 Test Loss: 1.0471784
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5909419
	speed: 0.0109s/iter; left time: 12.6606s
	iters: 200, epoch: 5 | loss: 0.6244372
	speed: 0.0095s/iter; left time: 10.0750s
Epoch: 5 cost time: 2.0890603065490723
Epoch: 5, Steps: 210 | Train Loss: 0.5683115 Vali Loss: 0.6119725 Test Loss: 1.0180266
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5124923
	speed: 0.0139s/iter; left time: 13.2200s
	iters: 200, epoch: 6 | loss: 0.4816092
	speed: 0.0127s/iter; left time: 10.8127s
Epoch: 6 cost time: 2.650684118270874
Epoch: 6, Steps: 210 | Train Loss: 0.5590653 Vali Loss: 0.6182321 Test Loss: 1.0224799
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5684285
	speed: 0.0138s/iter; left time: 10.2363s
	iters: 200, epoch: 7 | loss: 0.5614601
	speed: 0.0127s/iter; left time: 8.1254s
Epoch: 7 cost time: 2.6924145221710205
Epoch: 7, Steps: 210 | Train Loss: 0.5543560 Vali Loss: 0.6199765 Test Loss: 1.0257300
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5956898
	speed: 0.0138s/iter; left time: 7.3290s
	iters: 200, epoch: 8 | loss: 0.5806832
	speed: 0.0121s/iter; left time: 5.2215s
Epoch: 8 cost time: 2.625300407409668
Epoch: 8, Steps: 210 | Train Loss: 0.5538859 Vali Loss: 0.6220516 Test Loss: 1.0267882
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9781987071037292, mae:0.7766958475112915
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7893262
	speed: 0.0089s/iter; left time: 17.7958s
	iters: 200, epoch: 1 | loss: 0.6640707
	speed: 0.0089s/iter; left time: 16.9065s
Epoch: 1 cost time: 1.9559400081634521
Epoch: 1, Steps: 210 | Train Loss: 0.6776398 Vali Loss: 0.6137910 Test Loss: 0.9467717
Validation loss decreased (inf --> 0.613791).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5954702
	speed: 0.0122s/iter; left time: 21.8376s
	iters: 200, epoch: 2 | loss: 0.5622858
	speed: 0.0123s/iter; left time: 20.7627s
Epoch: 2 cost time: 2.6473588943481445
Epoch: 2, Steps: 210 | Train Loss: 0.6370835 Vali Loss: 0.6073540 Test Loss: 0.9435443
Validation loss decreased (0.613791 --> 0.607354).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5865969
	speed: 0.0125s/iter; left time: 19.6870s
	iters: 200, epoch: 3 | loss: 0.6439056
	speed: 0.0121s/iter; left time: 17.8543s
Epoch: 3 cost time: 2.5946905612945557
Epoch: 3, Steps: 210 | Train Loss: 0.6122245 Vali Loss: 0.6060034 Test Loss: 0.9838860
Validation loss decreased (0.607354 --> 0.606003).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6350892
	speed: 0.0122s/iter; left time: 16.7166s
	iters: 200, epoch: 4 | loss: 0.6118762
	speed: 0.0122s/iter; left time: 15.5516s
Epoch: 4 cost time: 2.6179473400115967
Epoch: 4, Steps: 210 | Train Loss: 0.5946291 Vali Loss: 0.6142920 Test Loss: 0.9877188
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5583596
	speed: 0.0091s/iter; left time: 10.5923s
	iters: 200, epoch: 5 | loss: 0.6087889
	speed: 0.0091s/iter; left time: 9.7042s
Epoch: 5 cost time: 1.980065107345581
Epoch: 5, Steps: 210 | Train Loss: 0.5834467 Vali Loss: 0.6103774 Test Loss: 0.9694442
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5464124
	speed: 0.0128s/iter; left time: 12.1567s
	iters: 200, epoch: 6 | loss: 0.5910954
	speed: 0.0126s/iter; left time: 10.6967s
Epoch: 6 cost time: 2.6874516010284424
Epoch: 6, Steps: 210 | Train Loss: 0.5762615 Vali Loss: 0.6158010 Test Loss: 0.9595540
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6707603
	speed: 0.0130s/iter; left time: 9.6669s
	iters: 200, epoch: 7 | loss: 0.5204393
	speed: 0.0127s/iter; left time: 8.1166s
Epoch: 7 cost time: 2.7271692752838135
Epoch: 7, Steps: 210 | Train Loss: 0.5717568 Vali Loss: 0.6174560 Test Loss: 0.9669225
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5921024
	speed: 0.0142s/iter; left time: 7.5504s
	iters: 200, epoch: 8 | loss: 0.4961042
	speed: 0.0133s/iter; left time: 5.7521s
Epoch: 8 cost time: 2.823296308517456
Epoch: 8, Steps: 210 | Train Loss: 0.5703973 Vali Loss: 0.6247818 Test Loss: 0.9666952
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9838859438896179, mae:0.776724636554718
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7654719
	speed: 0.0215s/iter; left time: 42.1704s
	iters: 200, epoch: 1 | loss: 0.8811325
	speed: 0.0167s/iter; left time: 30.9860s
Epoch: 1 cost time: 3.4687063694000244
Epoch: 1, Steps: 206 | Train Loss: 0.8562146 Vali Loss: 0.6764596 Test Loss: 1.3230263
Validation loss decreased (inf --> 0.676460).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8607857
	speed: 0.0121s/iter; left time: 21.2556s
	iters: 200, epoch: 2 | loss: 0.7502665
	speed: 0.0121s/iter; left time: 20.0786s
Epoch: 2 cost time: 2.5606765747070312
Epoch: 2, Steps: 206 | Train Loss: 0.8101901 Vali Loss: 0.6505262 Test Loss: 1.3623340
Validation loss decreased (0.676460 --> 0.650526).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6927963
	speed: 0.0106s/iter; left time: 16.3875s
	iters: 200, epoch: 3 | loss: 0.7613005
	speed: 0.0097s/iter; left time: 13.9879s
Epoch: 3 cost time: 2.030057430267334
Epoch: 3, Steps: 206 | Train Loss: 0.7756680 Vali Loss: 0.6469687 Test Loss: 1.4257270
Validation loss decreased (0.650526 --> 0.646969).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8551512
	speed: 0.0093s/iter; left time: 12.4711s
	iters: 200, epoch: 4 | loss: 0.8346691
	speed: 0.0083s/iter; left time: 10.3007s
Epoch: 4 cost time: 1.7685046195983887
Epoch: 4, Steps: 206 | Train Loss: 0.7454120 Vali Loss: 0.6361883 Test Loss: 1.4080555
Validation loss decreased (0.646969 --> 0.636188).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7621433
	speed: 0.0077s/iter; left time: 8.7508s
	iters: 200, epoch: 5 | loss: 0.7502862
	speed: 0.0072s/iter; left time: 7.4320s
Epoch: 5 cost time: 1.5491743087768555
Epoch: 5, Steps: 206 | Train Loss: 0.7225125 Vali Loss: 0.6345176 Test Loss: 1.4372847
Validation loss decreased (0.636188 --> 0.634518).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7669608
	speed: 0.0080s/iter; left time: 7.4596s
	iters: 200, epoch: 6 | loss: 0.7178721
	speed: 0.0076s/iter; left time: 6.2923s
Epoch: 6 cost time: 1.631981611251831
Epoch: 6, Steps: 206 | Train Loss: 0.7084761 Vali Loss: 0.6345246 Test Loss: 1.4443452
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9022144
	speed: 0.0104s/iter; left time: 7.5285s
	iters: 200, epoch: 7 | loss: 0.6033636
	speed: 0.0108s/iter; left time: 6.7226s
Epoch: 7 cost time: 2.290573835372925
Epoch: 7, Steps: 206 | Train Loss: 0.7015362 Vali Loss: 0.6395261 Test Loss: 1.4501657
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6117336
	speed: 0.0137s/iter; left time: 7.1202s
	iters: 200, epoch: 8 | loss: 0.6531385
	speed: 0.0125s/iter; left time: 5.2389s
Epoch: 8 cost time: 2.618165969848633
Epoch: 8, Steps: 206 | Train Loss: 0.6987938 Vali Loss: 0.6362004 Test Loss: 1.4438276
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7302499
	speed: 0.0140s/iter; left time: 4.3721s
	iters: 200, epoch: 9 | loss: 0.6711248
	speed: 0.0121s/iter; left time: 2.5857s
Epoch: 9 cost time: 2.5434625148773193
Epoch: 9, Steps: 206 | Train Loss: 0.6964830 Vali Loss: 0.6368272 Test Loss: 1.4431517
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6821211
	speed: 0.0133s/iter; left time: 1.4216s
	iters: 200, epoch: 10 | loss: 0.7187926
	speed: 0.0116s/iter; left time: 0.0815s
Epoch: 10 cost time: 2.4602110385894775
Epoch: 10, Steps: 206 | Train Loss: 0.6963772 Vali Loss: 0.6366897 Test Loss: 1.4428031
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4372848272323608, mae:0.9451027512550354
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7387596
	speed: 0.0090s/iter; left time: 17.5802s
	iters: 200, epoch: 1 | loss: 0.8168504
	speed: 0.0088s/iter; left time: 16.4376s
Epoch: 1 cost time: 1.8949615955352783
Epoch: 1, Steps: 206 | Train Loss: 0.8560950 Vali Loss: 0.6622816 Test Loss: 1.3228617
Validation loss decreased (inf --> 0.662282).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6953802
	speed: 0.0122s/iter; left time: 21.4744s
	iters: 200, epoch: 2 | loss: 0.8826427
	speed: 0.0122s/iter; left time: 20.1475s
Epoch: 2 cost time: 2.5545146465301514
Epoch: 2, Steps: 206 | Train Loss: 0.8084409 Vali Loss: 0.7229713 Test Loss: 1.4310349
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7586672
	speed: 0.0125s/iter; left time: 19.3707s
	iters: 200, epoch: 3 | loss: 0.8446503
	speed: 0.0124s/iter; left time: 17.9427s
Epoch: 3 cost time: 2.6110353469848633
Epoch: 3, Steps: 206 | Train Loss: 0.7747675 Vali Loss: 0.6593174 Test Loss: 1.4711821
Validation loss decreased (0.662282 --> 0.659317).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6860927
	speed: 0.0128s/iter; left time: 17.1293s
	iters: 200, epoch: 4 | loss: 0.8162904
	speed: 0.0126s/iter; left time: 15.6521s
Epoch: 4 cost time: 2.664226770401001
Epoch: 4, Steps: 206 | Train Loss: 0.7442841 Vali Loss: 0.6372150 Test Loss: 1.4631519
Validation loss decreased (0.659317 --> 0.637215).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6720873
	speed: 0.0138s/iter; left time: 15.6958s
	iters: 200, epoch: 5 | loss: 0.6410501
	speed: 0.0111s/iter; left time: 11.5083s
Epoch: 5 cost time: 2.3391811847686768
Epoch: 5, Steps: 206 | Train Loss: 0.7230496 Vali Loss: 0.6447181 Test Loss: 1.4719976
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6186720
	speed: 0.0101s/iter; left time: 9.4341s
	iters: 200, epoch: 6 | loss: 0.7072964
	speed: 0.0099s/iter; left time: 8.1946s
Epoch: 6 cost time: 2.1062510013580322
Epoch: 6, Steps: 206 | Train Loss: 0.7129052 Vali Loss: 0.6560717 Test Loss: 1.4890699
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7101142
	speed: 0.0144s/iter; left time: 10.4642s
	iters: 200, epoch: 7 | loss: 0.7599283
	speed: 0.0134s/iter; left time: 8.3766s
Epoch: 7 cost time: 2.8056960105895996
Epoch: 7, Steps: 206 | Train Loss: 0.7054831 Vali Loss: 0.6440365 Test Loss: 1.4739145
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6542087
	speed: 0.0138s/iter; left time: 7.1570s
	iters: 200, epoch: 8 | loss: 0.6895149
	speed: 0.0123s/iter; left time: 5.1653s
Epoch: 8 cost time: 2.5921554565429688
Epoch: 8, Steps: 206 | Train Loss: 0.6999409 Vali Loss: 0.6431754 Test Loss: 1.4709007
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7229789
	speed: 0.0140s/iter; left time: 4.3709s
	iters: 200, epoch: 9 | loss: 0.7153422
	speed: 0.0125s/iter; left time: 2.6644s
Epoch: 9 cost time: 2.626556873321533
Epoch: 9, Steps: 206 | Train Loss: 0.6997410 Vali Loss: 0.6435840 Test Loss: 1.4722166
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4631519317626953, mae:0.9565274119377136
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8839929
	speed: 0.0096s/iter; left time: 18.7282s
	iters: 200, epoch: 1 | loss: 0.9263163
	speed: 0.0080s/iter; left time: 14.9317s
Epoch: 1 cost time: 1.7324652671813965
Epoch: 1, Steps: 206 | Train Loss: 0.8571638 Vali Loss: 0.6668780 Test Loss: 1.2933085
Validation loss decreased (inf --> 0.666878).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6807482
	speed: 0.0127s/iter; left time: 22.2067s
	iters: 200, epoch: 2 | loss: 0.8012968
	speed: 0.0120s/iter; left time: 19.8449s
Epoch: 2 cost time: 2.5344631671905518
Epoch: 2, Steps: 206 | Train Loss: 0.8071350 Vali Loss: 0.6454245 Test Loss: 1.3472061
Validation loss decreased (0.666878 --> 0.645425).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7430477
	speed: 0.0124s/iter; left time: 19.2476s
	iters: 200, epoch: 3 | loss: 0.8028858
	speed: 0.0122s/iter; left time: 17.7335s
Epoch: 3 cost time: 2.5817971229553223
Epoch: 3, Steps: 206 | Train Loss: 0.7714607 Vali Loss: 0.6410820 Test Loss: 1.4238865
Validation loss decreased (0.645425 --> 0.641082).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8073380
	speed: 0.0135s/iter; left time: 18.1654s
	iters: 200, epoch: 4 | loss: 0.7691498
	speed: 0.0130s/iter; left time: 16.1332s
Epoch: 4 cost time: 2.7191379070281982
Epoch: 4, Steps: 206 | Train Loss: 0.7437956 Vali Loss: 0.6426570 Test Loss: 1.4240535
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6537027
	speed: 0.0129s/iter; left time: 14.6826s
	iters: 200, epoch: 5 | loss: 0.7244816
	speed: 0.0107s/iter; left time: 11.0785s
Epoch: 5 cost time: 2.2929139137268066
Epoch: 5, Steps: 206 | Train Loss: 0.7214416 Vali Loss: 0.6455616 Test Loss: 1.4496475
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5821944
	speed: 0.0112s/iter; left time: 10.3856s
	iters: 200, epoch: 6 | loss: 0.6692424
	speed: 0.0112s/iter; left time: 9.2892s
Epoch: 6 cost time: 2.3775343894958496
Epoch: 6, Steps: 206 | Train Loss: 0.7089289 Vali Loss: 0.6425683 Test Loss: 1.4332925
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7833174
	speed: 0.0117s/iter; left time: 8.5145s
	iters: 200, epoch: 7 | loss: 0.6745449
	speed: 0.0106s/iter; left time: 6.6037s
Epoch: 7 cost time: 2.2284607887268066
Epoch: 7, Steps: 206 | Train Loss: 0.7041280 Vali Loss: 0.6388450 Test Loss: 1.4422185
Validation loss decreased (0.641082 --> 0.638845).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6618286
	speed: 0.0126s/iter; left time: 6.5256s
	iters: 200, epoch: 8 | loss: 0.6658949
	speed: 0.0103s/iter; left time: 4.3002s
Epoch: 8 cost time: 2.1463661193847656
Epoch: 8, Steps: 206 | Train Loss: 0.7022204 Vali Loss: 0.6366189 Test Loss: 1.4471976
Validation loss decreased (0.638845 --> 0.636619).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6018672
	speed: 0.0111s/iter; left time: 3.4837s
	iters: 200, epoch: 9 | loss: 0.6422757
	speed: 0.0099s/iter; left time: 2.1085s
Epoch: 9 cost time: 2.0848069190979004
Epoch: 9, Steps: 206 | Train Loss: 0.6991336 Vali Loss: 0.6370723 Test Loss: 1.4465110
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6594390
	speed: 0.0073s/iter; left time: 0.7840s
	iters: 200, epoch: 10 | loss: 0.7539431
	speed: 0.0066s/iter; left time: 0.0462s
Epoch: 10 cost time: 1.4129226207733154
Epoch: 10, Steps: 206 | Train Loss: 0.7007792 Vali Loss: 0.6382840 Test Loss: 1.4464335
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.447197437286377, mae:0.9524952173233032
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0321510
	speed: 0.0175s/iter; left time: 32.2294s
Epoch: 1 cost time: 2.368393898010254
Epoch: 1, Steps: 194 | Train Loss: 1.2445370 Vali Loss: 0.5857962 Test Loss: 1.4335016
Validation loss decreased (inf --> 0.585796).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3701283
	speed: 0.0095s/iter; left time: 15.6104s
Epoch: 2 cost time: 1.8885204792022705
Epoch: 2, Steps: 194 | Train Loss: 1.1890355 Vali Loss: 0.6242253 Test Loss: 1.4315603
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0403395
	speed: 0.0107s/iter; left time: 15.5161s
Epoch: 3 cost time: 2.0038747787475586
Epoch: 3, Steps: 194 | Train Loss: 1.1273539 Vali Loss: 0.8031741 Test Loss: 1.5228627
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2910253
	speed: 0.0108s/iter; left time: 13.5865s
Epoch: 4 cost time: 2.004706621170044
Epoch: 4, Steps: 194 | Train Loss: 1.0639569 Vali Loss: 0.8206060 Test Loss: 1.6414244
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1097937
	speed: 0.0101s/iter; left time: 10.7478s
Epoch: 5 cost time: 1.8804659843444824
Epoch: 5, Steps: 194 | Train Loss: 1.0174099 Vali Loss: 0.9043397 Test Loss: 1.6700603
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0832615
	speed: 0.0074s/iter; left time: 6.4508s
Epoch: 6 cost time: 1.3607258796691895
Epoch: 6, Steps: 194 | Train Loss: 0.9923784 Vali Loss: 0.9494603 Test Loss: 1.7137341
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4335016012191772, mae:0.9390513300895691
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.3131030
	speed: 0.0111s/iter; left time: 20.3614s
Epoch: 1 cost time: 2.0479986667633057
Epoch: 1, Steps: 194 | Train Loss: 1.2410808 Vali Loss: 0.6283725 Test Loss: 1.3816752
Validation loss decreased (inf --> 0.628372).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2529883
	speed: 0.0097s/iter; left time: 16.0169s
Epoch: 2 cost time: 1.900942325592041
Epoch: 2, Steps: 194 | Train Loss: 1.1840809 Vali Loss: 0.6503961 Test Loss: 1.4232391
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9775150
	speed: 0.0107s/iter; left time: 15.5529s
Epoch: 3 cost time: 1.9989008903503418
Epoch: 3, Steps: 194 | Train Loss: 1.1268241 Vali Loss: 0.7276503 Test Loss: 1.5811379
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2742814
	speed: 0.0108s/iter; left time: 13.5644s
Epoch: 4 cost time: 2.0090935230255127
Epoch: 4, Steps: 194 | Train Loss: 1.0601848 Vali Loss: 0.7865415 Test Loss: 1.6815649
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0926824
	speed: 0.0074s/iter; left time: 7.8764s
Epoch: 5 cost time: 1.3294436931610107
Epoch: 5, Steps: 194 | Train Loss: 1.0158195 Vali Loss: 0.8279172 Test Loss: 1.7105199
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9831366
	speed: 0.0100s/iter; left time: 8.6917s
Epoch: 6 cost time: 1.9335291385650635
Epoch: 6, Steps: 194 | Train Loss: 0.9909637 Vali Loss: 0.8686237 Test Loss: 1.7044854
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3816754817962646, mae:0.9235084652900696
Use GPU: cuda:0
no_skip False
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1972201
	speed: 0.0109s/iter; left time: 20.1171s
Epoch: 1 cost time: 2.03464674949646
Epoch: 1, Steps: 194 | Train Loss: 1.2433766 Vali Loss: 0.5550554 Test Loss: 1.4461839
Validation loss decreased (inf --> 0.555055).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2774588
	speed: 0.0109s/iter; left time: 17.9262s
Epoch: 2 cost time: 2.0340054035186768
Epoch: 2, Steps: 194 | Train Loss: 1.1845739 Vali Loss: 0.6060164 Test Loss: 1.4903889
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2915398
	speed: 0.0107s/iter; left time: 15.6158s
Epoch: 3 cost time: 2.0112617015838623
Epoch: 3, Steps: 194 | Train Loss: 1.1088454 Vali Loss: 0.7270538 Test Loss: 1.4297488
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9900795
	speed: 0.0071s/iter; left time: 8.9121s
Epoch: 4 cost time: 1.308598279953003
Epoch: 4, Steps: 194 | Train Loss: 1.0372732 Vali Loss: 0.7152881 Test Loss: 1.5130230
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9517722
	speed: 0.0076s/iter; left time: 8.0706s
Epoch: 5 cost time: 1.3490650653839111
Epoch: 5, Steps: 194 | Train Loss: 0.9969409 Vali Loss: 0.7855477 Test Loss: 1.4462051
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9569515
	speed: 0.0109s/iter; left time: 9.4768s
Epoch: 6 cost time: 2.0219473838806152
Epoch: 6, Steps: 194 | Train Loss: 0.9782318 Vali Loss: 0.8123601 Test Loss: 1.4634157
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipFalse_FDCFalse_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4461839199066162, mae:0.9423100352287292
