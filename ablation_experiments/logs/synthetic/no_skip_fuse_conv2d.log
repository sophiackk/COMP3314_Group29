nohup: ignoring input
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9936422
	speed: 0.0435s/iter; left time: 88.2933s
	iters: 200, epoch: 1 | loss: 1.0327791
	speed: 0.0306s/iter; left time: 59.0703s
Epoch: 1 cost time: 6.311833620071411
Epoch: 1, Steps: 213 | Train Loss: 1.0304721 Vali Loss: 1.0411687 Test Loss: 1.0228521
Validation loss decreased (inf --> 1.041169).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0476676
	speed: 0.0214s/iter; left time: 38.8400s
	iters: 200, epoch: 2 | loss: 1.0353253
	speed: 0.0187s/iter; left time: 32.0643s
Epoch: 2 cost time: 4.020824909210205
Epoch: 2, Steps: 213 | Train Loss: 1.0251906 Vali Loss: 1.0415552 Test Loss: 1.0238330
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0019636
	speed: 0.0184s/iter; left time: 29.5187s
	iters: 200, epoch: 3 | loss: 1.0214915
	speed: 0.0174s/iter; left time: 26.2276s
Epoch: 3 cost time: 3.7378957271575928
Epoch: 3, Steps: 213 | Train Loss: 1.0225511 Vali Loss: 1.0410670 Test Loss: 1.0241798
Validation loss decreased (1.041169 --> 1.041067).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0469854
	speed: 0.0191s/iter; left time: 26.6183s
	iters: 200, epoch: 4 | loss: 1.0253414
	speed: 0.0168s/iter; left time: 21.7161s
Epoch: 4 cost time: 3.6612274646759033
Epoch: 4, Steps: 213 | Train Loss: 1.0206672 Vali Loss: 1.0420094 Test Loss: 1.0260860
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0360398
	speed: 0.0227s/iter; left time: 26.7438s
	iters: 200, epoch: 5 | loss: 1.0153358
	speed: 0.0171s/iter; left time: 18.4343s
Epoch: 5 cost time: 3.6315603256225586
Epoch: 5, Steps: 213 | Train Loss: 1.0192888 Vali Loss: 1.0410615 Test Loss: 1.0266182
Validation loss decreased (1.041067 --> 1.041062).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0346774
	speed: 0.0156s/iter; left time: 15.1029s
	iters: 200, epoch: 6 | loss: 1.0238205
	speed: 0.0142s/iter; left time: 12.3302s
Epoch: 6 cost time: 3.1421515941619873
Epoch: 6, Steps: 213 | Train Loss: 1.0184615 Vali Loss: 1.0405957 Test Loss: 1.0279050
Validation loss decreased (1.041062 --> 1.040596).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0488605
	speed: 0.0207s/iter; left time: 15.5684s
	iters: 200, epoch: 7 | loss: 1.0009403
	speed: 0.0191s/iter; left time: 12.4641s
Epoch: 7 cost time: 4.063041687011719
Epoch: 7, Steps: 213 | Train Loss: 1.0179090 Vali Loss: 1.0414515 Test Loss: 1.0281689
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0135732
	speed: 0.0161s/iter; left time: 8.6880s
	iters: 200, epoch: 8 | loss: 1.0248191
	speed: 0.0143s/iter; left time: 6.2970s
Epoch: 8 cost time: 3.1112282276153564
Epoch: 8, Steps: 213 | Train Loss: 1.0177397 Vali Loss: 1.0414546 Test Loss: 1.0283257
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0047846
	speed: 0.0201s/iter; left time: 6.5619s
	iters: 200, epoch: 9 | loss: 1.0047268
	speed: 0.0170s/iter; left time: 3.8574s
Epoch: 9 cost time: 3.645967721939087
Epoch: 9, Steps: 213 | Train Loss: 1.0176737 Vali Loss: 1.0422927 Test Loss: 1.0283824
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0125864
	speed: 0.0144s/iter; left time: 1.6400s
	iters: 200, epoch: 10 | loss: 1.0107442
	speed: 0.0127s/iter; left time: 0.1780s
Epoch: 10 cost time: 2.7318015098571777
Epoch: 10, Steps: 213 | Train Loss: 1.0176007 Vali Loss: 1.0415667 Test Loss: 1.0284319
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.027904987335205, mae:0.8086762428283691
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9996470
	speed: 0.0170s/iter; left time: 34.5871s
	iters: 200, epoch: 1 | loss: 0.9989074
	speed: 0.0147s/iter; left time: 28.4798s
Epoch: 1 cost time: 3.1626381874084473
Epoch: 1, Steps: 213 | Train Loss: 1.0321523 Vali Loss: 1.0414817 Test Loss: 1.0228083
Validation loss decreased (inf --> 1.041482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0056798
	speed: 0.0197s/iter; left time: 35.8276s
	iters: 200, epoch: 2 | loss: 0.9945763
	speed: 0.0159s/iter; left time: 27.3380s
Epoch: 2 cost time: 3.4011101722717285
Epoch: 2, Steps: 213 | Train Loss: 1.0260752 Vali Loss: 1.0397911 Test Loss: 1.0246109
Validation loss decreased (1.041482 --> 1.039791).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9840876
	speed: 0.0203s/iter; left time: 32.5828s
	iters: 200, epoch: 3 | loss: 1.0236086
	speed: 0.0160s/iter; left time: 24.0361s
Epoch: 3 cost time: 3.3444535732269287
Epoch: 3, Steps: 213 | Train Loss: 1.0233029 Vali Loss: 1.0413644 Test Loss: 1.0250237
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9918765
	speed: 0.0148s/iter; left time: 20.6012s
	iters: 200, epoch: 4 | loss: 1.0200331
	speed: 0.0133s/iter; left time: 17.1465s
Epoch: 4 cost time: 2.8221819400787354
Epoch: 4, Steps: 213 | Train Loss: 1.0210213 Vali Loss: 1.0426335 Test Loss: 1.0261945
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0260665
	speed: 0.0184s/iter; left time: 21.6675s
	iters: 200, epoch: 5 | loss: 1.0289762
	speed: 0.0170s/iter; left time: 18.3077s
Epoch: 5 cost time: 3.6322476863861084
Epoch: 5, Steps: 213 | Train Loss: 1.0190194 Vali Loss: 1.0415913 Test Loss: 1.0277159
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0067911
	speed: 0.0258s/iter; left time: 24.9323s
	iters: 200, epoch: 6 | loss: 1.0372061
	speed: 0.0205s/iter; left time: 17.7236s
Epoch: 6 cost time: 4.346686601638794
Epoch: 6, Steps: 213 | Train Loss: 1.0181479 Vali Loss: 1.0403926 Test Loss: 1.0284233
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0189861
	speed: 0.0184s/iter; left time: 13.8793s
	iters: 200, epoch: 7 | loss: 1.0151122
	speed: 0.0164s/iter; left time: 10.7163s
Epoch: 7 cost time: 3.489534378051758
Epoch: 7, Steps: 213 | Train Loss: 1.0176242 Vali Loss: 1.0431309 Test Loss: 1.0286878
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0246108770370483, mae:0.8077675700187683
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0274248
	speed: 0.0211s/iter; left time: 42.9008s
	iters: 200, epoch: 1 | loss: 1.0198530
	speed: 0.0176s/iter; left time: 34.0040s
Epoch: 1 cost time: 3.8095390796661377
Epoch: 1, Steps: 213 | Train Loss: 1.0314420 Vali Loss: 1.0412198 Test Loss: 1.0236417
Validation loss decreased (inf --> 1.041220).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0371022
	speed: 0.0238s/iter; left time: 43.3309s
	iters: 200, epoch: 2 | loss: 1.0400281
	speed: 0.0185s/iter; left time: 31.6997s
Epoch: 2 cost time: 3.9464240074157715
Epoch: 2, Steps: 213 | Train Loss: 1.0258061 Vali Loss: 1.0398449 Test Loss: 1.0243474
Validation loss decreased (1.041220 --> 1.039845).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0126021
	speed: 0.0213s/iter; left time: 34.1743s
	iters: 200, epoch: 3 | loss: 1.0254877
	speed: 0.0181s/iter; left time: 27.3026s
Epoch: 3 cost time: 3.81113600730896
Epoch: 3, Steps: 213 | Train Loss: 1.0228346 Vali Loss: 1.0403076 Test Loss: 1.0243300
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0161521
	speed: 0.0186s/iter; left time: 25.8498s
	iters: 200, epoch: 4 | loss: 1.0294031
	speed: 0.0148s/iter; left time: 19.0979s
Epoch: 4 cost time: 3.140868902206421
Epoch: 4, Steps: 213 | Train Loss: 1.0208418 Vali Loss: 1.0401106 Test Loss: 1.0265921
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0100472
	speed: 0.0186s/iter; left time: 21.9494s
	iters: 200, epoch: 5 | loss: 1.0408810
	speed: 0.0160s/iter; left time: 17.2459s
Epoch: 5 cost time: 3.4928646087646484
Epoch: 5, Steps: 213 | Train Loss: 1.0193727 Vali Loss: 1.0397851 Test Loss: 1.0281347
Validation loss decreased (1.039845 --> 1.039785).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0088174
	speed: 0.0174s/iter; left time: 16.8312s
	iters: 200, epoch: 6 | loss: 1.0512402
	speed: 0.0182s/iter; left time: 15.7242s
Epoch: 6 cost time: 3.978865385055542
Epoch: 6, Steps: 213 | Train Loss: 1.0184778 Vali Loss: 1.0398459 Test Loss: 1.0284865
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0113878
	speed: 0.0182s/iter; left time: 13.6731s
	iters: 200, epoch: 7 | loss: 1.0141954
	speed: 0.0162s/iter; left time: 10.5830s
Epoch: 7 cost time: 3.538524627685547
Epoch: 7, Steps: 213 | Train Loss: 1.0182366 Vali Loss: 1.0414599 Test Loss: 1.0287788
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0148357
	speed: 0.0151s/iter; left time: 8.1551s
	iters: 200, epoch: 8 | loss: 1.0261707
	speed: 0.0124s/iter; left time: 5.4570s
Epoch: 8 cost time: 2.749222993850708
Epoch: 8, Steps: 213 | Train Loss: 1.0177095 Vali Loss: 1.0408969 Test Loss: 1.0289642
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0158447
	speed: 0.0211s/iter; left time: 6.9118s
	iters: 200, epoch: 9 | loss: 1.0057390
	speed: 0.0215s/iter; left time: 4.8733s
Epoch: 9 cost time: 4.696923732757568
Epoch: 9, Steps: 213 | Train Loss: 1.0175796 Vali Loss: 1.0427366 Test Loss: 1.0290958
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0106349
	speed: 0.0164s/iter; left time: 1.8748s
	iters: 200, epoch: 10 | loss: 1.0091065
	speed: 0.0141s/iter; left time: 0.1978s
Epoch: 10 cost time: 3.0825977325439453
Epoch: 10, Steps: 213 | Train Loss: 1.0175314 Vali Loss: 1.0419724 Test Loss: 1.0291480
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.028134822845459, mae:0.8087399005889893
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0225685
	speed: 0.0429s/iter; left time: 85.8046s
	iters: 200, epoch: 1 | loss: 1.0316002
	speed: 0.0302s/iter; left time: 57.5020s
Epoch: 1 cost time: 6.230072259902954
Epoch: 1, Steps: 210 | Train Loss: 1.0344778 Vali Loss: 1.0472324 Test Loss: 1.0219349
Validation loss decreased (inf --> 1.047232).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0317409
	speed: 0.0200s/iter; left time: 35.7983s
	iters: 200, epoch: 2 | loss: 1.0223730
	speed: 0.0168s/iter; left time: 28.3748s
Epoch: 2 cost time: 3.6969752311706543
Epoch: 2, Steps: 210 | Train Loss: 1.0301687 Vali Loss: 1.0472388 Test Loss: 1.0221086
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9964048
	speed: 0.0190s/iter; left time: 30.1125s
	iters: 200, epoch: 3 | loss: 1.0078769
	speed: 0.0177s/iter; left time: 26.1466s
Epoch: 3 cost time: 3.7606799602508545
Epoch: 3, Steps: 210 | Train Loss: 1.0282452 Vali Loss: 1.0475724 Test Loss: 1.0218079
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0263472
	speed: 0.0264s/iter; left time: 36.1717s
	iters: 200, epoch: 4 | loss: 1.0226812
	speed: 0.0227s/iter; left time: 28.8722s
Epoch: 4 cost time: 4.892218828201294
Epoch: 4, Steps: 210 | Train Loss: 1.0267313 Vali Loss: 1.0470622 Test Loss: 1.0231893
Validation loss decreased (1.047232 --> 1.047062).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0273162
	speed: 0.0228s/iter; left time: 26.4937s
	iters: 200, epoch: 5 | loss: 1.0187142
	speed: 0.0190s/iter; left time: 20.2051s
Epoch: 5 cost time: 4.134761333465576
Epoch: 5, Steps: 210 | Train Loss: 1.0257552 Vali Loss: 1.0475776 Test Loss: 1.0232747
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0389513
	speed: 0.0216s/iter; left time: 20.5537s
	iters: 200, epoch: 6 | loss: 1.0271058
	speed: 0.0189s/iter; left time: 16.0927s
Epoch: 6 cost time: 3.9361841678619385
Epoch: 6, Steps: 210 | Train Loss: 1.0250886 Vali Loss: 1.0482427 Test Loss: 1.0239085
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0240377
	speed: 0.0196s/iter; left time: 14.5406s
	iters: 200, epoch: 7 | loss: 1.0372882
	speed: 0.0187s/iter; left time: 11.9975s
Epoch: 7 cost time: 3.9907093048095703
Epoch: 7, Steps: 210 | Train Loss: 1.0246549 Vali Loss: 1.0470436 Test Loss: 1.0241055
Validation loss decreased (1.047062 --> 1.047044).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0278600
	speed: 0.0202s/iter; left time: 10.7269s
	iters: 200, epoch: 8 | loss: 1.0491971
	speed: 0.0181s/iter; left time: 7.7803s
Epoch: 8 cost time: 3.9228999614715576
Epoch: 8, Steps: 210 | Train Loss: 1.0245395 Vali Loss: 1.0481261 Test Loss: 1.0242440
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0174241
	speed: 0.0156s/iter; left time: 5.0211s
	iters: 200, epoch: 9 | loss: 0.9921615
	speed: 0.0159s/iter; left time: 3.5083s
Epoch: 9 cost time: 3.539541244506836
Epoch: 9, Steps: 210 | Train Loss: 1.0244889 Vali Loss: 1.0482169 Test Loss: 1.0242628
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0345662
	speed: 0.0147s/iter; left time: 1.6284s
	iters: 200, epoch: 10 | loss: 1.0208788
	speed: 0.0136s/iter; left time: 0.1495s
Epoch: 10 cost time: 2.882822036743164
Epoch: 10, Steps: 210 | Train Loss: 1.0243472 Vali Loss: 1.0485749 Test Loss: 1.0242945
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.024105429649353, mae:0.8065975904464722
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0240510
	speed: 0.0169s/iter; left time: 33.8184s
	iters: 200, epoch: 1 | loss: 1.0426199
	speed: 0.0142s/iter; left time: 27.0852s
Epoch: 1 cost time: 3.142592668533325
Epoch: 1, Steps: 210 | Train Loss: 1.0338735 Vali Loss: 1.0465685 Test Loss: 1.0215861
Validation loss decreased (inf --> 1.046569).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0263009
	speed: 0.0161s/iter; left time: 28.8052s
	iters: 200, epoch: 2 | loss: 1.0473380
	speed: 0.0151s/iter; left time: 25.4862s
Epoch: 2 cost time: 3.20951509475708
Epoch: 2, Steps: 210 | Train Loss: 1.0297942 Vali Loss: 1.0475503 Test Loss: 1.0220183
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0181738
	speed: 0.0141s/iter; left time: 22.2575s
	iters: 200, epoch: 3 | loss: 1.0323547
	speed: 0.0125s/iter; left time: 18.4393s
Epoch: 3 cost time: 2.6741104125976562
Epoch: 3, Steps: 210 | Train Loss: 1.0280943 Vali Loss: 1.0468192 Test Loss: 1.0218519
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0374238
	speed: 0.0196s/iter; left time: 26.8212s
	iters: 200, epoch: 4 | loss: 1.0268220
	speed: 0.0177s/iter; left time: 22.4739s
Epoch: 4 cost time: 3.796039342880249
Epoch: 4, Steps: 210 | Train Loss: 1.0265501 Vali Loss: 1.0480723 Test Loss: 1.0227562
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9971142
	speed: 0.0168s/iter; left time: 19.4585s
	iters: 200, epoch: 5 | loss: 1.0260646
	speed: 0.0151s/iter; left time: 16.0471s
Epoch: 5 cost time: 3.2547895908355713
Epoch: 5, Steps: 210 | Train Loss: 1.0255513 Vali Loss: 1.0484815 Test Loss: 1.0236286
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0577530
	speed: 0.0187s/iter; left time: 17.8160s
	iters: 200, epoch: 6 | loss: 1.0089822
	speed: 0.0166s/iter; left time: 14.1294s
Epoch: 6 cost time: 3.5580267906188965
Epoch: 6, Steps: 210 | Train Loss: 1.0248254 Vali Loss: 1.0486598 Test Loss: 1.0239016
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.021586298942566, mae:0.8056014180183411
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0564573
	speed: 0.0171s/iter; left time: 34.3167s
	iters: 200, epoch: 1 | loss: 1.0420183
	speed: 0.0155s/iter; left time: 29.5062s
Epoch: 1 cost time: 3.3051586151123047
Epoch: 1, Steps: 210 | Train Loss: 1.0333959 Vali Loss: 1.0483115 Test Loss: 1.0211667
Validation loss decreased (inf --> 1.048311).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0434558
	speed: 0.0186s/iter; left time: 33.3631s
	iters: 200, epoch: 2 | loss: 1.0282838
	speed: 0.0160s/iter; left time: 27.0903s
Epoch: 2 cost time: 3.4766342639923096
Epoch: 2, Steps: 210 | Train Loss: 1.0304552 Vali Loss: 1.0486778 Test Loss: 1.0208371
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0584114
	speed: 0.0224s/iter; left time: 35.3892s
	iters: 200, epoch: 3 | loss: 1.0228970
	speed: 0.0190s/iter; left time: 28.1974s
Epoch: 3 cost time: 4.046472072601318
Epoch: 3, Steps: 210 | Train Loss: 1.0288633 Vali Loss: 1.0468115 Test Loss: 1.0215281
Validation loss decreased (1.048311 --> 1.046811).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0143664
	speed: 0.0198s/iter; left time: 27.1989s
	iters: 200, epoch: 4 | loss: 1.0134900
	speed: 0.0164s/iter; left time: 20.8450s
Epoch: 4 cost time: 3.5264337062835693
Epoch: 4, Steps: 210 | Train Loss: 1.0277048 Vali Loss: 1.0470653 Test Loss: 1.0212868
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0211211
	speed: 0.0197s/iter; left time: 22.8705s
	iters: 200, epoch: 5 | loss: 1.0416453
	speed: 0.0161s/iter; left time: 17.0443s
Epoch: 5 cost time: 3.406497001647949
Epoch: 5, Steps: 210 | Train Loss: 1.0269968 Vali Loss: 1.0477121 Test Loss: 1.0217034
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0307153
	speed: 0.0137s/iter; left time: 12.9924s
	iters: 200, epoch: 6 | loss: 1.0316858
	speed: 0.0130s/iter; left time: 11.0491s
Epoch: 6 cost time: 2.8131697177886963
Epoch: 6, Steps: 210 | Train Loss: 1.0263482 Vali Loss: 1.0480067 Test Loss: 1.0221845
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0267096
	speed: 0.0207s/iter; left time: 15.3196s
	iters: 200, epoch: 7 | loss: 1.0201552
	speed: 0.0183s/iter; left time: 11.7354s
Epoch: 7 cost time: 4.020739555358887
Epoch: 7, Steps: 210 | Train Loss: 1.0261038 Vali Loss: 1.0476086 Test Loss: 1.0224377
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0264432
	speed: 0.0191s/iter; left time: 10.1594s
	iters: 200, epoch: 8 | loss: 1.0262834
	speed: 0.0164s/iter; left time: 7.0483s
Epoch: 8 cost time: 3.492340087890625
Epoch: 8, Steps: 210 | Train Loss: 1.0259459 Vali Loss: 1.0481513 Test Loss: 1.0225302
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0215281248092651, mae:0.8055281639099121
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0330691
	speed: 0.0403s/iter; left time: 79.0116s
	iters: 200, epoch: 1 | loss: 1.0294743
	speed: 0.0287s/iter; left time: 53.3502s
Epoch: 1 cost time: 5.874236822128296
Epoch: 1, Steps: 206 | Train Loss: 1.0337063 Vali Loss: 1.0560523 Test Loss: 1.0362333
Validation loss decreased (inf --> 1.056052).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0295910
	speed: 0.0267s/iter; left time: 46.8315s
	iters: 200, epoch: 2 | loss: 1.0309268
	speed: 0.0208s/iter; left time: 34.4454s
Epoch: 2 cost time: 4.4545252323150635
Epoch: 2, Steps: 206 | Train Loss: 1.0303691 Vali Loss: 1.0558012 Test Loss: 1.0358939
Validation loss decreased (1.056052 --> 1.055801).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0223906
	speed: 0.0176s/iter; left time: 27.2135s
	iters: 200, epoch: 3 | loss: 1.0287124
	speed: 0.0137s/iter; left time: 19.8075s
Epoch: 3 cost time: 2.8703432083129883
Epoch: 3, Steps: 206 | Train Loss: 1.0290836 Vali Loss: 1.0559210 Test Loss: 1.0359093
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0283383
	speed: 0.0163s/iter; left time: 21.8590s
	iters: 200, epoch: 4 | loss: 1.0292144
	speed: 0.0170s/iter; left time: 21.1484s
Epoch: 4 cost time: 3.581498861312866
Epoch: 4, Steps: 206 | Train Loss: 1.0280991 Vali Loss: 1.0562261 Test Loss: 1.0357739
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0450456
	speed: 0.0205s/iter; left time: 23.2597s
	iters: 200, epoch: 5 | loss: 1.0312437
	speed: 0.0176s/iter; left time: 18.2326s
Epoch: 5 cost time: 3.7291219234466553
Epoch: 5, Steps: 206 | Train Loss: 1.0274652 Vali Loss: 1.0561974 Test Loss: 1.0365076
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0325183
	speed: 0.0182s/iter; left time: 16.9405s
	iters: 200, epoch: 6 | loss: 1.0263407
	speed: 0.0161s/iter; left time: 13.3881s
Epoch: 6 cost time: 3.4000632762908936
Epoch: 6, Steps: 206 | Train Loss: 1.0269383 Vali Loss: 1.0563791 Test Loss: 1.0369606
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0267915
	speed: 0.0140s/iter; left time: 10.1638s
	iters: 200, epoch: 7 | loss: 1.0338298
	speed: 0.0142s/iter; left time: 8.8780s
Epoch: 7 cost time: 3.061485767364502
Epoch: 7, Steps: 206 | Train Loss: 1.0267222 Vali Loss: 1.0563273 Test Loss: 1.0370127
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0358939170837402, mae:0.8093544244766235
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0103703
	speed: 0.0152s/iter; left time: 29.8665s
	iters: 200, epoch: 1 | loss: 1.0336207
	speed: 0.0130s/iter; left time: 24.1354s
Epoch: 1 cost time: 2.772735118865967
Epoch: 1, Steps: 206 | Train Loss: 1.0331184 Vali Loss: 1.0575844 Test Loss: 1.0349990
Validation loss decreased (inf --> 1.057584).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0103028
	speed: 0.0277s/iter; left time: 48.5568s
	iters: 200, epoch: 2 | loss: 1.0436227
	speed: 0.0202s/iter; left time: 33.3630s
Epoch: 2 cost time: 4.146332263946533
Epoch: 2, Steps: 206 | Train Loss: 1.0300028 Vali Loss: 1.0570024 Test Loss: 1.0350487
Validation loss decreased (1.057584 --> 1.057002).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0442001
	speed: 0.0262s/iter; left time: 40.5778s
	iters: 200, epoch: 3 | loss: 1.0434706
	speed: 0.0197s/iter; left time: 28.5393s
Epoch: 3 cost time: 4.152957916259766
Epoch: 3, Steps: 206 | Train Loss: 1.0288346 Vali Loss: 1.0563847 Test Loss: 1.0356076
Validation loss decreased (1.057002 --> 1.056385).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0185435
	speed: 0.0191s/iter; left time: 25.6969s
	iters: 200, epoch: 4 | loss: 1.0075877
	speed: 0.0151s/iter; left time: 18.7575s
Epoch: 4 cost time: 3.2444472312927246
Epoch: 4, Steps: 206 | Train Loss: 1.0277907 Vali Loss: 1.0561309 Test Loss: 1.0360404
Validation loss decreased (1.056385 --> 1.056131).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0095615
	speed: 0.0219s/iter; left time: 24.8735s
	iters: 200, epoch: 5 | loss: 1.0472836
	speed: 0.0174s/iter; left time: 18.0543s
Epoch: 5 cost time: 3.6753368377685547
Epoch: 5, Steps: 206 | Train Loss: 1.0271406 Vali Loss: 1.0562739 Test Loss: 1.0366098
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0266082
	speed: 0.0182s/iter; left time: 16.9399s
	iters: 200, epoch: 6 | loss: 1.0485684
	speed: 0.0167s/iter; left time: 13.9125s
Epoch: 6 cost time: 3.506225347518921
Epoch: 6, Steps: 206 | Train Loss: 1.0266490 Vali Loss: 1.0563191 Test Loss: 1.0368097
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0118260
	speed: 0.0211s/iter; left time: 15.3132s
	iters: 200, epoch: 7 | loss: 1.0341574
	speed: 0.0174s/iter; left time: 10.8738s
Epoch: 7 cost time: 3.6849255561828613
Epoch: 7, Steps: 206 | Train Loss: 1.0264415 Vali Loss: 1.0561944 Test Loss: 1.0371373
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0260596
	speed: 0.0193s/iter; left time: 10.0164s
	iters: 200, epoch: 8 | loss: 1.0043709
	speed: 0.0160s/iter; left time: 6.6994s
Epoch: 8 cost time: 3.4013967514038086
Epoch: 8, Steps: 206 | Train Loss: 1.0263577 Vali Loss: 1.0563829 Test Loss: 1.0373307
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9989837
	speed: 0.0136s/iter; left time: 4.2472s
	iters: 200, epoch: 9 | loss: 1.0220461
	speed: 0.0118s/iter; left time: 2.5160s
Epoch: 9 cost time: 2.5531833171844482
Epoch: 9, Steps: 206 | Train Loss: 1.0260964 Vali Loss: 1.0563456 Test Loss: 1.0373849
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0360405445098877, mae:0.8093818426132202
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0417957
	speed: 0.0238s/iter; left time: 46.7297s
	iters: 200, epoch: 1 | loss: 1.0143489
	speed: 0.0206s/iter; left time: 38.2753s
Epoch: 1 cost time: 4.352319955825806
Epoch: 1, Steps: 206 | Train Loss: 1.0331213 Vali Loss: 1.0564479 Test Loss: 1.0351615
Validation loss decreased (inf --> 1.056448).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0358365
	speed: 0.0217s/iter; left time: 38.0756s
	iters: 200, epoch: 2 | loss: 1.0150969
	speed: 0.0179s/iter; left time: 29.6702s
Epoch: 2 cost time: 3.814974308013916
Epoch: 2, Steps: 206 | Train Loss: 1.0300659 Vali Loss: 1.0558580 Test Loss: 1.0354370
Validation loss decreased (1.056448 --> 1.055858).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0484763
	speed: 0.0157s/iter; left time: 24.3848s
	iters: 200, epoch: 3 | loss: 1.0289373
	speed: 0.0130s/iter; left time: 18.8358s
Epoch: 3 cost time: 2.7930572032928467
Epoch: 3, Steps: 206 | Train Loss: 1.0290080 Vali Loss: 1.0562290 Test Loss: 1.0360023
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0195932
	speed: 0.0200s/iter; left time: 26.9032s
	iters: 200, epoch: 4 | loss: 1.0346925
	speed: 0.0224s/iter; left time: 27.8613s
Epoch: 4 cost time: 4.7801127433776855
Epoch: 4, Steps: 206 | Train Loss: 1.0278622 Vali Loss: 1.0561113 Test Loss: 1.0360162
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0293497
	speed: 0.0303s/iter; left time: 34.4944s
	iters: 200, epoch: 5 | loss: 1.0300899
	speed: 0.0255s/iter; left time: 26.4009s
Epoch: 5 cost time: 5.3945252895355225
Epoch: 5, Steps: 206 | Train Loss: 1.0272991 Vali Loss: 1.0563580 Test Loss: 1.0365651
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0339217
	speed: 0.0282s/iter; left time: 26.2259s
	iters: 200, epoch: 6 | loss: 1.0462812
	speed: 0.0214s/iter; left time: 17.8131s
Epoch: 6 cost time: 4.501990079879761
Epoch: 6, Steps: 206 | Train Loss: 1.0268789 Vali Loss: 1.0565656 Test Loss: 1.0371214
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0296698
	speed: 0.0176s/iter; left time: 12.7820s
	iters: 200, epoch: 7 | loss: 1.0214666
	speed: 0.0140s/iter; left time: 8.7451s
Epoch: 7 cost time: 2.9472694396972656
Epoch: 7, Steps: 206 | Train Loss: 1.0265425 Vali Loss: 1.0564451 Test Loss: 1.0373082
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0354373455047607, mae:0.8091209530830383
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0293977
	speed: 0.0345s/iter; left time: 63.4783s
Epoch: 1 cost time: 4.6626877784729
Epoch: 1, Steps: 194 | Train Loss: 1.0359977 Vali Loss: 1.0550723 Test Loss: 1.0287430
Validation loss decreased (inf --> 1.055072).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0504508
	speed: 0.0202s/iter; left time: 33.3019s
Epoch: 2 cost time: 3.285217046737671
Epoch: 2, Steps: 194 | Train Loss: 1.0328601 Vali Loss: 1.0540344 Test Loss: 1.0283244
Validation loss decreased (1.055072 --> 1.054034).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0358608
	speed: 0.0178s/iter; left time: 25.9106s
Epoch: 3 cost time: 3.19094181060791
Epoch: 3, Steps: 194 | Train Loss: 1.0318562 Vali Loss: 1.0540978 Test Loss: 1.0276703
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0313053
	speed: 0.0206s/iter; left time: 25.9820s
Epoch: 4 cost time: 3.967851161956787
Epoch: 4, Steps: 194 | Train Loss: 1.0313664 Vali Loss: 1.0525284 Test Loss: 1.0285175
Validation loss decreased (1.054034 --> 1.052528).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0279742
	speed: 0.0213s/iter; left time: 22.6435s
Epoch: 5 cost time: 3.502089738845825
Epoch: 5, Steps: 194 | Train Loss: 1.0307929 Vali Loss: 1.0526445 Test Loss: 1.0297035
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0489842
	speed: 0.0211s/iter; left time: 18.4000s
Epoch: 6 cost time: 3.6321523189544678
Epoch: 6, Steps: 194 | Train Loss: 1.0304868 Vali Loss: 1.0522537 Test Loss: 1.0298264
Validation loss decreased (1.052528 --> 1.052254).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0287789
	speed: 0.0195s/iter; left time: 13.1965s
Epoch: 7 cost time: 4.053454875946045
Epoch: 7, Steps: 194 | Train Loss: 1.0301119 Vali Loss: 1.0522358 Test Loss: 1.0300121
Validation loss decreased (1.052254 --> 1.052236).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0246373
	speed: 0.0153s/iter; left time: 7.4050s
Epoch: 8 cost time: 3.1538243293762207
Epoch: 8, Steps: 194 | Train Loss: 1.0301785 Vali Loss: 1.0523541 Test Loss: 1.0300547
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0206251
	speed: 0.0240s/iter; left time: 6.9289s
Epoch: 9 cost time: 4.5875771045684814
Epoch: 9, Steps: 194 | Train Loss: 1.0300856 Vali Loss: 1.0524992 Test Loss: 1.0300913
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0212096
	speed: 0.0202s/iter; left time: 1.9206s
Epoch: 10 cost time: 3.444352388381958
Epoch: 10, Steps: 194 | Train Loss: 1.0299775 Vali Loss: 1.0524601 Test Loss: 1.0300994
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0300120115280151, mae:0.8057083487510681
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0337874
	speed: 0.0260s/iter; left time: 47.8622s
Epoch: 1 cost time: 4.047956705093384
Epoch: 1, Steps: 194 | Train Loss: 1.0359619 Vali Loss: 1.0557237 Test Loss: 1.0283964
Validation loss decreased (inf --> 1.055724).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0248990
	speed: 0.0226s/iter; left time: 37.2485s
Epoch: 2 cost time: 3.1788551807403564
Epoch: 2, Steps: 194 | Train Loss: 1.0328828 Vali Loss: 1.0557801 Test Loss: 1.0279709
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0357167
	speed: 0.0167s/iter; left time: 24.2438s
Epoch: 3 cost time: 3.0920872688293457
Epoch: 3, Steps: 194 | Train Loss: 1.0320334 Vali Loss: 1.0548892 Test Loss: 1.0276266
Validation loss decreased (1.055724 --> 1.054889).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0335857
	speed: 0.0152s/iter; left time: 19.1143s
Epoch: 4 cost time: 2.727858066558838
Epoch: 4, Steps: 194 | Train Loss: 1.0316203 Vali Loss: 1.0546155 Test Loss: 1.0275308
Validation loss decreased (1.054889 --> 1.054615).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0238934
	speed: 0.0240s/iter; left time: 25.5940s
Epoch: 5 cost time: 3.9952075481414795
Epoch: 5, Steps: 194 | Train Loss: 1.0313644 Vali Loss: 1.0541083 Test Loss: 1.0272448
Validation loss decreased (1.054615 --> 1.054108).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0374331
	speed: 0.0166s/iter; left time: 14.4189s
Epoch: 6 cost time: 2.754925012588501
Epoch: 6, Steps: 194 | Train Loss: 1.0310728 Vali Loss: 1.0539970 Test Loss: 1.0272639
Validation loss decreased (1.054108 --> 1.053997).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0308042
	speed: 0.0164s/iter; left time: 11.1075s
Epoch: 7 cost time: 2.9336886405944824
Epoch: 7, Steps: 194 | Train Loss: 1.0310320 Vali Loss: 1.0543916 Test Loss: 1.0272495
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0457423
	speed: 0.0205s/iter; left time: 9.9222s
Epoch: 8 cost time: 3.839312791824341
Epoch: 8, Steps: 194 | Train Loss: 1.0309434 Vali Loss: 1.0545998 Test Loss: 1.0272604
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0529186
	speed: 0.0203s/iter; left time: 5.8752s
Epoch: 9 cost time: 3.708644390106201
Epoch: 9, Steps: 194 | Train Loss: 1.0308596 Vali Loss: 1.0538789 Test Loss: 1.0272639
Validation loss decreased (1.053997 --> 1.053879).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0154409
	speed: 0.0229s/iter; left time: 2.1718s
Epoch: 10 cost time: 3.81377911567688
Epoch: 10, Steps: 194 | Train Loss: 1.0308434 Vali Loss: 1.0539136 Test Loss: 1.0272621
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0272637605667114, mae:0.8044400811195374
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0498532
	speed: 0.0180s/iter; left time: 33.2134s
Epoch: 1 cost time: 2.8321290016174316
Epoch: 1, Steps: 194 | Train Loss: 1.0360917 Vali Loss: 1.0562053 Test Loss: 1.0283500
Validation loss decreased (inf --> 1.056205).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0520128
	speed: 0.0196s/iter; left time: 32.3238s
Epoch: 2 cost time: 3.3461246490478516
Epoch: 2, Steps: 194 | Train Loss: 1.0328264 Vali Loss: 1.0556641 Test Loss: 1.0279170
Validation loss decreased (1.056205 --> 1.055664).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0328811
	speed: 0.0245s/iter; left time: 35.6005s
Epoch: 3 cost time: 3.886735200881958
Epoch: 3, Steps: 194 | Train Loss: 1.0317675 Vali Loss: 1.0551527 Test Loss: 1.0277356
Validation loss decreased (1.055664 --> 1.055153).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0343158
	speed: 0.0165s/iter; left time: 20.7266s
Epoch: 4 cost time: 2.942934274673462
Epoch: 4, Steps: 194 | Train Loss: 1.0312151 Vali Loss: 1.0549216 Test Loss: 1.0281683
Validation loss decreased (1.055153 --> 1.054922).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0453343
	speed: 0.0230s/iter; left time: 24.5181s
Epoch: 5 cost time: 3.3062186241149902
Epoch: 5, Steps: 194 | Train Loss: 1.0308796 Vali Loss: 1.0550861 Test Loss: 1.0288512
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0387671
	speed: 0.0216s/iter; left time: 18.7814s
Epoch: 6 cost time: 3.983150005340576
Epoch: 6, Steps: 194 | Train Loss: 1.0305257 Vali Loss: 1.0550960 Test Loss: 1.0290058
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0526994
	speed: 0.0191s/iter; left time: 12.9452s
Epoch: 7 cost time: 3.2229695320129395
Epoch: 7, Steps: 194 | Train Loss: 1.0303507 Vali Loss: 1.0549943 Test Loss: 1.0291616
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0239428
	speed: 0.0165s/iter; left time: 7.9726s
Epoch: 8 cost time: 3.224998950958252
Epoch: 8, Steps: 194 | Train Loss: 1.0303174 Vali Loss: 1.0554167 Test Loss: 1.0292004
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0351398
	speed: 0.0173s/iter; left time: 4.9868s
Epoch: 9 cost time: 2.81502103805542
Epoch: 9, Steps: 194 | Train Loss: 1.0302503 Vali Loss: 1.0550683 Test Loss: 1.0292140
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0281682014465332, mae:0.8048020005226135
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9863075
	speed: 0.0280s/iter; left time: 56.9017s
	iters: 200, epoch: 1 | loss: 1.0421032
	speed: 0.0216s/iter; left time: 41.6473s
Epoch: 1 cost time: 4.549676895141602
Epoch: 1, Steps: 213 | Train Loss: 1.0304803 Vali Loss: 1.0408133 Test Loss: 1.0228096
Validation loss decreased (inf --> 1.040813).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0476418
	speed: 0.0212s/iter; left time: 38.5092s
	iters: 200, epoch: 2 | loss: 1.0244343
	speed: 0.0150s/iter; left time: 25.7753s
Epoch: 2 cost time: 3.183753728866577
Epoch: 2, Steps: 213 | Train Loss: 1.0249502 Vali Loss: 1.0408729 Test Loss: 1.0239649
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0067147
	speed: 0.0195s/iter; left time: 31.2916s
	iters: 200, epoch: 3 | loss: 0.9904995
	speed: 0.0153s/iter; left time: 22.9727s
Epoch: 3 cost time: 3.2971322536468506
Epoch: 3, Steps: 213 | Train Loss: 1.0222585 Vali Loss: 1.0402350 Test Loss: 1.0247328
Validation loss decreased (1.040813 --> 1.040235).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0171177
	speed: 0.0255s/iter; left time: 35.5003s
	iters: 200, epoch: 4 | loss: 0.9961740
	speed: 0.0186s/iter; left time: 23.9922s
Epoch: 4 cost time: 3.9839701652526855
Epoch: 4, Steps: 213 | Train Loss: 1.0200269 Vali Loss: 1.0417199 Test Loss: 1.0273598
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9867873
	speed: 0.0157s/iter; left time: 18.5164s
	iters: 200, epoch: 5 | loss: 1.0276992
	speed: 0.0150s/iter; left time: 16.1993s
Epoch: 5 cost time: 3.306300640106201
Epoch: 5, Steps: 213 | Train Loss: 1.0184027 Vali Loss: 1.0411232 Test Loss: 1.0273786
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0408868
	speed: 0.0201s/iter; left time: 19.4065s
	iters: 200, epoch: 6 | loss: 1.0132596
	speed: 0.0183s/iter; left time: 15.8374s
Epoch: 6 cost time: 3.9558563232421875
Epoch: 6, Steps: 213 | Train Loss: 1.0173251 Vali Loss: 1.0413659 Test Loss: 1.0281869
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0131516
	speed: 0.0151s/iter; left time: 11.3999s
	iters: 200, epoch: 7 | loss: 1.0107577
	speed: 0.0133s/iter; left time: 8.6879s
Epoch: 7 cost time: 2.922166585922241
Epoch: 7, Steps: 213 | Train Loss: 1.0169232 Vali Loss: 1.0431441 Test Loss: 1.0287745
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9748093
	speed: 0.0229s/iter; left time: 12.3613s
	iters: 200, epoch: 8 | loss: 1.0280395
	speed: 0.0199s/iter; left time: 8.7540s
Epoch: 8 cost time: 4.35723614692688
Epoch: 8, Steps: 213 | Train Loss: 1.0166930 Vali Loss: 1.0419261 Test Loss: 1.0289053
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0247329473495483, mae:0.8076024055480957
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0513966
	speed: 0.0198s/iter; left time: 40.1301s
	iters: 200, epoch: 1 | loss: 1.0270976
	speed: 0.0182s/iter; left time: 35.0822s
Epoch: 1 cost time: 3.903738021850586
Epoch: 1, Steps: 213 | Train Loss: 1.0294425 Vali Loss: 1.0393164 Test Loss: 1.0225039
Validation loss decreased (inf --> 1.039316).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0287793
	speed: 0.0147s/iter; left time: 26.7012s
	iters: 200, epoch: 2 | loss: 1.0138588
	speed: 0.0146s/iter; left time: 25.1194s
Epoch: 2 cost time: 3.160980463027954
Epoch: 2, Steps: 213 | Train Loss: 1.0254710 Vali Loss: 1.0414493 Test Loss: 1.0226682
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0230274
	speed: 0.0130s/iter; left time: 20.8838s
	iters: 200, epoch: 3 | loss: 1.0057710
	speed: 0.0127s/iter; left time: 19.0824s
Epoch: 3 cost time: 2.7992191314697266
Epoch: 3, Steps: 213 | Train Loss: 1.0229614 Vali Loss: 1.0403812 Test Loss: 1.0241185
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0498129
	speed: 0.0154s/iter; left time: 21.4158s
	iters: 200, epoch: 4 | loss: 0.9904913
	speed: 0.0126s/iter; left time: 16.2919s
Epoch: 4 cost time: 2.760087013244629
Epoch: 4, Steps: 213 | Train Loss: 1.0204709 Vali Loss: 1.0409858 Test Loss: 1.0252811
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0052072
	speed: 0.0115s/iter; left time: 13.6017s
	iters: 200, epoch: 5 | loss: 1.0327368
	speed: 0.0147s/iter; left time: 15.8721s
Epoch: 5 cost time: 3.155538320541382
Epoch: 5, Steps: 213 | Train Loss: 1.0186450 Vali Loss: 1.0417615 Test Loss: 1.0269769
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0507377
	speed: 0.0169s/iter; left time: 16.3206s
	iters: 200, epoch: 6 | loss: 1.0411147
	speed: 0.0134s/iter; left time: 11.6313s
Epoch: 6 cost time: 2.8897416591644287
Epoch: 6, Steps: 213 | Train Loss: 1.0178462 Vali Loss: 1.0418720 Test Loss: 1.0271819
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0225038528442383, mae:0.80693519115448
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0361804
	speed: 0.0150s/iter; left time: 30.4763s
	iters: 200, epoch: 1 | loss: 0.9950726
	speed: 0.0131s/iter; left time: 25.2942s
Epoch: 1 cost time: 2.9562594890594482
Epoch: 1, Steps: 213 | Train Loss: 1.0311910 Vali Loss: 1.0421257 Test Loss: 1.0231829
Validation loss decreased (inf --> 1.042126).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0382097
	speed: 0.0157s/iter; left time: 28.4657s
	iters: 200, epoch: 2 | loss: 1.0181211
	speed: 0.0144s/iter; left time: 24.7865s
Epoch: 2 cost time: 3.1592705249786377
Epoch: 2, Steps: 213 | Train Loss: 1.0257977 Vali Loss: 1.0419918 Test Loss: 1.0236521
Validation loss decreased (1.042126 --> 1.041992).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0165968
	speed: 0.0180s/iter; left time: 28.8642s
	iters: 200, epoch: 3 | loss: 1.0065044
	speed: 0.0166s/iter; left time: 25.0358s
Epoch: 3 cost time: 3.6455743312835693
Epoch: 3, Steps: 213 | Train Loss: 1.0233504 Vali Loss: 1.0410300 Test Loss: 1.0238436
Validation loss decreased (1.041992 --> 1.041030).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0423036
	speed: 0.0158s/iter; left time: 22.0461s
	iters: 200, epoch: 4 | loss: 1.0424795
	speed: 0.0149s/iter; left time: 19.2571s
Epoch: 4 cost time: 3.2790236473083496
Epoch: 4, Steps: 213 | Train Loss: 1.0213554 Vali Loss: 1.0428869 Test Loss: 1.0258580
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0399592
	speed: 0.0139s/iter; left time: 16.4207s
	iters: 200, epoch: 5 | loss: 1.0345109
	speed: 0.0124s/iter; left time: 13.3785s
Epoch: 5 cost time: 2.7392101287841797
Epoch: 5, Steps: 213 | Train Loss: 1.0199766 Vali Loss: 1.0426147 Test Loss: 1.0268934
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0237255
	speed: 0.0209s/iter; left time: 20.1903s
	iters: 200, epoch: 6 | loss: 0.9942324
	speed: 0.0251s/iter; left time: 21.7666s
Epoch: 6 cost time: 5.539099931716919
Epoch: 6, Steps: 213 | Train Loss: 1.0190725 Vali Loss: 1.0429368 Test Loss: 1.0273528
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0192714
	speed: 0.0169s/iter; left time: 12.7552s
	iters: 200, epoch: 7 | loss: 0.9891195
	speed: 0.0159s/iter; left time: 10.3874s
Epoch: 7 cost time: 3.491976737976074
Epoch: 7, Steps: 213 | Train Loss: 1.0186737 Vali Loss: 1.0433164 Test Loss: 1.0277076
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0035868
	speed: 0.0161s/iter; left time: 8.6917s
	iters: 200, epoch: 8 | loss: 1.0296006
	speed: 0.0125s/iter; left time: 5.4924s
Epoch: 8 cost time: 2.73772931098938
Epoch: 8, Steps: 213 | Train Loss: 1.0186287 Vali Loss: 1.0429261 Test Loss: 1.0278549
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0238436460494995, mae:0.8073563575744629
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0407244
	speed: 0.0325s/iter; left time: 64.9343s
	iters: 200, epoch: 1 | loss: 1.0069027
	speed: 0.0252s/iter; left time: 47.8545s
Epoch: 1 cost time: 5.458031892776489
Epoch: 1, Steps: 210 | Train Loss: 1.0341830 Vali Loss: 1.0492345 Test Loss: 1.0217152
Validation loss decreased (inf --> 1.049235).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0345834
	speed: 0.0151s/iter; left time: 26.9675s
	iters: 200, epoch: 2 | loss: 1.0276432
	speed: 0.0161s/iter; left time: 27.1498s
Epoch: 2 cost time: 3.436480760574341
Epoch: 2, Steps: 210 | Train Loss: 1.0300763 Vali Loss: 1.0463463 Test Loss: 1.0217581
Validation loss decreased (1.049235 --> 1.046346).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0501953
	speed: 0.0182s/iter; left time: 28.7879s
	iters: 200, epoch: 3 | loss: 1.0330815
	speed: 0.0164s/iter; left time: 24.2882s
Epoch: 3 cost time: 3.564748764038086
Epoch: 3, Steps: 210 | Train Loss: 1.0283184 Vali Loss: 1.0469697 Test Loss: 1.0214680
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0452073
	speed: 0.0157s/iter; left time: 21.5301s
	iters: 200, epoch: 4 | loss: 1.0201423
	speed: 0.0156s/iter; left time: 19.7717s
Epoch: 4 cost time: 3.385450839996338
Epoch: 4, Steps: 210 | Train Loss: 1.0267647 Vali Loss: 1.0480318 Test Loss: 1.0233396
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0464346
	speed: 0.0173s/iter; left time: 20.0438s
	iters: 200, epoch: 5 | loss: 1.0270789
	speed: 0.0157s/iter; left time: 16.6893s
Epoch: 5 cost time: 3.3661346435546875
Epoch: 5, Steps: 210 | Train Loss: 1.0256746 Vali Loss: 1.0479703 Test Loss: 1.0234792
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0286195
	speed: 0.0137s/iter; left time: 13.0174s
	iters: 200, epoch: 6 | loss: 1.0193782
	speed: 0.0124s/iter; left time: 10.5678s
Epoch: 6 cost time: 2.677096128463745
Epoch: 6, Steps: 210 | Train Loss: 1.0249444 Vali Loss: 1.0478432 Test Loss: 1.0237756
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0270946
	speed: 0.0149s/iter; left time: 11.0514s
	iters: 200, epoch: 7 | loss: 1.0371648
	speed: 0.0147s/iter; left time: 9.4058s
Epoch: 7 cost time: 3.1547625064849854
Epoch: 7, Steps: 210 | Train Loss: 1.0246279 Vali Loss: 1.0479035 Test Loss: 1.0241412
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0217581987380981, mae:0.8055731058120728
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0230999
	speed: 0.0176s/iter; left time: 35.2509s
	iters: 200, epoch: 1 | loss: 1.0359129
	speed: 0.0168s/iter; left time: 31.9543s
Epoch: 1 cost time: 3.658050060272217
Epoch: 1, Steps: 210 | Train Loss: 1.0358021 Vali Loss: 1.0483701 Test Loss: 1.0221268
Validation loss decreased (inf --> 1.048370).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0254744
	speed: 0.0226s/iter; left time: 40.4602s
	iters: 200, epoch: 2 | loss: 1.0114206
	speed: 0.0195s/iter; left time: 33.0268s
Epoch: 2 cost time: 4.256277799606323
Epoch: 2, Steps: 210 | Train Loss: 1.0307537 Vali Loss: 1.0476562 Test Loss: 1.0221200
Validation loss decreased (1.048370 --> 1.047656).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0393746
	speed: 0.0160s/iter; left time: 25.2318s
	iters: 200, epoch: 3 | loss: 1.0210685
	speed: 0.0122s/iter; left time: 18.0049s
Epoch: 3 cost time: 2.5774085521698
Epoch: 3, Steps: 210 | Train Loss: 1.0287227 Vali Loss: 1.0479411 Test Loss: 1.0222977
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0203263
	speed: 0.0171s/iter; left time: 23.4492s
	iters: 200, epoch: 4 | loss: 1.0003831
	speed: 0.0160s/iter; left time: 20.3419s
Epoch: 4 cost time: 3.4047532081604004
Epoch: 4, Steps: 210 | Train Loss: 1.0271050 Vali Loss: 1.0482669 Test Loss: 1.0225438
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0294406
	speed: 0.0165s/iter; left time: 19.1558s
	iters: 200, epoch: 5 | loss: 1.0255790
	speed: 0.0155s/iter; left time: 16.4718s
Epoch: 5 cost time: 3.336949348449707
Epoch: 5, Steps: 210 | Train Loss: 1.0261807 Vali Loss: 1.0485060 Test Loss: 1.0234709
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0121878
	speed: 0.0204s/iter; left time: 19.4075s
	iters: 200, epoch: 6 | loss: 1.0323000
	speed: 0.0172s/iter; left time: 14.6399s
Epoch: 6 cost time: 3.6370651721954346
Epoch: 6, Steps: 210 | Train Loss: 1.0254316 Vali Loss: 1.0476587 Test Loss: 1.0240744
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0339189
	speed: 0.0168s/iter; left time: 12.4792s
	iters: 200, epoch: 7 | loss: 1.0126778
	speed: 0.0154s/iter; left time: 9.8470s
Epoch: 7 cost time: 3.3529927730560303
Epoch: 7, Steps: 210 | Train Loss: 1.0251061 Vali Loss: 1.0474832 Test Loss: 1.0241412
Validation loss decreased (1.047656 --> 1.047483).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0235795
	speed: 0.0240s/iter; left time: 12.7241s
	iters: 200, epoch: 8 | loss: 1.0335889
	speed: 0.0209s/iter; left time: 9.0263s
Epoch: 8 cost time: 4.451280832290649
Epoch: 8, Steps: 210 | Train Loss: 1.0248459 Vali Loss: 1.0481400 Test Loss: 1.0243239
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0487967
	speed: 0.0177s/iter; left time: 5.6716s
	iters: 200, epoch: 9 | loss: 1.0317056
	speed: 0.0165s/iter; left time: 3.6548s
Epoch: 9 cost time: 3.5492851734161377
Epoch: 9, Steps: 210 | Train Loss: 1.0248495 Vali Loss: 1.0479009 Test Loss: 1.0243709
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0444901
	speed: 0.0186s/iter; left time: 2.0615s
	iters: 200, epoch: 10 | loss: 1.0395780
	speed: 0.0198s/iter; left time: 0.2182s
Epoch: 10 cost time: 4.166958808898926
Epoch: 10, Steps: 210 | Train Loss: 1.0247881 Vali Loss: 1.0482080 Test Loss: 1.0244199
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0241410732269287, mae:0.8066246509552002
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0267184
	speed: 0.0177s/iter; left time: 35.3327s
	iters: 200, epoch: 1 | loss: 1.0293288
	speed: 0.0145s/iter; left time: 27.5585s
Epoch: 1 cost time: 3.1030995845794678
Epoch: 1, Steps: 210 | Train Loss: 1.0355114 Vali Loss: 1.0463157 Test Loss: 1.0224600
Validation loss decreased (inf --> 1.046316).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0203924
	speed: 0.0169s/iter; left time: 30.3394s
	iters: 200, epoch: 2 | loss: 1.0326173
	speed: 0.0145s/iter; left time: 24.5620s
Epoch: 2 cost time: 3.1420438289642334
Epoch: 2, Steps: 210 | Train Loss: 1.0304864 Vali Loss: 1.0483170 Test Loss: 1.0223602
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0350175
	speed: 0.0167s/iter; left time: 26.4362s
	iters: 200, epoch: 3 | loss: 1.0243114
	speed: 0.0155s/iter; left time: 22.8932s
Epoch: 3 cost time: 3.3258860111236572
Epoch: 3, Steps: 210 | Train Loss: 1.0285166 Vali Loss: 1.0489256 Test Loss: 1.0224274
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0272517
	speed: 0.0176s/iter; left time: 24.1877s
	iters: 200, epoch: 4 | loss: 1.0136265
	speed: 0.0131s/iter; left time: 16.6469s
Epoch: 4 cost time: 2.7785558700561523
Epoch: 4, Steps: 210 | Train Loss: 1.0270280 Vali Loss: 1.0470031 Test Loss: 1.0232166
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0281038
	speed: 0.0192s/iter; left time: 22.2446s
	iters: 200, epoch: 5 | loss: 1.0448217
	speed: 0.0155s/iter; left time: 16.4474s
Epoch: 5 cost time: 3.3483567237854004
Epoch: 5, Steps: 210 | Train Loss: 1.0260401 Vali Loss: 1.0473565 Test Loss: 1.0239409
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0137981
	speed: 0.0180s/iter; left time: 17.1218s
	iters: 200, epoch: 6 | loss: 1.0303965
	speed: 0.0161s/iter; left time: 13.7182s
Epoch: 6 cost time: 3.559833526611328
Epoch: 6, Steps: 210 | Train Loss: 1.0254002 Vali Loss: 1.0468593 Test Loss: 1.0244129
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0224602222442627, mae:0.8059691190719604
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0145605
	speed: 0.0377s/iter; left time: 73.9237s
	iters: 200, epoch: 1 | loss: 1.0308918
	speed: 0.0259s/iter; left time: 48.2590s
Epoch: 1 cost time: 5.368385553359985
Epoch: 1, Steps: 206 | Train Loss: 1.0340025 Vali Loss: 1.0567178 Test Loss: 1.0356820
Validation loss decreased (inf --> 1.056718).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0452520
	speed: 0.0209s/iter; left time: 36.7570s
	iters: 200, epoch: 2 | loss: 1.0340967
	speed: 0.0176s/iter; left time: 29.0635s
Epoch: 2 cost time: 3.720816135406494
Epoch: 2, Steps: 206 | Train Loss: 1.0302734 Vali Loss: 1.0557173 Test Loss: 1.0363241
Validation loss decreased (1.056718 --> 1.055717).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0396988
	speed: 0.0161s/iter; left time: 24.9892s
	iters: 200, epoch: 3 | loss: 1.0366976
	speed: 0.0151s/iter; left time: 21.9178s
Epoch: 3 cost time: 3.159061908721924
Epoch: 3, Steps: 206 | Train Loss: 1.0290102 Vali Loss: 1.0556837 Test Loss: 1.0359380
Validation loss decreased (1.055717 --> 1.055684).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0174590
	speed: 0.0143s/iter; left time: 19.1702s
	iters: 200, epoch: 4 | loss: 1.0421056
	speed: 0.0123s/iter; left time: 15.2854s
Epoch: 4 cost time: 2.60201096534729
Epoch: 4, Steps: 206 | Train Loss: 1.0281130 Vali Loss: 1.0557579 Test Loss: 1.0366461
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0253958
	speed: 0.0139s/iter; left time: 15.7516s
	iters: 200, epoch: 5 | loss: 1.0174481
	speed: 0.0117s/iter; left time: 12.1536s
Epoch: 5 cost time: 2.5282838344573975
Epoch: 5, Steps: 206 | Train Loss: 1.0273586 Vali Loss: 1.0558813 Test Loss: 1.0366253
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0328150
	speed: 0.0188s/iter; left time: 17.5405s
	iters: 200, epoch: 6 | loss: 1.0358765
	speed: 0.0158s/iter; left time: 13.1514s
Epoch: 6 cost time: 3.318347454071045
Epoch: 6, Steps: 206 | Train Loss: 1.0267470 Vali Loss: 1.0559542 Test Loss: 1.0377061
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0455352
	speed: 0.0140s/iter; left time: 10.1267s
	iters: 200, epoch: 7 | loss: 1.0359496
	speed: 0.0120s/iter; left time: 7.5294s
Epoch: 7 cost time: 2.5956106185913086
Epoch: 7, Steps: 206 | Train Loss: 1.0267553 Vali Loss: 1.0559309 Test Loss: 1.0375264
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0303948
	speed: 0.0205s/iter; left time: 10.6162s
	iters: 200, epoch: 8 | loss: 1.0092775
	speed: 0.0177s/iter; left time: 7.4005s
Epoch: 8 cost time: 3.7041923999786377
Epoch: 8, Steps: 206 | Train Loss: 1.0264890 Vali Loss: 1.0562212 Test Loss: 1.0375665
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.035938024520874, mae:0.8093876242637634
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0330273
	speed: 0.0238s/iter; left time: 46.6632s
	iters: 200, epoch: 1 | loss: 1.0394307
	speed: 0.0190s/iter; left time: 35.2751s
Epoch: 1 cost time: 3.971660614013672
Epoch: 1, Steps: 206 | Train Loss: 1.0337993 Vali Loss: 1.0566851 Test Loss: 1.0352628
Validation loss decreased (inf --> 1.056685).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0371972
	speed: 0.0252s/iter; left time: 44.1780s
	iters: 200, epoch: 2 | loss: 1.0248053
	speed: 0.0198s/iter; left time: 32.7099s
Epoch: 2 cost time: 4.083724737167358
Epoch: 2, Steps: 206 | Train Loss: 1.0301941 Vali Loss: 1.0560591 Test Loss: 1.0352262
Validation loss decreased (1.056685 --> 1.056059).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0235671
	speed: 0.0153s/iter; left time: 23.7750s
	iters: 200, epoch: 3 | loss: 1.0305343
	speed: 0.0140s/iter; left time: 20.2967s
Epoch: 3 cost time: 2.9802918434143066
Epoch: 3, Steps: 206 | Train Loss: 1.0292827 Vali Loss: 1.0562334 Test Loss: 1.0352945
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0194861
	speed: 0.0143s/iter; left time: 19.1733s
	iters: 200, epoch: 4 | loss: 1.0375196
	speed: 0.0159s/iter; left time: 19.7471s
Epoch: 4 cost time: 3.463801383972168
Epoch: 4, Steps: 206 | Train Loss: 1.0282323 Vali Loss: 1.0559961 Test Loss: 1.0357782
Validation loss decreased (1.056059 --> 1.055996).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0159010
	speed: 0.0184s/iter; left time: 20.9284s
	iters: 200, epoch: 5 | loss: 1.0301112
	speed: 0.0165s/iter; left time: 17.1486s
Epoch: 5 cost time: 3.5202839374542236
Epoch: 5, Steps: 206 | Train Loss: 1.0276623 Vali Loss: 1.0561254 Test Loss: 1.0364366
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0313203
	speed: 0.0187s/iter; left time: 17.3811s
	iters: 200, epoch: 6 | loss: 1.0298846
	speed: 0.0170s/iter; left time: 14.1469s
Epoch: 6 cost time: 3.623701333999634
Epoch: 6, Steps: 206 | Train Loss: 1.0272946 Vali Loss: 1.0561858 Test Loss: 1.0365801
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0311958
	speed: 0.0134s/iter; left time: 9.7132s
	iters: 200, epoch: 7 | loss: 1.0311031
	speed: 0.0123s/iter; left time: 7.6781s
Epoch: 7 cost time: 2.657320022583008
Epoch: 7, Steps: 206 | Train Loss: 1.0270391 Vali Loss: 1.0564295 Test Loss: 1.0366688
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0227491
	speed: 0.0226s/iter; left time: 11.7299s
	iters: 200, epoch: 8 | loss: 1.0297885
	speed: 0.0191s/iter; left time: 7.9993s
Epoch: 8 cost time: 3.9637675285339355
Epoch: 8, Steps: 206 | Train Loss: 1.0268470 Vali Loss: 1.0564775 Test Loss: 1.0367399
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0319880
	speed: 0.0141s/iter; left time: 4.4168s
	iters: 200, epoch: 9 | loss: 1.0149511
	speed: 0.0141s/iter; left time: 3.0056s
Epoch: 9 cost time: 2.990489959716797
Epoch: 9, Steps: 206 | Train Loss: 1.0269256 Vali Loss: 1.0564842 Test Loss: 1.0367943
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0357781648635864, mae:0.8093239068984985
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0524523
	speed: 0.0200s/iter; left time: 39.1893s
	iters: 200, epoch: 1 | loss: 1.0263258
	speed: 0.0162s/iter; left time: 30.1468s
Epoch: 1 cost time: 3.387742519378662
Epoch: 1, Steps: 206 | Train Loss: 1.0331955 Vali Loss: 1.0553193 Test Loss: 1.0354494
Validation loss decreased (inf --> 1.055319).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0410322
	speed: 0.0181s/iter; left time: 31.7985s
	iters: 200, epoch: 2 | loss: 1.0306115
	speed: 0.0159s/iter; left time: 26.2502s
Epoch: 2 cost time: 3.3774948120117188
Epoch: 2, Steps: 206 | Train Loss: 1.0303154 Vali Loss: 1.0552189 Test Loss: 1.0354804
Validation loss decreased (1.055319 --> 1.055219).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0458422
	speed: 0.0218s/iter; left time: 33.8256s
	iters: 200, epoch: 3 | loss: 1.0323550
	speed: 0.0186s/iter; left time: 26.9137s
Epoch: 3 cost time: 3.943554401397705
Epoch: 3, Steps: 206 | Train Loss: 1.0289464 Vali Loss: 1.0556355 Test Loss: 1.0359403
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0243250
	speed: 0.0160s/iter; left time: 21.4298s
	iters: 200, epoch: 4 | loss: 1.0294577
	speed: 0.0162s/iter; left time: 20.1870s
Epoch: 4 cost time: 3.4605133533477783
Epoch: 4, Steps: 206 | Train Loss: 1.0283073 Vali Loss: 1.0555913 Test Loss: 1.0363076
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0226833
	speed: 0.0133s/iter; left time: 15.1703s
	iters: 200, epoch: 5 | loss: 1.0214988
	speed: 0.0136s/iter; left time: 14.0564s
Epoch: 5 cost time: 2.9069666862487793
Epoch: 5, Steps: 206 | Train Loss: 1.0274872 Vali Loss: 1.0554054 Test Loss: 1.0368664
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0232984
	speed: 0.0129s/iter; left time: 12.0247s
	iters: 200, epoch: 6 | loss: 1.0300720
	speed: 0.0127s/iter; left time: 10.5276s
Epoch: 6 cost time: 2.7107625007629395
Epoch: 6, Steps: 206 | Train Loss: 1.0270770 Vali Loss: 1.0557131 Test Loss: 1.0372201
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0282279
	speed: 0.0170s/iter; left time: 12.3249s
	iters: 200, epoch: 7 | loss: 1.0142895
	speed: 0.0180s/iter; left time: 11.2458s
Epoch: 7 cost time: 3.908529043197632
Epoch: 7, Steps: 206 | Train Loss: 1.0268754 Vali Loss: 1.0556597 Test Loss: 1.0373722
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.035480260848999, mae:0.8091903924942017
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0280417
	speed: 0.0312s/iter; left time: 57.4517s
Epoch: 1 cost time: 4.587206840515137
Epoch: 1, Steps: 194 | Train Loss: 1.0361759 Vali Loss: 1.0561366 Test Loss: 1.0282446
Validation loss decreased (inf --> 1.056137).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0411623
	speed: 0.0183s/iter; left time: 30.0904s
Epoch: 2 cost time: 3.1124396324157715
Epoch: 2, Steps: 194 | Train Loss: 1.0328574 Vali Loss: 1.0554065 Test Loss: 1.0281895
Validation loss decreased (1.056137 --> 1.055406).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0458268
	speed: 0.0157s/iter; left time: 22.7788s
Epoch: 3 cost time: 2.941704511642456
Epoch: 3, Steps: 194 | Train Loss: 1.0317842 Vali Loss: 1.0543122 Test Loss: 1.0281680
Validation loss decreased (1.055406 --> 1.054312).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0339869
	speed: 0.0119s/iter; left time: 15.0272s
Epoch: 4 cost time: 2.377340793609619
Epoch: 4, Steps: 194 | Train Loss: 1.0311549 Vali Loss: 1.0531982 Test Loss: 1.0295249
Validation loss decreased (1.054312 --> 1.053198).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0421078
	speed: 0.0204s/iter; left time: 21.7696s
Epoch: 5 cost time: 3.599588394165039
Epoch: 5, Steps: 194 | Train Loss: 1.0306755 Vali Loss: 1.0527028 Test Loss: 1.0299083
Validation loss decreased (1.053198 --> 1.052703).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0177877
	speed: 0.0168s/iter; left time: 14.6311s
Epoch: 6 cost time: 3.2276556491851807
Epoch: 6, Steps: 194 | Train Loss: 1.0304570 Vali Loss: 1.0529493 Test Loss: 1.0303737
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0297452
	speed: 0.0162s/iter; left time: 10.9960s
Epoch: 7 cost time: 3.353010654449463
Epoch: 7, Steps: 194 | Train Loss: 1.0302633 Vali Loss: 1.0528160 Test Loss: 1.0303361
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0270491
	speed: 0.0184s/iter; left time: 8.8680s
Epoch: 8 cost time: 3.0162017345428467
Epoch: 8, Steps: 194 | Train Loss: 1.0301071 Vali Loss: 1.0528483 Test Loss: 1.0302461
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0239779
	speed: 0.0161s/iter; left time: 4.6640s
Epoch: 9 cost time: 2.5214736461639404
Epoch: 9, Steps: 194 | Train Loss: 1.0301374 Vali Loss: 1.0524985 Test Loss: 1.0302409
Validation loss decreased (1.052703 --> 1.052498).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0192106
	speed: 0.0264s/iter; left time: 2.5074s
Epoch: 10 cost time: 3.9874427318573
Epoch: 10, Steps: 194 | Train Loss: 1.0301052 Vali Loss: 1.0525575 Test Loss: 1.0302368
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0302408933639526, mae:0.8058199882507324
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0424378
	speed: 0.0157s/iter; left time: 28.8119s
Epoch: 1 cost time: 3.2354674339294434
Epoch: 1, Steps: 194 | Train Loss: 1.0374425 Vali Loss: 1.0566553 Test Loss: 1.0284026
Validation loss decreased (inf --> 1.056655).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0231791
	speed: 0.0167s/iter; left time: 27.5763s
Epoch: 2 cost time: 3.0428457260131836
Epoch: 2, Steps: 194 | Train Loss: 1.0329008 Vali Loss: 1.0557117 Test Loss: 1.0284548
Validation loss decreased (1.056655 --> 1.055712).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0296719
	speed: 0.0184s/iter; left time: 26.8066s
Epoch: 3 cost time: 2.7568764686584473
Epoch: 3, Steps: 194 | Train Loss: 1.0321094 Vali Loss: 1.0548480 Test Loss: 1.0277419
Validation loss decreased (1.055712 --> 1.054848).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0324483
	speed: 0.0192s/iter; left time: 24.1559s
Epoch: 4 cost time: 2.9929001331329346
Epoch: 4, Steps: 194 | Train Loss: 1.0315165 Vali Loss: 1.0545821 Test Loss: 1.0276308
Validation loss decreased (1.054848 --> 1.054582).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0405034
	speed: 0.0196s/iter; left time: 20.8506s
Epoch: 5 cost time: 3.433298110961914
Epoch: 5, Steps: 194 | Train Loss: 1.0311798 Vali Loss: 1.0541530 Test Loss: 1.0275533
Validation loss decreased (1.054582 --> 1.054153).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0412564
	speed: 0.0177s/iter; left time: 15.4520s
Epoch: 6 cost time: 3.467060089111328
Epoch: 6, Steps: 194 | Train Loss: 1.0308316 Vali Loss: 1.0537105 Test Loss: 1.0276530
Validation loss decreased (1.054153 --> 1.053710).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0332540
	speed: 0.0247s/iter; left time: 16.7021s
Epoch: 7 cost time: 3.989901304244995
Epoch: 7, Steps: 194 | Train Loss: 1.0306390 Vali Loss: 1.0538387 Test Loss: 1.0276369
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0339000
	speed: 0.0143s/iter; left time: 6.9134s
Epoch: 8 cost time: 2.5237607955932617
Epoch: 8, Steps: 194 | Train Loss: 1.0305384 Vali Loss: 1.0539510 Test Loss: 1.0276828
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0240328
	speed: 0.0155s/iter; left time: 4.4692s
Epoch: 9 cost time: 2.925518751144409
Epoch: 9, Steps: 194 | Train Loss: 1.0305481 Vali Loss: 1.0536321 Test Loss: 1.0276991
Validation loss decreased (1.053710 --> 1.053632).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0280391
	speed: 0.0213s/iter; left time: 2.0240s
Epoch: 10 cost time: 3.486315965652466
Epoch: 10, Steps: 194 | Train Loss: 1.0306399 Vali Loss: 1.0535388 Test Loss: 1.0277088
Validation loss decreased (1.053632 --> 1.053539).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0277087688446045, mae:0.8046751618385315
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0271308
	speed: 0.0202s/iter; left time: 37.1746s
Epoch: 1 cost time: 3.817734718322754
Epoch: 1, Steps: 194 | Train Loss: 1.0364089 Vali Loss: 1.0558249 Test Loss: 1.0286746
Validation loss decreased (inf --> 1.055825).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0466422
	speed: 0.0177s/iter; left time: 29.0966s
Epoch: 2 cost time: 3.149670362472534
Epoch: 2, Steps: 194 | Train Loss: 1.0330781 Vali Loss: 1.0559574 Test Loss: 1.0282278
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0343728
	speed: 0.0130s/iter; left time: 18.9560s
Epoch: 3 cost time: 2.365208387374878
Epoch: 3, Steps: 194 | Train Loss: 1.0321552 Vali Loss: 1.0549968 Test Loss: 1.0279433
Validation loss decreased (1.055825 --> 1.054997).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0221713
	speed: 0.0222s/iter; left time: 27.9968s
Epoch: 4 cost time: 3.7530860900878906
Epoch: 4, Steps: 194 | Train Loss: 1.0315067 Vali Loss: 1.0531793 Test Loss: 1.0287493
Validation loss decreased (1.054997 --> 1.053179).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0222601
	speed: 0.0177s/iter; left time: 18.8766s
Epoch: 5 cost time: 3.2945525646209717
Epoch: 5, Steps: 194 | Train Loss: 1.0310744 Vali Loss: 1.0531317 Test Loss: 1.0302074
Validation loss decreased (1.053179 --> 1.053132).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0310669
	speed: 0.0177s/iter; left time: 15.4253s
Epoch: 6 cost time: 3.272813558578491
Epoch: 6, Steps: 194 | Train Loss: 1.0307768 Vali Loss: 1.0531478 Test Loss: 1.0300604
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0323647
	speed: 0.0145s/iter; left time: 9.8417s
Epoch: 7 cost time: 2.7758283615112305
Epoch: 7, Steps: 194 | Train Loss: 1.0307154 Vali Loss: 1.0530641 Test Loss: 1.0304979
Validation loss decreased (1.053132 --> 1.053064).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0140938
	speed: 0.0142s/iter; left time: 6.8462s
Epoch: 8 cost time: 2.4890284538269043
Epoch: 8, Steps: 194 | Train Loss: 1.0304870 Vali Loss: 1.0525670 Test Loss: 1.0305139
Validation loss decreased (1.053064 --> 1.052567).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0136319
	speed: 0.0217s/iter; left time: 6.2744s
Epoch: 9 cost time: 3.589670181274414
Epoch: 9, Steps: 194 | Train Loss: 1.0304242 Vali Loss: 1.0528269 Test Loss: 1.0305483
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0176290
	speed: 0.0227s/iter; left time: 2.1601s
Epoch: 10 cost time: 3.7916979789733887
Epoch: 10, Steps: 194 | Train Loss: 1.0305268 Vali Loss: 1.0526804 Test Loss: 1.0305318
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.030513882637024, mae:0.805898129940033
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0297210
	speed: 0.0239s/iter; left time: 48.4604s
	iters: 200, epoch: 1 | loss: 1.0345448
	speed: 0.0192s/iter; left time: 37.0545s
Epoch: 1 cost time: 4.155016183853149
Epoch: 1, Steps: 213 | Train Loss: 1.0302171 Vali Loss: 1.0408967 Test Loss: 1.0231919
Validation loss decreased (inf --> 1.040897).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9904443
	speed: 0.0137s/iter; left time: 24.8227s
	iters: 200, epoch: 2 | loss: 1.0270046
	speed: 0.0116s/iter; left time: 19.9898s
Epoch: 2 cost time: 2.5176126956939697
Epoch: 2, Steps: 213 | Train Loss: 1.0254275 Vali Loss: 1.0402367 Test Loss: 1.0229621
Validation loss decreased (1.040897 --> 1.040237).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0308646
	speed: 0.0158s/iter; left time: 25.4065s
	iters: 200, epoch: 3 | loss: 0.9958884
	speed: 0.0138s/iter; left time: 20.8161s
Epoch: 3 cost time: 3.002979278564453
Epoch: 3, Steps: 213 | Train Loss: 1.0227164 Vali Loss: 1.0403416 Test Loss: 1.0244746
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9901646
	speed: 0.0242s/iter; left time: 33.6393s
	iters: 200, epoch: 4 | loss: 1.0305026
	speed: 0.0218s/iter; left time: 28.1372s
Epoch: 4 cost time: 4.609814405441284
Epoch: 4, Steps: 213 | Train Loss: 1.0205902 Vali Loss: 1.0414013 Test Loss: 1.0258770
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0094106
	speed: 0.0200s/iter; left time: 23.5905s
	iters: 200, epoch: 5 | loss: 1.0191622
	speed: 0.0176s/iter; left time: 18.9382s
Epoch: 5 cost time: 3.9323108196258545
Epoch: 5, Steps: 213 | Train Loss: 1.0191602 Vali Loss: 1.0412760 Test Loss: 1.0275421
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9847168
	speed: 0.0194s/iter; left time: 18.7605s
	iters: 200, epoch: 6 | loss: 1.0450777
	speed: 0.0170s/iter; left time: 14.7013s
Epoch: 6 cost time: 3.6502695083618164
Epoch: 6, Steps: 213 | Train Loss: 1.0181333 Vali Loss: 1.0417793 Test Loss: 1.0281742
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9902875
	speed: 0.0171s/iter; left time: 12.8460s
	iters: 200, epoch: 7 | loss: 1.0115288
	speed: 0.0143s/iter; left time: 9.3170s
Epoch: 7 cost time: 3.087287664413452
Epoch: 7, Steps: 213 | Train Loss: 1.0175770 Vali Loss: 1.0413204 Test Loss: 1.0285321
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.022962212562561, mae:0.8068342208862305
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0507901
	speed: 0.0214s/iter; left time: 43.4406s
	iters: 200, epoch: 1 | loss: 1.0225300
	speed: 0.0176s/iter; left time: 34.0430s
Epoch: 1 cost time: 3.7942471504211426
Epoch: 1, Steps: 213 | Train Loss: 1.0302759 Vali Loss: 1.0429239 Test Loss: 1.0231249
Validation loss decreased (inf --> 1.042924).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0030234
	speed: 0.0215s/iter; left time: 39.0465s
	iters: 200, epoch: 2 | loss: 1.0515370
	speed: 0.0177s/iter; left time: 30.4836s
Epoch: 2 cost time: 3.8628978729248047
Epoch: 2, Steps: 213 | Train Loss: 1.0250916 Vali Loss: 1.0422754 Test Loss: 1.0237104
Validation loss decreased (1.042924 --> 1.042275).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0729885
	speed: 0.0226s/iter; left time: 36.3365s
	iters: 200, epoch: 3 | loss: 1.0432934
	speed: 0.0178s/iter; left time: 26.7575s
Epoch: 3 cost time: 3.789412498474121
Epoch: 3, Steps: 213 | Train Loss: 1.0225702 Vali Loss: 1.0417060 Test Loss: 1.0241193
Validation loss decreased (1.042275 --> 1.041706).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0676694
	speed: 0.0188s/iter; left time: 26.1608s
	iters: 200, epoch: 4 | loss: 1.0252655
	speed: 0.0168s/iter; left time: 21.6966s
Epoch: 4 cost time: 3.662605047225952
Epoch: 4, Steps: 213 | Train Loss: 1.0201150 Vali Loss: 1.0400940 Test Loss: 1.0257137
Validation loss decreased (1.041706 --> 1.040094).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0191593
	speed: 0.0183s/iter; left time: 21.5980s
	iters: 200, epoch: 5 | loss: 0.9981613
	speed: 0.0178s/iter; left time: 19.2586s
Epoch: 5 cost time: 3.8702147006988525
Epoch: 5, Steps: 213 | Train Loss: 1.0185765 Vali Loss: 1.0416541 Test Loss: 1.0273659
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0111814
	speed: 0.0236s/iter; left time: 22.8271s
	iters: 200, epoch: 6 | loss: 1.0145388
	speed: 0.0212s/iter; left time: 18.3425s
Epoch: 6 cost time: 4.476293325424194
Epoch: 6, Steps: 213 | Train Loss: 1.0176205 Vali Loss: 1.0420910 Test Loss: 1.0278605
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0329044
	speed: 0.0148s/iter; left time: 11.1148s
	iters: 200, epoch: 7 | loss: 1.0140905
	speed: 0.0122s/iter; left time: 7.9520s
Epoch: 7 cost time: 2.59706711769104
Epoch: 7, Steps: 213 | Train Loss: 1.0170241 Vali Loss: 1.0417295 Test Loss: 1.0280633
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0178545
	speed: 0.0245s/iter; left time: 13.2072s
	iters: 200, epoch: 8 | loss: 1.0200577
	speed: 0.0184s/iter; left time: 8.0904s
Epoch: 8 cost time: 4.021353721618652
Epoch: 8, Steps: 213 | Train Loss: 1.0169192 Vali Loss: 1.0429409 Test Loss: 1.0281340
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0415239
	speed: 0.0196s/iter; left time: 6.3971s
	iters: 200, epoch: 9 | loss: 1.0260952
	speed: 0.0195s/iter; left time: 4.4269s
Epoch: 9 cost time: 4.2217888832092285
Epoch: 9, Steps: 213 | Train Loss: 1.0165396 Vali Loss: 1.0412898 Test Loss: 1.0281867
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0257136821746826, mae:0.807900071144104
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0103903
	speed: 0.0260s/iter; left time: 52.8750s
	iters: 200, epoch: 1 | loss: 1.0332345
	speed: 0.0181s/iter; left time: 34.8910s
Epoch: 1 cost time: 3.828572988510132
Epoch: 1, Steps: 213 | Train Loss: 1.0298565 Vali Loss: 1.0418438 Test Loss: 1.0226641
Validation loss decreased (inf --> 1.041844).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0820973
	speed: 0.0160s/iter; left time: 29.1152s
	iters: 200, epoch: 2 | loss: 1.0320389
	speed: 0.0151s/iter; left time: 25.8833s
Epoch: 2 cost time: 3.4104301929473877
Epoch: 2, Steps: 213 | Train Loss: 1.0252335 Vali Loss: 1.0405792 Test Loss: 1.0237561
Validation loss decreased (1.041844 --> 1.040579).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0284899
	speed: 0.0168s/iter; left time: 27.0143s
	iters: 200, epoch: 3 | loss: 1.0147823
	speed: 0.0160s/iter; left time: 24.0125s
Epoch: 3 cost time: 3.4586880207061768
Epoch: 3, Steps: 213 | Train Loss: 1.0223914 Vali Loss: 1.0423877 Test Loss: 1.0254518
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0336164
	speed: 0.0152s/iter; left time: 21.1422s
	iters: 200, epoch: 4 | loss: 1.0053096
	speed: 0.0171s/iter; left time: 22.0569s
Epoch: 4 cost time: 3.8177225589752197
Epoch: 4, Steps: 213 | Train Loss: 1.0201171 Vali Loss: 1.0407535 Test Loss: 1.0256817
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0420086
	speed: 0.0177s/iter; left time: 20.8435s
	iters: 200, epoch: 5 | loss: 1.0042214
	speed: 0.0150s/iter; left time: 16.2339s
Epoch: 5 cost time: 3.2871923446655273
Epoch: 5, Steps: 213 | Train Loss: 1.0187304 Vali Loss: 1.0439398 Test Loss: 1.0271519
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0195622
	speed: 0.0121s/iter; left time: 11.7140s
	iters: 200, epoch: 6 | loss: 1.0131254
	speed: 0.0111s/iter; left time: 9.6004s
Epoch: 6 cost time: 2.483462333679199
Epoch: 6, Steps: 213 | Train Loss: 1.0177508 Vali Loss: 1.0418952 Test Loss: 1.0277236
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0244300
	speed: 0.0164s/iter; left time: 12.3760s
	iters: 200, epoch: 7 | loss: 1.0443439
	speed: 0.0163s/iter; left time: 10.6179s
Epoch: 7 cost time: 3.5590779781341553
Epoch: 7, Steps: 213 | Train Loss: 1.0173874 Vali Loss: 1.0426090 Test Loss: 1.0281417
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0237561464309692, mae:0.8073275089263916
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0173199
	speed: 0.0300s/iter; left time: 60.0661s
	iters: 200, epoch: 1 | loss: 1.0424213
	speed: 0.0224s/iter; left time: 42.6727s
Epoch: 1 cost time: 4.748763084411621
Epoch: 1, Steps: 210 | Train Loss: 1.0345264 Vali Loss: 1.0458472 Test Loss: 1.0217521
Validation loss decreased (inf --> 1.045847).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0213125
	speed: 0.0200s/iter; left time: 35.8167s
	iters: 200, epoch: 2 | loss: 1.0230825
	speed: 0.0177s/iter; left time: 29.9607s
Epoch: 2 cost time: 3.8332221508026123
Epoch: 2, Steps: 210 | Train Loss: 1.0303609 Vali Loss: 1.0482348 Test Loss: 1.0212705
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0190494
	speed: 0.0184s/iter; left time: 29.1575s
	iters: 200, epoch: 3 | loss: 1.0290699
	speed: 0.0156s/iter; left time: 23.0410s
Epoch: 3 cost time: 3.3784165382385254
Epoch: 3, Steps: 210 | Train Loss: 1.0284509 Vali Loss: 1.0476661 Test Loss: 1.0216106
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0319421
	speed: 0.0194s/iter; left time: 26.6375s
	iters: 200, epoch: 4 | loss: 1.0364504
	speed: 0.0166s/iter; left time: 21.1464s
Epoch: 4 cost time: 3.5152945518493652
Epoch: 4, Steps: 210 | Train Loss: 1.0270683 Vali Loss: 1.0483087 Test Loss: 1.0225902
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0192494
	speed: 0.0207s/iter; left time: 24.0473s
	iters: 200, epoch: 5 | loss: 1.0328918
	speed: 0.0158s/iter; left time: 16.7126s
Epoch: 5 cost time: 3.390195846557617
Epoch: 5, Steps: 210 | Train Loss: 1.0260708 Vali Loss: 1.0478060 Test Loss: 1.0232493
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0346804
	speed: 0.0141s/iter; left time: 13.4312s
	iters: 200, epoch: 6 | loss: 1.0292487
	speed: 0.0136s/iter; left time: 11.5377s
Epoch: 6 cost time: 2.900455951690674
Epoch: 6, Steps: 210 | Train Loss: 1.0252439 Vali Loss: 1.0470130 Test Loss: 1.0235238
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.021752119064331, mae:0.805691659450531
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0429814
	speed: 0.0237s/iter; left time: 47.3993s
	iters: 200, epoch: 1 | loss: 1.0388335
	speed: 0.0176s/iter; left time: 33.3955s
Epoch: 1 cost time: 3.742645025253296
Epoch: 1, Steps: 210 | Train Loss: 1.0343542 Vali Loss: 1.0456113 Test Loss: 1.0215257
Validation loss decreased (inf --> 1.045611).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0171016
	speed: 0.0288s/iter; left time: 51.5085s
	iters: 200, epoch: 2 | loss: 1.0339502
	speed: 0.0211s/iter; left time: 35.7295s
Epoch: 2 cost time: 4.6424620151519775
Epoch: 2, Steps: 210 | Train Loss: 1.0304192 Vali Loss: 1.0475376 Test Loss: 1.0214956
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0096655
	speed: 0.0151s/iter; left time: 23.9276s
	iters: 200, epoch: 3 | loss: 1.0159644
	speed: 0.0128s/iter; left time: 18.9062s
Epoch: 3 cost time: 2.806971549987793
Epoch: 3, Steps: 210 | Train Loss: 1.0285878 Vali Loss: 1.0471692 Test Loss: 1.0217967
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0310502
	speed: 0.0165s/iter; left time: 22.6203s
	iters: 200, epoch: 4 | loss: 1.0348809
	speed: 0.0153s/iter; left time: 19.4400s
Epoch: 4 cost time: 3.344348430633545
Epoch: 4, Steps: 210 | Train Loss: 1.0271472 Vali Loss: 1.0477711 Test Loss: 1.0226271
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0401015
	speed: 0.0194s/iter; left time: 22.5179s
	iters: 200, epoch: 5 | loss: 1.0078290
	speed: 0.0164s/iter; left time: 17.4049s
Epoch: 5 cost time: 3.554779052734375
Epoch: 5, Steps: 210 | Train Loss: 1.0260499 Vali Loss: 1.0476145 Test Loss: 1.0234191
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0125823
	speed: 0.0175s/iter; left time: 16.6027s
	iters: 200, epoch: 6 | loss: 0.9924248
	speed: 0.0172s/iter; left time: 14.6106s
Epoch: 6 cost time: 3.6638991832733154
Epoch: 6, Steps: 210 | Train Loss: 1.0253739 Vali Loss: 1.0476929 Test Loss: 1.0238918
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0215258598327637, mae:0.8055802583694458
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0179696
	speed: 0.0132s/iter; left time: 26.4997s
	iters: 200, epoch: 1 | loss: 1.0264258
	speed: 0.0125s/iter; left time: 23.7693s
Epoch: 1 cost time: 2.750931978225708
Epoch: 1, Steps: 210 | Train Loss: 1.0351118 Vali Loss: 1.0473520 Test Loss: 1.0216430
Validation loss decreased (inf --> 1.047352).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0193132
	speed: 0.0188s/iter; left time: 33.6216s
	iters: 200, epoch: 2 | loss: 1.0464677
	speed: 0.0175s/iter; left time: 29.5970s
Epoch: 2 cost time: 3.807454824447632
Epoch: 2, Steps: 210 | Train Loss: 1.0305699 Vali Loss: 1.0466605 Test Loss: 1.0216607
Validation loss decreased (1.047352 --> 1.046661).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0212457
	speed: 0.0174s/iter; left time: 27.5777s
	iters: 200, epoch: 3 | loss: 1.0399966
	speed: 0.0166s/iter; left time: 24.5815s
Epoch: 3 cost time: 3.592059373855591
Epoch: 3, Steps: 210 | Train Loss: 1.0287743 Vali Loss: 1.0462445 Test Loss: 1.0215611
Validation loss decreased (1.046661 --> 1.046245).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0182319
	speed: 0.0151s/iter; left time: 20.6497s
	iters: 200, epoch: 4 | loss: 1.0062771
	speed: 0.0177s/iter; left time: 22.4543s
Epoch: 4 cost time: 3.907177448272705
Epoch: 4, Steps: 210 | Train Loss: 1.0272894 Vali Loss: 1.0484252 Test Loss: 1.0226990
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0246923
	speed: 0.0146s/iter; left time: 16.8985s
	iters: 200, epoch: 5 | loss: 1.0300999
	speed: 0.0135s/iter; left time: 14.3034s
Epoch: 5 cost time: 2.9460692405700684
Epoch: 5, Steps: 210 | Train Loss: 1.0261261 Vali Loss: 1.0482503 Test Loss: 1.0228813
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0194521
	speed: 0.0175s/iter; left time: 16.6550s
	iters: 200, epoch: 6 | loss: 1.0492053
	speed: 0.0162s/iter; left time: 13.7641s
Epoch: 6 cost time: 3.4801933765411377
Epoch: 6, Steps: 210 | Train Loss: 1.0255155 Vali Loss: 1.0478518 Test Loss: 1.0237703
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0101216
	speed: 0.0160s/iter; left time: 11.8477s
	iters: 200, epoch: 7 | loss: 1.0103984
	speed: 0.0149s/iter; left time: 9.5304s
Epoch: 7 cost time: 3.242032051086426
Epoch: 7, Steps: 210 | Train Loss: 1.0252668 Vali Loss: 1.0473920 Test Loss: 1.0239540
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0115036
	speed: 0.0169s/iter; left time: 8.9704s
	iters: 200, epoch: 8 | loss: 1.0364418
	speed: 0.0142s/iter; left time: 6.1281s
Epoch: 8 cost time: 3.067384719848633
Epoch: 8, Steps: 210 | Train Loss: 1.0249793 Vali Loss: 1.0479901 Test Loss: 1.0240622
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0215611457824707, mae:0.8055240511894226
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0508163
	speed: 0.0280s/iter; left time: 54.8591s
	iters: 200, epoch: 1 | loss: 1.0290431
	speed: 0.0201s/iter; left time: 37.3464s
Epoch: 1 cost time: 4.2156805992126465
Epoch: 1, Steps: 206 | Train Loss: 1.0341074 Vali Loss: 1.0565516 Test Loss: 1.0357627
Validation loss decreased (inf --> 1.056552).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0293905
	speed: 0.0204s/iter; left time: 35.8329s
	iters: 200, epoch: 2 | loss: 1.0256444
	speed: 0.0163s/iter; left time: 26.9090s
Epoch: 2 cost time: 3.415302276611328
Epoch: 2, Steps: 206 | Train Loss: 1.0303152 Vali Loss: 1.0566103 Test Loss: 1.0353569
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0173057
	speed: 0.0203s/iter; left time: 31.4056s
	iters: 200, epoch: 3 | loss: 1.0313290
	speed: 0.0152s/iter; left time: 21.9553s
Epoch: 3 cost time: 3.210181474685669
Epoch: 3, Steps: 206 | Train Loss: 1.0293273 Vali Loss: 1.0561478 Test Loss: 1.0355709
Validation loss decreased (1.056552 --> 1.056148).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0301998
	speed: 0.0162s/iter; left time: 21.7781s
	iters: 200, epoch: 4 | loss: 1.0272762
	speed: 0.0157s/iter; left time: 19.4627s
Epoch: 4 cost time: 3.2686586380004883
Epoch: 4, Steps: 206 | Train Loss: 1.0284370 Vali Loss: 1.0556890 Test Loss: 1.0361409
Validation loss decreased (1.056148 --> 1.055689).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0130881
	speed: 0.0175s/iter; left time: 19.8837s
	iters: 200, epoch: 5 | loss: 1.0238680
	speed: 0.0161s/iter; left time: 16.6952s
Epoch: 5 cost time: 3.4132063388824463
Epoch: 5, Steps: 206 | Train Loss: 1.0276385 Vali Loss: 1.0562042 Test Loss: 1.0365913
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0314978
	speed: 0.0154s/iter; left time: 14.3053s
	iters: 200, epoch: 6 | loss: 1.0355130
	speed: 0.0151s/iter; left time: 12.5729s
Epoch: 6 cost time: 3.247102975845337
Epoch: 6, Steps: 206 | Train Loss: 1.0272989 Vali Loss: 1.0559258 Test Loss: 1.0369986
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0307258
	speed: 0.0145s/iter; left time: 10.4908s
	iters: 200, epoch: 7 | loss: 1.0094310
	speed: 0.0137s/iter; left time: 8.5451s
Epoch: 7 cost time: 2.8966891765594482
Epoch: 7, Steps: 206 | Train Loss: 1.0269956 Vali Loss: 1.0562060 Test Loss: 1.0369421
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0436698
	speed: 0.0155s/iter; left time: 8.0559s
	iters: 200, epoch: 8 | loss: 1.0085262
	speed: 0.0126s/iter; left time: 5.2748s
Epoch: 8 cost time: 2.6701433658599854
Epoch: 8, Steps: 206 | Train Loss: 1.0268783 Vali Loss: 1.0562372 Test Loss: 1.0370671
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0202906
	speed: 0.0140s/iter; left time: 4.3670s
	iters: 200, epoch: 9 | loss: 1.0153421
	speed: 0.0133s/iter; left time: 2.8424s
Epoch: 9 cost time: 2.9380974769592285
Epoch: 9, Steps: 206 | Train Loss: 1.0267551 Vali Loss: 1.0561969 Test Loss: 1.0371065
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0361409187316895, mae:0.8094546794891357
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0356057
	speed: 0.0264s/iter; left time: 51.7831s
	iters: 200, epoch: 1 | loss: 1.0202099
	speed: 0.0242s/iter; left time: 45.1011s
Epoch: 1 cost time: 5.074635028839111
Epoch: 1, Steps: 206 | Train Loss: 1.0353515 Vali Loss: 1.0568761 Test Loss: 1.0357955
Validation loss decreased (inf --> 1.056876).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0368087
	speed: 0.0178s/iter; left time: 31.3114s
	iters: 200, epoch: 2 | loss: 1.0310249
	speed: 0.0156s/iter; left time: 25.8318s
Epoch: 2 cost time: 3.2484848499298096
Epoch: 2, Steps: 206 | Train Loss: 1.0308045 Vali Loss: 1.0566883 Test Loss: 1.0358652
Validation loss decreased (1.056876 --> 1.056688).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0387014
	speed: 0.0140s/iter; left time: 21.7014s
	iters: 200, epoch: 3 | loss: 1.0328045
	speed: 0.0122s/iter; left time: 17.7170s
Epoch: 3 cost time: 2.5960230827331543
Epoch: 3, Steps: 206 | Train Loss: 1.0294348 Vali Loss: 1.0553211 Test Loss: 1.0364122
Validation loss decreased (1.056688 --> 1.055321).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0151443
	speed: 0.0176s/iter; left time: 23.6558s
	iters: 200, epoch: 4 | loss: 1.0338854
	speed: 0.0153s/iter; left time: 19.0094s
Epoch: 4 cost time: 3.205888509750366
Epoch: 4, Steps: 206 | Train Loss: 1.0284434 Vali Loss: 1.0560021 Test Loss: 1.0361291
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0200962
	speed: 0.0210s/iter; left time: 23.9136s
	iters: 200, epoch: 5 | loss: 1.0092341
	speed: 0.0164s/iter; left time: 16.9607s
Epoch: 5 cost time: 3.453981876373291
Epoch: 5, Steps: 206 | Train Loss: 1.0276004 Vali Loss: 1.0555124 Test Loss: 1.0369018
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0270633
	speed: 0.0157s/iter; left time: 14.6302s
	iters: 200, epoch: 6 | loss: 1.0150106
	speed: 0.0146s/iter; left time: 12.1633s
Epoch: 6 cost time: 3.0814836025238037
Epoch: 6, Steps: 206 | Train Loss: 1.0270986 Vali Loss: 1.0555849 Test Loss: 1.0372175
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0384904
	speed: 0.0180s/iter; left time: 13.0394s
	iters: 200, epoch: 7 | loss: 1.0344884
	speed: 0.0142s/iter; left time: 8.8972s
Epoch: 7 cost time: 3.0345687866210938
Epoch: 7, Steps: 206 | Train Loss: 1.0268407 Vali Loss: 1.0556533 Test Loss: 1.0374810
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0241116
	speed: 0.0152s/iter; left time: 7.8758s
	iters: 200, epoch: 8 | loss: 1.0075849
	speed: 0.0135s/iter; left time: 5.6588s
Epoch: 8 cost time: 2.891308546066284
Epoch: 8, Steps: 206 | Train Loss: 1.0267233 Vali Loss: 1.0556161 Test Loss: 1.0375541
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0364121198654175, mae:0.8095230460166931
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0383730
	speed: 0.0141s/iter; left time: 27.6061s
	iters: 200, epoch: 1 | loss: 1.0161698
	speed: 0.0132s/iter; left time: 24.5080s
Epoch: 1 cost time: 2.8135337829589844
Epoch: 1, Steps: 206 | Train Loss: 1.0340939 Vali Loss: 1.0567205 Test Loss: 1.0353920
Validation loss decreased (inf --> 1.056720).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0380064
	speed: 0.0134s/iter; left time: 23.5543s
	iters: 200, epoch: 2 | loss: 1.0576944
	speed: 0.0132s/iter; left time: 21.9232s
Epoch: 2 cost time: 2.8254363536834717
Epoch: 2, Steps: 206 | Train Loss: 1.0304152 Vali Loss: 1.0555853 Test Loss: 1.0361758
Validation loss decreased (1.056720 --> 1.055585).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0428908
	speed: 0.0260s/iter; left time: 40.2569s
	iters: 200, epoch: 3 | loss: 1.0054301
	speed: 0.0204s/iter; left time: 29.5673s
Epoch: 3 cost time: 4.290340423583984
Epoch: 3, Steps: 206 | Train Loss: 1.0292466 Vali Loss: 1.0563668 Test Loss: 1.0354053
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0187435
	speed: 0.0182s/iter; left time: 24.4308s
	iters: 200, epoch: 4 | loss: 1.0407060
	speed: 0.0149s/iter; left time: 18.5140s
Epoch: 4 cost time: 3.1641275882720947
Epoch: 4, Steps: 206 | Train Loss: 1.0284613 Vali Loss: 1.0557369 Test Loss: 1.0356858
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0233893
	speed: 0.0184s/iter; left time: 20.9768s
	iters: 200, epoch: 5 | loss: 1.0259205
	speed: 0.0161s/iter; left time: 16.6634s
Epoch: 5 cost time: 3.4016222953796387
Epoch: 5, Steps: 206 | Train Loss: 1.0277377 Vali Loss: 1.0558705 Test Loss: 1.0362517
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0380591
	speed: 0.0151s/iter; left time: 14.0524s
	iters: 200, epoch: 6 | loss: 1.0363998
	speed: 0.0123s/iter; left time: 10.2620s
Epoch: 6 cost time: 2.691558837890625
Epoch: 6, Steps: 206 | Train Loss: 1.0273073 Vali Loss: 1.0559629 Test Loss: 1.0365243
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0190566
	speed: 0.0179s/iter; left time: 12.9612s
	iters: 200, epoch: 7 | loss: 1.0144293
	speed: 0.0155s/iter; left time: 9.7016s
Epoch: 7 cost time: 3.2791552543640137
Epoch: 7, Steps: 206 | Train Loss: 1.0269919 Vali Loss: 1.0560602 Test Loss: 1.0367513
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0361758470535278, mae:0.8094750046730042
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0309433
	speed: 0.0324s/iter; left time: 59.6340s
Epoch: 1 cost time: 4.60595965385437
Epoch: 1, Steps: 194 | Train Loss: 1.0364928 Vali Loss: 1.0558867 Test Loss: 1.0284610
Validation loss decreased (inf --> 1.055887).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0254880
	speed: 0.0194s/iter; left time: 31.9049s
Epoch: 2 cost time: 3.606107234954834
Epoch: 2, Steps: 194 | Train Loss: 1.0330284 Vali Loss: 1.0557770 Test Loss: 1.0279742
Validation loss decreased (1.055887 --> 1.055777).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0439022
	speed: 0.0164s/iter; left time: 23.8529s
Epoch: 3 cost time: 2.911123037338257
Epoch: 3, Steps: 194 | Train Loss: 1.0320342 Vali Loss: 1.0541970 Test Loss: 1.0279207
Validation loss decreased (1.055777 --> 1.054197).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0487252
	speed: 0.0258s/iter; left time: 32.4743s
Epoch: 4 cost time: 3.7372376918792725
Epoch: 4, Steps: 194 | Train Loss: 1.0314494 Vali Loss: 1.0535746 Test Loss: 1.0295604
Validation loss decreased (1.054197 --> 1.053575).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0390604
	speed: 0.0257s/iter; left time: 27.3325s
Epoch: 5 cost time: 3.6743595600128174
Epoch: 5, Steps: 194 | Train Loss: 1.0310594 Vali Loss: 1.0532695 Test Loss: 1.0298418
Validation loss decreased (1.053575 --> 1.053270).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0331883
	speed: 0.0222s/iter; left time: 19.3210s
Epoch: 6 cost time: 3.350844383239746
Epoch: 6, Steps: 194 | Train Loss: 1.0307218 Vali Loss: 1.0531840 Test Loss: 1.0299695
Validation loss decreased (1.053270 --> 1.053184).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0399162
	speed: 0.0199s/iter; left time: 13.4995s
Epoch: 7 cost time: 3.476221799850464
Epoch: 7, Steps: 194 | Train Loss: 1.0305849 Vali Loss: 1.0530946 Test Loss: 1.0299292
Validation loss decreased (1.053184 --> 1.053095).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0316972
	speed: 0.0136s/iter; left time: 6.5537s
Epoch: 8 cost time: 2.784116744995117
Epoch: 8, Steps: 194 | Train Loss: 1.0305915 Vali Loss: 1.0528941 Test Loss: 1.0299579
Validation loss decreased (1.053095 --> 1.052894).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0366329
	speed: 0.0179s/iter; left time: 5.1589s
Epoch: 9 cost time: 3.0169990062713623
Epoch: 9, Steps: 194 | Train Loss: 1.0304589 Vali Loss: 1.0527437 Test Loss: 1.0299401
Validation loss decreased (1.052894 --> 1.052744).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0337665
	speed: 0.0168s/iter; left time: 1.6003s
Epoch: 10 cost time: 2.6786715984344482
Epoch: 10, Steps: 194 | Train Loss: 1.0304028 Vali Loss: 1.0527476 Test Loss: 1.0299408
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.029940128326416, mae:0.805671751499176
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0231516
	speed: 0.0172s/iter; left time: 31.6164s
Epoch: 1 cost time: 3.108227491378784
Epoch: 1, Steps: 194 | Train Loss: 1.0373739 Vali Loss: 1.0560069 Test Loss: 1.0286355
Validation loss decreased (inf --> 1.056007).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0258038
	speed: 0.0198s/iter; left time: 32.5971s
Epoch: 2 cost time: 4.312337636947632
Epoch: 2, Steps: 194 | Train Loss: 1.0333915 Vali Loss: 1.0563848 Test Loss: 1.0280831
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0398237
	speed: 0.0178s/iter; left time: 25.9156s
Epoch: 3 cost time: 4.270427227020264
Epoch: 3, Steps: 194 | Train Loss: 1.0323958 Vali Loss: 1.0549591 Test Loss: 1.0281043
Validation loss decreased (1.056007 --> 1.054959).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0291201
	speed: 0.0143s/iter; left time: 17.9874s
Epoch: 4 cost time: 2.644198417663574
Epoch: 4, Steps: 194 | Train Loss: 1.0317704 Vali Loss: 1.0542305 Test Loss: 1.0279218
Validation loss decreased (1.054959 --> 1.054230).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0222634
	speed: 0.0132s/iter; left time: 14.0739s
Epoch: 5 cost time: 2.8216781616210938
Epoch: 5, Steps: 194 | Train Loss: 1.0313877 Vali Loss: 1.0536063 Test Loss: 1.0280480
Validation loss decreased (1.054230 --> 1.053606).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0336192
	speed: 0.0156s/iter; left time: 13.5798s
Epoch: 6 cost time: 2.918846845626831
Epoch: 6, Steps: 194 | Train Loss: 1.0312106 Vali Loss: 1.0536853 Test Loss: 1.0282425
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0438361
	speed: 0.0147s/iter; left time: 9.9844s
Epoch: 7 cost time: 3.0852913856506348
Epoch: 7, Steps: 194 | Train Loss: 1.0309584 Vali Loss: 1.0534335 Test Loss: 1.0284346
Validation loss decreased (1.053606 --> 1.053434).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0265530
	speed: 0.0182s/iter; left time: 8.7722s
Epoch: 8 cost time: 3.5298521518707275
Epoch: 8, Steps: 194 | Train Loss: 1.0309432 Vali Loss: 1.0532850 Test Loss: 1.0285107
Validation loss decreased (1.053434 --> 1.053285).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0342145
	speed: 0.0124s/iter; left time: 3.5816s
Epoch: 9 cost time: 2.3831450939178467
Epoch: 9, Steps: 194 | Train Loss: 1.0309008 Vali Loss: 1.0533943 Test Loss: 1.0285841
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0235463
	speed: 0.0128s/iter; left time: 1.2198s
Epoch: 10 cost time: 2.5951128005981445
Epoch: 10, Steps: 194 | Train Loss: 1.0308087 Vali Loss: 1.0536002 Test Loss: 1.0286053
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0285106897354126, mae:0.8050066828727722
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0269655
	speed: 0.0193s/iter; left time: 35.4801s
Epoch: 1 cost time: 3.676093816757202
Epoch: 1, Steps: 194 | Train Loss: 1.0367400 Vali Loss: 1.0558857 Test Loss: 1.0285603
Validation loss decreased (inf --> 1.055886).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0396358
	speed: 0.0158s/iter; left time: 26.0844s
Epoch: 2 cost time: 2.8840157985687256
Epoch: 2, Steps: 194 | Train Loss: 1.0327810 Vali Loss: 1.0557157 Test Loss: 1.0280671
Validation loss decreased (1.055886 --> 1.055716).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0248623
	speed: 0.0229s/iter; left time: 33.3166s
Epoch: 3 cost time: 3.473956346511841
Epoch: 3, Steps: 194 | Train Loss: 1.0319404 Vali Loss: 1.0549483 Test Loss: 1.0279920
Validation loss decreased (1.055716 --> 1.054948).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0329601
	speed: 0.0204s/iter; left time: 25.6810s
Epoch: 4 cost time: 3.2654807567596436
Epoch: 4, Steps: 194 | Train Loss: 1.0313610 Vali Loss: 1.0536608 Test Loss: 1.0281806
Validation loss decreased (1.054948 --> 1.053661).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0285238
	speed: 0.0193s/iter; left time: 20.5438s
Epoch: 5 cost time: 3.6553661823272705
Epoch: 5, Steps: 194 | Train Loss: 1.0309236 Vali Loss: 1.0533867 Test Loss: 1.0282441
Validation loss decreased (1.053661 --> 1.053387).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0227177
	speed: 0.0176s/iter; left time: 15.3705s
Epoch: 6 cost time: 3.2140603065490723
Epoch: 6, Steps: 194 | Train Loss: 1.0307184 Vali Loss: 1.0530673 Test Loss: 1.0284718
Validation loss decreased (1.053387 --> 1.053067).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0505179
	speed: 0.0210s/iter; left time: 14.2250s
Epoch: 7 cost time: 3.5294392108917236
Epoch: 7, Steps: 194 | Train Loss: 1.0305305 Vali Loss: 1.0530534 Test Loss: 1.0286380
Validation loss decreased (1.053067 --> 1.053053).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0187818
	speed: 0.0175s/iter; left time: 8.4753s
Epoch: 8 cost time: 2.914503335952759
Epoch: 8, Steps: 194 | Train Loss: 1.0304456 Vali Loss: 1.0529510 Test Loss: 1.0287193
Validation loss decreased (1.053053 --> 1.052951).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0197461
	speed: 0.0191s/iter; left time: 5.5087s
Epoch: 9 cost time: 3.054481267929077
Epoch: 9, Steps: 194 | Train Loss: 1.0304464 Vali Loss: 1.0530404 Test Loss: 1.0287744
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0447063
	speed: 0.0179s/iter; left time: 1.6963s
Epoch: 10 cost time: 3.399744987487793
Epoch: 10, Steps: 194 | Train Loss: 1.0303766 Vali Loss: 1.0531214 Test Loss: 1.0287836
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.028719186782837, mae:0.805121898651123
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7034895
	speed: 0.0287s/iter; left time: 58.3004s
	iters: 200, epoch: 1 | loss: 0.6875201
	speed: 0.0197s/iter; left time: 38.1180s
Epoch: 1 cost time: 4.157195806503296
Epoch: 1, Steps: 213 | Train Loss: 0.7316156 Vali Loss: 0.6960687 Test Loss: 0.6633885
Validation loss decreased (inf --> 0.696069).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7136084
	speed: 0.0196s/iter; left time: 35.7055s
	iters: 200, epoch: 2 | loss: 0.6796009
	speed: 0.0180s/iter; left time: 30.9853s
Epoch: 2 cost time: 3.865354061126709
Epoch: 2, Steps: 213 | Train Loss: 0.7127831 Vali Loss: 0.7028587 Test Loss: 0.6545249
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6812483
	speed: 0.0193s/iter; left time: 30.9625s
	iters: 200, epoch: 3 | loss: 0.6968279
	speed: 0.0183s/iter; left time: 27.5514s
Epoch: 3 cost time: 4.003963470458984
Epoch: 3, Steps: 213 | Train Loss: 0.6944428 Vali Loss: 0.7128396 Test Loss: 0.6558770
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6708117
	speed: 0.0198s/iter; left time: 27.4952s
	iters: 200, epoch: 4 | loss: 0.7015020
	speed: 0.0175s/iter; left time: 22.5711s
Epoch: 4 cost time: 3.8374135494232178
Epoch: 4, Steps: 213 | Train Loss: 0.6862107 Vali Loss: 0.7093095 Test Loss: 0.6577086
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6895676
	speed: 0.0183s/iter; left time: 21.5462s
	iters: 200, epoch: 5 | loss: 0.6680195
	speed: 0.0167s/iter; left time: 18.0074s
Epoch: 5 cost time: 3.570389986038208
Epoch: 5, Steps: 213 | Train Loss: 0.6827841 Vali Loss: 0.6984683 Test Loss: 0.6580876
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6470551
	speed: 0.0169s/iter; left time: 16.3140s
	iters: 200, epoch: 6 | loss: 0.6442971
	speed: 0.0165s/iter; left time: 14.2724s
Epoch: 6 cost time: 3.639451742172241
Epoch: 6, Steps: 213 | Train Loss: 0.6805881 Vali Loss: 0.7068118 Test Loss: 0.6581302
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6633886098861694, mae:0.6540825963020325
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6791134
	speed: 0.0179s/iter; left time: 36.3911s
	iters: 200, epoch: 1 | loss: 0.6941754
	speed: 0.0170s/iter; left time: 32.8242s
Epoch: 1 cost time: 3.728823184967041
Epoch: 1, Steps: 213 | Train Loss: 0.7322402 Vali Loss: 0.6818644 Test Loss: 0.6641231
Validation loss decreased (inf --> 0.681864).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7142681
	speed: 0.0216s/iter; left time: 39.2528s
	iters: 200, epoch: 2 | loss: 0.6844277
	speed: 0.0228s/iter; left time: 39.1576s
Epoch: 2 cost time: 4.742291450500488
Epoch: 2, Steps: 213 | Train Loss: 0.7092936 Vali Loss: 0.6881433 Test Loss: 0.6521807
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6623341
	speed: 0.0151s/iter; left time: 24.2792s
	iters: 200, epoch: 3 | loss: 0.7359588
	speed: 0.0164s/iter; left time: 24.6705s
Epoch: 3 cost time: 3.473534345626831
Epoch: 3, Steps: 213 | Train Loss: 0.6853255 Vali Loss: 0.7237402 Test Loss: 0.6595975
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6892872
	speed: 0.0235s/iter; left time: 32.7020s
	iters: 200, epoch: 4 | loss: 0.6523203
	speed: 0.0179s/iter; left time: 23.1505s
Epoch: 4 cost time: 3.899968147277832
Epoch: 4, Steps: 213 | Train Loss: 0.6744708 Vali Loss: 0.7154093 Test Loss: 0.6566855
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7231223
	speed: 0.0158s/iter; left time: 18.6868s
	iters: 200, epoch: 5 | loss: 0.6585644
	speed: 0.0173s/iter; left time: 18.6628s
Epoch: 5 cost time: 3.9269142150878906
Epoch: 5, Steps: 213 | Train Loss: 0.6690903 Vali Loss: 0.7210395 Test Loss: 0.6631010
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6730688
	speed: 0.0172s/iter; left time: 16.6023s
	iters: 200, epoch: 6 | loss: 0.6348459
	speed: 0.0167s/iter; left time: 14.4583s
Epoch: 6 cost time: 3.5212624073028564
Epoch: 6, Steps: 213 | Train Loss: 0.6662430 Vali Loss: 0.7244006 Test Loss: 0.6639017
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6641231775283813, mae:0.6541154384613037
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7276618
	speed: 0.0171s/iter; left time: 34.7355s
	iters: 200, epoch: 1 | loss: 0.7065521
	speed: 0.0145s/iter; left time: 28.0125s
Epoch: 1 cost time: 3.110591173171997
Epoch: 1, Steps: 213 | Train Loss: 0.7306229 Vali Loss: 0.7387021 Test Loss: 0.6629551
Validation loss decreased (inf --> 0.738702).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7534732
	speed: 0.0187s/iter; left time: 33.9686s
	iters: 200, epoch: 2 | loss: 0.6770333
	speed: 0.0183s/iter; left time: 31.4826s
Epoch: 2 cost time: 3.913086175918579
Epoch: 2, Steps: 213 | Train Loss: 0.7081757 Vali Loss: 0.7019390 Test Loss: 0.6419213
Validation loss decreased (0.738702 --> 0.701939).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6653669
	speed: 0.0167s/iter; left time: 26.7233s
	iters: 200, epoch: 3 | loss: 0.7111109
	speed: 0.0149s/iter; left time: 22.3905s
Epoch: 3 cost time: 3.2017359733581543
Epoch: 3, Steps: 213 | Train Loss: 0.6905893 Vali Loss: 0.6762407 Test Loss: 0.6436045
Validation loss decreased (0.701939 --> 0.676241).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6799524
	speed: 0.0170s/iter; left time: 23.6223s
	iters: 200, epoch: 4 | loss: 0.6658920
	speed: 0.0141s/iter; left time: 18.2493s
Epoch: 4 cost time: 2.999593734741211
Epoch: 4, Steps: 213 | Train Loss: 0.6827138 Vali Loss: 0.6863294 Test Loss: 0.6452883
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6858215
	speed: 0.0128s/iter; left time: 15.0889s
	iters: 200, epoch: 5 | loss: 0.7133848
	speed: 0.0113s/iter; left time: 12.1772s
Epoch: 5 cost time: 2.5116891860961914
Epoch: 5, Steps: 213 | Train Loss: 0.6785151 Vali Loss: 0.7039787 Test Loss: 0.6467025
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6927187
	speed: 0.0242s/iter; left time: 23.3359s
	iters: 200, epoch: 6 | loss: 0.6788901
	speed: 0.0205s/iter; left time: 17.7386s
Epoch: 6 cost time: 4.434497356414795
Epoch: 6, Steps: 213 | Train Loss: 0.6754744 Vali Loss: 0.7010979 Test Loss: 0.6468153
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7026507
	speed: 0.0199s/iter; left time: 15.0118s
	iters: 200, epoch: 7 | loss: 0.7523113
	speed: 0.0181s/iter; left time: 11.8428s
Epoch: 7 cost time: 3.951472759246826
Epoch: 7, Steps: 213 | Train Loss: 0.6748177 Vali Loss: 0.7052824 Test Loss: 0.6474888
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6623692
	speed: 0.0202s/iter; left time: 10.9238s
	iters: 200, epoch: 8 | loss: 0.7116541
	speed: 0.0190s/iter; left time: 8.3472s
Epoch: 8 cost time: 3.9666335582733154
Epoch: 8, Steps: 213 | Train Loss: 0.6739925 Vali Loss: 0.7036234 Test Loss: 0.6478556
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6436046361923218, mae:0.6441450715065002
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8200951
	speed: 0.0310s/iter; left time: 61.9322s
	iters: 200, epoch: 1 | loss: 0.8635608
	speed: 0.0249s/iter; left time: 47.4018s
Epoch: 1 cost time: 5.335101366043091
Epoch: 1, Steps: 210 | Train Loss: 0.8259463 Vali Loss: 0.8893467 Test Loss: 0.7448413
Validation loss decreased (inf --> 0.889347).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7816142
	speed: 0.0215s/iter; left time: 38.4534s
	iters: 200, epoch: 2 | loss: 0.8255841
	speed: 0.0179s/iter; left time: 30.2807s
Epoch: 2 cost time: 3.7914223670959473
Epoch: 2, Steps: 210 | Train Loss: 0.8066753 Vali Loss: 0.9295906 Test Loss: 0.7561327
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8103232
	speed: 0.0163s/iter; left time: 25.7269s
	iters: 200, epoch: 3 | loss: 0.7652697
	speed: 0.0133s/iter; left time: 19.7011s
Epoch: 3 cost time: 2.8614678382873535
Epoch: 3, Steps: 210 | Train Loss: 0.7909018 Vali Loss: 0.9900887 Test Loss: 0.7646622
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8011026
	speed: 0.0188s/iter; left time: 25.8292s
	iters: 200, epoch: 4 | loss: 0.7402567
	speed: 0.0179s/iter; left time: 22.8080s
Epoch: 4 cost time: 3.836798667907715
Epoch: 4, Steps: 210 | Train Loss: 0.7804715 Vali Loss: 1.0023755 Test Loss: 0.7700816
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7381246
	speed: 0.0201s/iter; left time: 23.3305s
	iters: 200, epoch: 5 | loss: 0.8188866
	speed: 0.0190s/iter; left time: 20.2019s
Epoch: 5 cost time: 4.043907165527344
Epoch: 5, Steps: 210 | Train Loss: 0.7735010 Vali Loss: 1.0059479 Test Loss: 0.7702751
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8038430
	speed: 0.0286s/iter; left time: 27.2202s
	iters: 200, epoch: 6 | loss: 0.7678763
	speed: 0.0218s/iter; left time: 18.5381s
Epoch: 6 cost time: 4.6033806800842285
Epoch: 6, Steps: 210 | Train Loss: 0.7692385 Vali Loss: 1.0102836 Test Loss: 0.7721130
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7448413968086243, mae:0.6912145614624023
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8659648
	speed: 0.0167s/iter; left time: 33.3334s
	iters: 200, epoch: 1 | loss: 0.7709069
	speed: 0.0153s/iter; left time: 29.1663s
Epoch: 1 cost time: 3.307966470718384
Epoch: 1, Steps: 210 | Train Loss: 0.8256817 Vali Loss: 0.9149252 Test Loss: 0.7516400
Validation loss decreased (inf --> 0.914925).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8213872
	speed: 0.0191s/iter; left time: 34.1681s
	iters: 200, epoch: 2 | loss: 0.7440969
	speed: 0.0155s/iter; left time: 26.1896s
Epoch: 2 cost time: 3.257404088973999
Epoch: 2, Steps: 210 | Train Loss: 0.8057382 Vali Loss: 0.9562154 Test Loss: 0.7557963
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7818281
	speed: 0.0236s/iter; left time: 37.2349s
	iters: 200, epoch: 3 | loss: 0.8395187
	speed: 0.0190s/iter; left time: 28.1114s
Epoch: 3 cost time: 4.045872211456299
Epoch: 3, Steps: 210 | Train Loss: 0.7893392 Vali Loss: 0.9939511 Test Loss: 0.7734669
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8223776
	speed: 0.0175s/iter; left time: 23.9403s
	iters: 200, epoch: 4 | loss: 0.7681988
	speed: 0.0171s/iter; left time: 21.7004s
Epoch: 4 cost time: 3.8778955936431885
Epoch: 4, Steps: 210 | Train Loss: 0.7754366 Vali Loss: 0.9868037 Test Loss: 0.7664779
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7929667
	speed: 0.0227s/iter; left time: 26.3971s
	iters: 200, epoch: 5 | loss: 0.7783045
	speed: 0.0185s/iter; left time: 19.5783s
Epoch: 5 cost time: 3.911377429962158
Epoch: 5, Steps: 210 | Train Loss: 0.7672312 Vali Loss: 1.0051705 Test Loss: 0.7748787
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7325886
	speed: 0.0147s/iter; left time: 13.9344s
	iters: 200, epoch: 6 | loss: 0.7312767
	speed: 0.0119s/iter; left time: 10.1411s
Epoch: 6 cost time: 2.54054856300354
Epoch: 6, Steps: 210 | Train Loss: 0.7619731 Vali Loss: 1.0049002 Test Loss: 0.7800096
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7516399621963501, mae:0.6945627331733704
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8662437
	speed: 0.0187s/iter; left time: 37.3618s
	iters: 200, epoch: 1 | loss: 0.7721024
	speed: 0.0171s/iter; left time: 32.4427s
Epoch: 1 cost time: 3.617964744567871
Epoch: 1, Steps: 210 | Train Loss: 0.8251757 Vali Loss: 0.9064363 Test Loss: 0.7511498
Validation loss decreased (inf --> 0.906436).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8701714
	speed: 0.0188s/iter; left time: 33.6970s
	iters: 200, epoch: 2 | loss: 0.7365450
	speed: 0.0178s/iter; left time: 30.0184s
Epoch: 2 cost time: 3.7589781284332275
Epoch: 2, Steps: 210 | Train Loss: 0.7937272 Vali Loss: 0.9906218 Test Loss: 0.7777652
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7421869
	speed: 0.0197s/iter; left time: 31.0811s
	iters: 200, epoch: 3 | loss: 0.7528297
	speed: 0.0166s/iter; left time: 24.5535s
Epoch: 3 cost time: 3.5549089908599854
Epoch: 3, Steps: 210 | Train Loss: 0.7568783 Vali Loss: 0.9979591 Test Loss: 0.7821170
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7041075
	speed: 0.0148s/iter; left time: 20.3047s
	iters: 200, epoch: 4 | loss: 0.7137876
	speed: 0.0124s/iter; left time: 15.8192s
Epoch: 4 cost time: 2.724407911300659
Epoch: 4, Steps: 210 | Train Loss: 0.7366648 Vali Loss: 1.0431334 Test Loss: 0.7924258
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7756798
	speed: 0.0206s/iter; left time: 23.8939s
	iters: 200, epoch: 5 | loss: 0.7426955
	speed: 0.0195s/iter; left time: 20.6441s
Epoch: 5 cost time: 4.269779920578003
Epoch: 5, Steps: 210 | Train Loss: 0.7269867 Vali Loss: 1.0494215 Test Loss: 0.7993289
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7398643
	speed: 0.0194s/iter; left time: 18.4284s
	iters: 200, epoch: 6 | loss: 0.7256143
	speed: 0.0192s/iter; left time: 16.3315s
Epoch: 6 cost time: 4.140138864517212
Epoch: 6, Steps: 210 | Train Loss: 0.7216827 Vali Loss: 1.0337839 Test Loss: 0.7967154
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7511498928070068, mae:0.6936218738555908
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9207126
	speed: 0.0280s/iter; left time: 54.9760s
	iters: 200, epoch: 1 | loss: 0.9727249
	speed: 0.0195s/iter; left time: 36.2481s
Epoch: 1 cost time: 4.047242879867554
Epoch: 1, Steps: 206 | Train Loss: 0.9345634 Vali Loss: 1.0626295 Test Loss: 0.8075721
Validation loss decreased (inf --> 1.062629).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9219742
	speed: 0.0154s/iter; left time: 27.0748s
	iters: 200, epoch: 2 | loss: 0.8752362
	speed: 0.0140s/iter; left time: 23.0955s
Epoch: 2 cost time: 2.949683904647827
Epoch: 2, Steps: 206 | Train Loss: 0.8939687 Vali Loss: 1.1097361 Test Loss: 0.8354028
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9626000
	speed: 0.0161s/iter; left time: 24.9460s
	iters: 200, epoch: 3 | loss: 0.8457543
	speed: 0.0145s/iter; left time: 20.9409s
Epoch: 3 cost time: 3.0862224102020264
Epoch: 3, Steps: 206 | Train Loss: 0.8658581 Vali Loss: 1.1060797 Test Loss: 0.8424411
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8656297
	speed: 0.0177s/iter; left time: 23.8345s
	iters: 200, epoch: 4 | loss: 0.8131554
	speed: 0.0154s/iter; left time: 19.0881s
Epoch: 4 cost time: 3.2183268070220947
Epoch: 4, Steps: 206 | Train Loss: 0.8468267 Vali Loss: 1.1270167 Test Loss: 0.8403748
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8165160
	speed: 0.0135s/iter; left time: 15.3335s
	iters: 200, epoch: 5 | loss: 0.8809122
	speed: 0.0121s/iter; left time: 12.5459s
Epoch: 5 cost time: 2.5712878704071045
Epoch: 5, Steps: 206 | Train Loss: 0.8365751 Vali Loss: 1.1226280 Test Loss: 0.8527333
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8232784
	speed: 0.0237s/iter; left time: 22.0361s
	iters: 200, epoch: 6 | loss: 0.8633661
	speed: 0.0204s/iter; left time: 16.9402s
Epoch: 6 cost time: 4.2549474239349365
Epoch: 6, Steps: 206 | Train Loss: 0.8310637 Vali Loss: 1.1326379 Test Loss: 0.8600422
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8075721263885498, mae:0.7188369631767273
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8399582
	speed: 0.0216s/iter; left time: 42.3366s
	iters: 200, epoch: 1 | loss: 0.9117031
	speed: 0.0177s/iter; left time: 32.9775s
Epoch: 1 cost time: 3.7500433921813965
Epoch: 1, Steps: 206 | Train Loss: 0.9327971 Vali Loss: 1.0218227 Test Loss: 0.8088703
Validation loss decreased (inf --> 1.021823).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9123564
	speed: 0.0218s/iter; left time: 38.3263s
	iters: 200, epoch: 2 | loss: 0.8557425
	speed: 0.0172s/iter; left time: 28.5136s
Epoch: 2 cost time: 3.576866626739502
Epoch: 2, Steps: 206 | Train Loss: 0.8942861 Vali Loss: 1.0798231 Test Loss: 0.8298822
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8601832
	speed: 0.0146s/iter; left time: 22.6217s
	iters: 200, epoch: 3 | loss: 0.8309737
	speed: 0.0130s/iter; left time: 18.8465s
Epoch: 3 cost time: 2.784728527069092
Epoch: 3, Steps: 206 | Train Loss: 0.8601126 Vali Loss: 1.0531943 Test Loss: 0.8333989
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8648062
	speed: 0.0171s/iter; left time: 22.9927s
	iters: 200, epoch: 4 | loss: 0.7756557
	speed: 0.0159s/iter; left time: 19.7954s
Epoch: 4 cost time: 3.397244930267334
Epoch: 4, Steps: 206 | Train Loss: 0.8324926 Vali Loss: 1.0750895 Test Loss: 0.8325264
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7898304
	speed: 0.0170s/iter; left time: 19.3424s
	iters: 200, epoch: 5 | loss: 0.8223199
	speed: 0.0161s/iter; left time: 16.6695s
Epoch: 5 cost time: 3.39882493019104
Epoch: 5, Steps: 206 | Train Loss: 0.8185122 Vali Loss: 1.0821863 Test Loss: 0.8384051
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8328382
	speed: 0.0154s/iter; left time: 14.3615s
	iters: 200, epoch: 6 | loss: 0.7636297
	speed: 0.0163s/iter; left time: 13.5763s
Epoch: 6 cost time: 3.459937572479248
Epoch: 6, Steps: 206 | Train Loss: 0.8090825 Vali Loss: 1.0937839 Test Loss: 0.8455464
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8088701367378235, mae:0.7192330360412598
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9363115
	speed: 0.0202s/iter; left time: 39.6663s
	iters: 200, epoch: 1 | loss: 0.8774685
	speed: 0.0140s/iter; left time: 26.1205s
Epoch: 1 cost time: 3.0033628940582275
Epoch: 1, Steps: 206 | Train Loss: 0.9364237 Vali Loss: 1.0716805 Test Loss: 0.8369056
Validation loss decreased (inf --> 1.071681).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9742861
	speed: 0.0173s/iter; left time: 30.3021s
	iters: 200, epoch: 2 | loss: 0.8831624
	speed: 0.0153s/iter; left time: 25.3777s
Epoch: 2 cost time: 3.2493042945861816
Epoch: 2, Steps: 206 | Train Loss: 0.8984891 Vali Loss: 1.0932871 Test Loss: 0.8188300
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8918294
	speed: 0.0179s/iter; left time: 27.6947s
	iters: 200, epoch: 3 | loss: 0.8134205
	speed: 0.0147s/iter; left time: 21.3481s
Epoch: 3 cost time: 3.1726861000061035
Epoch: 3, Steps: 206 | Train Loss: 0.8654947 Vali Loss: 1.1395696 Test Loss: 0.8547208
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7970348
	speed: 0.0263s/iter; left time: 35.3183s
	iters: 200, epoch: 4 | loss: 0.8338888
	speed: 0.0200s/iter; left time: 24.8825s
Epoch: 4 cost time: 4.2015955448150635
Epoch: 4, Steps: 206 | Train Loss: 0.8404312 Vali Loss: 1.1201711 Test Loss: 0.8531707
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8373097
	speed: 0.0172s/iter; left time: 19.5929s
	iters: 200, epoch: 5 | loss: 0.7932567
	speed: 0.0145s/iter; left time: 15.0438s
Epoch: 5 cost time: 3.1260504722595215
Epoch: 5, Steps: 206 | Train Loss: 0.8261502 Vali Loss: 1.1284953 Test Loss: 0.8641250
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8198251
	speed: 0.0151s/iter; left time: 14.0886s
	iters: 200, epoch: 6 | loss: 0.8644133
	speed: 0.0155s/iter; left time: 12.8626s
Epoch: 6 cost time: 3.3475778102874756
Epoch: 6, Steps: 206 | Train Loss: 0.8182842 Vali Loss: 1.1263987 Test Loss: 0.8605423
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8369054198265076, mae:0.7323368787765503
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0237499
	speed: 0.0358s/iter; left time: 65.8685s
Epoch: 1 cost time: 5.41567587852478
Epoch: 1, Steps: 194 | Train Loss: 1.1309787 Vali Loss: 1.6467133 Test Loss: 0.9020652
Validation loss decreased (inf --> 1.646713).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0471485
	speed: 0.0134s/iter; left time: 22.1270s
Epoch: 2 cost time: 2.6323916912078857
Epoch: 2, Steps: 194 | Train Loss: 1.0829325 Vali Loss: 1.4937663 Test Loss: 0.9405825
Validation loss decreased (1.646713 --> 1.493766).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0661354
	speed: 0.0209s/iter; left time: 30.4271s
Epoch: 3 cost time: 3.8946280479431152
Epoch: 3, Steps: 194 | Train Loss: 1.0466679 Vali Loss: 1.2706745 Test Loss: 0.9735056
Validation loss decreased (1.493766 --> 1.270674).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0123918
	speed: 0.0177s/iter; left time: 22.2907s
Epoch: 4 cost time: 3.21642804145813
Epoch: 4, Steps: 194 | Train Loss: 1.0213924 Vali Loss: 1.2599409 Test Loss: 0.9771790
Validation loss decreased (1.270674 --> 1.259941).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9591691
	speed: 0.0167s/iter; left time: 17.7383s
Epoch: 5 cost time: 3.3896431922912598
Epoch: 5, Steps: 194 | Train Loss: 1.0037800 Vali Loss: 1.3072925 Test Loss: 1.0074074
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0025438
	speed: 0.0164s/iter; left time: 14.2664s
Epoch: 6 cost time: 2.780956745147705
Epoch: 6, Steps: 194 | Train Loss: 0.9950169 Vali Loss: 1.2596469 Test Loss: 1.0159041
Validation loss decreased (1.259941 --> 1.259647).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9320019
	speed: 0.0134s/iter; left time: 9.0869s
Epoch: 7 cost time: 2.607156991958618
Epoch: 7, Steps: 194 | Train Loss: 0.9917716 Vali Loss: 1.2616256 Test Loss: 1.0251315
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0125103
	speed: 0.0144s/iter; left time: 6.9368s
Epoch: 8 cost time: 2.421419382095337
Epoch: 8, Steps: 194 | Train Loss: 0.9888581 Vali Loss: 1.2753626 Test Loss: 1.0283086
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0691332
	speed: 0.0133s/iter; left time: 3.8377s
Epoch: 9 cost time: 2.6190741062164307
Epoch: 9, Steps: 194 | Train Loss: 0.9877908 Vali Loss: 1.2753564 Test Loss: 1.0304159
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0351225
	speed: 0.0141s/iter; left time: 1.3386s
Epoch: 10 cost time: 2.471215009689331
Epoch: 10, Steps: 194 | Train Loss: 0.9879699 Vali Loss: 1.2728827 Test Loss: 1.0311103
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0159039497375488, mae:0.8049688339233398
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1178398
	speed: 0.0176s/iter; left time: 32.4561s
Epoch: 1 cost time: 3.2699859142303467
Epoch: 1, Steps: 194 | Train Loss: 1.1275480 Vali Loss: 1.6055969 Test Loss: 0.9042120
Validation loss decreased (inf --> 1.605597).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0972657
	speed: 0.0199s/iter; left time: 32.7896s
Epoch: 2 cost time: 3.371739387512207
Epoch: 2, Steps: 194 | Train Loss: 1.0855864 Vali Loss: 1.5717088 Test Loss: 0.9195958
Validation loss decreased (1.605597 --> 1.571709).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0496467
	speed: 0.0228s/iter; left time: 33.1071s
Epoch: 3 cost time: 3.5640869140625
Epoch: 3, Steps: 194 | Train Loss: 1.0485087 Vali Loss: 1.3884752 Test Loss: 0.9536082
Validation loss decreased (1.571709 --> 1.388475).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9257184
	speed: 0.0233s/iter; left time: 29.3645s
Epoch: 4 cost time: 3.7333035469055176
Epoch: 4, Steps: 194 | Train Loss: 1.0212115 Vali Loss: 1.3379933 Test Loss: 0.9867511
Validation loss decreased (1.388475 --> 1.337993).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9128813
	speed: 0.0163s/iter; left time: 17.3386s
Epoch: 5 cost time: 2.6492772102355957
Epoch: 5, Steps: 194 | Train Loss: 1.0057881 Vali Loss: 1.3788246 Test Loss: 0.9974945
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0434710
	speed: 0.0156s/iter; left time: 13.6062s
Epoch: 6 cost time: 3.069040298461914
Epoch: 6, Steps: 194 | Train Loss: 0.9974600 Vali Loss: 1.3099139 Test Loss: 1.0094085
Validation loss decreased (1.337993 --> 1.309914).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.1005388
	speed: 0.0168s/iter; left time: 11.3915s
Epoch: 7 cost time: 3.784834146499634
Epoch: 7, Steps: 194 | Train Loss: 0.9946616 Vali Loss: 1.2962911 Test Loss: 1.0150429
Validation loss decreased (1.309914 --> 1.296291).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0400085
	speed: 0.0205s/iter; left time: 9.9248s
Epoch: 8 cost time: 3.817326545715332
Epoch: 8, Steps: 194 | Train Loss: 0.9934366 Vali Loss: 1.2981623 Test Loss: 1.0179553
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9266304
	speed: 0.0190s/iter; left time: 5.4859s
Epoch: 9 cost time: 2.9360337257385254
Epoch: 9, Steps: 194 | Train Loss: 0.9903568 Vali Loss: 1.2946992 Test Loss: 1.0193152
Validation loss decreased (1.296291 --> 1.294699).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9873125
	speed: 0.0171s/iter; left time: 1.6269s
Epoch: 10 cost time: 3.1824240684509277
Epoch: 10, Steps: 194 | Train Loss: 0.9898678 Vali Loss: 1.2993312 Test Loss: 1.0197328
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.019315242767334, mae:0.8065418004989624
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1145965
	speed: 0.0156s/iter; left time: 28.6411s
Epoch: 1 cost time: 2.5896153450012207
Epoch: 1, Steps: 194 | Train Loss: 1.1273729 Vali Loss: 1.5910995 Test Loss: 0.9024763
Validation loss decreased (inf --> 1.591100).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1318052
	speed: 0.0181s/iter; left time: 29.7434s
Epoch: 2 cost time: 3.0045971870422363
Epoch: 2, Steps: 194 | Train Loss: 1.0812204 Vali Loss: 1.5673035 Test Loss: 0.9469437
Validation loss decreased (1.591100 --> 1.567304).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0746089
	speed: 0.0174s/iter; left time: 25.3251s
Epoch: 3 cost time: 2.782222270965576
Epoch: 3, Steps: 194 | Train Loss: 1.0501833 Vali Loss: 1.4747860 Test Loss: 0.9811544
Validation loss decreased (1.567304 --> 1.474786).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9939772
	speed: 0.0201s/iter; left time: 25.3501s
Epoch: 4 cost time: 3.608272075653076
Epoch: 4, Steps: 194 | Train Loss: 1.0232710 Vali Loss: 1.3667312 Test Loss: 1.0037851
Validation loss decreased (1.474786 --> 1.366731).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9600115
	speed: 0.0261s/iter; left time: 27.7984s
Epoch: 5 cost time: 3.8898987770080566
Epoch: 5, Steps: 194 | Train Loss: 1.0080005 Vali Loss: 1.4018451 Test Loss: 1.0236220
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9146620
	speed: 0.0166s/iter; left time: 14.4852s
Epoch: 6 cost time: 3.045806884765625
Epoch: 6, Steps: 194 | Train Loss: 0.9984060 Vali Loss: 1.3514813 Test Loss: 1.0291580
Validation loss decreased (1.366731 --> 1.351481).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9994785
	speed: 0.0230s/iter; left time: 15.5806s
Epoch: 7 cost time: 3.488798141479492
Epoch: 7, Steps: 194 | Train Loss: 0.9957293 Vali Loss: 1.3545543 Test Loss: 1.0320309
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0589788
	speed: 0.0141s/iter; left time: 6.8019s
Epoch: 8 cost time: 2.812133312225342
Epoch: 8, Steps: 194 | Train Loss: 0.9933288 Vali Loss: 1.3549731 Test Loss: 1.0358605
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0215690
	speed: 0.0158s/iter; left time: 4.5728s
Epoch: 9 cost time: 3.267031669616699
Epoch: 9, Steps: 194 | Train Loss: 0.9932881 Vali Loss: 1.3486842 Test Loss: 1.0364026
Validation loss decreased (1.351481 --> 1.348684).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0017767
	speed: 0.0177s/iter; left time: 1.6812s
Epoch: 10 cost time: 2.931657314300537
Epoch: 10, Steps: 194 | Train Loss: 0.9901346 Vali Loss: 1.3459433 Test Loss: 1.0369483
Validation loss decreased (1.348684 --> 1.345943).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0369480848312378, mae:0.8135232329368591
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7179009
	speed: 0.0319s/iter; left time: 64.7165s
	iters: 200, epoch: 1 | loss: 0.7265579
	speed: 0.0220s/iter; left time: 42.5309s
Epoch: 1 cost time: 4.6387834548950195
Epoch: 1, Steps: 213 | Train Loss: 0.7318602 Vali Loss: 0.7133221 Test Loss: 0.6633187
Validation loss decreased (inf --> 0.713322).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6733974
	speed: 0.0132s/iter; left time: 24.0096s
	iters: 200, epoch: 2 | loss: 0.7377477
	speed: 0.0121s/iter; left time: 20.7077s
Epoch: 2 cost time: 2.6942968368530273
Epoch: 2, Steps: 213 | Train Loss: 0.7102976 Vali Loss: 0.7073201 Test Loss: 0.6587782
Validation loss decreased (0.713322 --> 0.707320).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6669745
	speed: 0.0191s/iter; left time: 30.6475s
	iters: 200, epoch: 3 | loss: 0.7141420
	speed: 0.0160s/iter; left time: 24.0351s
Epoch: 3 cost time: 3.391028881072998
Epoch: 3, Steps: 213 | Train Loss: 0.6902115 Vali Loss: 0.7230162 Test Loss: 0.6579660
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6665708
	speed: 0.0140s/iter; left time: 19.4421s
	iters: 200, epoch: 4 | loss: 0.6752757
	speed: 0.0117s/iter; left time: 15.1760s
Epoch: 4 cost time: 2.6587581634521484
Epoch: 4, Steps: 213 | Train Loss: 0.6816953 Vali Loss: 0.7092850 Test Loss: 0.6634818
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6585776
	speed: 0.0153s/iter; left time: 18.0208s
	iters: 200, epoch: 5 | loss: 0.6884364
	speed: 0.0152s/iter; left time: 16.3663s
Epoch: 5 cost time: 3.355116844177246
Epoch: 5, Steps: 213 | Train Loss: 0.6767396 Vali Loss: 0.7219446 Test Loss: 0.6661170
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6720409
	speed: 0.0190s/iter; left time: 18.3653s
	iters: 200, epoch: 6 | loss: 0.7000998
	speed: 0.0169s/iter; left time: 14.6128s
Epoch: 6 cost time: 3.668687582015991
Epoch: 6, Steps: 213 | Train Loss: 0.6745453 Vali Loss: 0.7185480 Test Loss: 0.6682584
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6749055
	speed: 0.0175s/iter; left time: 13.1900s
	iters: 200, epoch: 7 | loss: 0.6609153
	speed: 0.0154s/iter; left time: 10.0332s
Epoch: 7 cost time: 3.330509662628174
Epoch: 7, Steps: 213 | Train Loss: 0.6736288 Vali Loss: 0.7198675 Test Loss: 0.6689560
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6587783098220825, mae:0.651512622833252
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7374020
	speed: 0.0238s/iter; left time: 48.2453s
	iters: 200, epoch: 1 | loss: 0.6776496
	speed: 0.0189s/iter; left time: 36.4098s
Epoch: 1 cost time: 4.1066155433654785
Epoch: 1, Steps: 213 | Train Loss: 0.7318979 Vali Loss: 0.6997061 Test Loss: 0.6705730
Validation loss decreased (inf --> 0.699706).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7215642
	speed: 0.0214s/iter; left time: 38.8179s
	iters: 200, epoch: 2 | loss: 0.6764823
	speed: 0.0182s/iter; left time: 31.2842s
Epoch: 2 cost time: 3.9367456436157227
Epoch: 2, Steps: 213 | Train Loss: 0.7164755 Vali Loss: 0.7333518 Test Loss: 0.6629550
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7047087
	speed: 0.0171s/iter; left time: 27.5255s
	iters: 200, epoch: 3 | loss: 0.6689266
	speed: 0.0134s/iter; left time: 20.2001s
Epoch: 3 cost time: 2.8817193508148193
Epoch: 3, Steps: 213 | Train Loss: 0.6944001 Vali Loss: 0.7230058 Test Loss: 0.6612117
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6448237
	speed: 0.0158s/iter; left time: 21.9832s
	iters: 200, epoch: 4 | loss: 0.7001712
	speed: 0.0139s/iter; left time: 17.9584s
Epoch: 4 cost time: 3.204848289489746
Epoch: 4, Steps: 213 | Train Loss: 0.6804618 Vali Loss: 0.6950054 Test Loss: 0.6647130
Validation loss decreased (0.699706 --> 0.695005).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6743441
	speed: 0.0177s/iter; left time: 20.8216s
	iters: 200, epoch: 5 | loss: 0.7042531
	speed: 0.0157s/iter; left time: 16.9122s
Epoch: 5 cost time: 3.4036879539489746
Epoch: 5, Steps: 213 | Train Loss: 0.6739659 Vali Loss: 0.7199534 Test Loss: 0.6710268
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6359951
	speed: 0.0181s/iter; left time: 17.5233s
	iters: 200, epoch: 6 | loss: 0.7054195
	speed: 0.0166s/iter; left time: 14.3343s
Epoch: 6 cost time: 3.6664962768554688
Epoch: 6, Steps: 213 | Train Loss: 0.6716492 Vali Loss: 0.7099606 Test Loss: 0.6694325
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6471815
	speed: 0.0158s/iter; left time: 11.9298s
	iters: 200, epoch: 7 | loss: 0.7710492
	speed: 0.0155s/iter; left time: 10.1069s
Epoch: 7 cost time: 3.402257204055786
Epoch: 7, Steps: 213 | Train Loss: 0.6691995 Vali Loss: 0.7184895 Test Loss: 0.6702538
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6999288
	speed: 0.0164s/iter; left time: 8.8668s
	iters: 200, epoch: 8 | loss: 0.6485273
	speed: 0.0142s/iter; left time: 6.2324s
Epoch: 8 cost time: 3.1048946380615234
Epoch: 8, Steps: 213 | Train Loss: 0.6682955 Vali Loss: 0.7173534 Test Loss: 0.6709244
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6731623
	speed: 0.0139s/iter; left time: 4.5440s
	iters: 200, epoch: 9 | loss: 0.6813049
	speed: 0.0148s/iter; left time: 3.3677s
Epoch: 9 cost time: 3.2799839973449707
Epoch: 9, Steps: 213 | Train Loss: 0.6684900 Vali Loss: 0.7159130 Test Loss: 0.6713913
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6647130250930786, mae:0.6534930467605591
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7288375
	speed: 0.0344s/iter; left time: 69.8001s
	iters: 200, epoch: 1 | loss: 0.7025201
	speed: 0.0258s/iter; left time: 49.7436s
Epoch: 1 cost time: 5.430056571960449
Epoch: 1, Steps: 213 | Train Loss: 0.7327728 Vali Loss: 0.7131538 Test Loss: 0.6638991
Validation loss decreased (inf --> 0.713154).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6945464
	speed: 0.0177s/iter; left time: 32.2313s
	iters: 200, epoch: 2 | loss: 0.6613588
	speed: 0.0164s/iter; left time: 28.1200s
Epoch: 2 cost time: 3.498659610748291
Epoch: 2, Steps: 213 | Train Loss: 0.7151683 Vali Loss: 0.6740059 Test Loss: 0.6635576
Validation loss decreased (0.713154 --> 0.674006).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7184295
	speed: 0.0159s/iter; left time: 25.4946s
	iters: 200, epoch: 3 | loss: 0.7361296
	speed: 0.0128s/iter; left time: 19.2719s
Epoch: 3 cost time: 2.7843077182769775
Epoch: 3, Steps: 213 | Train Loss: 0.6942967 Vali Loss: 0.7113068 Test Loss: 0.6541776
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6640104
	speed: 0.0195s/iter; left time: 27.1975s
	iters: 200, epoch: 4 | loss: 0.7141234
	speed: 0.0174s/iter; left time: 22.4480s
Epoch: 4 cost time: 3.822563648223877
Epoch: 4, Steps: 213 | Train Loss: 0.6832648 Vali Loss: 0.7178814 Test Loss: 0.6621091
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6552066
	speed: 0.0197s/iter; left time: 23.2478s
	iters: 200, epoch: 5 | loss: 0.6379657
	speed: 0.0182s/iter; left time: 19.6393s
Epoch: 5 cost time: 3.9615492820739746
Epoch: 5, Steps: 213 | Train Loss: 0.6785633 Vali Loss: 0.7545236 Test Loss: 0.6692364
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6884512
	speed: 0.0158s/iter; left time: 15.2732s
	iters: 200, epoch: 6 | loss: 0.7001923
	speed: 0.0149s/iter; left time: 12.8870s
Epoch: 6 cost time: 3.2702977657318115
Epoch: 6, Steps: 213 | Train Loss: 0.6753686 Vali Loss: 0.7359952 Test Loss: 0.6677341
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6691210
	speed: 0.0119s/iter; left time: 8.9605s
	iters: 200, epoch: 7 | loss: 0.6748752
	speed: 0.0110s/iter; left time: 7.1949s
Epoch: 7 cost time: 2.4755170345306396
Epoch: 7, Steps: 213 | Train Loss: 0.6744418 Vali Loss: 0.7391722 Test Loss: 0.6703212
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6635574698448181, mae:0.653082549571991
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8953178
	speed: 0.0297s/iter; left time: 59.4078s
	iters: 200, epoch: 1 | loss: 0.9515187
	speed: 0.0243s/iter; left time: 46.1146s
Epoch: 1 cost time: 5.059779405593872
Epoch: 1, Steps: 210 | Train Loss: 0.8245162 Vali Loss: 0.9317976 Test Loss: 0.7602639
Validation loss decreased (inf --> 0.931798).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7309086
	speed: 0.0165s/iter; left time: 29.5785s
	iters: 200, epoch: 2 | loss: 0.7610919
	speed: 0.0156s/iter; left time: 26.4128s
Epoch: 2 cost time: 3.386880397796631
Epoch: 2, Steps: 210 | Train Loss: 0.7987647 Vali Loss: 0.9404200 Test Loss: 0.7455091
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7193596
	speed: 0.0159s/iter; left time: 25.2030s
	iters: 200, epoch: 3 | loss: 0.7503244
	speed: 0.0213s/iter; left time: 31.4777s
Epoch: 3 cost time: 4.513202428817749
Epoch: 3, Steps: 210 | Train Loss: 0.7710083 Vali Loss: 0.9433938 Test Loss: 0.7673149
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7594535
	speed: 0.0214s/iter; left time: 29.3989s
	iters: 200, epoch: 4 | loss: 0.7206630
	speed: 0.0173s/iter; left time: 21.9755s
Epoch: 4 cost time: 3.642467498779297
Epoch: 4, Steps: 210 | Train Loss: 0.7520846 Vali Loss: 0.9431981 Test Loss: 0.7723957
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7520313
	speed: 0.0220s/iter; left time: 25.5116s
	iters: 200, epoch: 5 | loss: 0.6697428
	speed: 0.0188s/iter; left time: 19.9675s
Epoch: 5 cost time: 4.052504777908325
Epoch: 5, Steps: 210 | Train Loss: 0.7413672 Vali Loss: 0.9833944 Test Loss: 0.7792149
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7057196
	speed: 0.0147s/iter; left time: 13.9366s
	iters: 200, epoch: 6 | loss: 0.7447243
	speed: 0.0136s/iter; left time: 11.5586s
Epoch: 6 cost time: 2.8798906803131104
Epoch: 6, Steps: 210 | Train Loss: 0.7371918 Vali Loss: 0.9713606 Test Loss: 0.7788066
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7602640986442566, mae:0.6983552575111389
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8069898
	speed: 0.0186s/iter; left time: 37.1528s
	iters: 200, epoch: 1 | loss: 0.7817631
	speed: 0.0194s/iter; left time: 36.8416s
Epoch: 1 cost time: 4.178693056106567
Epoch: 1, Steps: 210 | Train Loss: 0.8236863 Vali Loss: 0.9493744 Test Loss: 0.7583483
Validation loss decreased (inf --> 0.949374).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7435576
	speed: 0.0165s/iter; left time: 29.6051s
	iters: 200, epoch: 2 | loss: 0.8050126
	speed: 0.0159s/iter; left time: 26.9614s
Epoch: 2 cost time: 3.4379568099975586
Epoch: 2, Steps: 210 | Train Loss: 0.8009222 Vali Loss: 0.9692705 Test Loss: 0.7506834
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8032486
	speed: 0.0248s/iter; left time: 39.2300s
	iters: 200, epoch: 3 | loss: 0.7558341
	speed: 0.0199s/iter; left time: 29.5023s
Epoch: 3 cost time: 4.210430860519409
Epoch: 3, Steps: 210 | Train Loss: 0.7766773 Vali Loss: 0.9572220 Test Loss: 0.7616770
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7260627
	speed: 0.0139s/iter; left time: 19.0275s
	iters: 200, epoch: 4 | loss: 0.7181430
	speed: 0.0116s/iter; left time: 14.7087s
Epoch: 4 cost time: 2.5340476036071777
Epoch: 4, Steps: 210 | Train Loss: 0.7574692 Vali Loss: 1.0265138 Test Loss: 0.7792364
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6954336
	speed: 0.0190s/iter; left time: 22.0057s
	iters: 200, epoch: 5 | loss: 0.7503871
	speed: 0.0162s/iter; left time: 17.1993s
Epoch: 5 cost time: 3.4671452045440674
Epoch: 5, Steps: 210 | Train Loss: 0.7476877 Vali Loss: 1.0208783 Test Loss: 0.7887328
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7743717
	speed: 0.0188s/iter; left time: 17.9103s
	iters: 200, epoch: 6 | loss: 0.7429129
	speed: 0.0166s/iter; left time: 14.1247s
Epoch: 6 cost time: 3.5091841220855713
Epoch: 6, Steps: 210 | Train Loss: 0.7424573 Vali Loss: 1.0122594 Test Loss: 0.7849596
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7583483457565308, mae:0.6977612972259521
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8493959
	speed: 0.0179s/iter; left time: 35.7747s
	iters: 200, epoch: 1 | loss: 0.7990241
	speed: 0.0147s/iter; left time: 27.9000s
Epoch: 1 cost time: 3.1866261959075928
Epoch: 1, Steps: 210 | Train Loss: 0.8238680 Vali Loss: 0.9217182 Test Loss: 0.7498779
Validation loss decreased (inf --> 0.921718).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8140883
	speed: 0.0184s/iter; left time: 32.8918s
	iters: 200, epoch: 2 | loss: 0.7678201
	speed: 0.0152s/iter; left time: 25.7669s
Epoch: 2 cost time: 3.2797956466674805
Epoch: 2, Steps: 210 | Train Loss: 0.8024017 Vali Loss: 0.9392840 Test Loss: 0.7510504
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7598764
	speed: 0.0165s/iter; left time: 26.1652s
	iters: 200, epoch: 3 | loss: 0.7563487
	speed: 0.0177s/iter; left time: 26.2038s
Epoch: 3 cost time: 3.7986998558044434
Epoch: 3, Steps: 210 | Train Loss: 0.7836052 Vali Loss: 0.9653740 Test Loss: 0.7558604
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7912409
	speed: 0.0171s/iter; left time: 23.4549s
	iters: 200, epoch: 4 | loss: 0.7641116
	speed: 0.0169s/iter; left time: 21.4540s
Epoch: 4 cost time: 3.6598708629608154
Epoch: 4, Steps: 210 | Train Loss: 0.7719447 Vali Loss: 0.9910138 Test Loss: 0.7708491
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7989972
	speed: 0.0170s/iter; left time: 19.7890s
	iters: 200, epoch: 5 | loss: 0.7269217
	speed: 0.0152s/iter; left time: 16.0868s
Epoch: 5 cost time: 3.2810912132263184
Epoch: 5, Steps: 210 | Train Loss: 0.7638188 Vali Loss: 0.9873086 Test Loss: 0.7747350
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7707276
	speed: 0.0149s/iter; left time: 14.1327s
	iters: 200, epoch: 6 | loss: 0.7414572
	speed: 0.0121s/iter; left time: 10.2963s
Epoch: 6 cost time: 2.6116976737976074
Epoch: 6, Steps: 210 | Train Loss: 0.7589467 Vali Loss: 0.9788261 Test Loss: 0.7740107
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7498779296875, mae:0.6944388747215271
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9358751
	speed: 0.0287s/iter; left time: 56.2565s
	iters: 200, epoch: 1 | loss: 0.9207973
	speed: 0.0205s/iter; left time: 38.0766s
Epoch: 1 cost time: 4.218876600265503
Epoch: 1, Steps: 206 | Train Loss: 0.9334001 Vali Loss: 1.0761110 Test Loss: 0.8182272
Validation loss decreased (inf --> 1.076111).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9045712
	speed: 0.0144s/iter; left time: 25.2360s
	iters: 200, epoch: 2 | loss: 0.9062028
	speed: 0.0123s/iter; left time: 20.4288s
Epoch: 2 cost time: 2.6172335147857666
Epoch: 2, Steps: 206 | Train Loss: 0.8949336 Vali Loss: 1.1044523 Test Loss: 0.8177467
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8795716
	speed: 0.0172s/iter; left time: 26.6181s
	iters: 200, epoch: 3 | loss: 0.8447206
	speed: 0.0149s/iter; left time: 21.5671s
Epoch: 3 cost time: 3.1619904041290283
Epoch: 3, Steps: 206 | Train Loss: 0.8603983 Vali Loss: 1.1278280 Test Loss: 0.8262371
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8460457
	speed: 0.0235s/iter; left time: 31.4983s
	iters: 200, epoch: 4 | loss: 0.8319257
	speed: 0.0182s/iter; left time: 22.6827s
Epoch: 4 cost time: 3.804795742034912
Epoch: 4, Steps: 206 | Train Loss: 0.8329104 Vali Loss: 1.1226449 Test Loss: 0.8296453
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7728368
	speed: 0.0184s/iter; left time: 20.9396s
	iters: 200, epoch: 5 | loss: 0.8039779
	speed: 0.0154s/iter; left time: 15.9490s
Epoch: 5 cost time: 3.2313733100891113
Epoch: 5, Steps: 206 | Train Loss: 0.8201309 Vali Loss: 1.1748414 Test Loss: 0.8481143
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7860443
	speed: 0.0146s/iter; left time: 13.5611s
	iters: 200, epoch: 6 | loss: 0.7816828
	speed: 0.0123s/iter; left time: 10.2269s
Epoch: 6 cost time: 2.6937859058380127
Epoch: 6, Steps: 206 | Train Loss: 0.8111474 Vali Loss: 1.1581008 Test Loss: 0.8451736
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8182271122932434, mae:0.7241824269294739
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9230627
	speed: 0.0171s/iter; left time: 33.6266s
	iters: 200, epoch: 1 | loss: 0.9190475
	speed: 0.0156s/iter; left time: 29.0611s
Epoch: 1 cost time: 3.334481716156006
Epoch: 1, Steps: 206 | Train Loss: 0.9317232 Vali Loss: 1.0705274 Test Loss: 0.8050163
Validation loss decreased (inf --> 1.070527).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9557484
	speed: 0.0180s/iter; left time: 31.6642s
	iters: 200, epoch: 2 | loss: 0.8838869
	speed: 0.0159s/iter; left time: 26.3128s
Epoch: 2 cost time: 3.3684370517730713
Epoch: 2, Steps: 206 | Train Loss: 0.8902596 Vali Loss: 1.0874565 Test Loss: 0.8394589
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8597394
	speed: 0.0208s/iter; left time: 32.2011s
	iters: 200, epoch: 3 | loss: 0.7779494
	speed: 0.0181s/iter; left time: 26.2328s
Epoch: 3 cost time: 3.8402411937713623
Epoch: 3, Steps: 206 | Train Loss: 0.8592945 Vali Loss: 1.0908235 Test Loss: 0.8434531
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8218078
	speed: 0.0156s/iter; left time: 20.9068s
	iters: 200, epoch: 4 | loss: 0.7832615
	speed: 0.0153s/iter; left time: 18.9662s
Epoch: 4 cost time: 3.2441720962524414
Epoch: 4, Steps: 206 | Train Loss: 0.8372924 Vali Loss: 1.0786393 Test Loss: 0.8231225
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8100292
	speed: 0.0147s/iter; left time: 16.6687s
	iters: 200, epoch: 5 | loss: 0.8652567
	speed: 0.0121s/iter; left time: 12.5493s
Epoch: 5 cost time: 2.5798091888427734
Epoch: 5, Steps: 206 | Train Loss: 0.8259896 Vali Loss: 1.0818963 Test Loss: 0.8334922
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8689509
	speed: 0.0146s/iter; left time: 13.6092s
	iters: 200, epoch: 6 | loss: 0.8026906
	speed: 0.0134s/iter; left time: 11.1634s
Epoch: 6 cost time: 2.8622303009033203
Epoch: 6, Steps: 206 | Train Loss: 0.8186001 Vali Loss: 1.0673305 Test Loss: 0.8338689
Validation loss decreased (1.070527 --> 1.067330).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8676376
	speed: 0.0175s/iter; left time: 12.6619s
	iters: 200, epoch: 7 | loss: 0.8260109
	speed: 0.0159s/iter; left time: 9.9305s
Epoch: 7 cost time: 3.350287914276123
Epoch: 7, Steps: 206 | Train Loss: 0.8164043 Vali Loss: 1.0845518 Test Loss: 0.8385450
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8173252
	speed: 0.0164s/iter; left time: 8.4893s
	iters: 200, epoch: 8 | loss: 0.8343720
	speed: 0.0188s/iter; left time: 7.8753s
Epoch: 8 cost time: 3.911716938018799
Epoch: 8, Steps: 206 | Train Loss: 0.8160834 Vali Loss: 1.0821307 Test Loss: 0.8387313
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7724351
	speed: 0.0141s/iter; left time: 4.4017s
	iters: 200, epoch: 9 | loss: 0.8775142
	speed: 0.0119s/iter; left time: 2.5330s
Epoch: 9 cost time: 2.5785019397735596
Epoch: 9, Steps: 206 | Train Loss: 0.8139379 Vali Loss: 1.0812851 Test Loss: 0.8389180
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8936079
	speed: 0.0166s/iter; left time: 1.7766s
	iters: 200, epoch: 10 | loss: 0.8816081
	speed: 0.0158s/iter; left time: 0.1108s
Epoch: 10 cost time: 3.3808772563934326
Epoch: 10, Steps: 206 | Train Loss: 0.8131692 Vali Loss: 1.0810833 Test Loss: 0.8388072
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8338686227798462, mae:0.7244214415550232
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9787719
	speed: 0.0208s/iter; left time: 40.7999s
	iters: 200, epoch: 1 | loss: 0.9761215
	speed: 0.0179s/iter; left time: 33.2246s
Epoch: 1 cost time: 3.7299611568450928
Epoch: 1, Steps: 206 | Train Loss: 0.9339280 Vali Loss: 1.0635598 Test Loss: 0.8082543
Validation loss decreased (inf --> 1.063560).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8710412
	speed: 0.0186s/iter; left time: 32.6548s
	iters: 200, epoch: 2 | loss: 0.9269459
	speed: 0.0157s/iter; left time: 25.9544s
Epoch: 2 cost time: 3.359011173248291
Epoch: 2, Steps: 206 | Train Loss: 0.8964451 Vali Loss: 1.0937072 Test Loss: 0.8195627
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9080642
	speed: 0.0149s/iter; left time: 23.0728s
	iters: 200, epoch: 3 | loss: 0.8523371
	speed: 0.0122s/iter; left time: 17.6608s
Epoch: 3 cost time: 2.588597059249878
Epoch: 3, Steps: 206 | Train Loss: 0.8681054 Vali Loss: 1.1797199 Test Loss: 0.8535069
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7846293
	speed: 0.0170s/iter; left time: 22.8540s
	iters: 200, epoch: 4 | loss: 0.8670793
	speed: 0.0161s/iter; left time: 20.0373s
Epoch: 4 cost time: 3.430483341217041
Epoch: 4, Steps: 206 | Train Loss: 0.8487688 Vali Loss: 1.1755122 Test Loss: 0.8463166
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8526873
	speed: 0.0246s/iter; left time: 27.9636s
	iters: 200, epoch: 5 | loss: 0.8452212
	speed: 0.0188s/iter; left time: 19.4745s
Epoch: 5 cost time: 3.901794910430908
Epoch: 5, Steps: 206 | Train Loss: 0.8379276 Vali Loss: 1.1966470 Test Loss: 0.8660690
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8281735
	speed: 0.0220s/iter; left time: 20.4482s
	iters: 200, epoch: 6 | loss: 0.8567584
	speed: 0.0179s/iter; left time: 14.8502s
Epoch: 6 cost time: 3.761833429336548
Epoch: 6, Steps: 206 | Train Loss: 0.8301889 Vali Loss: 1.2021030 Test Loss: 0.8635370
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8082544803619385, mae:0.720209538936615
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1422838
	speed: 0.0285s/iter; left time: 52.3883s
Epoch: 1 cost time: 4.553992509841919
Epoch: 1, Steps: 194 | Train Loss: 1.1295736 Vali Loss: 1.5330012 Test Loss: 0.9029011
Validation loss decreased (inf --> 1.533001).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0518645
	speed: 0.0211s/iter; left time: 34.8287s
Epoch: 2 cost time: 3.6057755947113037
Epoch: 2, Steps: 194 | Train Loss: 1.0842702 Vali Loss: 1.6140901 Test Loss: 0.9614866
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9838498
	speed: 0.0148s/iter; left time: 21.4646s
Epoch: 3 cost time: 2.9469196796417236
Epoch: 3, Steps: 194 | Train Loss: 1.0462187 Vali Loss: 1.4221270 Test Loss: 0.9972866
Validation loss decreased (1.533001 --> 1.422127).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9900613
	speed: 0.0205s/iter; left time: 25.7996s
Epoch: 4 cost time: 3.3570919036865234
Epoch: 4, Steps: 194 | Train Loss: 1.0193603 Vali Loss: 1.3543973 Test Loss: 1.0266873
Validation loss decreased (1.422127 --> 1.354397).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9606284
	speed: 0.0284s/iter; left time: 30.2868s
Epoch: 5 cost time: 4.692524671554565
Epoch: 5, Steps: 194 | Train Loss: 1.0047495 Vali Loss: 1.3417250 Test Loss: 1.0466807
Validation loss decreased (1.354397 --> 1.341725).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0649726
	speed: 0.0199s/iter; left time: 17.3293s
Epoch: 6 cost time: 3.4765267372131348
Epoch: 6, Steps: 194 | Train Loss: 0.9977403 Vali Loss: 1.3554751 Test Loss: 1.0616466
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8920826
	speed: 0.0154s/iter; left time: 10.4051s
Epoch: 7 cost time: 2.733386754989624
Epoch: 7, Steps: 194 | Train Loss: 0.9950395 Vali Loss: 1.3580494 Test Loss: 1.0605923
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9748151
	speed: 0.0142s/iter; left time: 6.8619s
Epoch: 8 cost time: 2.385204315185547
Epoch: 8, Steps: 194 | Train Loss: 0.9930682 Vali Loss: 1.3472924 Test Loss: 1.0615067
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9487537
	speed: 0.0195s/iter; left time: 5.6274s
Epoch: 9 cost time: 3.5286285877227783
Epoch: 9, Steps: 194 | Train Loss: 0.9916144 Vali Loss: 1.3443582 Test Loss: 1.0616292
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9228609
	speed: 0.0182s/iter; left time: 1.7331s
Epoch: 10 cost time: 3.2849574089050293
Epoch: 10, Steps: 194 | Train Loss: 0.9924519 Vali Loss: 1.3436201 Test Loss: 1.0621479
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0466806888580322, mae:0.8150737881660461
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1748179
	speed: 0.0251s/iter; left time: 46.2018s
Epoch: 1 cost time: 3.732175827026367
Epoch: 1, Steps: 194 | Train Loss: 1.1257081 Vali Loss: 1.5889711 Test Loss: 0.9331698
Validation loss decreased (inf --> 1.588971).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0958468
	speed: 0.0161s/iter; left time: 26.4762s
Epoch: 2 cost time: 2.5932090282440186
Epoch: 2, Steps: 194 | Train Loss: 1.0831603 Vali Loss: 1.6032279 Test Loss: 0.9986868
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0445131
	speed: 0.0174s/iter; left time: 25.3470s
Epoch: 3 cost time: 3.327608823776245
Epoch: 3, Steps: 194 | Train Loss: 1.0452518 Vali Loss: 1.4596806 Test Loss: 1.0315448
Validation loss decreased (1.588971 --> 1.459681).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0804591
	speed: 0.0181s/iter; left time: 22.7361s
Epoch: 4 cost time: 3.6601181030273438
Epoch: 4, Steps: 194 | Train Loss: 1.0211541 Vali Loss: 1.4100893 Test Loss: 1.0697196
Validation loss decreased (1.459681 --> 1.410089).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8901203
	speed: 0.0163s/iter; left time: 17.3390s
Epoch: 5 cost time: 3.144711494445801
Epoch: 5, Steps: 194 | Train Loss: 1.0075583 Vali Loss: 1.3784242 Test Loss: 1.0875963
Validation loss decreased (1.410089 --> 1.378424).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9834704
	speed: 0.0150s/iter; left time: 13.0406s
Epoch: 6 cost time: 2.506946325302124
Epoch: 6, Steps: 194 | Train Loss: 0.9992451 Vali Loss: 1.3766586 Test Loss: 1.0938636
Validation loss decreased (1.378424 --> 1.376659).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.1213024
	speed: 0.0153s/iter; left time: 10.3729s
Epoch: 7 cost time: 3.1157681941986084
Epoch: 7, Steps: 194 | Train Loss: 0.9959062 Vali Loss: 1.3649030 Test Loss: 1.1008914
Validation loss decreased (1.376659 --> 1.364903).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9235727
	speed: 0.0194s/iter; left time: 9.3939s
Epoch: 8 cost time: 3.4048502445220947
Epoch: 8, Steps: 194 | Train Loss: 0.9944827 Vali Loss: 1.3647885 Test Loss: 1.0991067
Validation loss decreased (1.364903 --> 1.364789).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0036274
	speed: 0.0197s/iter; left time: 5.6833s
Epoch: 9 cost time: 3.4977803230285645
Epoch: 9, Steps: 194 | Train Loss: 0.9919727 Vali Loss: 1.3651122 Test Loss: 1.1003319
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9473174
	speed: 0.0173s/iter; left time: 1.6426s
Epoch: 10 cost time: 2.985651969909668
Epoch: 10, Steps: 194 | Train Loss: 0.9921425 Vali Loss: 1.3658605 Test Loss: 1.1007785
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0991066694259644, mae:0.8396764397621155
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1524818
	speed: 0.0201s/iter; left time: 37.0700s
Epoch: 1 cost time: 3.3055150508880615
Epoch: 1, Steps: 194 | Train Loss: 1.1277007 Vali Loss: 1.5746157 Test Loss: 0.9129626
Validation loss decreased (inf --> 1.574616).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1044749
	speed: 0.0246s/iter; left time: 40.5838s
Epoch: 2 cost time: 4.078457355499268
Epoch: 2, Steps: 194 | Train Loss: 1.0861899 Vali Loss: 1.5455564 Test Loss: 0.9522849
Validation loss decreased (1.574616 --> 1.545556).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0369321
	speed: 0.0192s/iter; left time: 27.9502s
Epoch: 3 cost time: 3.9528963565826416
Epoch: 3, Steps: 194 | Train Loss: 1.0506099 Vali Loss: 1.3809290 Test Loss: 0.9904253
Validation loss decreased (1.545556 --> 1.380929).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0385420
	speed: 0.0187s/iter; left time: 23.5488s
Epoch: 4 cost time: 2.898895263671875
Epoch: 4, Steps: 194 | Train Loss: 1.0262703 Vali Loss: 1.3152909 Test Loss: 1.0153533
Validation loss decreased (1.380929 --> 1.315291).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0905906
	speed: 0.0181s/iter; left time: 19.2732s
Epoch: 5 cost time: 3.0228419303894043
Epoch: 5, Steps: 194 | Train Loss: 1.0087321 Vali Loss: 1.2597053 Test Loss: 1.0450647
Validation loss decreased (1.315291 --> 1.259705).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0141443
	speed: 0.0166s/iter; left time: 14.4782s
Epoch: 6 cost time: 2.6474995613098145
Epoch: 6, Steps: 194 | Train Loss: 1.0009411 Vali Loss: 1.2824807 Test Loss: 1.0504627
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9224787
	speed: 0.0174s/iter; left time: 11.7693s
Epoch: 7 cost time: 2.8166615962982178
Epoch: 7, Steps: 194 | Train Loss: 0.9945040 Vali Loss: 1.2760236 Test Loss: 1.0588834
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9997885
	speed: 0.0145s/iter; left time: 7.0034s
Epoch: 8 cost time: 2.735792636871338
Epoch: 8, Steps: 194 | Train Loss: 0.9941671 Vali Loss: 1.2788141 Test Loss: 1.0620215
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9961691
	speed: 0.0209s/iter; left time: 6.0276s
Epoch: 9 cost time: 3.5764992237091064
Epoch: 9, Steps: 194 | Train Loss: 0.9923062 Vali Loss: 1.2785550 Test Loss: 1.0641110
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0864097
	speed: 0.0158s/iter; left time: 1.5028s
Epoch: 10 cost time: 2.9190585613250732
Epoch: 10, Steps: 194 | Train Loss: 0.9921471 Vali Loss: 1.2779384 Test Loss: 1.0649294
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0450646877288818, mae:0.8157843947410583
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7315499
	speed: 0.0253s/iter; left time: 51.3320s
	iters: 200, epoch: 1 | loss: 0.7278828
	speed: 0.0175s/iter; left time: 33.8591s
Epoch: 1 cost time: 3.6908681392669678
Epoch: 1, Steps: 213 | Train Loss: 0.7326294 Vali Loss: 0.7336507 Test Loss: 0.6684273
Validation loss decreased (inf --> 0.733651).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7406904
	speed: 0.0251s/iter; left time: 45.7070s
	iters: 200, epoch: 2 | loss: 0.6925089
	speed: 0.0202s/iter; left time: 34.6655s
Epoch: 2 cost time: 4.2969582080841064
Epoch: 2, Steps: 213 | Train Loss: 0.7195468 Vali Loss: 0.6847201 Test Loss: 0.6624846
Validation loss decreased (0.733651 --> 0.684720).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6670944
	speed: 0.0216s/iter; left time: 34.7025s
	iters: 200, epoch: 3 | loss: 0.6954998
	speed: 0.0170s/iter; left time: 25.6399s
Epoch: 3 cost time: 3.696197748184204
Epoch: 3, Steps: 213 | Train Loss: 0.7038646 Vali Loss: 0.6994650 Test Loss: 0.6554855
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7528431
	speed: 0.0145s/iter; left time: 20.1985s
	iters: 200, epoch: 4 | loss: 0.6963059
	speed: 0.0127s/iter; left time: 16.4685s
Epoch: 4 cost time: 2.78857421875
Epoch: 4, Steps: 213 | Train Loss: 0.6890971 Vali Loss: 0.7107354 Test Loss: 0.6609963
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6387773
	speed: 0.0136s/iter; left time: 16.0862s
	iters: 200, epoch: 5 | loss: 0.6772024
	speed: 0.0127s/iter; left time: 13.7319s
Epoch: 5 cost time: 2.8233282566070557
Epoch: 5, Steps: 213 | Train Loss: 0.6823061 Vali Loss: 0.7248543 Test Loss: 0.6640501
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6831009
	speed: 0.0211s/iter; left time: 20.4051s
	iters: 200, epoch: 6 | loss: 0.6389948
	speed: 0.0172s/iter; left time: 14.8939s
Epoch: 6 cost time: 3.7727558612823486
Epoch: 6, Steps: 213 | Train Loss: 0.6804008 Vali Loss: 0.7149936 Test Loss: 0.6646494
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6341412
	speed: 0.0252s/iter; left time: 18.9482s
	iters: 200, epoch: 7 | loss: 0.6909365
	speed: 0.0209s/iter; left time: 13.6740s
Epoch: 7 cost time: 4.447986841201782
Epoch: 7, Steps: 213 | Train Loss: 0.6784132 Vali Loss: 0.7119129 Test Loss: 0.6648846
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6624846458435059, mae:0.6537206172943115
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6993071
	speed: 0.0188s/iter; left time: 38.1996s
	iters: 200, epoch: 1 | loss: 0.6706209
	speed: 0.0141s/iter; left time: 27.1845s
Epoch: 1 cost time: 3.086367607116699
Epoch: 1, Steps: 213 | Train Loss: 0.7323205 Vali Loss: 0.7079799 Test Loss: 0.6673806
Validation loss decreased (inf --> 0.707980).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7290800
	speed: 0.0209s/iter; left time: 38.0601s
	iters: 200, epoch: 2 | loss: 0.7213088
	speed: 0.0214s/iter; left time: 36.7689s
Epoch: 2 cost time: 4.648502588272095
Epoch: 2, Steps: 213 | Train Loss: 0.7193756 Vali Loss: 0.6976823 Test Loss: 0.6630099
Validation loss decreased (0.707980 --> 0.697682).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7060649
	speed: 0.0209s/iter; left time: 33.5217s
	iters: 200, epoch: 3 | loss: 0.7428383
	speed: 0.0183s/iter; left time: 27.5326s
Epoch: 3 cost time: 3.8936927318573
Epoch: 3, Steps: 213 | Train Loss: 0.6993621 Vali Loss: 0.6979133 Test Loss: 0.6587989
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6579099
	speed: 0.0208s/iter; left time: 29.0049s
	iters: 200, epoch: 4 | loss: 0.6530697
	speed: 0.0182s/iter; left time: 23.5376s
Epoch: 4 cost time: 3.8695085048675537
Epoch: 4, Steps: 213 | Train Loss: 0.6832109 Vali Loss: 0.7095415 Test Loss: 0.6618470
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6541874
	speed: 0.0122s/iter; left time: 14.4009s
	iters: 200, epoch: 5 | loss: 0.6239783
	speed: 0.0122s/iter; left time: 13.2047s
Epoch: 5 cost time: 2.6516637802124023
Epoch: 5, Steps: 213 | Train Loss: 0.6764390 Vali Loss: 0.7139227 Test Loss: 0.6650519
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6828799
	speed: 0.0179s/iter; left time: 17.2660s
	iters: 200, epoch: 6 | loss: 0.6711203
	speed: 0.0174s/iter; left time: 15.1086s
Epoch: 6 cost time: 3.7677834033966064
Epoch: 6, Steps: 213 | Train Loss: 0.6737653 Vali Loss: 0.7170564 Test Loss: 0.6663862
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6797742
	speed: 0.0245s/iter; left time: 18.4332s
	iters: 200, epoch: 7 | loss: 0.6854271
	speed: 0.0213s/iter; left time: 13.9239s
Epoch: 7 cost time: 4.534165620803833
Epoch: 7, Steps: 213 | Train Loss: 0.6729853 Vali Loss: 0.7215836 Test Loss: 0.6655567
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6630099415779114, mae:0.6533092856407166
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7443835
	speed: 0.0207s/iter; left time: 42.1304s
	iters: 200, epoch: 1 | loss: 0.6838511
	speed: 0.0173s/iter; left time: 33.3346s
Epoch: 1 cost time: 3.746124505996704
Epoch: 1, Steps: 213 | Train Loss: 0.7325444 Vali Loss: 0.6981712 Test Loss: 0.6725391
Validation loss decreased (inf --> 0.698171).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7048224
	speed: 0.0133s/iter; left time: 24.1471s
	iters: 200, epoch: 2 | loss: 0.7344105
	speed: 0.0152s/iter; left time: 26.1969s
Epoch: 2 cost time: 3.2979135513305664
Epoch: 2, Steps: 213 | Train Loss: 0.7166013 Vali Loss: 0.7115587 Test Loss: 0.6614807
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6771164
	speed: 0.0176s/iter; left time: 28.2613s
	iters: 200, epoch: 3 | loss: 0.6861821
	speed: 0.0174s/iter; left time: 26.1969s
Epoch: 3 cost time: 3.8395960330963135
Epoch: 3, Steps: 213 | Train Loss: 0.6987195 Vali Loss: 0.7036424 Test Loss: 0.6627321
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6754774
	speed: 0.0255s/iter; left time: 35.4872s
	iters: 200, epoch: 4 | loss: 0.6687334
	speed: 0.0209s/iter; left time: 27.0300s
Epoch: 4 cost time: 4.513679504394531
Epoch: 4, Steps: 213 | Train Loss: 0.6884705 Vali Loss: 0.7143148 Test Loss: 0.6666685
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7086123
	speed: 0.0157s/iter; left time: 18.4989s
	iters: 200, epoch: 5 | loss: 0.6616061
	speed: 0.0140s/iter; left time: 15.0978s
Epoch: 5 cost time: 3.067377805709839
Epoch: 5, Steps: 213 | Train Loss: 0.6829466 Vali Loss: 0.7302093 Test Loss: 0.6701192
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6572961
	speed: 0.0180s/iter; left time: 17.3516s
	iters: 200, epoch: 6 | loss: 0.7074446
	speed: 0.0162s/iter; left time: 13.9894s
Epoch: 6 cost time: 3.4616756439208984
Epoch: 6, Steps: 213 | Train Loss: 0.6802458 Vali Loss: 0.7212393 Test Loss: 0.6697871
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6725392937660217, mae:0.6583813428878784
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8585480
	speed: 0.0311s/iter; left time: 62.2985s
	iters: 200, epoch: 1 | loss: 0.8841194
	speed: 0.0223s/iter; left time: 42.4507s
Epoch: 1 cost time: 4.6048243045806885
Epoch: 1, Steps: 210 | Train Loss: 0.8245444 Vali Loss: 0.9109692 Test Loss: 0.7567533
Validation loss decreased (inf --> 0.910969).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7590075
	speed: 0.0180s/iter; left time: 32.2006s
	iters: 200, epoch: 2 | loss: 0.8570963
	speed: 0.0147s/iter; left time: 24.8098s
Epoch: 2 cost time: 3.064223289489746
Epoch: 2, Steps: 210 | Train Loss: 0.8050525 Vali Loss: 0.9528031 Test Loss: 0.7585030
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8000541
	speed: 0.0173s/iter; left time: 27.3781s
	iters: 200, epoch: 3 | loss: 0.7945646
	speed: 0.0145s/iter; left time: 21.4021s
Epoch: 3 cost time: 3.121236562728882
Epoch: 3, Steps: 210 | Train Loss: 0.7904796 Vali Loss: 0.9960514 Test Loss: 0.7710293
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7577475
	speed: 0.0172s/iter; left time: 23.5174s
	iters: 200, epoch: 4 | loss: 0.7565460
	speed: 0.0148s/iter; left time: 18.8199s
Epoch: 4 cost time: 3.2808074951171875
Epoch: 4, Steps: 210 | Train Loss: 0.7801159 Vali Loss: 0.9904194 Test Loss: 0.7718957
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8144326
	speed: 0.0189s/iter; left time: 21.9932s
	iters: 200, epoch: 5 | loss: 0.7597603
	speed: 0.0160s/iter; left time: 16.9447s
Epoch: 5 cost time: 3.396270513534546
Epoch: 5, Steps: 210 | Train Loss: 0.7738138 Vali Loss: 0.9975635 Test Loss: 0.7674550
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7552420
	speed: 0.0143s/iter; left time: 13.5788s
	iters: 200, epoch: 6 | loss: 0.8318710
	speed: 0.0124s/iter; left time: 10.5555s
Epoch: 6 cost time: 2.6983296871185303
Epoch: 6, Steps: 210 | Train Loss: 0.7693528 Vali Loss: 0.9943923 Test Loss: 0.7702331
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7567533850669861, mae:0.6965996623039246
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8777392
	speed: 0.0216s/iter; left time: 43.2531s
	iters: 200, epoch: 1 | loss: 0.7849044
	speed: 0.0181s/iter; left time: 34.3990s
Epoch: 1 cost time: 3.810894250869751
Epoch: 1, Steps: 210 | Train Loss: 0.8278538 Vali Loss: 0.8966277 Test Loss: 0.7406995
Validation loss decreased (inf --> 0.896628).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7853259
	speed: 0.0206s/iter; left time: 36.9575s
	iters: 200, epoch: 2 | loss: 0.8191465
	speed: 0.0217s/iter; left time: 36.7736s
Epoch: 2 cost time: 4.644041299819946
Epoch: 2, Steps: 210 | Train Loss: 0.8010408 Vali Loss: 0.9088869 Test Loss: 0.7417617
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7762780
	speed: 0.0159s/iter; left time: 25.1025s
	iters: 200, epoch: 3 | loss: 0.7875261
	speed: 0.0141s/iter; left time: 20.8775s
Epoch: 3 cost time: 3.052306890487671
Epoch: 3, Steps: 210 | Train Loss: 0.7730685 Vali Loss: 0.9482206 Test Loss: 0.7505640
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7704915
	speed: 0.0156s/iter; left time: 21.3850s
	iters: 200, epoch: 4 | loss: 0.7135215
	speed: 0.0138s/iter; left time: 17.5949s
Epoch: 4 cost time: 3.000986099243164
Epoch: 4, Steps: 210 | Train Loss: 0.7530567 Vali Loss: 0.9698789 Test Loss: 0.7613719
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7062947
	speed: 0.0182s/iter; left time: 21.1269s
	iters: 200, epoch: 5 | loss: 0.6835876
	speed: 0.0165s/iter; left time: 17.5072s
Epoch: 5 cost time: 3.565009593963623
Epoch: 5, Steps: 210 | Train Loss: 0.7414262 Vali Loss: 0.9656090 Test Loss: 0.7707708
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7807603
	speed: 0.0174s/iter; left time: 16.5846s
	iters: 200, epoch: 6 | loss: 0.7098931
	speed: 0.0165s/iter; left time: 14.0840s
Epoch: 6 cost time: 3.6677725315093994
Epoch: 6, Steps: 210 | Train Loss: 0.7369816 Vali Loss: 0.9786015 Test Loss: 0.7700661
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7406995892524719, mae:0.6904452443122864
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8681555
	speed: 0.0166s/iter; left time: 33.2989s
	iters: 200, epoch: 1 | loss: 0.8006217
	speed: 0.0155s/iter; left time: 29.4983s
Epoch: 1 cost time: 3.345855951309204
Epoch: 1, Steps: 210 | Train Loss: 0.8248673 Vali Loss: 0.9214738 Test Loss: 0.7514307
Validation loss decreased (inf --> 0.921474).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7781808
	speed: 0.0188s/iter; left time: 33.6050s
	iters: 200, epoch: 2 | loss: 0.8050952
	speed: 0.0157s/iter; left time: 26.4856s
Epoch: 2 cost time: 3.387022018432617
Epoch: 2, Steps: 210 | Train Loss: 0.8004656 Vali Loss: 0.9511575 Test Loss: 0.7527942
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7138693
	speed: 0.0206s/iter; left time: 32.5914s
	iters: 200, epoch: 3 | loss: 0.7500439
	speed: 0.0176s/iter; left time: 26.0823s
Epoch: 3 cost time: 3.808103084564209
Epoch: 3, Steps: 210 | Train Loss: 0.7775030 Vali Loss: 0.9930943 Test Loss: 0.7701408
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7504188
	speed: 0.0175s/iter; left time: 23.9582s
	iters: 200, epoch: 4 | loss: 0.7788972
	speed: 0.0153s/iter; left time: 19.4993s
Epoch: 4 cost time: 3.2920031547546387
Epoch: 4, Steps: 210 | Train Loss: 0.7574672 Vali Loss: 1.0217872 Test Loss: 0.7765131
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7083851
	speed: 0.0189s/iter; left time: 21.9577s
	iters: 200, epoch: 5 | loss: 0.7300360
	speed: 0.0156s/iter; left time: 16.5071s
Epoch: 5 cost time: 3.3413052558898926
Epoch: 5, Steps: 210 | Train Loss: 0.7460178 Vali Loss: 1.0243142 Test Loss: 0.7704610
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7574784
	speed: 0.0150s/iter; left time: 14.2896s
	iters: 200, epoch: 6 | loss: 0.7433687
	speed: 0.0130s/iter; left time: 11.0241s
Epoch: 6 cost time: 2.797140598297119
Epoch: 6, Steps: 210 | Train Loss: 0.7399410 Vali Loss: 1.0362509 Test Loss: 0.7795367
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.7514306902885437, mae:0.6950848698616028
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9170286
	speed: 0.0328s/iter; left time: 64.3395s
	iters: 200, epoch: 1 | loss: 0.9580976
	speed: 0.0230s/iter; left time: 42.7921s
Epoch: 1 cost time: 4.739017724990845
Epoch: 1, Steps: 206 | Train Loss: 0.9372400 Vali Loss: 1.1154177 Test Loss: 0.8434963
Validation loss decreased (inf --> 1.115418).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8799112
	speed: 0.0211s/iter; left time: 37.0234s
	iters: 200, epoch: 2 | loss: 0.9112160
	speed: 0.0183s/iter; left time: 30.2072s
Epoch: 2 cost time: 3.8263728618621826
Epoch: 2, Steps: 206 | Train Loss: 0.9026825 Vali Loss: 1.1232572 Test Loss: 0.8213754
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8864298
	speed: 0.0161s/iter; left time: 24.9611s
	iters: 200, epoch: 3 | loss: 0.8724075
	speed: 0.0210s/iter; left time: 30.4914s
Epoch: 3 cost time: 4.3717451095581055
Epoch: 3, Steps: 206 | Train Loss: 0.8753037 Vali Loss: 1.1571813 Test Loss: 0.8332692
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8064163
	speed: 0.0222s/iter; left time: 29.7819s
	iters: 200, epoch: 4 | loss: 0.8810564
	speed: 0.0185s/iter; left time: 23.0202s
Epoch: 4 cost time: 3.865615129470825
Epoch: 4, Steps: 206 | Train Loss: 0.8544576 Vali Loss: 1.1011068 Test Loss: 0.8284922
Validation loss decreased (1.115418 --> 1.101107).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8813530
	speed: 0.0156s/iter; left time: 17.7429s
	iters: 200, epoch: 5 | loss: 0.8217645
	speed: 0.0120s/iter; left time: 12.3987s
Epoch: 5 cost time: 2.607227087020874
Epoch: 5, Steps: 206 | Train Loss: 0.8422639 Vali Loss: 1.1066214 Test Loss: 0.8374315
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8042772
	speed: 0.0162s/iter; left time: 15.0850s
	iters: 200, epoch: 6 | loss: 0.7922313
	speed: 0.0150s/iter; left time: 12.5048s
Epoch: 6 cost time: 3.178118944168091
Epoch: 6, Steps: 206 | Train Loss: 0.8359359 Vali Loss: 1.0910029 Test Loss: 0.8379322
Validation loss decreased (1.101107 --> 1.091003).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8474929
	speed: 0.0195s/iter; left time: 14.1709s
	iters: 200, epoch: 7 | loss: 0.7765287
	speed: 0.0173s/iter; left time: 10.8399s
Epoch: 7 cost time: 3.658160448074341
Epoch: 7, Steps: 206 | Train Loss: 0.8328245 Vali Loss: 1.0921116 Test Loss: 0.8411964
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8037945
	speed: 0.0232s/iter; left time: 12.0204s
	iters: 200, epoch: 8 | loss: 0.8226190
	speed: 0.0200s/iter; left time: 8.3832s
Epoch: 8 cost time: 4.190072774887085
Epoch: 8, Steps: 206 | Train Loss: 0.8318609 Vali Loss: 1.0971584 Test Loss: 0.8409188
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8111069
	speed: 0.0197s/iter; left time: 6.1794s
	iters: 200, epoch: 9 | loss: 0.7930233
	speed: 0.0173s/iter; left time: 3.6937s
Epoch: 9 cost time: 3.5903215408325195
Epoch: 9, Steps: 206 | Train Loss: 0.8294252 Vali Loss: 1.0989271 Test Loss: 0.8418931
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8045829
	speed: 0.0193s/iter; left time: 2.0695s
	iters: 200, epoch: 10 | loss: 0.8640277
	speed: 0.0182s/iter; left time: 0.1272s
Epoch: 10 cost time: 3.8223049640655518
Epoch: 10, Steps: 206 | Train Loss: 0.8292430 Vali Loss: 1.0997069 Test Loss: 0.8422515
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8379321098327637, mae:0.7279996275901794
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8688907
	speed: 0.0164s/iter; left time: 32.2073s
	iters: 200, epoch: 1 | loss: 0.8803114
	speed: 0.0166s/iter; left time: 30.9195s
Epoch: 1 cost time: 3.502910614013672
Epoch: 1, Steps: 206 | Train Loss: 0.9384422 Vali Loss: 1.1024495 Test Loss: 0.8404733
Validation loss decreased (inf --> 1.102450).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9028599
	speed: 0.0166s/iter; left time: 29.1232s
	iters: 200, epoch: 2 | loss: 0.8709153
	speed: 0.0149s/iter; left time: 24.7192s
Epoch: 2 cost time: 3.1543242931365967
Epoch: 2, Steps: 206 | Train Loss: 0.9004175 Vali Loss: 1.0695666 Test Loss: 0.8107682
Validation loss decreased (1.102450 --> 1.069567).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8720049
	speed: 0.0172s/iter; left time: 26.7137s
	iters: 200, epoch: 3 | loss: 0.8575689
	speed: 0.0137s/iter; left time: 19.8972s
Epoch: 3 cost time: 2.8732404708862305
Epoch: 3, Steps: 206 | Train Loss: 0.8667111 Vali Loss: 1.0670156 Test Loss: 0.8335268
Validation loss decreased (1.069567 --> 1.067016).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8050086
	speed: 0.0182s/iter; left time: 24.4196s
	iters: 200, epoch: 4 | loss: 0.7980160
	speed: 0.0185s/iter; left time: 22.9780s
Epoch: 4 cost time: 3.9692673683166504
Epoch: 4, Steps: 206 | Train Loss: 0.8395874 Vali Loss: 1.0361233 Test Loss: 0.8467349
Validation loss decreased (1.067016 --> 1.036123).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8287260
	speed: 0.0179s/iter; left time: 20.3516s
	iters: 200, epoch: 5 | loss: 0.8540813
	speed: 0.0176s/iter; left time: 18.2767s
Epoch: 5 cost time: 3.7198948860168457
Epoch: 5, Steps: 206 | Train Loss: 0.8257372 Vali Loss: 1.0355101 Test Loss: 0.8469841
Validation loss decreased (1.036123 --> 1.035510).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8054962
	speed: 0.0284s/iter; left time: 26.4859s
	iters: 200, epoch: 6 | loss: 0.7627575
	speed: 0.0231s/iter; left time: 19.1614s
Epoch: 6 cost time: 4.829272270202637
Epoch: 6, Steps: 206 | Train Loss: 0.8193473 Vali Loss: 1.0378866 Test Loss: 0.8456789
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8255866
	speed: 0.0164s/iter; left time: 11.8948s
	iters: 200, epoch: 7 | loss: 0.8287762
	speed: 0.0139s/iter; left time: 8.6661s
Epoch: 7 cost time: 2.945492744445801
Epoch: 7, Steps: 206 | Train Loss: 0.8144690 Vali Loss: 1.0435187 Test Loss: 0.8436532
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7834834
	speed: 0.0223s/iter; left time: 11.5807s
	iters: 200, epoch: 8 | loss: 0.8485943
	speed: 0.0183s/iter; left time: 7.6636s
Epoch: 8 cost time: 3.817366361618042
Epoch: 8, Steps: 206 | Train Loss: 0.8142409 Vali Loss: 1.0430244 Test Loss: 0.8443392
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8638558
	speed: 0.0154s/iter; left time: 4.8351s
	iters: 200, epoch: 9 | loss: 0.8609775
	speed: 0.0150s/iter; left time: 3.1870s
Epoch: 9 cost time: 3.195075035095215
Epoch: 9, Steps: 206 | Train Loss: 0.8111411 Vali Loss: 1.0404142 Test Loss: 0.8443100
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8057457
	speed: 0.0162s/iter; left time: 1.7379s
	iters: 200, epoch: 10 | loss: 0.7799486
	speed: 0.0170s/iter; left time: 0.1187s
Epoch: 10 cost time: 3.592961072921753
Epoch: 10, Steps: 206 | Train Loss: 0.8124323 Vali Loss: 1.0394715 Test Loss: 0.8443553
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8469840288162231, mae:0.7294281125068665
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9316017
	speed: 0.0161s/iter; left time: 31.5662s
	iters: 200, epoch: 1 | loss: 0.8547041
	speed: 0.0139s/iter; left time: 25.9030s
Epoch: 1 cost time: 3.048532485961914
Epoch: 1, Steps: 206 | Train Loss: 0.9333827 Vali Loss: 1.1397103 Test Loss: 0.8322457
Validation loss decreased (inf --> 1.139710).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8194263
	speed: 0.0174s/iter; left time: 30.6124s
	iters: 200, epoch: 2 | loss: 0.8715624
	speed: 0.0157s/iter; left time: 26.0070s
Epoch: 2 cost time: 3.3226540088653564
Epoch: 2, Steps: 206 | Train Loss: 0.8993296 Vali Loss: 1.1073116 Test Loss: 0.8245814
Validation loss decreased (1.139710 --> 1.107312).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8701666
	speed: 0.0223s/iter; left time: 34.5731s
	iters: 200, epoch: 3 | loss: 0.8123371
	speed: 0.0228s/iter; left time: 32.9809s
Epoch: 3 cost time: 4.748269319534302
Epoch: 3, Steps: 206 | Train Loss: 0.8748008 Vali Loss: 1.0913630 Test Loss: 0.8485430
Validation loss decreased (1.107312 --> 1.091363).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8956671
	speed: 0.0154s/iter; left time: 20.6876s
	iters: 200, epoch: 4 | loss: 0.8388205
	speed: 0.0136s/iter; left time: 16.9447s
Epoch: 4 cost time: 2.8817710876464844
Epoch: 4, Steps: 206 | Train Loss: 0.8512535 Vali Loss: 1.0928503 Test Loss: 0.8463054
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9237844
	speed: 0.0167s/iter; left time: 19.0366s
	iters: 200, epoch: 5 | loss: 0.8517175
	speed: 0.0144s/iter; left time: 14.9564s
Epoch: 5 cost time: 3.053292989730835
Epoch: 5, Steps: 206 | Train Loss: 0.8372138 Vali Loss: 1.0845342 Test Loss: 0.8597772
Validation loss decreased (1.091363 --> 1.084534).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8237216
	speed: 0.0145s/iter; left time: 13.4706s
	iters: 200, epoch: 6 | loss: 0.8835611
	speed: 0.0122s/iter; left time: 10.1659s
Epoch: 6 cost time: 2.600454807281494
Epoch: 6, Steps: 206 | Train Loss: 0.8279134 Vali Loss: 1.0936362 Test Loss: 0.8631761
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8399757
	speed: 0.0203s/iter; left time: 14.7034s
	iters: 200, epoch: 7 | loss: 0.8025098
	speed: 0.0170s/iter; left time: 10.6555s
Epoch: 7 cost time: 3.6076478958129883
Epoch: 7, Steps: 206 | Train Loss: 0.8245419 Vali Loss: 1.0885077 Test Loss: 0.8593009
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8559181
	speed: 0.0193s/iter; left time: 10.0312s
	iters: 200, epoch: 8 | loss: 0.8340406
	speed: 0.0172s/iter; left time: 7.1887s
Epoch: 8 cost time: 3.6327240467071533
Epoch: 8, Steps: 206 | Train Loss: 0.8223426 Vali Loss: 1.0917143 Test Loss: 0.8577186
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7831894
	speed: 0.0204s/iter; left time: 6.3872s
	iters: 200, epoch: 9 | loss: 0.8354557
	speed: 0.0175s/iter; left time: 3.7366s
Epoch: 9 cost time: 3.6855459213256836
Epoch: 9, Steps: 206 | Train Loss: 0.8201854 Vali Loss: 1.0915339 Test Loss: 0.8597935
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8470764
	speed: 0.0214s/iter; left time: 2.2880s
	iters: 200, epoch: 10 | loss: 0.8242511
	speed: 0.0164s/iter; left time: 0.1148s
Epoch: 10 cost time: 3.4314424991607666
Epoch: 10, Steps: 206 | Train Loss: 0.8210474 Vali Loss: 1.0925092 Test Loss: 0.8606914
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8597771525382996, mae:0.7369645237922668
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.0_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.0.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1076378
	speed: 0.0371s/iter; left time: 68.3311s
Epoch: 1 cost time: 4.831246852874756
Epoch: 1, Steps: 194 | Train Loss: 1.1287837 Vali Loss: 1.6409942 Test Loss: 0.9183537
Validation loss decreased (inf --> 1.640994).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0738094
	speed: 0.0149s/iter; left time: 24.4825s
Epoch: 2 cost time: 2.7179319858551025
Epoch: 2, Steps: 194 | Train Loss: 1.0884319 Vali Loss: 1.5589948 Test Loss: 0.9600766
Validation loss decreased (1.640994 --> 1.558995).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1725117
	speed: 0.0165s/iter; left time: 23.9872s
Epoch: 3 cost time: 2.818742513656616
Epoch: 3, Steps: 194 | Train Loss: 1.0538461 Vali Loss: 1.4324770 Test Loss: 0.9790862
Validation loss decreased (1.558995 --> 1.432477).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0925950
	speed: 0.0183s/iter; left time: 23.0462s
Epoch: 4 cost time: 3.2601523399353027
Epoch: 4, Steps: 194 | Train Loss: 1.0285704 Vali Loss: 1.4673560 Test Loss: 1.0051879
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0449058
	speed: 0.0152s/iter; left time: 16.1956s
Epoch: 5 cost time: 2.8785548210144043
Epoch: 5, Steps: 194 | Train Loss: 1.0135013 Vali Loss: 1.3948971 Test Loss: 1.0134734
Validation loss decreased (1.432477 --> 1.394897).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0496597
	speed: 0.0174s/iter; left time: 15.1749s
Epoch: 6 cost time: 3.255370855331421
Epoch: 6, Steps: 194 | Train Loss: 1.0062497 Vali Loss: 1.4122356 Test Loss: 1.0225927
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0309786
	speed: 0.0220s/iter; left time: 14.9118s
Epoch: 7 cost time: 4.135354280471802
Epoch: 7, Steps: 194 | Train Loss: 1.0014534 Vali Loss: 1.3827939 Test Loss: 1.0226742
Validation loss decreased (1.394897 --> 1.382794).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9792705
	speed: 0.0148s/iter; left time: 7.1252s
Epoch: 8 cost time: 2.542776346206665
Epoch: 8, Steps: 194 | Train Loss: 1.0003080 Vali Loss: 1.3896879 Test Loss: 1.0236852
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9391467
	speed: 0.0179s/iter; left time: 5.1859s
Epoch: 9 cost time: 3.2413582801818848
Epoch: 9, Steps: 194 | Train Loss: 0.9997218 Vali Loss: 1.3959160 Test Loss: 1.0251843
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0199533
	speed: 0.0184s/iter; left time: 1.7435s
Epoch: 10 cost time: 3.187547206878662
Epoch: 10, Steps: 194 | Train Loss: 0.9986712 Vali Loss: 1.3934474 Test Loss: 1.0256803
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0226742029190063, mae:0.8074450492858887
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1589305
	speed: 0.0191s/iter; left time: 35.2007s
Epoch: 1 cost time: 3.466135025024414
Epoch: 1, Steps: 194 | Train Loss: 1.1309915 Vali Loss: 1.6691233 Test Loss: 0.9078004
Validation loss decreased (inf --> 1.669123).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0516472
	speed: 0.0150s/iter; left time: 24.7258s
Epoch: 2 cost time: 2.740854501724243
Epoch: 2, Steps: 194 | Train Loss: 1.0895037 Vali Loss: 1.5894558 Test Loss: 0.9164900
Validation loss decreased (1.669123 --> 1.589456).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0790299
	speed: 0.0167s/iter; left time: 24.2731s
Epoch: 3 cost time: 3.344637393951416
Epoch: 3, Steps: 194 | Train Loss: 1.0530825 Vali Loss: 1.4841274 Test Loss: 0.9445788
Validation loss decreased (1.589456 --> 1.484127).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0419906
	speed: 0.0158s/iter; left time: 19.8615s
Epoch: 4 cost time: 3.015608310699463
Epoch: 4, Steps: 194 | Train Loss: 1.0251524 Vali Loss: 1.3086262 Test Loss: 0.9913685
Validation loss decreased (1.484127 --> 1.308626).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0557485
	speed: 0.0222s/iter; left time: 23.6888s
Epoch: 5 cost time: 3.509063959121704
Epoch: 5, Steps: 194 | Train Loss: 1.0108855 Vali Loss: 1.3524935 Test Loss: 1.0223169
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0554270
	speed: 0.0159s/iter; left time: 13.8406s
Epoch: 6 cost time: 2.4726130962371826
Epoch: 6, Steps: 194 | Train Loss: 1.0025440 Vali Loss: 1.2592095 Test Loss: 1.0321618
Validation loss decreased (1.308626 --> 1.259210).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9957060
	speed: 0.0164s/iter; left time: 11.1205s
Epoch: 7 cost time: 2.7058048248291016
Epoch: 7, Steps: 194 | Train Loss: 0.9985553 Vali Loss: 1.2993907 Test Loss: 1.0399693
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9194129
	speed: 0.0173s/iter; left time: 8.3510s
Epoch: 8 cost time: 3.3119702339172363
Epoch: 8, Steps: 194 | Train Loss: 0.9962787 Vali Loss: 1.2813441 Test Loss: 1.0435162
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0302994
	speed: 0.0170s/iter; left time: 4.9065s
Epoch: 9 cost time: 3.09184193611145
Epoch: 9, Steps: 194 | Train Loss: 0.9948578 Vali Loss: 1.2885754 Test Loss: 1.0458835
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9551989
	speed: 0.0187s/iter; left time: 1.7739s
Epoch: 10 cost time: 3.349609851837158
Epoch: 10, Steps: 194 | Train Loss: 0.9938747 Vali Loss: 1.2866957 Test Loss: 1.0469190
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0321617126464844, mae:0.8116679787635803
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1583236
	speed: 0.0161s/iter; left time: 29.7199s
Epoch: 1 cost time: 2.887057065963745
Epoch: 1, Steps: 194 | Train Loss: 1.1303222 Vali Loss: 1.6009365 Test Loss: 0.9185737
Validation loss decreased (inf --> 1.600937).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1028125
	speed: 0.0244s/iter; left time: 40.2345s
Epoch: 2 cost time: 4.067697763442993
Epoch: 2, Steps: 194 | Train Loss: 1.0905013 Vali Loss: 1.5155896 Test Loss: 0.9434879
Validation loss decreased (1.600937 --> 1.515590).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1671321
	speed: 0.0251s/iter; left time: 36.4919s
Epoch: 3 cost time: 3.923647880554199
Epoch: 3, Steps: 194 | Train Loss: 1.0538499 Vali Loss: 1.4581915 Test Loss: 0.9646707
Validation loss decreased (1.515590 --> 1.458192).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0594782
	speed: 0.0177s/iter; left time: 22.2717s
Epoch: 4 cost time: 3.3822498321533203
Epoch: 4, Steps: 194 | Train Loss: 1.0305868 Vali Loss: 1.4171172 Test Loss: 1.0041811
Validation loss decreased (1.458192 --> 1.417117).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0796826
	speed: 0.0197s/iter; left time: 20.9554s
Epoch: 5 cost time: 3.063861131668091
Epoch: 5, Steps: 194 | Train Loss: 1.0164012 Vali Loss: 1.3566655 Test Loss: 1.0141590
Validation loss decreased (1.417117 --> 1.356665).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0644516
	speed: 0.0157s/iter; left time: 13.7177s
Epoch: 6 cost time: 2.644496202468872
Epoch: 6, Steps: 194 | Train Loss: 1.0090430 Vali Loss: 1.3582245 Test Loss: 1.0201728
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0307709
	speed: 0.0230s/iter; left time: 15.5758s
Epoch: 7 cost time: 4.321352481842041
Epoch: 7, Steps: 194 | Train Loss: 1.0036593 Vali Loss: 1.3502153 Test Loss: 1.0294902
Validation loss decreased (1.356665 --> 1.350215).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9305142
	speed: 0.0200s/iter; left time: 9.6624s
Epoch: 8 cost time: 3.328930377960205
Epoch: 8, Steps: 194 | Train Loss: 1.0024328 Vali Loss: 1.3268332 Test Loss: 1.0301622
Validation loss decreased (1.350215 --> 1.326833).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0279733
	speed: 0.0210s/iter; left time: 6.0557s
Epoch: 9 cost time: 3.565812826156616
Epoch: 9, Steps: 194 | Train Loss: 1.0019704 Vali Loss: 1.3311787 Test Loss: 1.0315695
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9549211
	speed: 0.0150s/iter; left time: 1.4280s
Epoch: 10 cost time: 2.3951711654663086
Epoch: 10, Steps: 194 | Train Loss: 1.0012752 Vali Loss: 1.3305571 Test Loss: 1.0316672
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.0_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0301620960235596, mae:0.8106642365455627
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0276076
	speed: 0.0329s/iter; left time: 66.8296s
	iters: 200, epoch: 1 | loss: 1.0285778
	speed: 0.0232s/iter; left time: 44.7096s
Epoch: 1 cost time: 4.900440454483032
Epoch: 1, Steps: 213 | Train Loss: 1.0281195 Vali Loss: 1.0496792 Test Loss: 1.0407737
Validation loss decreased (inf --> 1.049679).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0280846
	speed: 0.0203s/iter; left time: 36.9304s
	iters: 200, epoch: 2 | loss: 1.0641575
	speed: 0.0174s/iter; left time: 29.9718s
Epoch: 2 cost time: 3.685171604156494
Epoch: 2, Steps: 213 | Train Loss: 1.0195060 Vali Loss: 1.0505853 Test Loss: 1.0405928
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9927701
	speed: 0.0168s/iter; left time: 26.9242s
	iters: 200, epoch: 3 | loss: 0.9700242
	speed: 0.0135s/iter; left time: 20.3085s
Epoch: 3 cost time: 2.939166784286499
Epoch: 3, Steps: 213 | Train Loss: 1.0160387 Vali Loss: 1.0497134 Test Loss: 1.0409162
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9917511
	speed: 0.0213s/iter; left time: 29.5817s
	iters: 200, epoch: 4 | loss: 1.0227120
	speed: 0.0187s/iter; left time: 24.1686s
Epoch: 4 cost time: 4.022241115570068
Epoch: 4, Steps: 213 | Train Loss: 1.0132659 Vali Loss: 1.0535293 Test Loss: 1.0408342
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0159969
	speed: 0.0178s/iter; left time: 20.9644s
	iters: 200, epoch: 5 | loss: 0.9928070
	speed: 0.0159s/iter; left time: 17.2078s
Epoch: 5 cost time: 3.4630954265594482
Epoch: 5, Steps: 213 | Train Loss: 1.0109753 Vali Loss: 1.0536669 Test Loss: 1.0419468
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0359154
	speed: 0.0232s/iter; left time: 22.4506s
	iters: 200, epoch: 6 | loss: 1.0239640
	speed: 0.0178s/iter; left time: 15.4009s
Epoch: 6 cost time: 3.7155723571777344
Epoch: 6, Steps: 213 | Train Loss: 1.0097596 Vali Loss: 1.0518154 Test Loss: 1.0426743
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0407737493515015, mae:0.8184165954589844
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0458498
	speed: 0.0191s/iter; left time: 38.7080s
	iters: 200, epoch: 1 | loss: 0.9786374
	speed: 0.0164s/iter; left time: 31.7074s
Epoch: 1 cost time: 3.5535800457000732
Epoch: 1, Steps: 213 | Train Loss: 1.0258740 Vali Loss: 1.0507144 Test Loss: 1.0396296
Validation loss decreased (inf --> 1.050714).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0250963
	speed: 0.0145s/iter; left time: 26.3501s
	iters: 200, epoch: 2 | loss: 0.9822971
	speed: 0.0157s/iter; left time: 26.9255s
Epoch: 2 cost time: 3.431727647781372
Epoch: 2, Steps: 213 | Train Loss: 1.0202161 Vali Loss: 1.0512680 Test Loss: 1.0400054
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0120847
	speed: 0.0165s/iter; left time: 26.4565s
	iters: 200, epoch: 3 | loss: 1.0253158
	speed: 0.0156s/iter; left time: 23.4212s
Epoch: 3 cost time: 3.428133010864258
Epoch: 3, Steps: 213 | Train Loss: 1.0176782 Vali Loss: 1.0498734 Test Loss: 1.0393975
Validation loss decreased (1.050714 --> 1.049873).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0154804
	speed: 0.0157s/iter; left time: 21.8099s
	iters: 200, epoch: 4 | loss: 1.0093076
	speed: 0.0152s/iter; left time: 19.6119s
Epoch: 4 cost time: 3.337257146835327
Epoch: 4, Steps: 213 | Train Loss: 1.0153315 Vali Loss: 1.0511817 Test Loss: 1.0401659
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0016468
	speed: 0.0237s/iter; left time: 27.9680s
	iters: 200, epoch: 5 | loss: 1.0302451
	speed: 0.0244s/iter; left time: 26.3355s
Epoch: 5 cost time: 5.147769212722778
Epoch: 5, Steps: 213 | Train Loss: 1.0136486 Vali Loss: 1.0493542 Test Loss: 1.0408440
Validation loss decreased (1.049873 --> 1.049354).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0246855
	speed: 0.0271s/iter; left time: 26.2036s
	iters: 200, epoch: 6 | loss: 1.0133250
	speed: 0.0226s/iter; left time: 19.6063s
Epoch: 6 cost time: 4.800044059753418
Epoch: 6, Steps: 213 | Train Loss: 1.0126106 Vali Loss: 1.0498834 Test Loss: 1.0410695
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0137343
	speed: 0.0234s/iter; left time: 17.6364s
	iters: 200, epoch: 7 | loss: 1.0373425
	speed: 0.0191s/iter; left time: 12.4638s
Epoch: 7 cost time: 3.990471839904785
Epoch: 7, Steps: 213 | Train Loss: 1.0119450 Vali Loss: 1.0531876 Test Loss: 1.0412635
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0381008
	speed: 0.0170s/iter; left time: 9.1587s
	iters: 200, epoch: 8 | loss: 0.9596024
	speed: 0.0133s/iter; left time: 5.8645s
Epoch: 8 cost time: 2.8676834106445312
Epoch: 8, Steps: 213 | Train Loss: 1.0116224 Vali Loss: 1.0518135 Test Loss: 1.0414110
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9873136
	speed: 0.0124s/iter; left time: 4.0534s
	iters: 200, epoch: 9 | loss: 1.0154245
	speed: 0.0108s/iter; left time: 2.4435s
Epoch: 9 cost time: 2.335171937942505
Epoch: 9, Steps: 213 | Train Loss: 1.0114004 Vali Loss: 1.0532312 Test Loss: 1.0414671
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.9896164
	speed: 0.0118s/iter; left time: 1.3462s
	iters: 200, epoch: 10 | loss: 0.9950224
	speed: 0.0105s/iter; left time: 0.1472s
Epoch: 10 cost time: 2.306483507156372
Epoch: 10, Steps: 213 | Train Loss: 1.0115629 Vali Loss: 1.0502318 Test Loss: 1.0414842
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040844202041626, mae:0.8186887502670288
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0731099
	speed: 0.0223s/iter; left time: 45.3620s
	iters: 200, epoch: 1 | loss: 1.0693325
	speed: 0.0195s/iter; left time: 37.6640s
Epoch: 1 cost time: 4.21386456489563
Epoch: 1, Steps: 213 | Train Loss: 1.0293624 Vali Loss: 1.0503176 Test Loss: 1.0415651
Validation loss decreased (inf --> 1.050318).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0366149
	speed: 0.0190s/iter; left time: 34.6184s
	iters: 200, epoch: 2 | loss: 1.0053357
	speed: 0.0160s/iter; left time: 27.4429s
Epoch: 2 cost time: 3.4772212505340576
Epoch: 2, Steps: 213 | Train Loss: 1.0203393 Vali Loss: 1.0498762 Test Loss: 1.0406709
Validation loss decreased (1.050318 --> 1.049876).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0154406
	speed: 0.0183s/iter; left time: 29.3720s
	iters: 200, epoch: 3 | loss: 1.0413686
	speed: 0.0164s/iter; left time: 24.6766s
Epoch: 3 cost time: 3.59224271774292
Epoch: 3, Steps: 213 | Train Loss: 1.0167268 Vali Loss: 1.0505211 Test Loss: 1.0403800
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0077484
	speed: 0.0163s/iter; left time: 22.7297s
	iters: 200, epoch: 4 | loss: 1.0144081
	speed: 0.0134s/iter; left time: 17.3115s
Epoch: 4 cost time: 3.077218532562256
Epoch: 4, Steps: 213 | Train Loss: 1.0142269 Vali Loss: 1.0525352 Test Loss: 1.0417126
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0159266
	speed: 0.0152s/iter; left time: 17.9689s
	iters: 200, epoch: 5 | loss: 1.0180984
	speed: 0.0173s/iter; left time: 18.7052s
Epoch: 5 cost time: 3.9989984035491943
Epoch: 5, Steps: 213 | Train Loss: 1.0119938 Vali Loss: 1.0512789 Test Loss: 1.0420552
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0176401
	speed: 0.0219s/iter; left time: 21.1083s
	iters: 200, epoch: 6 | loss: 0.9725380
	speed: 0.0192s/iter; left time: 16.6680s
Epoch: 6 cost time: 4.179055452346802
Epoch: 6, Steps: 213 | Train Loss: 1.0105966 Vali Loss: 1.0498213 Test Loss: 1.0423228
Validation loss decreased (1.049876 --> 1.049821).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9900753
	speed: 0.0181s/iter; left time: 13.6528s
	iters: 200, epoch: 7 | loss: 1.0195003
	speed: 0.0157s/iter; left time: 10.2450s
Epoch: 7 cost time: 3.410733222961426
Epoch: 7, Steps: 213 | Train Loss: 1.0096128 Vali Loss: 1.0532482 Test Loss: 1.0428139
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0283349
	speed: 0.0160s/iter; left time: 8.6274s
	iters: 200, epoch: 8 | loss: 0.9847211
	speed: 0.0164s/iter; left time: 7.2084s
Epoch: 8 cost time: 3.5418014526367188
Epoch: 8, Steps: 213 | Train Loss: 1.0094382 Vali Loss: 1.0541022 Test Loss: 1.0430877
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.9657768
	speed: 0.0168s/iter; left time: 5.5092s
	iters: 200, epoch: 9 | loss: 1.0531678
	speed: 0.0174s/iter; left time: 3.9468s
Epoch: 9 cost time: 3.8765406608581543
Epoch: 9, Steps: 213 | Train Loss: 1.0093244 Vali Loss: 1.0541778 Test Loss: 1.0431995
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0221907
	speed: 0.0182s/iter; left time: 2.0746s
	iters: 200, epoch: 10 | loss: 1.0360000
	speed: 0.0220s/iter; left time: 0.3087s
Epoch: 10 cost time: 4.84582257270813
Epoch: 10, Steps: 213 | Train Loss: 1.0090323 Vali Loss: 1.0535480 Test Loss: 1.0432513
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0423227548599243, mae:0.8193672895431519
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0254650
	speed: 0.0320s/iter; left time: 64.0504s
	iters: 200, epoch: 1 | loss: 1.0554903
	speed: 0.0246s/iter; left time: 46.7402s
Epoch: 1 cost time: 5.167702674865723
Epoch: 1, Steps: 210 | Train Loss: 1.0331612 Vali Loss: 1.0605900 Test Loss: 1.0482566
Validation loss decreased (inf --> 1.060590).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0265187
	speed: 0.0211s/iter; left time: 37.8385s
	iters: 200, epoch: 2 | loss: 1.0514596
	speed: 0.0178s/iter; left time: 30.1001s
Epoch: 2 cost time: 3.8235867023468018
Epoch: 2, Steps: 210 | Train Loss: 1.0260557 Vali Loss: 1.0599220 Test Loss: 1.0478786
Validation loss decreased (1.060590 --> 1.059922).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0308459
	speed: 0.0185s/iter; left time: 29.2731s
	iters: 200, epoch: 3 | loss: 1.0143387
	speed: 0.0168s/iter; left time: 24.8907s
Epoch: 3 cost time: 3.506174087524414
Epoch: 3, Steps: 210 | Train Loss: 1.0230685 Vali Loss: 1.0577403 Test Loss: 1.0478556
Validation loss decreased (1.059922 --> 1.057740).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0061969
	speed: 0.0227s/iter; left time: 31.0815s
	iters: 200, epoch: 4 | loss: 0.9990370
	speed: 0.0188s/iter; left time: 23.9084s
Epoch: 4 cost time: 4.037724018096924
Epoch: 4, Steps: 210 | Train Loss: 1.0207028 Vali Loss: 1.0586888 Test Loss: 1.0491986
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0058763
	speed: 0.0181s/iter; left time: 21.0134s
	iters: 200, epoch: 5 | loss: 1.0302911
	speed: 0.0167s/iter; left time: 17.6802s
Epoch: 5 cost time: 3.6004741191864014
Epoch: 5, Steps: 210 | Train Loss: 1.0189641 Vali Loss: 1.0608779 Test Loss: 1.0505368
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0326761
	speed: 0.0173s/iter; left time: 16.4640s
	iters: 200, epoch: 6 | loss: 0.9983379
	speed: 0.0153s/iter; left time: 12.9928s
Epoch: 6 cost time: 3.2834768295288086
Epoch: 6, Steps: 210 | Train Loss: 1.0176380 Vali Loss: 1.0642399 Test Loss: 1.0514131
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0108838
	speed: 0.0109s/iter; left time: 8.1053s
	iters: 200, epoch: 7 | loss: 1.0265582
	speed: 0.0102s/iter; left time: 6.5529s
Epoch: 7 cost time: 2.315495252609253
Epoch: 7, Steps: 210 | Train Loss: 1.0169977 Vali Loss: 1.0620593 Test Loss: 1.0516731
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9860701
	speed: 0.0199s/iter; left time: 10.5506s
	iters: 200, epoch: 8 | loss: 0.9999357
	speed: 0.0175s/iter; left time: 7.5615s
Epoch: 8 cost time: 3.747427225112915
Epoch: 8, Steps: 210 | Train Loss: 1.0168179 Vali Loss: 1.0631245 Test Loss: 1.0518105
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0478556156158447, mae:0.8210927248001099
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0507232
	speed: 0.0198s/iter; left time: 39.6236s
	iters: 200, epoch: 1 | loss: 1.0525912
	speed: 0.0186s/iter; left time: 35.3102s
Epoch: 1 cost time: 3.961714267730713
Epoch: 1, Steps: 210 | Train Loss: 1.0356433 Vali Loss: 1.0607938 Test Loss: 1.0481515
Validation loss decreased (inf --> 1.060794).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0222386
	speed: 0.0192s/iter; left time: 34.3162s
	iters: 200, epoch: 2 | loss: 1.0253862
	speed: 0.0148s/iter; left time: 25.0824s
Epoch: 2 cost time: 3.1687850952148438
Epoch: 2, Steps: 210 | Train Loss: 1.0270195 Vali Loss: 1.0596194 Test Loss: 1.0487663
Validation loss decreased (1.060794 --> 1.059619).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0013837
	speed: 0.0191s/iter; left time: 30.2092s
	iters: 200, epoch: 3 | loss: 1.0370739
	speed: 0.0185s/iter; left time: 27.3767s
Epoch: 3 cost time: 3.921049118041992
Epoch: 3, Steps: 210 | Train Loss: 1.0240237 Vali Loss: 1.0583887 Test Loss: 1.0477359
Validation loss decreased (1.059619 --> 1.058389).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0262442
	speed: 0.0204s/iter; left time: 28.0295s
	iters: 200, epoch: 4 | loss: 1.0378733
	speed: 0.0174s/iter; left time: 22.0963s
Epoch: 4 cost time: 3.772700309753418
Epoch: 4, Steps: 210 | Train Loss: 1.0216470 Vali Loss: 1.0601740 Test Loss: 1.0491757
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0115275
	speed: 0.0227s/iter; left time: 26.3977s
	iters: 200, epoch: 5 | loss: 1.0086453
	speed: 0.0185s/iter; left time: 19.6283s
Epoch: 5 cost time: 3.9675309658050537
Epoch: 5, Steps: 210 | Train Loss: 1.0201212 Vali Loss: 1.0627635 Test Loss: 1.0500593
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0358367
	speed: 0.0142s/iter; left time: 13.4814s
	iters: 200, epoch: 6 | loss: 1.0251777
	speed: 0.0127s/iter; left time: 10.7957s
Epoch: 6 cost time: 2.857038736343384
Epoch: 6, Steps: 210 | Train Loss: 1.0191594 Vali Loss: 1.0616106 Test Loss: 1.0505717
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0127003
	speed: 0.0151s/iter; left time: 11.2209s
	iters: 200, epoch: 7 | loss: 1.0188529
	speed: 0.0142s/iter; left time: 9.1163s
Epoch: 7 cost time: 3.118309736251831
Epoch: 7, Steps: 210 | Train Loss: 1.0185119 Vali Loss: 1.0612874 Test Loss: 1.0509371
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0433171
	speed: 0.0187s/iter; left time: 9.9200s
	iters: 200, epoch: 8 | loss: 1.0030063
	speed: 0.0169s/iter; left time: 7.3036s
Epoch: 8 cost time: 3.6805341243743896
Epoch: 8, Steps: 210 | Train Loss: 1.0181080 Vali Loss: 1.0604446 Test Loss: 1.0511746
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0477359294891357, mae:0.8210497498512268
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0532365
	speed: 0.0216s/iter; left time: 43.2082s
	iters: 200, epoch: 1 | loss: 1.0043873
	speed: 0.0184s/iter; left time: 35.0352s
Epoch: 1 cost time: 3.9570040702819824
Epoch: 1, Steps: 210 | Train Loss: 1.0315524 Vali Loss: 1.0624484 Test Loss: 1.0469732
Validation loss decreased (inf --> 1.062448).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0315673
	speed: 0.0157s/iter; left time: 28.0378s
	iters: 200, epoch: 2 | loss: 1.0219291
	speed: 0.0137s/iter; left time: 23.2440s
Epoch: 2 cost time: 3.043766975402832
Epoch: 2, Steps: 210 | Train Loss: 1.0265958 Vali Loss: 1.0604796 Test Loss: 1.0467980
Validation loss decreased (1.062448 --> 1.060480).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0056070
	speed: 0.0180s/iter; left time: 28.4341s
	iters: 200, epoch: 3 | loss: 1.0314645
	speed: 0.0162s/iter; left time: 23.9865s
Epoch: 3 cost time: 3.4814319610595703
Epoch: 3, Steps: 210 | Train Loss: 1.0243518 Vali Loss: 1.0596428 Test Loss: 1.0470111
Validation loss decreased (1.060480 --> 1.059643).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0305638
	speed: 0.0184s/iter; left time: 25.2232s
	iters: 200, epoch: 4 | loss: 1.0104554
	speed: 0.0163s/iter; left time: 20.7167s
Epoch: 4 cost time: 3.5682942867279053
Epoch: 4, Steps: 210 | Train Loss: 1.0222350 Vali Loss: 1.0583209 Test Loss: 1.0477896
Validation loss decreased (1.059643 --> 1.058321).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0405642
	speed: 0.0214s/iter; left time: 24.8075s
	iters: 200, epoch: 5 | loss: 1.0365924
	speed: 0.0193s/iter; left time: 20.4472s
Epoch: 5 cost time: 4.081477165222168
Epoch: 5, Steps: 210 | Train Loss: 1.0207736 Vali Loss: 1.0605024 Test Loss: 1.0485777
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0284048
	speed: 0.0117s/iter; left time: 11.1117s
	iters: 200, epoch: 6 | loss: 1.0011524
	speed: 0.0110s/iter; left time: 9.3737s
Epoch: 6 cost time: 2.3988218307495117
Epoch: 6, Steps: 210 | Train Loss: 1.0198360 Vali Loss: 1.0618393 Test Loss: 1.0490122
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0187122
	speed: 0.0168s/iter; left time: 12.4479s
	iters: 200, epoch: 7 | loss: 1.0493308
	speed: 0.0153s/iter; left time: 9.7878s
Epoch: 7 cost time: 3.3556764125823975
Epoch: 7, Steps: 210 | Train Loss: 1.0193327 Vali Loss: 1.0581889 Test Loss: 1.0492718
Validation loss decreased (1.058321 --> 1.058189).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9920618
	speed: 0.0181s/iter; left time: 9.6264s
	iters: 200, epoch: 8 | loss: 1.0163956
	speed: 0.0159s/iter; left time: 6.8723s
Epoch: 8 cost time: 3.456817388534546
Epoch: 8, Steps: 210 | Train Loss: 1.0191725 Vali Loss: 1.0612270 Test Loss: 1.0493964
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0236456
	speed: 0.0216s/iter; left time: 6.9225s
	iters: 200, epoch: 9 | loss: 1.0515621
	speed: 0.0191s/iter; left time: 4.2211s
Epoch: 9 cost time: 4.162703990936279
Epoch: 9, Steps: 210 | Train Loss: 1.0189311 Vali Loss: 1.0592304 Test Loss: 1.0494418
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0022004
	speed: 0.0154s/iter; left time: 1.7115s
	iters: 200, epoch: 10 | loss: 1.0232537
	speed: 0.0144s/iter; left time: 0.1588s
Epoch: 10 cost time: 3.1404922008514404
Epoch: 10, Steps: 210 | Train Loss: 1.0189062 Vali Loss: 1.0623275 Test Loss: 1.0494642
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.049271821975708, mae:0.8216401934623718
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0387679
	speed: 0.0305s/iter; left time: 59.8330s
	iters: 200, epoch: 1 | loss: 1.0479081
	speed: 0.0247s/iter; left time: 45.9584s
Epoch: 1 cost time: 5.110082387924194
Epoch: 1, Steps: 206 | Train Loss: 1.0377388 Vali Loss: 1.0533302 Test Loss: 1.0391046
Validation loss decreased (inf --> 1.053330).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0348340
	speed: 0.0159s/iter; left time: 27.8717s
	iters: 200, epoch: 2 | loss: 1.0408293
	speed: 0.0127s/iter; left time: 21.0827s
Epoch: 2 cost time: 2.687722682952881
Epoch: 2, Steps: 206 | Train Loss: 1.0315041 Vali Loss: 1.0501758 Test Loss: 1.0385725
Validation loss decreased (1.053330 --> 1.050176).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0143404
	speed: 0.0189s/iter; left time: 29.3148s
	iters: 200, epoch: 3 | loss: 1.0538421
	speed: 0.0166s/iter; left time: 24.1069s
Epoch: 3 cost time: 3.5312564373016357
Epoch: 3, Steps: 206 | Train Loss: 1.0287380 Vali Loss: 1.0497080 Test Loss: 1.0381743
Validation loss decreased (1.050176 --> 1.049708).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9962752
	speed: 0.0190s/iter; left time: 25.5715s
	iters: 200, epoch: 4 | loss: 1.0020040
	speed: 0.0193s/iter; left time: 24.0350s
Epoch: 4 cost time: 4.087925434112549
Epoch: 4, Steps: 206 | Train Loss: 1.0271211 Vali Loss: 1.0500895 Test Loss: 1.0399116
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0178431
	speed: 0.0160s/iter; left time: 18.2333s
	iters: 200, epoch: 5 | loss: 1.0602913
	speed: 0.0156s/iter; left time: 16.2105s
Epoch: 5 cost time: 3.333240032196045
Epoch: 5, Steps: 206 | Train Loss: 1.0257390 Vali Loss: 1.0514082 Test Loss: 1.0416410
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0275705
	speed: 0.0163s/iter; left time: 15.1886s
	iters: 200, epoch: 6 | loss: 1.0208601
	speed: 0.0165s/iter; left time: 13.7033s
Epoch: 6 cost time: 3.4724433422088623
Epoch: 6, Steps: 206 | Train Loss: 1.0250153 Vali Loss: 1.0517901 Test Loss: 1.0423243
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0013392
	speed: 0.0160s/iter; left time: 11.6195s
	iters: 200, epoch: 7 | loss: 1.0231375
	speed: 0.0129s/iter; left time: 8.0858s
Epoch: 7 cost time: 2.7291667461395264
Epoch: 7, Steps: 206 | Train Loss: 1.0244738 Vali Loss: 1.0514387 Test Loss: 1.0425334
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0177436
	speed: 0.0165s/iter; left time: 8.5782s
	iters: 200, epoch: 8 | loss: 1.0283183
	speed: 0.0143s/iter; left time: 5.9748s
Epoch: 8 cost time: 3.044644355773926
Epoch: 8, Steps: 206 | Train Loss: 1.0239084 Vali Loss: 1.0517979 Test Loss: 1.0427265
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0381741523742676, mae:0.8182247281074524
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0468808
	speed: 0.0139s/iter; left time: 27.2868s
	iters: 200, epoch: 1 | loss: 1.0372562
	speed: 0.0126s/iter; left time: 23.4396s
Epoch: 1 cost time: 2.6754488945007324
Epoch: 1, Steps: 206 | Train Loss: 1.0355481 Vali Loss: 1.0536489 Test Loss: 1.0373939
Validation loss decreased (inf --> 1.053649).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0233008
	speed: 0.0177s/iter; left time: 31.0886s
	iters: 200, epoch: 2 | loss: 1.0290430
	speed: 0.0138s/iter; left time: 22.7844s
Epoch: 2 cost time: 2.8625285625457764
Epoch: 2, Steps: 206 | Train Loss: 1.0319216 Vali Loss: 1.0519090 Test Loss: 1.0383085
Validation loss decreased (1.053649 --> 1.051909).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0549326
	speed: 0.0183s/iter; left time: 28.3258s
	iters: 200, epoch: 3 | loss: 1.0292315
	speed: 0.0147s/iter; left time: 21.2655s
Epoch: 3 cost time: 3.1294925212860107
Epoch: 3, Steps: 206 | Train Loss: 1.0300327 Vali Loss: 1.0516866 Test Loss: 1.0398821
Validation loss decreased (1.051909 --> 1.051687).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0394336
	speed: 0.0162s/iter; left time: 21.7574s
	iters: 200, epoch: 4 | loss: 1.0339370
	speed: 0.0159s/iter; left time: 19.7196s
Epoch: 4 cost time: 3.422389507293701
Epoch: 4, Steps: 206 | Train Loss: 1.0284992 Vali Loss: 1.0518502 Test Loss: 1.0397376
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0360823
	speed: 0.0185s/iter; left time: 21.0205s
	iters: 200, epoch: 5 | loss: 1.0373619
	speed: 0.0170s/iter; left time: 17.6642s
Epoch: 5 cost time: 3.6254732608795166
Epoch: 5, Steps: 206 | Train Loss: 1.0274228 Vali Loss: 1.0514704 Test Loss: 1.0399008
Validation loss decreased (1.051687 --> 1.051470).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0041403
	speed: 0.0191s/iter; left time: 17.7760s
	iters: 200, epoch: 6 | loss: 1.0352267
	speed: 0.0186s/iter; left time: 15.4559s
Epoch: 6 cost time: 3.913724422454834
Epoch: 6, Steps: 206 | Train Loss: 1.0267040 Vali Loss: 1.0515202 Test Loss: 1.0407768
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0428839
	speed: 0.0172s/iter; left time: 12.4623s
	iters: 200, epoch: 7 | loss: 1.0303549
	speed: 0.0138s/iter; left time: 8.6108s
Epoch: 7 cost time: 2.937558889389038
Epoch: 7, Steps: 206 | Train Loss: 1.0260082 Vali Loss: 1.0521955 Test Loss: 1.0411271
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0311767
	speed: 0.0151s/iter; left time: 7.8531s
	iters: 200, epoch: 8 | loss: 1.0527228
	speed: 0.0148s/iter; left time: 6.1962s
Epoch: 8 cost time: 3.1701955795288086
Epoch: 8, Steps: 206 | Train Loss: 1.0261727 Vali Loss: 1.0523962 Test Loss: 1.0412825
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0324930
	speed: 0.0207s/iter; left time: 6.4641s
	iters: 200, epoch: 9 | loss: 1.0010608
	speed: 0.0171s/iter; left time: 3.6468s
Epoch: 9 cost time: 3.640627145767212
Epoch: 9, Steps: 206 | Train Loss: 1.0259694 Vali Loss: 1.0522292 Test Loss: 1.0413314
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0465415
	speed: 0.0165s/iter; left time: 1.7704s
	iters: 200, epoch: 10 | loss: 1.0251541
	speed: 0.0145s/iter; left time: 0.1012s
Epoch: 10 cost time: 3.1039388179779053
Epoch: 10, Steps: 206 | Train Loss: 1.0256931 Vali Loss: 1.0525409 Test Loss: 1.0413601
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.039900541305542, mae:0.8189300298690796
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0222811
	speed: 0.0144s/iter; left time: 28.3300s
	iters: 200, epoch: 1 | loss: 1.0593181
	speed: 0.0121s/iter; left time: 22.4895s
Epoch: 1 cost time: 2.6154725551605225
Epoch: 1, Steps: 206 | Train Loss: 1.0420245 Vali Loss: 1.0548178 Test Loss: 1.0402479
Validation loss decreased (inf --> 1.054818).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0432657
	speed: 0.0138s/iter; left time: 24.1959s
	iters: 200, epoch: 2 | loss: 1.0043550
	speed: 0.0129s/iter; left time: 21.3724s
Epoch: 2 cost time: 2.7615137100219727
Epoch: 2, Steps: 206 | Train Loss: 1.0331914 Vali Loss: 1.0546216 Test Loss: 1.0425409
Validation loss decreased (1.054818 --> 1.054622).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0313200
	speed: 0.0175s/iter; left time: 27.0444s
	iters: 200, epoch: 3 | loss: 1.0199050
	speed: 0.0184s/iter; left time: 26.6388s
Epoch: 3 cost time: 3.8053886890411377
Epoch: 3, Steps: 206 | Train Loss: 1.0298161 Vali Loss: 1.0505021 Test Loss: 1.0397283
Validation loss decreased (1.054622 --> 1.050502).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0261918
	speed: 0.0173s/iter; left time: 23.2164s
	iters: 200, epoch: 4 | loss: 1.0516257
	speed: 0.0163s/iter; left time: 20.2237s
Epoch: 4 cost time: 3.4662203788757324
Epoch: 4, Steps: 206 | Train Loss: 1.0280880 Vali Loss: 1.0514033 Test Loss: 1.0412225
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0250392
	speed: 0.0176s/iter; left time: 20.0523s
	iters: 200, epoch: 5 | loss: 1.0354714
	speed: 0.0162s/iter; left time: 16.7771s
Epoch: 5 cost time: 3.449913501739502
Epoch: 5, Steps: 206 | Train Loss: 1.0271555 Vali Loss: 1.0519627 Test Loss: 1.0416037
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0246691
	speed: 0.0142s/iter; left time: 13.2648s
	iters: 200, epoch: 6 | loss: 1.0013529
	speed: 0.0128s/iter; left time: 10.6392s
Epoch: 6 cost time: 2.7379775047302246
Epoch: 6, Steps: 206 | Train Loss: 1.0261306 Vali Loss: 1.0524225 Test Loss: 1.0418723
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0483969
	speed: 0.0207s/iter; left time: 14.9974s
	iters: 200, epoch: 7 | loss: 1.0220675
	speed: 0.0162s/iter; left time: 10.0970s
Epoch: 7 cost time: 3.3929481506347656
Epoch: 7, Steps: 206 | Train Loss: 1.0257425 Vali Loss: 1.0522196 Test Loss: 1.0421439
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0037102
	speed: 0.0174s/iter; left time: 9.0475s
	iters: 200, epoch: 8 | loss: 1.0490160
	speed: 0.0166s/iter; left time: 6.9659s
Epoch: 8 cost time: 3.560465097427368
Epoch: 8, Steps: 206 | Train Loss: 1.0253827 Vali Loss: 1.0523164 Test Loss: 1.0422158
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0397284030914307, mae:0.8187498450279236
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0569725
	speed: 0.0241s/iter; left time: 44.3459s
Epoch: 1 cost time: 3.98777174949646
Epoch: 1, Steps: 194 | Train Loss: 1.0431097 Vali Loss: 1.0439038 Test Loss: 1.0404890
Validation loss decreased (inf --> 1.043904).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0339049
	speed: 0.0207s/iter; left time: 34.0948s
Epoch: 2 cost time: 4.000452995300293
Epoch: 2, Steps: 194 | Train Loss: 1.0383251 Vali Loss: 1.0451083 Test Loss: 1.0385091
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0414618
	speed: 0.0187s/iter; left time: 27.1415s
Epoch: 3 cost time: 3.401226282119751
Epoch: 3, Steps: 194 | Train Loss: 1.0362283 Vali Loss: 1.0430310 Test Loss: 1.0403783
Validation loss decreased (1.043904 --> 1.043031).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0427929
	speed: 0.0235s/iter; left time: 29.6175s
Epoch: 4 cost time: 4.085747957229614
Epoch: 4, Steps: 194 | Train Loss: 1.0349214 Vali Loss: 1.0420358 Test Loss: 1.0418214
Validation loss decreased (1.043031 --> 1.042036).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0486770
	speed: 0.0159s/iter; left time: 16.8861s
Epoch: 5 cost time: 2.8880937099456787
Epoch: 5, Steps: 194 | Train Loss: 1.0341771 Vali Loss: 1.0434783 Test Loss: 1.0407294
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0198319
	speed: 0.0183s/iter; left time: 15.9479s
Epoch: 6 cost time: 3.115962505340576
Epoch: 6, Steps: 194 | Train Loss: 1.0334212 Vali Loss: 1.0432496 Test Loss: 1.0415297
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0168536
	speed: 0.0192s/iter; left time: 13.0174s
Epoch: 7 cost time: 3.372396945953369
Epoch: 7, Steps: 194 | Train Loss: 1.0334065 Vali Loss: 1.0436245 Test Loss: 1.0413542
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0401710
	speed: 0.0191s/iter; left time: 9.2460s
Epoch: 8 cost time: 3.4630982875823975
Epoch: 8, Steps: 194 | Train Loss: 1.0329400 Vali Loss: 1.0434932 Test Loss: 1.0413710
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0378015
	speed: 0.0177s/iter; left time: 5.1254s
Epoch: 9 cost time: 3.3636908531188965
Epoch: 9, Steps: 194 | Train Loss: 1.0329275 Vali Loss: 1.0438452 Test Loss: 1.0413563
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0418212413787842, mae:0.8191061615943909
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0646446
	speed: 0.0212s/iter; left time: 39.0467s
Epoch: 1 cost time: 3.682398557662964
Epoch: 1, Steps: 194 | Train Loss: 1.0430775 Vali Loss: 1.0441171 Test Loss: 1.0386839
Validation loss decreased (inf --> 1.044117).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0292623
	speed: 0.0185s/iter; left time: 30.4556s
Epoch: 2 cost time: 3.5781607627868652
Epoch: 2, Steps: 194 | Train Loss: 1.0383384 Vali Loss: 1.0444673 Test Loss: 1.0393300
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0201484
	speed: 0.0209s/iter; left time: 30.3206s
Epoch: 3 cost time: 4.174461126327515
Epoch: 3, Steps: 194 | Train Loss: 1.0367349 Vali Loss: 1.0446413 Test Loss: 1.0388199
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0299864
	speed: 0.0165s/iter; left time: 20.7662s
Epoch: 4 cost time: 2.9970455169677734
Epoch: 4, Steps: 194 | Train Loss: 1.0355135 Vali Loss: 1.0434774 Test Loss: 1.0399675
Validation loss decreased (1.044117 --> 1.043477).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0470383
	speed: 0.0127s/iter; left time: 13.5343s
Epoch: 5 cost time: 2.334529399871826
Epoch: 5, Steps: 194 | Train Loss: 1.0347222 Vali Loss: 1.0436584 Test Loss: 1.0398362
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0371550
	speed: 0.0121s/iter; left time: 10.5079s
Epoch: 6 cost time: 2.4279491901397705
Epoch: 6, Steps: 194 | Train Loss: 1.0340740 Vali Loss: 1.0434353 Test Loss: 1.0405010
Validation loss decreased (1.043477 --> 1.043435).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0341442
	speed: 0.0160s/iter; left time: 10.8488s
Epoch: 7 cost time: 2.87263822555542
Epoch: 7, Steps: 194 | Train Loss: 1.0339829 Vali Loss: 1.0438901 Test Loss: 1.0404794
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0370551
	speed: 0.0210s/iter; left time: 10.1444s
Epoch: 8 cost time: 3.604226589202881
Epoch: 8, Steps: 194 | Train Loss: 1.0336283 Vali Loss: 1.0437722 Test Loss: 1.0405850
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0185086
	speed: 0.0178s/iter; left time: 5.1435s
Epoch: 9 cost time: 3.348383665084839
Epoch: 9, Steps: 194 | Train Loss: 1.0336199 Vali Loss: 1.0433737 Test Loss: 1.0406085
Validation loss decreased (1.043435 --> 1.043374).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0340743
	speed: 0.0189s/iter; left time: 1.7982s
Epoch: 10 cost time: 2.980130195617676
Epoch: 10, Steps: 194 | Train Loss: 1.0335853 Vali Loss: 1.0436164 Test Loss: 1.0406148
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0406086444854736, mae:0.8186115622520447
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0371844
	speed: 0.0207s/iter; left time: 38.0210s
Epoch: 1 cost time: 3.0934925079345703
Epoch: 1, Steps: 194 | Train Loss: 1.0428735 Vali Loss: 1.0437464 Test Loss: 1.0395358
Validation loss decreased (inf --> 1.043746).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0376081
	speed: 0.0315s/iter; left time: 51.8142s
Epoch: 2 cost time: 4.647848844528198
Epoch: 2, Steps: 194 | Train Loss: 1.0382958 Vali Loss: 1.0444564 Test Loss: 1.0390192
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0337344
	speed: 0.0221s/iter; left time: 32.1459s
Epoch: 3 cost time: 3.4394731521606445
Epoch: 3, Steps: 194 | Train Loss: 1.0366036 Vali Loss: 1.0439292 Test Loss: 1.0386698
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0495664
	speed: 0.0234s/iter; left time: 29.4786s
Epoch: 4 cost time: 3.654438018798828
Epoch: 4, Steps: 194 | Train Loss: 1.0356875 Vali Loss: 1.0444283 Test Loss: 1.0391049
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0293425
	speed: 0.0148s/iter; left time: 15.7184s
Epoch: 5 cost time: 2.9223625659942627
Epoch: 5, Steps: 194 | Train Loss: 1.0345311 Vali Loss: 1.0444888 Test Loss: 1.0392257
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0441065
	speed: 0.0169s/iter; left time: 14.7166s
Epoch: 6 cost time: 2.777522563934326
Epoch: 6, Steps: 194 | Train Loss: 1.0341537 Vali Loss: 1.0434337 Test Loss: 1.0404372
Validation loss decreased (1.043746 --> 1.043434).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0284495
	speed: 0.0212s/iter; left time: 14.3604s
Epoch: 7 cost time: 3.4234955310821533
Epoch: 7, Steps: 194 | Train Loss: 1.0338041 Vali Loss: 1.0432211 Test Loss: 1.0408512
Validation loss decreased (1.043434 --> 1.043221).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0276614
	speed: 0.0184s/iter; left time: 8.8757s
Epoch: 8 cost time: 3.483724594116211
Epoch: 8, Steps: 194 | Train Loss: 1.0336258 Vali Loss: 1.0437368 Test Loss: 1.0408971
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0328430
	speed: 0.0254s/iter; left time: 7.3450s
Epoch: 9 cost time: 3.6955678462982178
Epoch: 9, Steps: 194 | Train Loss: 1.0336234 Vali Loss: 1.0434849 Test Loss: 1.0408798
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0300570
	speed: 0.0203s/iter; left time: 1.9297s
Epoch: 10 cost time: 3.4635226726531982
Epoch: 10, Steps: 194 | Train Loss: 1.0335120 Vali Loss: 1.0434253 Test Loss: 1.0408988
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0408512353897095, mae:0.81875079870224
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9997491
	speed: 0.0301s/iter; left time: 61.0460s
	iters: 200, epoch: 1 | loss: 1.0100080
	speed: 0.0215s/iter; left time: 41.4879s
Epoch: 1 cost time: 4.54498028755188
Epoch: 1, Steps: 213 | Train Loss: 1.0278265 Vali Loss: 1.0502186 Test Loss: 1.0407656
Validation loss decreased (inf --> 1.050219).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0576104
	speed: 0.0153s/iter; left time: 27.8207s
	iters: 200, epoch: 2 | loss: 1.0285408
	speed: 0.0146s/iter; left time: 25.0770s
Epoch: 2 cost time: 3.2452831268310547
Epoch: 2, Steps: 213 | Train Loss: 1.0193877 Vali Loss: 1.0526655 Test Loss: 1.0409055
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0697244
	speed: 0.0181s/iter; left time: 29.0350s
	iters: 200, epoch: 3 | loss: 1.0168104
	speed: 0.0193s/iter; left time: 28.9740s
Epoch: 3 cost time: 4.125225782394409
Epoch: 3, Steps: 213 | Train Loss: 1.0162784 Vali Loss: 1.0521290 Test Loss: 1.0400012
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0316610
	speed: 0.0212s/iter; left time: 29.4496s
	iters: 200, epoch: 4 | loss: 1.0125526
	speed: 0.0184s/iter; left time: 23.8297s
Epoch: 4 cost time: 4.018953561782837
Epoch: 4, Steps: 213 | Train Loss: 1.0135118 Vali Loss: 1.0505170 Test Loss: 1.0405999
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0214379
	speed: 0.0199s/iter; left time: 23.4504s
	iters: 200, epoch: 5 | loss: 0.9981179
	speed: 0.0169s/iter; left time: 18.2718s
Epoch: 5 cost time: 3.616847276687622
Epoch: 5, Steps: 213 | Train Loss: 1.0115131 Vali Loss: 1.0552087 Test Loss: 1.0417287
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9711258
	speed: 0.0132s/iter; left time: 12.7325s
	iters: 200, epoch: 6 | loss: 1.0001731
	speed: 0.0137s/iter; left time: 11.8441s
Epoch: 6 cost time: 3.02020525932312
Epoch: 6, Steps: 213 | Train Loss: 1.0102252 Vali Loss: 1.0543909 Test Loss: 1.0425465
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0407655239105225, mae:0.8184191584587097
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9650016
	speed: 0.0176s/iter; left time: 35.6943s
	iters: 200, epoch: 1 | loss: 1.0553067
	speed: 0.0167s/iter; left time: 32.2323s
Epoch: 1 cost time: 3.6698317527770996
Epoch: 1, Steps: 213 | Train Loss: 1.0286463 Vali Loss: 1.0492263 Test Loss: 1.0404240
Validation loss decreased (inf --> 1.049226).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9999633
	speed: 0.0194s/iter; left time: 35.3144s
	iters: 200, epoch: 2 | loss: 1.0063980
	speed: 0.0176s/iter; left time: 30.1511s
Epoch: 2 cost time: 3.901421308517456
Epoch: 2, Steps: 213 | Train Loss: 1.0198939 Vali Loss: 1.0522727 Test Loss: 1.0406195
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0271304
	speed: 0.0152s/iter; left time: 24.3698s
	iters: 200, epoch: 3 | loss: 1.0470319
	speed: 0.0136s/iter; left time: 20.4817s
Epoch: 3 cost time: 2.9200565814971924
Epoch: 3, Steps: 213 | Train Loss: 1.0165133 Vali Loss: 1.0513818 Test Loss: 1.0404593
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0158457
	speed: 0.0164s/iter; left time: 22.8641s
	iters: 200, epoch: 4 | loss: 1.0302284
	speed: 0.0170s/iter; left time: 21.9914s
Epoch: 4 cost time: 3.741849184036255
Epoch: 4, Steps: 213 | Train Loss: 1.0133613 Vali Loss: 1.0523188 Test Loss: 1.0410678
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9998393
	speed: 0.0195s/iter; left time: 23.0075s
	iters: 200, epoch: 5 | loss: 1.0159851
	speed: 0.0173s/iter; left time: 18.6561s
Epoch: 5 cost time: 3.7160704135894775
Epoch: 5, Steps: 213 | Train Loss: 1.0112236 Vali Loss: 1.0554750 Test Loss: 1.0420986
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9774582
	speed: 0.0173s/iter; left time: 16.6734s
	iters: 200, epoch: 6 | loss: 1.0324707
	speed: 0.0150s/iter; left time: 12.9521s
Epoch: 6 cost time: 3.253375768661499
Epoch: 6, Steps: 213 | Train Loss: 1.0099301 Vali Loss: 1.0555568 Test Loss: 1.0424883
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040424108505249, mae:0.8182722330093384
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0372581
	speed: 0.0189s/iter; left time: 38.2888s
	iters: 200, epoch: 1 | loss: 0.9748973
	speed: 0.0157s/iter; left time: 30.3773s
Epoch: 1 cost time: 3.4160633087158203
Epoch: 1, Steps: 213 | Train Loss: 1.0254650 Vali Loss: 1.0521840 Test Loss: 1.0398341
Validation loss decreased (inf --> 1.052184).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0598556
	speed: 0.0202s/iter; left time: 36.6870s
	iters: 200, epoch: 2 | loss: 0.9975952
	speed: 0.0183s/iter; left time: 31.4125s
Epoch: 2 cost time: 3.930161476135254
Epoch: 2, Steps: 213 | Train Loss: 1.0191884 Vali Loss: 1.0496098 Test Loss: 1.0397900
Validation loss decreased (1.052184 --> 1.049610).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0092621
	speed: 0.0180s/iter; left time: 28.8336s
	iters: 200, epoch: 3 | loss: 1.0409594
	speed: 0.0166s/iter; left time: 24.9825s
Epoch: 3 cost time: 3.591843366622925
Epoch: 3, Steps: 213 | Train Loss: 1.0162641 Vali Loss: 1.0489901 Test Loss: 1.0396047
Validation loss decreased (1.049610 --> 1.048990).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0109630
	speed: 0.0252s/iter; left time: 35.0226s
	iters: 200, epoch: 4 | loss: 1.0429051
	speed: 0.0195s/iter; left time: 25.1377s
Epoch: 4 cost time: 4.100010395050049
Epoch: 4, Steps: 213 | Train Loss: 1.0138987 Vali Loss: 1.0529871 Test Loss: 1.0404826
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9937782
	speed: 0.0167s/iter; left time: 19.7340s
	iters: 200, epoch: 5 | loss: 1.0155549
	speed: 0.0137s/iter; left time: 14.8105s
Epoch: 5 cost time: 3.0228679180145264
Epoch: 5, Steps: 213 | Train Loss: 1.0118758 Vali Loss: 1.0520461 Test Loss: 1.0417155
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9697060
	speed: 0.0216s/iter; left time: 20.8572s
	iters: 200, epoch: 6 | loss: 1.0332371
	speed: 0.0192s/iter; left time: 16.6641s
Epoch: 6 cost time: 4.148521184921265
Epoch: 6, Steps: 213 | Train Loss: 1.0106103 Vali Loss: 1.0528793 Test Loss: 1.0421573
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0445930
	speed: 0.0167s/iter; left time: 12.5837s
	iters: 200, epoch: 7 | loss: 0.9893278
	speed: 0.0169s/iter; left time: 11.0147s
Epoch: 7 cost time: 3.690321922302246
Epoch: 7, Steps: 213 | Train Loss: 1.0099136 Vali Loss: 1.0538116 Test Loss: 1.0423992
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9489148
	speed: 0.0177s/iter; left time: 9.5568s
	iters: 200, epoch: 8 | loss: 1.0172976
	speed: 0.0172s/iter; left time: 7.5461s
Epoch: 8 cost time: 3.656705141067505
Epoch: 8, Steps: 213 | Train Loss: 1.0096639 Vali Loss: 1.0533170 Test Loss: 1.0425230
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0396047830581665, mae:0.8181294202804565
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0274091
	speed: 0.0342s/iter; left time: 68.4908s
	iters: 200, epoch: 1 | loss: 1.0065289
	speed: 0.0240s/iter; left time: 45.6808s
Epoch: 1 cost time: 4.992630481719971
Epoch: 1, Steps: 210 | Train Loss: 1.0329679 Vali Loss: 1.0614611 Test Loss: 1.0478871
Validation loss decreased (inf --> 1.061461).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0211437
	speed: 0.0174s/iter; left time: 31.1304s
	iters: 200, epoch: 2 | loss: 1.0258658
	speed: 0.0139s/iter; left time: 23.5648s
Epoch: 2 cost time: 2.9523072242736816
Epoch: 2, Steps: 210 | Train Loss: 1.0260644 Vali Loss: 1.0590301 Test Loss: 1.0476654
Validation loss decreased (1.061461 --> 1.059030).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0414777
	speed: 0.0159s/iter; left time: 25.1056s
	iters: 200, epoch: 3 | loss: 1.0660107
	speed: 0.0133s/iter; left time: 19.7658s
Epoch: 3 cost time: 2.8634626865386963
Epoch: 3, Steps: 210 | Train Loss: 1.0233027 Vali Loss: 1.0625215 Test Loss: 1.0478814
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0169278
	speed: 0.0134s/iter; left time: 18.3131s
	iters: 200, epoch: 4 | loss: 1.0713165
	speed: 0.0118s/iter; left time: 14.9558s
Epoch: 4 cost time: 2.515413284301758
Epoch: 4, Steps: 210 | Train Loss: 1.0211358 Vali Loss: 1.0612332 Test Loss: 1.0493021
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0299792
	speed: 0.0139s/iter; left time: 16.1374s
	iters: 200, epoch: 5 | loss: 1.0570183
	speed: 0.0127s/iter; left time: 13.4939s
Epoch: 5 cost time: 2.750605821609497
Epoch: 5, Steps: 210 | Train Loss: 1.0195498 Vali Loss: 1.0625321 Test Loss: 1.0498718
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0517458
	speed: 0.0165s/iter; left time: 15.6515s
	iters: 200, epoch: 6 | loss: 1.0196842
	speed: 0.0145s/iter; left time: 12.3120s
Epoch: 6 cost time: 3.175337076187134
Epoch: 6, Steps: 210 | Train Loss: 1.0184888 Vali Loss: 1.0603299 Test Loss: 1.0505050
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0142531
	speed: 0.0210s/iter; left time: 15.5854s
	iters: 200, epoch: 7 | loss: 1.0222950
	speed: 0.0193s/iter; left time: 12.3882s
Epoch: 7 cost time: 4.038418531417847
Epoch: 7, Steps: 210 | Train Loss: 1.0180294 Vali Loss: 1.0639315 Test Loss: 1.0508522
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0476652383804321, mae:0.8209598660469055
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0458272
	speed: 0.0239s/iter; left time: 47.8064s
	iters: 200, epoch: 1 | loss: 0.9960569
	speed: 0.0206s/iter; left time: 39.0719s
Epoch: 1 cost time: 4.370004415512085
Epoch: 1, Steps: 210 | Train Loss: 1.0352517 Vali Loss: 1.0618305 Test Loss: 1.0480050
Validation loss decreased (inf --> 1.061831).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0144801
	speed: 0.0197s/iter; left time: 35.3451s
	iters: 200, epoch: 2 | loss: 1.0471510
	speed: 0.0155s/iter; left time: 26.2385s
Epoch: 2 cost time: 3.2852299213409424
Epoch: 2, Steps: 210 | Train Loss: 1.0268769 Vali Loss: 1.0576329 Test Loss: 1.0478022
Validation loss decreased (1.061831 --> 1.057633).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0320750
	speed: 0.0185s/iter; left time: 29.2655s
	iters: 200, epoch: 3 | loss: 1.0136893
	speed: 0.0175s/iter; left time: 25.8545s
Epoch: 3 cost time: 3.778090715408325
Epoch: 3, Steps: 210 | Train Loss: 1.0235524 Vali Loss: 1.0618737 Test Loss: 1.0485076
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0236340
	speed: 0.0195s/iter; left time: 26.7641s
	iters: 200, epoch: 4 | loss: 1.0133622
	speed: 0.0180s/iter; left time: 22.9085s
Epoch: 4 cost time: 3.846550464630127
Epoch: 4, Steps: 210 | Train Loss: 1.0213507 Vali Loss: 1.0605849 Test Loss: 1.0495675
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9867555
	speed: 0.0237s/iter; left time: 27.5330s
	iters: 200, epoch: 5 | loss: 1.0201702
	speed: 0.0200s/iter; left time: 21.2328s
Epoch: 5 cost time: 4.239979028701782
Epoch: 5, Steps: 210 | Train Loss: 1.0194354 Vali Loss: 1.0617201 Test Loss: 1.0504583
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0079041
	speed: 0.0162s/iter; left time: 15.4483s
	iters: 200, epoch: 6 | loss: 1.0542208
	speed: 0.0138s/iter; left time: 11.7633s
Epoch: 6 cost time: 2.9952619075775146
Epoch: 6, Steps: 210 | Train Loss: 1.0184431 Vali Loss: 1.0607904 Test Loss: 1.0512013
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0233392
	speed: 0.0197s/iter; left time: 14.5801s
	iters: 200, epoch: 7 | loss: 1.0053128
	speed: 0.0178s/iter; left time: 11.4009s
Epoch: 7 cost time: 3.75227427482605
Epoch: 7, Steps: 210 | Train Loss: 1.0178430 Vali Loss: 1.0603482 Test Loss: 1.0515209
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0478023290634155, mae:0.820975124835968
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9883635
	speed: 0.0170s/iter; left time: 33.9285s
	iters: 200, epoch: 1 | loss: 0.9831010
	speed: 0.0158s/iter; left time: 29.9599s
Epoch: 1 cost time: 3.4592883586883545
Epoch: 1, Steps: 210 | Train Loss: 1.0340751 Vali Loss: 1.0628310 Test Loss: 1.0476756
Validation loss decreased (inf --> 1.062831).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0245285
	speed: 0.0175s/iter; left time: 31.3867s
	iters: 200, epoch: 2 | loss: 1.0222034
	speed: 0.0192s/iter; left time: 32.4014s
Epoch: 2 cost time: 4.030024528503418
Epoch: 2, Steps: 210 | Train Loss: 1.0265732 Vali Loss: 1.0607110 Test Loss: 1.0478497
Validation loss decreased (1.062831 --> 1.060711).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0217605
	speed: 0.0171s/iter; left time: 27.0878s
	iters: 200, epoch: 3 | loss: 0.9967092
	speed: 0.0153s/iter; left time: 22.6594s
Epoch: 3 cost time: 3.21934175491333
Epoch: 3, Steps: 210 | Train Loss: 1.0236627 Vali Loss: 1.0578799 Test Loss: 1.0483693
Validation loss decreased (1.060711 --> 1.057880).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0222070
	speed: 0.0301s/iter; left time: 41.3268s
	iters: 200, epoch: 4 | loss: 1.0202059
	speed: 0.0223s/iter; left time: 28.3368s
Epoch: 4 cost time: 4.697734594345093
Epoch: 4, Steps: 210 | Train Loss: 1.0214422 Vali Loss: 1.0610955 Test Loss: 1.0486081
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0064238
	speed: 0.0226s/iter; left time: 26.2774s
	iters: 200, epoch: 5 | loss: 1.0273846
	speed: 0.0194s/iter; left time: 20.5732s
Epoch: 5 cost time: 4.122373580932617
Epoch: 5, Steps: 210 | Train Loss: 1.0197704 Vali Loss: 1.0632769 Test Loss: 1.0501642
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0075126
	speed: 0.0249s/iter; left time: 23.7182s
	iters: 200, epoch: 6 | loss: 1.0207071
	speed: 0.0206s/iter; left time: 17.5654s
Epoch: 6 cost time: 4.3106300830841064
Epoch: 6, Steps: 210 | Train Loss: 1.0186495 Vali Loss: 1.0617675 Test Loss: 1.0505502
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0209820
	speed: 0.0140s/iter; left time: 10.3734s
	iters: 200, epoch: 7 | loss: 1.0196476
	speed: 0.0110s/iter; left time: 7.0764s
Epoch: 7 cost time: 2.347876787185669
Epoch: 7, Steps: 210 | Train Loss: 1.0181441 Vali Loss: 1.0606151 Test Loss: 1.0508773
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0278320
	speed: 0.0246s/iter; left time: 13.0837s
	iters: 200, epoch: 8 | loss: 1.0011420
	speed: 0.0195s/iter; left time: 8.3837s
Epoch: 8 cost time: 4.1429383754730225
Epoch: 8, Steps: 210 | Train Loss: 1.0177026 Vali Loss: 1.0623366 Test Loss: 1.0510321
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.04836905002594, mae:0.8212379217147827
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0599061
	speed: 0.0252s/iter; left time: 49.4231s
	iters: 200, epoch: 1 | loss: 1.0616645
	speed: 0.0177s/iter; left time: 33.0175s
Epoch: 1 cost time: 3.6852376461029053
Epoch: 1, Steps: 206 | Train Loss: 1.0373633 Vali Loss: 1.0537840 Test Loss: 1.0390693
Validation loss decreased (inf --> 1.053784).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0307916
	speed: 0.0157s/iter; left time: 27.5120s
	iters: 200, epoch: 2 | loss: 1.0527824
	speed: 0.0160s/iter; left time: 26.5067s
Epoch: 2 cost time: 3.4147017002105713
Epoch: 2, Steps: 206 | Train Loss: 1.0315043 Vali Loss: 1.0509211 Test Loss: 1.0382968
Validation loss decreased (1.053784 --> 1.050921).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9870773
	speed: 0.0173s/iter; left time: 26.8532s
	iters: 200, epoch: 3 | loss: 1.0190561
	speed: 0.0158s/iter; left time: 22.8440s
Epoch: 3 cost time: 3.3264429569244385
Epoch: 3, Steps: 206 | Train Loss: 1.0296118 Vali Loss: 1.0505778 Test Loss: 1.0386353
Validation loss decreased (1.050921 --> 1.050578).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0227523
	speed: 0.0279s/iter; left time: 37.5159s
	iters: 200, epoch: 4 | loss: 1.0209572
	speed: 0.0223s/iter; left time: 27.7562s
Epoch: 4 cost time: 4.619678497314453
Epoch: 4, Steps: 206 | Train Loss: 1.0276816 Vali Loss: 1.0501965 Test Loss: 1.0395730
Validation loss decreased (1.050578 --> 1.050197).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0387150
	speed: 0.0170s/iter; left time: 19.3358s
	iters: 200, epoch: 5 | loss: 1.0318398
	speed: 0.0134s/iter; left time: 13.9187s
Epoch: 5 cost time: 2.894174814224243
Epoch: 5, Steps: 206 | Train Loss: 1.0264479 Vali Loss: 1.0515063 Test Loss: 1.0406431
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0283558
	speed: 0.0155s/iter; left time: 14.3973s
	iters: 200, epoch: 6 | loss: 1.0007491
	speed: 0.0150s/iter; left time: 12.4507s
Epoch: 6 cost time: 3.210529088973999
Epoch: 6, Steps: 206 | Train Loss: 1.0253772 Vali Loss: 1.0520695 Test Loss: 1.0413650
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0645771
	speed: 0.0186s/iter; left time: 13.4828s
	iters: 200, epoch: 7 | loss: 1.0434489
	speed: 0.0160s/iter; left time: 10.0190s
Epoch: 7 cost time: 3.3548812866210938
Epoch: 7, Steps: 206 | Train Loss: 1.0252433 Vali Loss: 1.0520097 Test Loss: 1.0417496
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0572292
	speed: 0.0167s/iter; left time: 8.6615s
	iters: 200, epoch: 8 | loss: 1.0287764
	speed: 0.0178s/iter; left time: 7.4722s
Epoch: 8 cost time: 3.751844882965088
Epoch: 8, Steps: 206 | Train Loss: 1.0248068 Vali Loss: 1.0523821 Test Loss: 1.0418826
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0075308
	speed: 0.0200s/iter; left time: 6.2456s
	iters: 200, epoch: 9 | loss: 1.0313308
	speed: 0.0178s/iter; left time: 3.7998s
Epoch: 9 cost time: 3.8167896270751953
Epoch: 9, Steps: 206 | Train Loss: 1.0247861 Vali Loss: 1.0522304 Test Loss: 1.0419328
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0395729541778564, mae:0.8187917470932007
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0220746
	speed: 0.0176s/iter; left time: 34.5629s
	iters: 200, epoch: 1 | loss: 1.0419264
	speed: 0.0145s/iter; left time: 26.9238s
Epoch: 1 cost time: 3.0792431831359863
Epoch: 1, Steps: 206 | Train Loss: 1.0376767 Vali Loss: 1.0538366 Test Loss: 1.0387410
Validation loss decreased (inf --> 1.053837).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0558715
	speed: 0.0210s/iter; left time: 36.8852s
	iters: 200, epoch: 2 | loss: 1.0368347
	speed: 0.0191s/iter; left time: 31.6011s
Epoch: 2 cost time: 4.074923753738403
Epoch: 2, Steps: 206 | Train Loss: 1.0313222 Vali Loss: 1.0510595 Test Loss: 1.0386496
Validation loss decreased (1.053837 --> 1.051059).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0281959
	speed: 0.0217s/iter; left time: 33.5955s
	iters: 200, epoch: 3 | loss: 1.0279574
	speed: 0.0189s/iter; left time: 27.3315s
Epoch: 3 cost time: 3.9627413749694824
Epoch: 3, Steps: 206 | Train Loss: 1.0292560 Vali Loss: 1.0506308 Test Loss: 1.0385518
Validation loss decreased (1.051059 --> 1.050631).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0568085
	speed: 0.0188s/iter; left time: 25.2921s
	iters: 200, epoch: 4 | loss: 1.0197734
	speed: 0.0154s/iter; left time: 19.2002s
Epoch: 4 cost time: 3.3116509914398193
Epoch: 4, Steps: 206 | Train Loss: 1.0275372 Vali Loss: 1.0519204 Test Loss: 1.0407995
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9985613
	speed: 0.0159s/iter; left time: 18.0248s
	iters: 200, epoch: 5 | loss: 1.0067846
	speed: 0.0129s/iter; left time: 13.4256s
Epoch: 5 cost time: 2.736370086669922
Epoch: 5, Steps: 206 | Train Loss: 1.0260774 Vali Loss: 1.0521410 Test Loss: 1.0407782
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0097667
	speed: 0.0208s/iter; left time: 19.3277s
	iters: 200, epoch: 6 | loss: 1.0074359
	speed: 0.0168s/iter; left time: 13.9660s
Epoch: 6 cost time: 3.535604476928711
Epoch: 6, Steps: 206 | Train Loss: 1.0254714 Vali Loss: 1.0526915 Test Loss: 1.0417160
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0255420
	speed: 0.0175s/iter; left time: 12.7008s
	iters: 200, epoch: 7 | loss: 1.0312269
	speed: 0.0147s/iter; left time: 9.1723s
Epoch: 7 cost time: 3.064361333847046
Epoch: 7, Steps: 206 | Train Loss: 1.0250246 Vali Loss: 1.0533204 Test Loss: 1.0419445
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0011588
	speed: 0.0249s/iter; left time: 12.9287s
	iters: 200, epoch: 8 | loss: 1.0103329
	speed: 0.0194s/iter; left time: 8.1257s
Epoch: 8 cost time: 4.076113700866699
Epoch: 8, Steps: 206 | Train Loss: 1.0247994 Vali Loss: 1.0530093 Test Loss: 1.0421156
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0385518074035645, mae:0.8183775544166565
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0200783
	speed: 0.0144s/iter; left time: 28.3135s
	iters: 200, epoch: 1 | loss: 1.0512155
	speed: 0.0120s/iter; left time: 22.4162s
Epoch: 1 cost time: 2.5855047702789307
Epoch: 1, Steps: 206 | Train Loss: 1.0359386 Vali Loss: 1.0527971 Test Loss: 1.0375229
Validation loss decreased (inf --> 1.052797).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0246922
	speed: 0.0154s/iter; left time: 26.9735s
	iters: 200, epoch: 2 | loss: 1.0181998
	speed: 0.0131s/iter; left time: 21.6665s
Epoch: 2 cost time: 2.7372913360595703
Epoch: 2, Steps: 206 | Train Loss: 1.0318467 Vali Loss: 1.0514250 Test Loss: 1.0387468
Validation loss decreased (1.052797 --> 1.051425).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0337315
	speed: 0.0191s/iter; left time: 29.6080s
	iters: 200, epoch: 3 | loss: 1.0532115
	speed: 0.0163s/iter; left time: 23.6352s
Epoch: 3 cost time: 3.4457759857177734
Epoch: 3, Steps: 206 | Train Loss: 1.0298378 Vali Loss: 1.0513241 Test Loss: 1.0387599
Validation loss decreased (1.051425 --> 1.051324).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0211535
	speed: 0.0163s/iter; left time: 21.8270s
	iters: 200, epoch: 4 | loss: 1.0201581
	speed: 0.0152s/iter; left time: 18.8471s
Epoch: 4 cost time: 3.2427594661712646
Epoch: 4, Steps: 206 | Train Loss: 1.0284877 Vali Loss: 1.0510314 Test Loss: 1.0394788
Validation loss decreased (1.051324 --> 1.051031).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0288043
	speed: 0.0204s/iter; left time: 23.1434s
	iters: 200, epoch: 5 | loss: 1.0399821
	speed: 0.0180s/iter; left time: 18.7175s
Epoch: 5 cost time: 3.7962076663970947
Epoch: 5, Steps: 206 | Train Loss: 1.0276025 Vali Loss: 1.0509617 Test Loss: 1.0395900
Validation loss decreased (1.051031 --> 1.050962).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0307093
	speed: 0.0179s/iter; left time: 16.6868s
	iters: 200, epoch: 6 | loss: 1.0384358
	speed: 0.0160s/iter; left time: 13.3175s
Epoch: 6 cost time: 3.414375066757202
Epoch: 6, Steps: 206 | Train Loss: 1.0271018 Vali Loss: 1.0513380 Test Loss: 1.0403556
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0584502
	speed: 0.0110s/iter; left time: 7.9586s
	iters: 200, epoch: 7 | loss: 1.0110674
	speed: 0.0134s/iter; left time: 8.4008s
Epoch: 7 cost time: 2.901174306869507
Epoch: 7, Steps: 206 | Train Loss: 1.0265151 Vali Loss: 1.0514885 Test Loss: 1.0404786
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0311230
	speed: 0.0140s/iter; left time: 7.2520s
	iters: 200, epoch: 8 | loss: 1.0118457
	speed: 0.0141s/iter; left time: 5.8988s
Epoch: 8 cost time: 3.016282558441162
Epoch: 8, Steps: 206 | Train Loss: 1.0264252 Vali Loss: 1.0514779 Test Loss: 1.0405612
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0384545
	speed: 0.0169s/iter; left time: 5.2742s
	iters: 200, epoch: 9 | loss: 1.0041691
	speed: 0.0169s/iter; left time: 3.6067s
Epoch: 9 cost time: 3.5861868858337402
Epoch: 9, Steps: 206 | Train Loss: 1.0264579 Vali Loss: 1.0517915 Test Loss: 1.0406123
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0459039
	speed: 0.0206s/iter; left time: 2.2036s
	iters: 200, epoch: 10 | loss: 1.0510428
	speed: 0.0202s/iter; left time: 0.1417s
Epoch: 10 cost time: 4.17211127281189
Epoch: 10, Steps: 206 | Train Loss: 1.0264486 Vali Loss: 1.0515757 Test Loss: 1.0406247
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0395900011062622, mae:0.8187598586082458
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0237101
	speed: 0.0310s/iter; left time: 57.0626s
Epoch: 1 cost time: 4.347081422805786
Epoch: 1, Steps: 194 | Train Loss: 1.0427429 Vali Loss: 1.0434328 Test Loss: 1.0409137
Validation loss decreased (inf --> 1.043433).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0148764
	speed: 0.0178s/iter; left time: 29.2383s
Epoch: 2 cost time: 2.868898391723633
Epoch: 2, Steps: 194 | Train Loss: 1.0380697 Vali Loss: 1.0442445 Test Loss: 1.0379537
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0464953
	speed: 0.0193s/iter; left time: 28.0373s
Epoch: 3 cost time: 3.009380340576172
Epoch: 3, Steps: 194 | Train Loss: 1.0366133 Vali Loss: 1.0440300 Test Loss: 1.0385954
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0332443
	speed: 0.0269s/iter; left time: 33.8783s
Epoch: 4 cost time: 4.3422605991363525
Epoch: 4, Steps: 194 | Train Loss: 1.0354419 Vali Loss: 1.0425649 Test Loss: 1.0403472
Validation loss decreased (1.043433 --> 1.042565).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0310258
	speed: 0.0225s/iter; left time: 23.9562s
Epoch: 5 cost time: 3.7693331241607666
Epoch: 5, Steps: 194 | Train Loss: 1.0346289 Vali Loss: 1.0430170 Test Loss: 1.0407978
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0274850
	speed: 0.0158s/iter; left time: 13.7867s
Epoch: 6 cost time: 3.0457773208618164
Epoch: 6, Steps: 194 | Train Loss: 1.0340071 Vali Loss: 1.0439447 Test Loss: 1.0402262
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0742368
	speed: 0.0159s/iter; left time: 10.7310s
Epoch: 7 cost time: 2.7158467769622803
Epoch: 7, Steps: 194 | Train Loss: 1.0338218 Vali Loss: 1.0435920 Test Loss: 1.0408052
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0318943
	speed: 0.0180s/iter; left time: 8.6846s
Epoch: 8 cost time: 3.2868432998657227
Epoch: 8, Steps: 194 | Train Loss: 1.0336689 Vali Loss: 1.0432330 Test Loss: 1.0408700
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0373912
	speed: 0.0193s/iter; left time: 5.5701s
Epoch: 9 cost time: 3.4413485527038574
Epoch: 9, Steps: 194 | Train Loss: 1.0334378 Vali Loss: 1.0437849 Test Loss: 1.0408769
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0403472185134888, mae:0.818512499332428
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0507965
	speed: 0.0213s/iter; left time: 39.1690s
Epoch: 1 cost time: 3.5698041915893555
Epoch: 1, Steps: 194 | Train Loss: 1.0434213 Vali Loss: 1.0450476 Test Loss: 1.0390018
Validation loss decreased (inf --> 1.045048).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0549225
	speed: 0.0214s/iter; left time: 35.1900s
Epoch: 2 cost time: 3.3235831260681152
Epoch: 2, Steps: 194 | Train Loss: 1.0382867 Vali Loss: 1.0456924 Test Loss: 1.0379683
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0577483
	speed: 0.0132s/iter; left time: 19.2297s
Epoch: 3 cost time: 2.8148083686828613
Epoch: 3, Steps: 194 | Train Loss: 1.0370114 Vali Loss: 1.0430995 Test Loss: 1.0399085
Validation loss decreased (1.045048 --> 1.043100).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0343407
	speed: 0.0168s/iter; left time: 21.1164s
Epoch: 4 cost time: 2.991143226623535
Epoch: 4, Steps: 194 | Train Loss: 1.0357929 Vali Loss: 1.0441339 Test Loss: 1.0399337
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0571232
	speed: 0.0246s/iter; left time: 26.1809s
Epoch: 5 cost time: 4.049898862838745
Epoch: 5, Steps: 194 | Train Loss: 1.0351332 Vali Loss: 1.0447525 Test Loss: 1.0396110
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0361930
	speed: 0.0170s/iter; left time: 14.8197s
Epoch: 6 cost time: 3.503235340118408
Epoch: 6, Steps: 194 | Train Loss: 1.0345715 Vali Loss: 1.0433953 Test Loss: 1.0410329
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0342331
	speed: 0.0147s/iter; left time: 9.9439s
Epoch: 7 cost time: 2.5873677730560303
Epoch: 7, Steps: 194 | Train Loss: 1.0344059 Vali Loss: 1.0442502 Test Loss: 1.0405115
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0299902
	speed: 0.0185s/iter; left time: 8.9262s
Epoch: 8 cost time: 3.1490859985351562
Epoch: 8, Steps: 194 | Train Loss: 1.0341755 Vali Loss: 1.0443587 Test Loss: 1.0405667
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0399084091186523, mae:0.8182803392410278
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0388888
	speed: 0.0190s/iter; left time: 35.0005s
Epoch: 1 cost time: 3.322380304336548
Epoch: 1, Steps: 194 | Train Loss: 1.0436650 Vali Loss: 1.0441351 Test Loss: 1.0414987
Validation loss decreased (inf --> 1.044135).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0558898
	speed: 0.0213s/iter; left time: 35.0112s
Epoch: 2 cost time: 3.3340835571289062
Epoch: 2, Steps: 194 | Train Loss: 1.0385417 Vali Loss: 1.0440420 Test Loss: 1.0402675
Validation loss decreased (1.044135 --> 1.044042).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0405154
	speed: 0.0197s/iter; left time: 28.6566s
Epoch: 3 cost time: 3.3625199794769287
Epoch: 3, Steps: 194 | Train Loss: 1.0365957 Vali Loss: 1.0447900 Test Loss: 1.0382900
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0270851
	speed: 0.0146s/iter; left time: 18.3468s
Epoch: 4 cost time: 3.048826217651367
Epoch: 4, Steps: 194 | Train Loss: 1.0354454 Vali Loss: 1.0441025 Test Loss: 1.0404063
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0288868
	speed: 0.0169s/iter; left time: 17.9833s
Epoch: 5 cost time: 3.2257771492004395
Epoch: 5, Steps: 194 | Train Loss: 1.0343847 Vali Loss: 1.0438802 Test Loss: 1.0407412
Validation loss decreased (1.044042 --> 1.043880).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0139251
	speed: 0.0164s/iter; left time: 14.3273s
Epoch: 6 cost time: 3.017423629760742
Epoch: 6, Steps: 194 | Train Loss: 1.0336386 Vali Loss: 1.0440443 Test Loss: 1.0409069
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0261692
	speed: 0.0232s/iter; left time: 15.7033s
Epoch: 7 cost time: 3.854088068008423
Epoch: 7, Steps: 194 | Train Loss: 1.0333621 Vali Loss: 1.0443130 Test Loss: 1.0413228
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0221343
	speed: 0.0176s/iter; left time: 8.5010s
Epoch: 8 cost time: 2.9883902072906494
Epoch: 8, Steps: 194 | Train Loss: 1.0334643 Vali Loss: 1.0443707 Test Loss: 1.0412066
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0424162
	speed: 0.0159s/iter; left time: 4.5976s
Epoch: 9 cost time: 2.850372791290283
Epoch: 9, Steps: 194 | Train Loss: 1.0333755 Vali Loss: 1.0441315 Test Loss: 1.0412530
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0315557
	speed: 0.0249s/iter; left time: 2.3608s
Epoch: 10 cost time: 4.2489094734191895
Epoch: 10, Steps: 194 | Train Loss: 1.0332037 Vali Loss: 1.0442381 Test Loss: 1.0412471
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0407410860061646, mae:0.8186529874801636
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0509704
	speed: 0.0287s/iter; left time: 58.2455s
	iters: 200, epoch: 1 | loss: 1.0227065
	speed: 0.0200s/iter; left time: 38.6439s
Epoch: 1 cost time: 4.217461347579956
Epoch: 1, Steps: 213 | Train Loss: 1.0284869 Vali Loss: 1.0531958 Test Loss: 1.0403622
Validation loss decreased (inf --> 1.053196).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0017934
	speed: 0.0200s/iter; left time: 36.3059s
	iters: 200, epoch: 2 | loss: 0.9678922
	speed: 0.0183s/iter; left time: 31.4155s
Epoch: 2 cost time: 3.9643328189849854
Epoch: 2, Steps: 213 | Train Loss: 1.0197235 Vali Loss: 1.0517197 Test Loss: 1.0396997
Validation loss decreased (1.053196 --> 1.051720).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0030308
	speed: 0.0165s/iter; left time: 26.5219s
	iters: 200, epoch: 3 | loss: 1.0544858
	speed: 0.0158s/iter; left time: 23.7462s
Epoch: 3 cost time: 3.4493188858032227
Epoch: 3, Steps: 213 | Train Loss: 1.0165724 Vali Loss: 1.0489001 Test Loss: 1.0403606
Validation loss decreased (1.051720 --> 1.048900).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0654368
	speed: 0.0168s/iter; left time: 23.3972s
	iters: 200, epoch: 4 | loss: 0.9886848
	speed: 0.0159s/iter; left time: 20.5033s
Epoch: 4 cost time: 3.5078978538513184
Epoch: 4, Steps: 213 | Train Loss: 1.0137488 Vali Loss: 1.0534666 Test Loss: 1.0412753
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9881830
	speed: 0.0112s/iter; left time: 13.2111s
	iters: 200, epoch: 5 | loss: 0.9824106
	speed: 0.0104s/iter; left time: 11.1726s
Epoch: 5 cost time: 2.2717487812042236
Epoch: 5, Steps: 213 | Train Loss: 1.0118064 Vali Loss: 1.0529383 Test Loss: 1.0415652
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0451431
	speed: 0.0182s/iter; left time: 17.5633s
	iters: 200, epoch: 6 | loss: 1.0287760
	speed: 0.0145s/iter; left time: 12.5816s
Epoch: 6 cost time: 3.172739028930664
Epoch: 6, Steps: 213 | Train Loss: 1.0104089 Vali Loss: 1.0533773 Test Loss: 1.0425255
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0354675
	speed: 0.0204s/iter; left time: 15.3521s
	iters: 200, epoch: 7 | loss: 0.9964317
	speed: 0.0174s/iter; left time: 11.3341s
Epoch: 7 cost time: 3.7555460929870605
Epoch: 7, Steps: 213 | Train Loss: 1.0097055 Vali Loss: 1.0530676 Test Loss: 1.0428466
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0033712
	speed: 0.0154s/iter; left time: 8.2893s
	iters: 200, epoch: 8 | loss: 1.0315342
	speed: 0.0145s/iter; left time: 6.3901s
Epoch: 8 cost time: 3.3204386234283447
Epoch: 8, Steps: 213 | Train Loss: 1.0093292 Vali Loss: 1.0551150 Test Loss: 1.0429568
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0403603315353394, mae:0.818524956703186
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0625445
	speed: 0.0121s/iter; left time: 24.6737s
	iters: 200, epoch: 1 | loss: 1.0580968
	speed: 0.0117s/iter; left time: 22.6394s
Epoch: 1 cost time: 2.6547317504882812
Epoch: 1, Steps: 213 | Train Loss: 1.0274695 Vali Loss: 1.0525135 Test Loss: 1.0410857
Validation loss decreased (inf --> 1.052513).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0369916
	speed: 0.0166s/iter; left time: 30.1792s
	iters: 200, epoch: 2 | loss: 0.9703907
	speed: 0.0155s/iter; left time: 26.6846s
Epoch: 2 cost time: 3.3708138465881348
Epoch: 2, Steps: 213 | Train Loss: 1.0197232 Vali Loss: 1.0498650 Test Loss: 1.0404562
Validation loss decreased (1.052513 --> 1.049865).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9736704
	speed: 0.0207s/iter; left time: 33.1885s
	iters: 200, epoch: 3 | loss: 1.0232966
	speed: 0.0202s/iter; left time: 30.4448s
Epoch: 3 cost time: 4.456398248672485
Epoch: 3, Steps: 213 | Train Loss: 1.0164463 Vali Loss: 1.0485570 Test Loss: 1.0401585
Validation loss decreased (1.049865 --> 1.048557).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0211328
	speed: 0.0190s/iter; left time: 26.4243s
	iters: 200, epoch: 4 | loss: 1.0318689
	speed: 0.0175s/iter; left time: 22.6569s
Epoch: 4 cost time: 3.7589714527130127
Epoch: 4, Steps: 213 | Train Loss: 1.0140286 Vali Loss: 1.0506742 Test Loss: 1.0407422
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9818444
	speed: 0.0170s/iter; left time: 20.0155s
	iters: 200, epoch: 5 | loss: 1.0142016
	speed: 0.0142s/iter; left time: 15.2945s
Epoch: 5 cost time: 3.0789127349853516
Epoch: 5, Steps: 213 | Train Loss: 1.0121105 Vali Loss: 1.0515487 Test Loss: 1.0417920
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0034784
	speed: 0.0203s/iter; left time: 19.5659s
	iters: 200, epoch: 6 | loss: 1.0038846
	speed: 0.0189s/iter; left time: 16.3262s
Epoch: 6 cost time: 4.087824821472168
Epoch: 6, Steps: 213 | Train Loss: 1.0109613 Vali Loss: 1.0541474 Test Loss: 1.0422310
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9755620
	speed: 0.0185s/iter; left time: 13.9180s
	iters: 200, epoch: 7 | loss: 0.9763271
	speed: 0.0167s/iter; left time: 10.9177s
Epoch: 7 cost time: 3.616363763809204
Epoch: 7, Steps: 213 | Train Loss: 1.0101044 Vali Loss: 1.0552441 Test Loss: 1.0425490
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9698399
	speed: 0.0184s/iter; left time: 9.9161s
	iters: 200, epoch: 8 | loss: 1.0075505
	speed: 0.0171s/iter; left time: 7.5278s
Epoch: 8 cost time: 3.6431233882904053
Epoch: 8, Steps: 213 | Train Loss: 1.0098868 Vali Loss: 1.0537713 Test Loss: 1.0426618
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0401585102081299, mae:0.8183519840240479
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0307959
	speed: 0.0169s/iter; left time: 34.2755s
	iters: 200, epoch: 1 | loss: 1.0105172
	speed: 0.0148s/iter; left time: 28.5331s
Epoch: 1 cost time: 3.2267301082611084
Epoch: 1, Steps: 213 | Train Loss: 1.0272137 Vali Loss: 1.0502722 Test Loss: 1.0400848
Validation loss decreased (inf --> 1.050272).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0257291
	speed: 0.0173s/iter; left time: 31.5011s
	iters: 200, epoch: 2 | loss: 0.9721949
	speed: 0.0174s/iter; left time: 29.8746s
Epoch: 2 cost time: 3.7769405841827393
Epoch: 2, Steps: 213 | Train Loss: 1.0193843 Vali Loss: 1.0497103 Test Loss: 1.0401512
Validation loss decreased (1.050272 --> 1.049710).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0052605
	speed: 0.0177s/iter; left time: 28.3483s
	iters: 200, epoch: 3 | loss: 1.0274146
	speed: 0.0167s/iter; left time: 25.1559s
Epoch: 3 cost time: 3.636725425720215
Epoch: 3, Steps: 213 | Train Loss: 1.0162774 Vali Loss: 1.0524238 Test Loss: 1.0402838
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9881150
	speed: 0.0184s/iter; left time: 25.6143s
	iters: 200, epoch: 4 | loss: 0.9741925
	speed: 0.0162s/iter; left time: 20.8750s
Epoch: 4 cost time: 3.462221622467041
Epoch: 4, Steps: 213 | Train Loss: 1.0135275 Vali Loss: 1.0532655 Test Loss: 1.0407231
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0234432
	speed: 0.0176s/iter; left time: 20.7623s
	iters: 200, epoch: 5 | loss: 1.0426183
	speed: 0.0144s/iter; left time: 15.5042s
Epoch: 5 cost time: 3.0519356727600098
Epoch: 5, Steps: 213 | Train Loss: 1.0114548 Vali Loss: 1.0540102 Test Loss: 1.0414146
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0222639
	speed: 0.0152s/iter; left time: 14.7138s
	iters: 200, epoch: 6 | loss: 1.0101902
	speed: 0.0152s/iter; left time: 13.1909s
Epoch: 6 cost time: 3.3491032123565674
Epoch: 6, Steps: 213 | Train Loss: 1.0102503 Vali Loss: 1.0536984 Test Loss: 1.0421567
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.9962036
	speed: 0.0204s/iter; left time: 15.3389s
	iters: 200, epoch: 7 | loss: 1.0346875
	speed: 0.0189s/iter; left time: 12.3247s
Epoch: 7 cost time: 4.134779214859009
Epoch: 7, Steps: 213 | Train Loss: 1.0092200 Vali Loss: 1.0540841 Test Loss: 1.0425845
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0401512384414673, mae:0.8183302283287048
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0311798
	speed: 0.0317s/iter; left time: 63.3356s
	iters: 200, epoch: 1 | loss: 1.0148287
	speed: 0.0238s/iter; left time: 45.2798s
Epoch: 1 cost time: 5.012654781341553
Epoch: 1, Steps: 210 | Train Loss: 1.0332097 Vali Loss: 1.0610995 Test Loss: 1.0476506
Validation loss decreased (inf --> 1.061100).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0182581
	speed: 0.0181s/iter; left time: 32.3700s
	iters: 200, epoch: 2 | loss: 1.0271128
	speed: 0.0194s/iter; left time: 32.8512s
Epoch: 2 cost time: 4.1825926303863525
Epoch: 2, Steps: 210 | Train Loss: 1.0264055 Vali Loss: 1.0573182 Test Loss: 1.0470203
Validation loss decreased (1.061100 --> 1.057318).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0207126
	speed: 0.0175s/iter; left time: 27.5984s
	iters: 200, epoch: 3 | loss: 1.0310378
	speed: 0.0160s/iter; left time: 23.6511s
Epoch: 3 cost time: 3.440105438232422
Epoch: 3, Steps: 210 | Train Loss: 1.0236960 Vali Loss: 1.0590781 Test Loss: 1.0479987
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0223389
	speed: 0.0145s/iter; left time: 19.9057s
	iters: 200, epoch: 4 | loss: 1.0247835
	speed: 0.0131s/iter; left time: 16.6340s
Epoch: 4 cost time: 2.9345409870147705
Epoch: 4, Steps: 210 | Train Loss: 1.0214932 Vali Loss: 1.0598840 Test Loss: 1.0488672
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0452859
	speed: 0.0192s/iter; left time: 22.2571s
	iters: 200, epoch: 5 | loss: 1.0102246
	speed: 0.0172s/iter; left time: 18.2598s
Epoch: 5 cost time: 3.7160332202911377
Epoch: 5, Steps: 210 | Train Loss: 1.0198862 Vali Loss: 1.0600312 Test Loss: 1.0497657
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0148602
	speed: 0.0188s/iter; left time: 17.8967s
	iters: 200, epoch: 6 | loss: 1.0040491
	speed: 0.0179s/iter; left time: 15.2567s
Epoch: 6 cost time: 3.8699376583099365
Epoch: 6, Steps: 210 | Train Loss: 1.0187954 Vali Loss: 1.0591823 Test Loss: 1.0505196
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0315735
	speed: 0.0186s/iter; left time: 13.7521s
	iters: 200, epoch: 7 | loss: 1.0188297
	speed: 0.0177s/iter; left time: 11.3150s
Epoch: 7 cost time: 3.7825541496276855
Epoch: 7, Steps: 210 | Train Loss: 1.0180669 Vali Loss: 1.0616809 Test Loss: 1.0508999
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0470203161239624, mae:0.8207104802131653
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0644722
	speed: 0.0158s/iter; left time: 31.6947s
	iters: 200, epoch: 1 | loss: 1.0123429
	speed: 0.0126s/iter; left time: 23.9108s
Epoch: 1 cost time: 2.7071900367736816
Epoch: 1, Steps: 210 | Train Loss: 1.0318912 Vali Loss: 1.0626782 Test Loss: 1.0470332
Validation loss decreased (inf --> 1.062678).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0235133
	speed: 0.0168s/iter; left time: 30.1460s
	iters: 200, epoch: 2 | loss: 1.0163124
	speed: 0.0172s/iter; left time: 29.0908s
Epoch: 2 cost time: 3.717888832092285
Epoch: 2, Steps: 210 | Train Loss: 1.0261932 Vali Loss: 1.0592315 Test Loss: 1.0468037
Validation loss decreased (1.062678 --> 1.059232).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0051636
	speed: 0.0205s/iter; left time: 32.3508s
	iters: 200, epoch: 3 | loss: 1.0157959
	speed: 0.0172s/iter; left time: 25.4514s
Epoch: 3 cost time: 3.7084267139434814
Epoch: 3, Steps: 210 | Train Loss: 1.0240834 Vali Loss: 1.0596192 Test Loss: 1.0470731
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0733185
	speed: 0.0201s/iter; left time: 27.4965s
	iters: 200, epoch: 4 | loss: 1.0371838
	speed: 0.0189s/iter; left time: 23.9630s
Epoch: 4 cost time: 3.983595848083496
Epoch: 4, Steps: 210 | Train Loss: 1.0217441 Vali Loss: 1.0595826 Test Loss: 1.0478891
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0226512
	speed: 0.0117s/iter; left time: 13.5593s
	iters: 200, epoch: 5 | loss: 1.0292318
	speed: 0.0106s/iter; left time: 11.2598s
Epoch: 5 cost time: 2.337369203567505
Epoch: 5, Steps: 210 | Train Loss: 1.0202535 Vali Loss: 1.0618600 Test Loss: 1.0489718
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0352185
	speed: 0.0160s/iter; left time: 15.2098s
	iters: 200, epoch: 6 | loss: 0.9887265
	speed: 0.0136s/iter; left time: 11.5803s
Epoch: 6 cost time: 3.0073373317718506
Epoch: 6, Steps: 210 | Train Loss: 1.0191335 Vali Loss: 1.0621728 Test Loss: 1.0496150
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0313038
	speed: 0.0180s/iter; left time: 13.3697s
	iters: 200, epoch: 7 | loss: 1.0224245
	speed: 0.0140s/iter; left time: 8.9646s
Epoch: 7 cost time: 3.0032949447631836
Epoch: 7, Steps: 210 | Train Loss: 1.0186118 Vali Loss: 1.0610789 Test Loss: 1.0499415
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0468037128448486, mae:0.8206253051757812
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0575029
	speed: 0.0139s/iter; left time: 27.7827s
	iters: 200, epoch: 1 | loss: 0.9979936
	speed: 0.0134s/iter; left time: 25.5027s
Epoch: 1 cost time: 2.8542020320892334
Epoch: 1, Steps: 210 | Train Loss: 1.0353271 Vali Loss: 1.0604508 Test Loss: 1.0488048
Validation loss decreased (inf --> 1.060451).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0271580
	speed: 0.0191s/iter; left time: 34.1226s
	iters: 200, epoch: 2 | loss: 1.0174940
	speed: 0.0172s/iter; left time: 29.0520s
Epoch: 2 cost time: 3.7009270191192627
Epoch: 2, Steps: 210 | Train Loss: 1.0273816 Vali Loss: 1.0589658 Test Loss: 1.0484359
Validation loss decreased (1.060451 --> 1.058966).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0385940
	speed: 0.0200s/iter; left time: 31.6349s
	iters: 200, epoch: 3 | loss: 1.0173552
	speed: 0.0174s/iter; left time: 25.7622s
Epoch: 3 cost time: 3.749084949493408
Epoch: 3, Steps: 210 | Train Loss: 1.0242773 Vali Loss: 1.0578821 Test Loss: 1.0475528
Validation loss decreased (1.058966 --> 1.057882).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0334611
	speed: 0.0165s/iter; left time: 22.6335s
	iters: 200, epoch: 4 | loss: 1.0429801
	speed: 0.0136s/iter; left time: 17.3222s
Epoch: 4 cost time: 2.941303014755249
Epoch: 4, Steps: 210 | Train Loss: 1.0220271 Vali Loss: 1.0579853 Test Loss: 1.0486116
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0161515
	speed: 0.0143s/iter; left time: 16.5654s
	iters: 200, epoch: 5 | loss: 1.0199422
	speed: 0.0128s/iter; left time: 13.5451s
Epoch: 5 cost time: 2.8117237091064453
Epoch: 5, Steps: 210 | Train Loss: 1.0203504 Vali Loss: 1.0628238 Test Loss: 1.0493401
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0163860
	speed: 0.0158s/iter; left time: 14.9898s
	iters: 200, epoch: 6 | loss: 1.0195613
	speed: 0.0182s/iter; left time: 15.5204s
Epoch: 6 cost time: 4.098097085952759
Epoch: 6, Steps: 210 | Train Loss: 1.0193084 Vali Loss: 1.0615506 Test Loss: 1.0502473
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0048422
	speed: 0.0230s/iter; left time: 17.0427s
	iters: 200, epoch: 7 | loss: 1.0172348
	speed: 0.0193s/iter; left time: 12.3494s
Epoch: 7 cost time: 4.129255533218384
Epoch: 7, Steps: 210 | Train Loss: 1.0187562 Vali Loss: 1.0609177 Test Loss: 1.0505425
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0316410
	speed: 0.0215s/iter; left time: 11.4406s
	iters: 200, epoch: 8 | loss: 1.0105979
	speed: 0.0159s/iter; left time: 6.8587s
Epoch: 8 cost time: 3.412876844406128
Epoch: 8, Steps: 210 | Train Loss: 1.0183062 Vali Loss: 1.0621867 Test Loss: 1.0506841
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0475528240203857, mae:0.8209681510925293
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0778575
	speed: 0.0275s/iter; left time: 53.9415s
	iters: 200, epoch: 1 | loss: 1.0439075
	speed: 0.0199s/iter; left time: 37.0973s
Epoch: 1 cost time: 4.099745512008667
Epoch: 1, Steps: 206 | Train Loss: 1.0376162 Vali Loss: 1.0532148 Test Loss: 1.0390214
Validation loss decreased (inf --> 1.053215).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0550349
	speed: 0.0195s/iter; left time: 34.3007s
	iters: 200, epoch: 2 | loss: 1.0125686
	speed: 0.0164s/iter; left time: 27.0693s
Epoch: 2 cost time: 3.5144689083099365
Epoch: 2, Steps: 206 | Train Loss: 1.0317603 Vali Loss: 1.0515348 Test Loss: 1.0396924
Validation loss decreased (1.053215 --> 1.051535).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9971481
	speed: 0.0193s/iter; left time: 29.9612s
	iters: 200, epoch: 3 | loss: 1.0506269
	speed: 0.0196s/iter; left time: 28.4086s
Epoch: 3 cost time: 4.205977201461792
Epoch: 3, Steps: 206 | Train Loss: 1.0294891 Vali Loss: 1.0496823 Test Loss: 1.0385685
Validation loss decreased (1.051535 --> 1.049682).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0048106
	speed: 0.0252s/iter; left time: 33.8611s
	iters: 200, epoch: 4 | loss: 1.0205325
	speed: 0.0197s/iter; left time: 24.5108s
Epoch: 4 cost time: 4.12604546546936
Epoch: 4, Steps: 206 | Train Loss: 1.0278205 Vali Loss: 1.0512208 Test Loss: 1.0408731
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0536212
	speed: 0.0159s/iter; left time: 18.0535s
	iters: 200, epoch: 5 | loss: 1.0507354
	speed: 0.0138s/iter; left time: 14.2760s
Epoch: 5 cost time: 2.921131134033203
Epoch: 5, Steps: 206 | Train Loss: 1.0265421 Vali Loss: 1.0517720 Test Loss: 1.0408126
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0127656
	speed: 0.0153s/iter; left time: 14.2308s
	iters: 200, epoch: 6 | loss: 0.9943337
	speed: 0.0134s/iter; left time: 11.1648s
Epoch: 6 cost time: 2.826951742172241
Epoch: 6, Steps: 206 | Train Loss: 1.0257810 Vali Loss: 1.0516698 Test Loss: 1.0415220
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0271398
	speed: 0.0191s/iter; left time: 13.8582s
	iters: 200, epoch: 7 | loss: 1.0427723
	speed: 0.0181s/iter; left time: 11.3384s
Epoch: 7 cost time: 3.8327503204345703
Epoch: 7, Steps: 206 | Train Loss: 1.0253193 Vali Loss: 1.0523386 Test Loss: 1.0419255
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0216446
	speed: 0.0232s/iter; left time: 12.0326s
	iters: 200, epoch: 8 | loss: 1.0403962
	speed: 0.0187s/iter; left time: 7.8225s
Epoch: 8 cost time: 3.896935224533081
Epoch: 8, Steps: 206 | Train Loss: 1.0250733 Vali Loss: 1.0524324 Test Loss: 1.0420566
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0385684967041016, mae:0.8184127807617188
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0556754
	speed: 0.0181s/iter; left time: 35.5438s
	iters: 200, epoch: 1 | loss: 1.0451759
	speed: 0.0147s/iter; left time: 27.2993s
Epoch: 1 cost time: 3.117875337600708
Epoch: 1, Steps: 206 | Train Loss: 1.0393986 Vali Loss: 1.0542486 Test Loss: 1.0394788
Validation loss decreased (inf --> 1.054249).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0357016
	speed: 0.0134s/iter; left time: 23.5764s
	iters: 200, epoch: 2 | loss: 1.0204276
	speed: 0.0125s/iter; left time: 20.6949s
Epoch: 2 cost time: 2.7180283069610596
Epoch: 2, Steps: 206 | Train Loss: 1.0323767 Vali Loss: 1.0516121 Test Loss: 1.0398291
Validation loss decreased (1.054249 --> 1.051612).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0196617
	speed: 0.0184s/iter; left time: 28.5552s
	iters: 200, epoch: 3 | loss: 1.0411266
	speed: 0.0163s/iter; left time: 23.6417s
Epoch: 3 cost time: 3.4652347564697266
Epoch: 3, Steps: 206 | Train Loss: 1.0296664 Vali Loss: 1.0507897 Test Loss: 1.0393592
Validation loss decreased (1.051612 --> 1.050790).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0375574
	speed: 0.0202s/iter; left time: 27.0798s
	iters: 200, epoch: 4 | loss: 1.0111598
	speed: 0.0172s/iter; left time: 21.3930s
Epoch: 4 cost time: 3.6562252044677734
Epoch: 4, Steps: 206 | Train Loss: 1.0280755 Vali Loss: 1.0516080 Test Loss: 1.0410448
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9998717
	speed: 0.0227s/iter; left time: 25.8151s
	iters: 200, epoch: 5 | loss: 1.0265226
	speed: 0.0184s/iter; left time: 19.1038s
Epoch: 5 cost time: 3.8880462646484375
Epoch: 5, Steps: 206 | Train Loss: 1.0270177 Vali Loss: 1.0512854 Test Loss: 1.0412562
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0312122
	speed: 0.0135s/iter; left time: 12.5850s
	iters: 200, epoch: 6 | loss: 1.0013559
	speed: 0.0153s/iter; left time: 12.7327s
Epoch: 6 cost time: 3.237957239151001
Epoch: 6, Steps: 206 | Train Loss: 1.0259471 Vali Loss: 1.0511626 Test Loss: 1.0415374
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0332649
	speed: 0.0193s/iter; left time: 13.9615s
	iters: 200, epoch: 7 | loss: 1.0461358
	speed: 0.0166s/iter; left time: 10.3775s
Epoch: 7 cost time: 3.4914891719818115
Epoch: 7, Steps: 206 | Train Loss: 1.0255904 Vali Loss: 1.0517387 Test Loss: 1.0418816
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0146534
	speed: 0.0164s/iter; left time: 8.4940s
	iters: 200, epoch: 8 | loss: 1.0247921
	speed: 0.0154s/iter; left time: 6.4441s
Epoch: 8 cost time: 3.283994674682617
Epoch: 8, Steps: 206 | Train Loss: 1.0250256 Vali Loss: 1.0520369 Test Loss: 1.0420038
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.039359211921692, mae:0.8187143206596375
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0282555
	speed: 0.0158s/iter; left time: 31.0186s
	iters: 200, epoch: 1 | loss: 1.0086650
	speed: 0.0154s/iter; left time: 28.5734s
Epoch: 1 cost time: 3.182570457458496
Epoch: 1, Steps: 206 | Train Loss: 1.0385628 Vali Loss: 1.0536621 Test Loss: 1.0382015
Validation loss decreased (inf --> 1.053662).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0343856
	speed: 0.0128s/iter; left time: 22.3764s
	iters: 200, epoch: 2 | loss: 1.0409510
	speed: 0.0121s/iter; left time: 20.1042s
Epoch: 2 cost time: 2.586721658706665
Epoch: 2, Steps: 206 | Train Loss: 1.0320951 Vali Loss: 1.0518076 Test Loss: 1.0388097
Validation loss decreased (1.053662 --> 1.051808).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0373263
	speed: 0.0202s/iter; left time: 31.2774s
	iters: 200, epoch: 3 | loss: 1.0206105
	speed: 0.0180s/iter; left time: 26.0939s
Epoch: 3 cost time: 3.8179726600646973
Epoch: 3, Steps: 206 | Train Loss: 1.0292800 Vali Loss: 1.0497082 Test Loss: 1.0389862
Validation loss decreased (1.051808 --> 1.049708).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0127418
	speed: 0.0153s/iter; left time: 20.5291s
	iters: 200, epoch: 4 | loss: 1.0256470
	speed: 0.0166s/iter; left time: 20.6650s
Epoch: 4 cost time: 3.5537943840026855
Epoch: 4, Steps: 206 | Train Loss: 1.0278632 Vali Loss: 1.0504118 Test Loss: 1.0404211
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0169306
	speed: 0.0164s/iter; left time: 18.5975s
	iters: 200, epoch: 5 | loss: 1.0143783
	speed: 0.0143s/iter; left time: 14.7905s
Epoch: 5 cost time: 3.015151262283325
Epoch: 5, Steps: 206 | Train Loss: 1.0264908 Vali Loss: 1.0511153 Test Loss: 1.0408785
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0395319
	speed: 0.0173s/iter; left time: 16.1404s
	iters: 200, epoch: 6 | loss: 1.0033667
	speed: 0.0129s/iter; left time: 10.7376s
Epoch: 6 cost time: 2.722332715988159
Epoch: 6, Steps: 206 | Train Loss: 1.0257225 Vali Loss: 1.0517670 Test Loss: 1.0417968
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0187365
	speed: 0.0232s/iter; left time: 16.8433s
	iters: 200, epoch: 7 | loss: 0.9959701
	speed: 0.0171s/iter; left time: 10.6936s
Epoch: 7 cost time: 3.6358957290649414
Epoch: 7, Steps: 206 | Train Loss: 1.0253688 Vali Loss: 1.0521435 Test Loss: 1.0419900
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0295098
	speed: 0.0182s/iter; left time: 9.4510s
	iters: 200, epoch: 8 | loss: 1.0221196
	speed: 0.0149s/iter; left time: 6.2339s
Epoch: 8 cost time: 3.1273422241210938
Epoch: 8, Steps: 206 | Train Loss: 1.0249902 Vali Loss: 1.0522687 Test Loss: 1.0421921
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0389862060546875, mae:0.8185245990753174
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.5_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.5_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0341233
	speed: 0.0287s/iter; left time: 52.9148s
Epoch: 1 cost time: 4.4493248462677
Epoch: 1, Steps: 194 | Train Loss: 1.0429033 Vali Loss: 1.0450176 Test Loss: 1.0381087
Validation loss decreased (inf --> 1.045018).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0483265
	speed: 0.0193s/iter; left time: 31.8576s
Epoch: 2 cost time: 3.40981388092041
Epoch: 2, Steps: 194 | Train Loss: 1.0384344 Vali Loss: 1.0445943 Test Loss: 1.0386312
Validation loss decreased (1.045018 --> 1.044594).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0353780
	speed: 0.0188s/iter; left time: 27.3121s
Epoch: 3 cost time: 3.249446153640747
Epoch: 3, Steps: 194 | Train Loss: 1.0369258 Vali Loss: 1.0434965 Test Loss: 1.0394754
Validation loss decreased (1.044594 --> 1.043496).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0319533
	speed: 0.0172s/iter; left time: 21.6790s
Epoch: 4 cost time: 3.2406911849975586
Epoch: 4, Steps: 194 | Train Loss: 1.0357882 Vali Loss: 1.0433252 Test Loss: 1.0399501
Validation loss decreased (1.043496 --> 1.043325).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0454680
	speed: 0.0213s/iter; left time: 22.6741s
Epoch: 5 cost time: 3.3814640045166016
Epoch: 5, Steps: 194 | Train Loss: 1.0346831 Vali Loss: 1.0431633 Test Loss: 1.0408823
Validation loss decreased (1.043325 --> 1.043163).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0307959
	speed: 0.0177s/iter; left time: 15.4332s
Epoch: 6 cost time: 3.2620465755462646
Epoch: 6, Steps: 194 | Train Loss: 1.0342312 Vali Loss: 1.0434322 Test Loss: 1.0406054
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0135081
	speed: 0.0237s/iter; left time: 16.0393s
Epoch: 7 cost time: 3.737511396408081
Epoch: 7, Steps: 194 | Train Loss: 1.0340402 Vali Loss: 1.0436968 Test Loss: 1.0407656
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0354397
	speed: 0.0155s/iter; left time: 7.5069s
Epoch: 8 cost time: 2.9985430240631104
Epoch: 8, Steps: 194 | Train Loss: 1.0337014 Vali Loss: 1.0439423 Test Loss: 1.0407445
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0194654
	speed: 0.0187s/iter; left time: 5.4177s
Epoch: 9 cost time: 3.2265727519989014
Epoch: 9, Steps: 194 | Train Loss: 1.0336290 Vali Loss: 1.0437169 Test Loss: 1.0407979
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 1.0298197
	speed: 0.0138s/iter; left time: 1.3132s
Epoch: 10 cost time: 2.4605746269226074
Epoch: 10, Steps: 194 | Train Loss: 1.0337319 Vali Loss: 1.0437342 Test Loss: 1.0408167
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0408821105957031, mae:0.8187035322189331
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0643426
	speed: 0.0198s/iter; left time: 36.5157s
Epoch: 1 cost time: 3.4147770404815674
Epoch: 1, Steps: 194 | Train Loss: 1.0444333 Vali Loss: 1.0454422 Test Loss: 1.0399691
Validation loss decreased (inf --> 1.045442).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0356412
	speed: 0.0288s/iter; left time: 47.3538s
Epoch: 2 cost time: 4.154188394546509
Epoch: 2, Steps: 194 | Train Loss: 1.0387391 Vali Loss: 1.0437797 Test Loss: 1.0396491
Validation loss decreased (1.045442 --> 1.043780).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0314131
	speed: 0.0258s/iter; left time: 37.4825s
Epoch: 3 cost time: 3.686363935470581
Epoch: 3, Steps: 194 | Train Loss: 1.0372743 Vali Loss: 1.0431743 Test Loss: 1.0403811
Validation loss decreased (1.043780 --> 1.043174).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0178375
	speed: 0.0163s/iter; left time: 20.5712s
Epoch: 4 cost time: 2.6841623783111572
Epoch: 4, Steps: 194 | Train Loss: 1.0359858 Vali Loss: 1.0429004 Test Loss: 1.0406026
Validation loss decreased (1.043174 --> 1.042900).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0391161
	speed: 0.0182s/iter; left time: 19.3711s
Epoch: 5 cost time: 3.348417282104492
Epoch: 5, Steps: 194 | Train Loss: 1.0351756 Vali Loss: 1.0435611 Test Loss: 1.0405262
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0303795
	speed: 0.0163s/iter; left time: 14.1764s
Epoch: 6 cost time: 3.814819097518921
Epoch: 6, Steps: 194 | Train Loss: 1.0346687 Vali Loss: 1.0436032 Test Loss: 1.0404816
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0273687
	speed: 0.0181s/iter; left time: 12.2311s
Epoch: 7 cost time: 3.1860482692718506
Epoch: 7, Steps: 194 | Train Loss: 1.0343233 Vali Loss: 1.0438069 Test Loss: 1.0405679
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0327978
	speed: 0.0160s/iter; left time: 7.7207s
Epoch: 8 cost time: 2.705653190612793
Epoch: 8, Steps: 194 | Train Loss: 1.0341240 Vali Loss: 1.0438391 Test Loss: 1.0406326
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0242848
	speed: 0.0171s/iter; left time: 4.9287s
Epoch: 9 cost time: 2.8591504096984863
Epoch: 9, Steps: 194 | Train Loss: 1.0340092 Vali Loss: 1.0437542 Test Loss: 1.0406585
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.040602445602417, mae:0.8185864686965942
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0395432
	speed: 0.0165s/iter; left time: 30.4447s
Epoch: 1 cost time: 2.94498610496521
Epoch: 1, Steps: 194 | Train Loss: 1.0436644 Vali Loss: 1.0454366 Test Loss: 1.0385143
Validation loss decreased (inf --> 1.045437).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.0432631
	speed: 0.0188s/iter; left time: 31.0356s
Epoch: 2 cost time: 3.0389585494995117
Epoch: 2, Steps: 194 | Train Loss: 1.0381094 Vali Loss: 1.0453213 Test Loss: 1.0397525
Validation loss decreased (1.045437 --> 1.045321).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0305514
	speed: 0.0254s/iter; left time: 36.9623s
Epoch: 3 cost time: 3.7867438793182373
Epoch: 3, Steps: 194 | Train Loss: 1.0365380 Vali Loss: 1.0440701 Test Loss: 1.0390248
Validation loss decreased (1.045321 --> 1.044070).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0782130
	speed: 0.0195s/iter; left time: 24.5326s
Epoch: 4 cost time: 2.9618918895721436
Epoch: 4, Steps: 194 | Train Loss: 1.0354718 Vali Loss: 1.0438679 Test Loss: 1.0393260
Validation loss decreased (1.044070 --> 1.043868).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0317907
	speed: 0.0181s/iter; left time: 19.2768s
Epoch: 5 cost time: 3.3066980838775635
Epoch: 5, Steps: 194 | Train Loss: 1.0345740 Vali Loss: 1.0442880 Test Loss: 1.0398985
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0150803
	speed: 0.0176s/iter; left time: 15.3582s
Epoch: 6 cost time: 3.212822675704956
Epoch: 6, Steps: 194 | Train Loss: 1.0341179 Vali Loss: 1.0438983 Test Loss: 1.0401011
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.0188615
	speed: 0.0164s/iter; left time: 11.1347s
Epoch: 7 cost time: 3.085512399673462
Epoch: 7, Steps: 194 | Train Loss: 1.0339499 Vali Loss: 1.0440423 Test Loss: 1.0405514
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 1.0339611
	speed: 0.0210s/iter; left time: 10.1307s
Epoch: 8 cost time: 3.5908288955688477
Epoch: 8, Steps: 194 | Train Loss: 1.0336850 Vali Loss: 1.0440209 Test Loss: 1.0406107
EarlyStopping counter: 4 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 1.0449598
	speed: 0.0123s/iter; left time: 3.5455s
Epoch: 9 cost time: 2.2253799438476562
Epoch: 9, Steps: 194 | Train Loss: 1.0334761 Vali Loss: 1.0442588 Test Loss: 1.0406969
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.5_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.0393257141113281, mae:0.8181018233299255
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5368902
	speed: 0.0476s/iter; left time: 96.6311s
	iters: 200, epoch: 1 | loss: 0.5089414
	speed: 0.0320s/iter; left time: 61.8120s
Epoch: 1 cost time: 6.646918296813965
Epoch: 1, Steps: 213 | Train Loss: 0.5342740 Vali Loss: 0.5018744 Test Loss: 0.5986714
Validation loss decreased (inf --> 0.501874).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4319713
	speed: 0.0195s/iter; left time: 35.3960s
	iters: 200, epoch: 2 | loss: 0.5064109
	speed: 0.0141s/iter; left time: 24.1471s
Epoch: 2 cost time: 2.976165533065796
Epoch: 2, Steps: 213 | Train Loss: 0.5171958 Vali Loss: 0.5011216 Test Loss: 0.6163115
Validation loss decreased (0.501874 --> 0.501122).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5586669
	speed: 0.0234s/iter; left time: 37.4818s
	iters: 200, epoch: 3 | loss: 0.5756044
	speed: 0.0188s/iter; left time: 28.3222s
Epoch: 3 cost time: 4.075759172439575
Epoch: 3, Steps: 213 | Train Loss: 0.5068795 Vali Loss: 0.5055450 Test Loss: 0.5962181
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5149711
	speed: 0.0204s/iter; left time: 28.3323s
	iters: 200, epoch: 4 | loss: 0.4660637
	speed: 0.0173s/iter; left time: 22.3336s
Epoch: 4 cost time: 3.7297964096069336
Epoch: 4, Steps: 213 | Train Loss: 0.4991684 Vali Loss: 0.5090481 Test Loss: 0.6033655
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4806891
	speed: 0.0197s/iter; left time: 23.1821s
	iters: 200, epoch: 5 | loss: 0.4578888
	speed: 0.0159s/iter; left time: 17.2030s
Epoch: 5 cost time: 3.445216655731201
Epoch: 5, Steps: 213 | Train Loss: 0.4940923 Vali Loss: 0.5084065 Test Loss: 0.6056997
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4803650
	speed: 0.0139s/iter; left time: 13.4533s
	iters: 200, epoch: 6 | loss: 0.5440869
	speed: 0.0115s/iter; left time: 9.9909s
Epoch: 6 cost time: 2.499176263809204
Epoch: 6, Steps: 213 | Train Loss: 0.4918321 Vali Loss: 0.5088044 Test Loss: 0.6072562
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3959749
	speed: 0.0238s/iter; left time: 17.9493s
	iters: 200, epoch: 7 | loss: 0.5157177
	speed: 0.0185s/iter; left time: 12.0868s
Epoch: 7 cost time: 4.103225946426392
Epoch: 7, Steps: 213 | Train Loss: 0.4896905 Vali Loss: 0.5114477 Test Loss: 0.6085742
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6163116097450256, mae:0.6206470131874084
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5339700
	speed: 0.0246s/iter; left time: 50.0271s
	iters: 200, epoch: 1 | loss: 0.6400306
	speed: 0.0221s/iter; left time: 42.5932s
Epoch: 1 cost time: 4.721680164337158
Epoch: 1, Steps: 213 | Train Loss: 0.5353230 Vali Loss: 0.5101249 Test Loss: 0.6021327
Validation loss decreased (inf --> 0.510125).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4552264
	speed: 0.0163s/iter; left time: 29.7106s
	iters: 200, epoch: 2 | loss: 0.5395488
	speed: 0.0141s/iter; left time: 24.1631s
Epoch: 2 cost time: 3.0543599128723145
Epoch: 2, Steps: 213 | Train Loss: 0.5172581 Vali Loss: 0.5031698 Test Loss: 0.6077177
Validation loss decreased (0.510125 --> 0.503170).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4438934
	speed: 0.0213s/iter; left time: 34.1271s
	iters: 200, epoch: 3 | loss: 0.4938299
	speed: 0.0174s/iter; left time: 26.2420s
Epoch: 3 cost time: 3.726450204849243
Epoch: 3, Steps: 213 | Train Loss: 0.5056050 Vali Loss: 0.4995109 Test Loss: 0.6088596
Validation loss decreased (0.503170 --> 0.499511).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4985363
	speed: 0.0290s/iter; left time: 40.3887s
	iters: 200, epoch: 4 | loss: 0.5004942
	speed: 0.0225s/iter; left time: 29.0691s
Epoch: 4 cost time: 4.808751344680786
Epoch: 4, Steps: 213 | Train Loss: 0.4971788 Vali Loss: 0.5023987 Test Loss: 0.6071879
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4657350
	speed: 0.0168s/iter; left time: 19.8080s
	iters: 200, epoch: 5 | loss: 0.5041000
	speed: 0.0164s/iter; left time: 17.6514s
Epoch: 5 cost time: 3.524409532546997
Epoch: 5, Steps: 213 | Train Loss: 0.4930878 Vali Loss: 0.4976488 Test Loss: 0.6174008
Validation loss decreased (0.499511 --> 0.497649).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4779820
	speed: 0.0162s/iter; left time: 15.6246s
	iters: 200, epoch: 6 | loss: 0.4838915
	speed: 0.0138s/iter; left time: 11.9699s
Epoch: 6 cost time: 2.989197254180908
Epoch: 6, Steps: 213 | Train Loss: 0.4903621 Vali Loss: 0.5022134 Test Loss: 0.6115525
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4936105
	speed: 0.0174s/iter; left time: 13.1015s
	iters: 200, epoch: 7 | loss: 0.5248619
	speed: 0.0169s/iter; left time: 11.0294s
Epoch: 7 cost time: 3.645874500274658
Epoch: 7, Steps: 213 | Train Loss: 0.4885958 Vali Loss: 0.5102311 Test Loss: 0.6122960
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4737919
	speed: 0.0200s/iter; left time: 10.7827s
	iters: 200, epoch: 8 | loss: 0.5598161
	speed: 0.0178s/iter; left time: 7.8309s
Epoch: 8 cost time: 3.910902261734009
Epoch: 8, Steps: 213 | Train Loss: 0.4880178 Vali Loss: 0.5051002 Test Loss: 0.6136215
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4828191
	speed: 0.0203s/iter; left time: 6.6506s
	iters: 200, epoch: 9 | loss: 0.4768985
	speed: 0.0177s/iter; left time: 4.0278s
Epoch: 9 cost time: 3.8359153270721436
Epoch: 9, Steps: 213 | Train Loss: 0.4876920 Vali Loss: 0.5053328 Test Loss: 0.6136233
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.4381905
	speed: 0.0164s/iter; left time: 1.8659s
	iters: 200, epoch: 10 | loss: 0.4346012
	speed: 0.0140s/iter; left time: 0.1959s
Epoch: 10 cost time: 3.088592052459717
Epoch: 10, Steps: 213 | Train Loss: 0.4875185 Vali Loss: 0.5106620 Test Loss: 0.6136891
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6174007058143616, mae:0.6227635145187378
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5526035
	speed: 0.0192s/iter; left time: 39.0243s
	iters: 200, epoch: 1 | loss: 0.4927911
	speed: 0.0156s/iter; left time: 30.2154s
Epoch: 1 cost time: 3.3772475719451904
Epoch: 1, Steps: 213 | Train Loss: 0.5328460 Vali Loss: 0.5085866 Test Loss: 0.6056907
Validation loss decreased (inf --> 0.508587).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4442086
	speed: 0.0207s/iter; left time: 37.6935s
	iters: 200, epoch: 2 | loss: 0.4722577
	speed: 0.0172s/iter; left time: 29.4892s
Epoch: 2 cost time: 3.737874746322632
Epoch: 2, Steps: 213 | Train Loss: 0.5170056 Vali Loss: 0.4969333 Test Loss: 0.5834286
Validation loss decreased (0.508587 --> 0.496933).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4871076
	speed: 0.0183s/iter; left time: 29.3052s
	iters: 200, epoch: 3 | loss: 0.4735730
	speed: 0.0160s/iter; left time: 24.0748s
Epoch: 3 cost time: 3.5141830444335938
Epoch: 3, Steps: 213 | Train Loss: 0.5075889 Vali Loss: 0.5005129 Test Loss: 0.5981570
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5001891
	speed: 0.0139s/iter; left time: 19.2886s
	iters: 200, epoch: 4 | loss: 0.5562416
	speed: 0.0149s/iter; left time: 19.2332s
Epoch: 4 cost time: 3.2385289669036865
Epoch: 4, Steps: 213 | Train Loss: 0.5001663 Vali Loss: 0.5016600 Test Loss: 0.5978247
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5210322
	speed: 0.0156s/iter; left time: 18.3740s
	iters: 200, epoch: 5 | loss: 0.5059594
	speed: 0.0138s/iter; left time: 14.9092s
Epoch: 5 cost time: 2.984898567199707
Epoch: 5, Steps: 213 | Train Loss: 0.4944944 Vali Loss: 0.5054063 Test Loss: 0.5994508
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4965672
	speed: 0.0204s/iter; left time: 19.6588s
	iters: 200, epoch: 6 | loss: 0.4779100
	speed: 0.0188s/iter; left time: 16.2793s
Epoch: 6 cost time: 4.107936382293701
Epoch: 6, Steps: 213 | Train Loss: 0.4918881 Vali Loss: 0.5118413 Test Loss: 0.6027018
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5390712
	speed: 0.0200s/iter; left time: 15.0651s
	iters: 200, epoch: 7 | loss: 0.4547640
	speed: 0.0187s/iter; left time: 12.2211s
Epoch: 7 cost time: 4.053671836853027
Epoch: 7, Steps: 213 | Train Loss: 0.4900940 Vali Loss: 0.5167431 Test Loss: 0.6045755
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5834287405014038, mae:0.603463888168335
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8038437
	speed: 0.0339s/iter; left time: 67.8895s
	iters: 200, epoch: 1 | loss: 0.6936069
	speed: 0.0242s/iter; left time: 45.9807s
Epoch: 1 cost time: 5.138446092605591
Epoch: 1, Steps: 210 | Train Loss: 0.6644616 Vali Loss: 0.6154536 Test Loss: 0.8797152
Validation loss decreased (inf --> 0.615454).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6963680
	speed: 0.0211s/iter; left time: 37.7403s
	iters: 200, epoch: 2 | loss: 0.5972572
	speed: 0.0191s/iter; left time: 32.3228s
Epoch: 2 cost time: 4.008081436157227
Epoch: 2, Steps: 210 | Train Loss: 0.6481953 Vali Loss: 0.6052579 Test Loss: 0.8834565
Validation loss decreased (0.615454 --> 0.605258).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6772715
	speed: 0.0142s/iter; left time: 22.3916s
	iters: 200, epoch: 3 | loss: 0.6436535
	speed: 0.0118s/iter; left time: 17.4204s
Epoch: 3 cost time: 2.529766321182251
Epoch: 3, Steps: 210 | Train Loss: 0.6347193 Vali Loss: 0.6276733 Test Loss: 0.9494669
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6796357
	speed: 0.0137s/iter; left time: 18.7943s
	iters: 200, epoch: 4 | loss: 0.6297117
	speed: 0.0137s/iter; left time: 17.3670s
Epoch: 4 cost time: 2.9785921573638916
Epoch: 4, Steps: 210 | Train Loss: 0.6217051 Vali Loss: 0.6310685 Test Loss: 0.9478680
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6122185
	speed: 0.0193s/iter; left time: 22.4081s
	iters: 200, epoch: 5 | loss: 0.6323251
	speed: 0.0170s/iter; left time: 18.0435s
Epoch: 5 cost time: 3.6978745460510254
Epoch: 5, Steps: 210 | Train Loss: 0.6138819 Vali Loss: 0.6423667 Test Loss: 0.9647896
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6301754
	speed: 0.0223s/iter; left time: 21.1832s
	iters: 200, epoch: 6 | loss: 0.6351216
	speed: 0.0196s/iter; left time: 16.7186s
Epoch: 6 cost time: 4.180747032165527
Epoch: 6, Steps: 210 | Train Loss: 0.6104815 Vali Loss: 0.6449513 Test Loss: 0.9741343
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6470896
	speed: 0.0236s/iter; left time: 17.4670s
	iters: 200, epoch: 7 | loss: 0.6098605
	speed: 0.0179s/iter; left time: 11.4433s
Epoch: 7 cost time: 3.7651352882385254
Epoch: 7, Steps: 210 | Train Loss: 0.6088423 Vali Loss: 0.6543368 Test Loss: 0.9784804
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8834564685821533, mae:0.7376205921173096
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6803864
	speed: 0.0179s/iter; left time: 35.9060s
	iters: 200, epoch: 1 | loss: 0.6287336
	speed: 0.0170s/iter; left time: 32.3991s
Epoch: 1 cost time: 3.688760757446289
Epoch: 1, Steps: 210 | Train Loss: 0.6637432 Vali Loss: 0.6102968 Test Loss: 0.8943590
Validation loss decreased (inf --> 0.610297).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6474647
	speed: 0.0210s/iter; left time: 37.5759s
	iters: 200, epoch: 2 | loss: 0.6599900
	speed: 0.0184s/iter; left time: 31.0332s
Epoch: 2 cost time: 3.922853946685791
Epoch: 2, Steps: 210 | Train Loss: 0.6467452 Vali Loss: 0.6197230 Test Loss: 0.9163511
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5790042
	speed: 0.0215s/iter; left time: 33.9548s
	iters: 200, epoch: 3 | loss: 0.6422324
	speed: 0.0179s/iter; left time: 26.5729s
Epoch: 3 cost time: 3.7806522846221924
Epoch: 3, Steps: 210 | Train Loss: 0.6302136 Vali Loss: 0.6290542 Test Loss: 0.9060320
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5448042
	speed: 0.0154s/iter; left time: 21.1769s
	iters: 200, epoch: 4 | loss: 0.6409443
	speed: 0.0133s/iter; left time: 16.8730s
Epoch: 4 cost time: 2.787621259689331
Epoch: 4, Steps: 210 | Train Loss: 0.6164950 Vali Loss: 0.6369830 Test Loss: 0.9103490
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6442656
	speed: 0.0166s/iter; left time: 19.2923s
	iters: 200, epoch: 5 | loss: 0.7064067
	speed: 0.0140s/iter; left time: 14.8746s
Epoch: 5 cost time: 3.1255288124084473
Epoch: 5, Steps: 210 | Train Loss: 0.6074201 Vali Loss: 0.6314830 Test Loss: 0.9147558
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5848191
	speed: 0.0226s/iter; left time: 21.5399s
	iters: 200, epoch: 6 | loss: 0.6756899
	speed: 0.0201s/iter; left time: 17.0690s
Epoch: 6 cost time: 4.396394491195679
Epoch: 6, Steps: 210 | Train Loss: 0.6039765 Vali Loss: 0.6444865 Test Loss: 0.9329487
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8943589329719543, mae:0.7426093220710754
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6433622
	speed: 0.0215s/iter; left time: 42.9564s
	iters: 200, epoch: 1 | loss: 0.6331292
	speed: 0.0172s/iter; left time: 32.7694s
Epoch: 1 cost time: 3.653003692626953
Epoch: 1, Steps: 210 | Train Loss: 0.6695274 Vali Loss: 0.6056643 Test Loss: 0.8875870
Validation loss decreased (inf --> 0.605664).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6813737
	speed: 0.0160s/iter; left time: 28.6075s
	iters: 200, epoch: 2 | loss: 0.7036089
	speed: 0.0138s/iter; left time: 23.4142s
Epoch: 2 cost time: 3.1105215549468994
Epoch: 2, Steps: 210 | Train Loss: 0.6481321 Vali Loss: 0.6118587 Test Loss: 0.9008788
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6154631
	speed: 0.0166s/iter; left time: 26.2683s
	iters: 200, epoch: 3 | loss: 0.5471148
	speed: 0.0206s/iter; left time: 30.4359s
Epoch: 3 cost time: 4.554195880889893
Epoch: 3, Steps: 210 | Train Loss: 0.6297853 Vali Loss: 0.6252785 Test Loss: 0.9103092
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6361547
	speed: 0.0188s/iter; left time: 25.7702s
	iters: 200, epoch: 4 | loss: 0.5587895
	speed: 0.0166s/iter; left time: 21.1186s
Epoch: 4 cost time: 3.560765266418457
Epoch: 4, Steps: 210 | Train Loss: 0.6156266 Vali Loss: 0.6267523 Test Loss: 0.9442170
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5978667
	speed: 0.0188s/iter; left time: 21.7854s
	iters: 200, epoch: 5 | loss: 0.5234804
	speed: 0.0150s/iter; left time: 15.8973s
Epoch: 5 cost time: 3.163003921508789
Epoch: 5, Steps: 210 | Train Loss: 0.6071940 Vali Loss: 0.6517254 Test Loss: 0.9740301
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6582448
	speed: 0.0177s/iter; left time: 16.8660s
	iters: 200, epoch: 6 | loss: 0.5553880
	speed: 0.0180s/iter; left time: 15.3004s
Epoch: 6 cost time: 3.9749233722686768
Epoch: 6, Steps: 210 | Train Loss: 0.6029533 Vali Loss: 0.6516895 Test Loss: 0.9714875
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8875868916511536, mae:0.7408381700515747
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9065689
	speed: 0.0279s/iter; left time: 54.7704s
	iters: 200, epoch: 1 | loss: 0.8544816
	speed: 0.0205s/iter; left time: 38.2093s
Epoch: 1 cost time: 4.243379831314087
Epoch: 1, Steps: 206 | Train Loss: 0.8454639 Vali Loss: 0.7209387 Test Loss: 1.2348264
Validation loss decreased (inf --> 0.720939).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8541643
	speed: 0.0215s/iter; left time: 37.7828s
	iters: 200, epoch: 2 | loss: 0.7651259
	speed: 0.0177s/iter; left time: 29.3655s
Epoch: 2 cost time: 3.710003137588501
Epoch: 2, Steps: 206 | Train Loss: 0.8251472 Vali Loss: 0.7020566 Test Loss: 1.2472081
Validation loss decreased (0.720939 --> 0.702057).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0704284
	speed: 0.0215s/iter; left time: 33.3338s
	iters: 200, epoch: 3 | loss: 0.6768692
	speed: 0.0183s/iter; left time: 26.5609s
Epoch: 3 cost time: 3.936171293258667
Epoch: 3, Steps: 206 | Train Loss: 0.8050299 Vali Loss: 0.7095850 Test Loss: 1.3034511
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7318892
	speed: 0.0174s/iter; left time: 23.3573s
	iters: 200, epoch: 4 | loss: 0.6605703
	speed: 0.0159s/iter; left time: 19.7246s
Epoch: 4 cost time: 3.389587163925171
Epoch: 4, Steps: 206 | Train Loss: 0.7845937 Vali Loss: 0.7165275 Test Loss: 1.3560578
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7289052
	speed: 0.0190s/iter; left time: 21.5626s
	iters: 200, epoch: 5 | loss: 0.7428128
	speed: 0.0165s/iter; left time: 17.1170s
Epoch: 5 cost time: 3.4608099460601807
Epoch: 5, Steps: 206 | Train Loss: 0.7754017 Vali Loss: 0.7178031 Test Loss: 1.3626889
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7326264
	speed: 0.0145s/iter; left time: 13.4930s
	iters: 200, epoch: 6 | loss: 0.8316540
	speed: 0.0134s/iter; left time: 11.1273s
Epoch: 6 cost time: 2.9284353256225586
Epoch: 6, Steps: 206 | Train Loss: 0.7719320 Vali Loss: 0.7157813 Test Loss: 1.3639984
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6707433
	speed: 0.0123s/iter; left time: 8.9371s
	iters: 200, epoch: 7 | loss: 0.7715326
	speed: 0.0120s/iter; left time: 7.5191s
Epoch: 7 cost time: 2.5972979068756104
Epoch: 7, Steps: 206 | Train Loss: 0.7684529 Vali Loss: 0.7172187 Test Loss: 1.3675153
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2472079992294312, mae:0.8723692297935486
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7360371
	speed: 0.0157s/iter; left time: 30.8329s
	iters: 200, epoch: 1 | loss: 0.9136760
	speed: 0.0141s/iter; left time: 26.2674s
Epoch: 1 cost time: 3.006045341491699
Epoch: 1, Steps: 206 | Train Loss: 0.8453828 Vali Loss: 0.6746682 Test Loss: 1.2515440
Validation loss decreased (inf --> 0.674668).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7266691
	speed: 0.0138s/iter; left time: 24.2896s
	iters: 200, epoch: 2 | loss: 0.7433423
	speed: 0.0132s/iter; left time: 21.8429s
Epoch: 2 cost time: 2.8432676792144775
Epoch: 2, Steps: 206 | Train Loss: 0.8251616 Vali Loss: 0.7006496 Test Loss: 1.2389128
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7378733
	speed: 0.0161s/iter; left time: 25.0047s
	iters: 200, epoch: 3 | loss: 0.8791087
	speed: 0.0154s/iter; left time: 22.2606s
Epoch: 3 cost time: 3.2721517086029053
Epoch: 3, Steps: 206 | Train Loss: 0.8038216 Vali Loss: 0.6923020 Test Loss: 1.3177942
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8265569
	speed: 0.0167s/iter; left time: 22.4643s
	iters: 200, epoch: 4 | loss: 0.8208476
	speed: 0.0162s/iter; left time: 20.1180s
Epoch: 4 cost time: 3.536991596221924
Epoch: 4, Steps: 206 | Train Loss: 0.7863134 Vali Loss: 0.7384380 Test Loss: 1.3377455
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7292362
	speed: 0.0290s/iter; left time: 33.0225s
	iters: 200, epoch: 5 | loss: 0.8246243
	speed: 0.0225s/iter; left time: 23.3484s
Epoch: 5 cost time: 4.649953842163086
Epoch: 5, Steps: 206 | Train Loss: 0.7771709 Vali Loss: 0.7404380 Test Loss: 1.3588525
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8723922
	speed: 0.0149s/iter; left time: 13.9179s
	iters: 200, epoch: 6 | loss: 0.8483533
	speed: 0.0129s/iter; left time: 10.7372s
Epoch: 6 cost time: 2.7774078845977783
Epoch: 6, Steps: 206 | Train Loss: 0.7726000 Vali Loss: 0.7514302 Test Loss: 1.3630559
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2515439987182617, mae:0.8746888637542725
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8662967
	speed: 0.0218s/iter; left time: 42.7462s
	iters: 200, epoch: 1 | loss: 0.6595297
	speed: 0.0174s/iter; left time: 32.4723s
Epoch: 1 cost time: 3.648263692855835
Epoch: 1, Steps: 206 | Train Loss: 0.8469404 Vali Loss: 0.6717591 Test Loss: 1.2256932
Validation loss decreased (inf --> 0.671759).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8683237
	speed: 0.0188s/iter; left time: 32.9328s
	iters: 200, epoch: 2 | loss: 0.7626008
	speed: 0.0164s/iter; left time: 27.2222s
Epoch: 2 cost time: 3.4979748725891113
Epoch: 2, Steps: 206 | Train Loss: 0.8252248 Vali Loss: 0.7075194 Test Loss: 1.2235130
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7336971
	speed: 0.0153s/iter; left time: 23.6260s
	iters: 200, epoch: 3 | loss: 0.6560651
	speed: 0.0144s/iter; left time: 20.9297s
Epoch: 3 cost time: 3.074059247970581
Epoch: 3, Steps: 206 | Train Loss: 0.8076028 Vali Loss: 0.6992400 Test Loss: 1.2627661
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8213866
	speed: 0.0117s/iter; left time: 15.7616s
	iters: 200, epoch: 4 | loss: 0.7999845
	speed: 0.0109s/iter; left time: 13.4972s
Epoch: 4 cost time: 2.3722681999206543
Epoch: 4, Steps: 206 | Train Loss: 0.7914251 Vali Loss: 0.7167097 Test Loss: 1.3052204
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7348115
	speed: 0.0201s/iter; left time: 22.8667s
	iters: 200, epoch: 5 | loss: 0.7547902
	speed: 0.0172s/iter; left time: 17.8833s
Epoch: 5 cost time: 3.69431471824646
Epoch: 5, Steps: 206 | Train Loss: 0.7820685 Vali Loss: 0.7179177 Test Loss: 1.3224688
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8057976
	speed: 0.0173s/iter; left time: 16.0686s
	iters: 200, epoch: 6 | loss: 0.6997582
	speed: 0.0148s/iter; left time: 12.2938s
Epoch: 6 cost time: 3.1621673107147217
Epoch: 6, Steps: 206 | Train Loss: 0.7773953 Vali Loss: 0.7243396 Test Loss: 1.3398137
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2256932258605957, mae:0.8641634583473206
Seed: 42
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1341141
	speed: 0.0267s/iter; left time: 49.2157s
Epoch: 1 cost time: 4.166166305541992
Epoch: 1, Steps: 194 | Train Loss: 1.2274252 Vali Loss: 0.5680297 Test Loss: 1.4072489
Validation loss decreased (inf --> 0.568030).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1380005
	speed: 0.0256s/iter; left time: 42.1442s
Epoch: 2 cost time: 3.892906665802002
Epoch: 2, Steps: 194 | Train Loss: 1.2083865 Vali Loss: 0.5798029 Test Loss: 1.3900861
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0319110
	speed: 0.0249s/iter; left time: 36.2397s
Epoch: 3 cost time: 3.945887804031372
Epoch: 3, Steps: 194 | Train Loss: 1.1811775 Vali Loss: 0.6178935 Test Loss: 1.3647530
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2594624
	speed: 0.0180s/iter; left time: 22.6080s
Epoch: 4 cost time: 2.700263023376465
Epoch: 4, Steps: 194 | Train Loss: 1.1564432 Vali Loss: 0.6256996 Test Loss: 1.3704319
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1340718
	speed: 0.0159s/iter; left time: 16.9309s
Epoch: 5 cost time: 2.6349117755889893
Epoch: 5, Steps: 194 | Train Loss: 1.1384382 Vali Loss: 0.6387098 Test Loss: 1.3686377
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2693422
	speed: 0.0159s/iter; left time: 13.8421s
Epoch: 6 cost time: 3.0270493030548096
Epoch: 6, Steps: 194 | Train Loss: 1.1281778 Vali Loss: 0.6444781 Test Loss: 1.3713530
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.407248616218567, mae:0.928358256816864
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2219429
	speed: 0.0214s/iter; left time: 39.4205s
Epoch: 1 cost time: 4.007282495498657
Epoch: 1, Steps: 194 | Train Loss: 1.2297236 Vali Loss: 0.5565474 Test Loss: 1.4013619
Validation loss decreased (inf --> 0.556547).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.2217214
	speed: 0.0211s/iter; left time: 34.7405s
Epoch: 2 cost time: 3.3122029304504395
Epoch: 2, Steps: 194 | Train Loss: 1.2060281 Vali Loss: 0.5814965 Test Loss: 1.3977655
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1369828
	speed: 0.0153s/iter; left time: 22.1903s
Epoch: 3 cost time: 2.5049335956573486
Epoch: 3, Steps: 194 | Train Loss: 1.1791137 Vali Loss: 0.6428927 Test Loss: 1.3638164
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2392191
	speed: 0.0184s/iter; left time: 23.1583s
Epoch: 4 cost time: 3.605142593383789
Epoch: 4, Steps: 194 | Train Loss: 1.1536082 Vali Loss: 0.6662772 Test Loss: 1.3778825
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1631391
	speed: 0.0194s/iter; left time: 20.6428s
Epoch: 5 cost time: 3.1802942752838135
Epoch: 5, Steps: 194 | Train Loss: 1.1400520 Vali Loss: 0.6719958 Test Loss: 1.3809675
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9281909
	speed: 0.0230s/iter; left time: 20.0274s
Epoch: 6 cost time: 4.255016088485718
Epoch: 6, Steps: 194 | Train Loss: 1.1315934 Vali Loss: 0.6700134 Test Loss: 1.3888265
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4013620615005493, mae:0.9246529936790466
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9017278
	speed: 0.0156s/iter; left time: 28.6705s
Epoch: 1 cost time: 2.566070795059204
Epoch: 1, Steps: 194 | Train Loss: 1.2295388 Vali Loss: 0.5384046 Test Loss: 1.4179671
Validation loss decreased (inf --> 0.538405).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1618415
	speed: 0.0181s/iter; left time: 29.7944s
Epoch: 2 cost time: 3.3667824268341064
Epoch: 2, Steps: 194 | Train Loss: 1.2051800 Vali Loss: 0.5768164 Test Loss: 1.3441355
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.3171273
	speed: 0.0161s/iter; left time: 23.4066s
Epoch: 3 cost time: 2.837655544281006
Epoch: 3, Steps: 194 | Train Loss: 1.1767297 Vali Loss: 0.6464106 Test Loss: 1.3565803
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0525484
	speed: 0.0150s/iter; left time: 18.9144s
Epoch: 4 cost time: 2.669342517852783
Epoch: 4, Steps: 194 | Train Loss: 1.1534158 Vali Loss: 0.7043326 Test Loss: 1.3651439
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1535788
	speed: 0.0238s/iter; left time: 25.3072s
Epoch: 5 cost time: 3.988126516342163
Epoch: 5, Steps: 194 | Train Loss: 1.1417596 Vali Loss: 0.6968532 Test Loss: 1.3725977
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2807020
	speed: 0.0138s/iter; left time: 11.9933s
Epoch: 6 cost time: 2.6648755073547363
Epoch: 6, Steps: 194 | Train Loss: 1.1352646 Vali Loss: 0.6903346 Test Loss: 1.3774312
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_42<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4179669618606567, mae:0.9295995235443115
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.4551575
	speed: 0.0313s/iter; left time: 63.5230s
	iters: 200, epoch: 1 | loss: 0.5327554
	speed: 0.0218s/iter; left time: 42.1502s
Epoch: 1 cost time: 4.592453479766846
Epoch: 1, Steps: 213 | Train Loss: 0.5338602 Vali Loss: 0.5099040 Test Loss: 0.5924524
Validation loss decreased (inf --> 0.509904).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4608428
	speed: 0.0171s/iter; left time: 31.0613s
	iters: 200, epoch: 2 | loss: 0.5496804
	speed: 0.0141s/iter; left time: 24.2037s
Epoch: 2 cost time: 3.0881478786468506
Epoch: 2, Steps: 213 | Train Loss: 0.5156015 Vali Loss: 0.4927742 Test Loss: 0.5920820
Validation loss decreased (0.509904 --> 0.492774).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4478106
	speed: 0.0198s/iter; left time: 31.8125s
	iters: 200, epoch: 3 | loss: 0.4834128
	speed: 0.0209s/iter; left time: 31.4046s
Epoch: 3 cost time: 4.5545454025268555
Epoch: 3, Steps: 213 | Train Loss: 0.5047406 Vali Loss: 0.4951339 Test Loss: 0.6077854
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5385901
	speed: 0.0185s/iter; left time: 25.6891s
	iters: 200, epoch: 4 | loss: 0.5051288
	speed: 0.0173s/iter; left time: 22.3160s
Epoch: 4 cost time: 3.7990591526031494
Epoch: 4, Steps: 213 | Train Loss: 0.4960818 Vali Loss: 0.5042692 Test Loss: 0.6069803
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4552356
	speed: 0.0189s/iter; left time: 22.2740s
	iters: 200, epoch: 5 | loss: 0.4573831
	speed: 0.0175s/iter; left time: 18.8421s
Epoch: 5 cost time: 3.9820892810821533
Epoch: 5, Steps: 213 | Train Loss: 0.4918935 Vali Loss: 0.4988548 Test Loss: 0.6064527
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4972441
	speed: 0.0144s/iter; left time: 13.9385s
	iters: 200, epoch: 6 | loss: 0.4863056
	speed: 0.0129s/iter; left time: 11.1501s
Epoch: 6 cost time: 2.9188008308410645
Epoch: 6, Steps: 213 | Train Loss: 0.4881822 Vali Loss: 0.4998747 Test Loss: 0.6074463
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4793949
	speed: 0.0183s/iter; left time: 13.7696s
	iters: 200, epoch: 7 | loss: 0.4678454
	speed: 0.0169s/iter; left time: 11.0322s
Epoch: 7 cost time: 3.684389591217041
Epoch: 7, Steps: 213 | Train Loss: 0.4868660 Vali Loss: 0.5047809 Test Loss: 0.6074755
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.5920820832252502, mae:0.6077696084976196
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5427134
	speed: 0.0192s/iter; left time: 38.9212s
	iters: 200, epoch: 1 | loss: 0.4828181
	speed: 0.0172s/iter; left time: 33.1728s
Epoch: 1 cost time: 3.866340398788452
Epoch: 1, Steps: 213 | Train Loss: 0.5337671 Vali Loss: 0.5027509 Test Loss: 0.6128588
Validation loss decreased (inf --> 0.502751).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5155122
	speed: 0.0160s/iter; left time: 29.0796s
	iters: 200, epoch: 2 | loss: 0.4530828
	speed: 0.0135s/iter; left time: 23.1579s
Epoch: 2 cost time: 2.904067277908325
Epoch: 2, Steps: 213 | Train Loss: 0.5163362 Vali Loss: 0.5115285 Test Loss: 0.5967925
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4775049
	speed: 0.0160s/iter; left time: 25.6818s
	iters: 200, epoch: 3 | loss: 0.4969958
	speed: 0.0136s/iter; left time: 20.4747s
Epoch: 3 cost time: 2.922088384628296
Epoch: 3, Steps: 213 | Train Loss: 0.5062737 Vali Loss: 0.4944652 Test Loss: 0.6091985
Validation loss decreased (0.502751 --> 0.494465).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4845053
	speed: 0.0173s/iter; left time: 24.0183s
	iters: 200, epoch: 4 | loss: 0.5379967
	speed: 0.0154s/iter; left time: 19.9159s
Epoch: 4 cost time: 3.3585076332092285
Epoch: 4, Steps: 213 | Train Loss: 0.4980960 Vali Loss: 0.4967131 Test Loss: 0.6154672
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4935506
	speed: 0.0201s/iter; left time: 23.7034s
	iters: 200, epoch: 5 | loss: 0.4502800
	speed: 0.0172s/iter; left time: 18.6087s
Epoch: 5 cost time: 3.7733800411224365
Epoch: 5, Steps: 213 | Train Loss: 0.4933070 Vali Loss: 0.5002159 Test Loss: 0.6137657
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5095149
	speed: 0.0164s/iter; left time: 15.8233s
	iters: 200, epoch: 6 | loss: 0.4811341
	speed: 0.0158s/iter; left time: 13.6559s
Epoch: 6 cost time: 3.4662322998046875
Epoch: 6, Steps: 213 | Train Loss: 0.4897745 Vali Loss: 0.5056506 Test Loss: 0.6149275
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5792329
	speed: 0.0171s/iter; left time: 12.8898s
	iters: 200, epoch: 7 | loss: 0.4419793
	speed: 0.0129s/iter; left time: 8.4167s
Epoch: 7 cost time: 2.772193431854248
Epoch: 7, Steps: 213 | Train Loss: 0.4881964 Vali Loss: 0.5045182 Test Loss: 0.6128789
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5064620
	speed: 0.0177s/iter; left time: 9.5369s
	iters: 200, epoch: 8 | loss: 0.5185673
	speed: 0.0152s/iter; left time: 6.7020s
Epoch: 8 cost time: 3.3568239212036133
Epoch: 8, Steps: 213 | Train Loss: 0.4879392 Vali Loss: 0.5076530 Test Loss: 0.6132324
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6091984510421753, mae:0.6181131601333618
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5419368
	speed: 0.0172s/iter; left time: 34.9708s
	iters: 200, epoch: 1 | loss: 0.4419627
	speed: 0.0153s/iter; left time: 29.6386s
Epoch: 1 cost time: 3.4770753383636475
Epoch: 1, Steps: 213 | Train Loss: 0.5353739 Vali Loss: 0.5051504 Test Loss: 0.5955284
Validation loss decreased (inf --> 0.505150).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5006198
	speed: 0.0158s/iter; left time: 28.7357s
	iters: 200, epoch: 2 | loss: 0.5119414
	speed: 0.0169s/iter; left time: 29.0694s
Epoch: 2 cost time: 3.6481316089630127
Epoch: 2, Steps: 213 | Train Loss: 0.5175356 Vali Loss: 0.4925299 Test Loss: 0.6073157
Validation loss decreased (0.505150 --> 0.492530).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5314170
	speed: 0.0140s/iter; left time: 22.4050s
	iters: 200, epoch: 3 | loss: 0.4992456
	speed: 0.0128s/iter; left time: 19.2603s
Epoch: 3 cost time: 2.863882064819336
Epoch: 3, Steps: 213 | Train Loss: 0.5056422 Vali Loss: 0.4954718 Test Loss: 0.6089026
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5625812
	speed: 0.0155s/iter; left time: 21.5473s
	iters: 200, epoch: 4 | loss: 0.5750755
	speed: 0.0148s/iter; left time: 19.1084s
Epoch: 4 cost time: 3.265007495880127
Epoch: 4, Steps: 213 | Train Loss: 0.4981083 Vali Loss: 0.5057474 Test Loss: 0.6066347
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4958634
	speed: 0.0196s/iter; left time: 23.0674s
	iters: 200, epoch: 5 | loss: 0.4512587
	speed: 0.0177s/iter; left time: 19.0758s
Epoch: 5 cost time: 3.850390672683716
Epoch: 5, Steps: 213 | Train Loss: 0.4939480 Vali Loss: 0.5091341 Test Loss: 0.6053079
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4767419
	speed: 0.0195s/iter; left time: 18.8102s
	iters: 200, epoch: 6 | loss: 0.5361745
	speed: 0.0157s/iter; left time: 13.6181s
Epoch: 6 cost time: 3.367292881011963
Epoch: 6, Steps: 213 | Train Loss: 0.4910717 Vali Loss: 0.5063879 Test Loss: 0.6103062
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4671968
	speed: 0.0114s/iter; left time: 8.6031s
	iters: 200, epoch: 7 | loss: 0.4715102
	speed: 0.0108s/iter; left time: 7.0725s
Epoch: 7 cost time: 2.365666389465332
Epoch: 7, Steps: 213 | Train Loss: 0.4893900 Vali Loss: 0.5136142 Test Loss: 0.6107576
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6073156595230103, mae:0.6155220866203308
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6339461
	speed: 0.0311s/iter; left time: 62.3150s
	iters: 200, epoch: 1 | loss: 0.6426449
	speed: 0.0211s/iter; left time: 40.1426s
Epoch: 1 cost time: 4.368924140930176
Epoch: 1, Steps: 210 | Train Loss: 0.6644600 Vali Loss: 0.6163211 Test Loss: 0.8693606
Validation loss decreased (inf --> 0.616321).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7366395
	speed: 0.0181s/iter; left time: 32.4967s
	iters: 200, epoch: 2 | loss: 0.7003016
	speed: 0.0231s/iter; left time: 39.1366s
Epoch: 2 cost time: 5.037463903427124
Epoch: 2, Steps: 210 | Train Loss: 0.6478385 Vali Loss: 0.6069679 Test Loss: 0.8756812
Validation loss decreased (0.616321 --> 0.606968).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5941014
	speed: 0.0185s/iter; left time: 29.2821s
	iters: 200, epoch: 3 | loss: 0.6455822
	speed: 0.0174s/iter; left time: 25.7087s
Epoch: 3 cost time: 3.680695056915283
Epoch: 3, Steps: 210 | Train Loss: 0.6356849 Vali Loss: 0.6217602 Test Loss: 0.8880097
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6040263
	speed: 0.0228s/iter; left time: 31.3120s
	iters: 200, epoch: 4 | loss: 0.6979423
	speed: 0.0206s/iter; left time: 26.1422s
Epoch: 4 cost time: 4.317116975784302
Epoch: 4, Steps: 210 | Train Loss: 0.6253314 Vali Loss: 0.6268228 Test Loss: 0.9267042
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6328292
	speed: 0.0164s/iter; left time: 19.0766s
	iters: 200, epoch: 5 | loss: 0.6038347
	speed: 0.0142s/iter; left time: 15.0899s
Epoch: 5 cost time: 3.0760319232940674
Epoch: 5, Steps: 210 | Train Loss: 0.6194879 Vali Loss: 0.6245735 Test Loss: 0.9160302
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4909285
	speed: 0.0184s/iter; left time: 17.5091s
	iters: 200, epoch: 6 | loss: 0.6249745
	speed: 0.0166s/iter; left time: 14.1227s
Epoch: 6 cost time: 3.6221888065338135
Epoch: 6, Steps: 210 | Train Loss: 0.6153650 Vali Loss: 0.6271830 Test Loss: 0.9139432
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5617730
	speed: 0.0181s/iter; left time: 13.4048s
	iters: 200, epoch: 7 | loss: 0.6511486
	speed: 0.0182s/iter; left time: 11.6372s
Epoch: 7 cost time: 3.8524396419525146
Epoch: 7, Steps: 210 | Train Loss: 0.6132183 Vali Loss: 0.6292794 Test Loss: 0.9273906
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8756811022758484, mae:0.7347130179405212
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6691407
	speed: 0.0163s/iter; left time: 32.5400s
	iters: 200, epoch: 1 | loss: 0.7264332
	speed: 0.0153s/iter; left time: 29.0543s
Epoch: 1 cost time: 3.2758777141571045
Epoch: 1, Steps: 210 | Train Loss: 0.6644730 Vali Loss: 0.5992702 Test Loss: 0.9054111
Validation loss decreased (inf --> 0.599270).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7099561
	speed: 0.0148s/iter; left time: 26.5234s
	iters: 200, epoch: 2 | loss: 0.5629476
	speed: 0.0135s/iter; left time: 22.7872s
Epoch: 2 cost time: 2.9069039821624756
Epoch: 2, Steps: 210 | Train Loss: 0.6464821 Vali Loss: 0.5901989 Test Loss: 0.9290383
Validation loss decreased (0.599270 --> 0.590199).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6260496
	speed: 0.0179s/iter; left time: 28.3718s
	iters: 200, epoch: 3 | loss: 0.6444629
	speed: 0.0184s/iter; left time: 27.2831s
Epoch: 3 cost time: 3.9196958541870117
Epoch: 3, Steps: 210 | Train Loss: 0.6312003 Vali Loss: 0.6197596 Test Loss: 0.8932697
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5635515
	speed: 0.0179s/iter; left time: 24.5338s
	iters: 200, epoch: 4 | loss: 0.5682577
	speed: 0.0172s/iter; left time: 21.9131s
Epoch: 4 cost time: 3.67437744140625
Epoch: 4, Steps: 210 | Train Loss: 0.6185959 Vali Loss: 0.6203495 Test Loss: 0.9137719
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6885676
	speed: 0.0179s/iter; left time: 20.7360s
	iters: 200, epoch: 5 | loss: 0.6126236
	speed: 0.0172s/iter; left time: 18.2702s
Epoch: 5 cost time: 3.6814472675323486
Epoch: 5, Steps: 210 | Train Loss: 0.6113291 Vali Loss: 0.6229203 Test Loss: 0.9279009
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5932406
	speed: 0.0137s/iter; left time: 13.0496s
	iters: 200, epoch: 6 | loss: 0.5931887
	speed: 0.0139s/iter; left time: 11.8003s
Epoch: 6 cost time: 2.9692604541778564
Epoch: 6, Steps: 210 | Train Loss: 0.6060353 Vali Loss: 0.6338921 Test Loss: 0.9287817
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5405867
	speed: 0.0216s/iter; left time: 15.9852s
	iters: 200, epoch: 7 | loss: 0.6001306
	speed: 0.0225s/iter; left time: 14.4191s
Epoch: 7 cost time: 4.755570411682129
Epoch: 7, Steps: 210 | Train Loss: 0.6041580 Vali Loss: 0.6385195 Test Loss: 0.9262739
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9290382266044617, mae:0.7583957314491272
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8065402
	speed: 0.0160s/iter; left time: 32.0020s
	iters: 200, epoch: 1 | loss: 0.6503050
	speed: 0.0153s/iter; left time: 29.0960s
Epoch: 1 cost time: 3.335916757583618
Epoch: 1, Steps: 210 | Train Loss: 0.6647540 Vali Loss: 0.6083537 Test Loss: 0.8825380
Validation loss decreased (inf --> 0.608354).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5467116
	speed: 0.0207s/iter; left time: 37.1324s
	iters: 200, epoch: 2 | loss: 0.6877958
	speed: 0.0158s/iter; left time: 26.7259s
Epoch: 2 cost time: 3.340228319168091
Epoch: 2, Steps: 210 | Train Loss: 0.6470431 Vali Loss: 0.6193196 Test Loss: 0.8849813
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6141529
	speed: 0.0151s/iter; left time: 23.8300s
	iters: 200, epoch: 3 | loss: 0.6532820
	speed: 0.0136s/iter; left time: 20.0679s
Epoch: 3 cost time: 2.942471981048584
Epoch: 3, Steps: 210 | Train Loss: 0.6347503 Vali Loss: 0.6115725 Test Loss: 0.8873181
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7071611
	speed: 0.0168s/iter; left time: 23.0929s
	iters: 200, epoch: 4 | loss: 0.5896401
	speed: 0.0152s/iter; left time: 19.3516s
Epoch: 4 cost time: 3.279611349105835
Epoch: 4, Steps: 210 | Train Loss: 0.6230515 Vali Loss: 0.6194119 Test Loss: 0.9040782
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5450146
	speed: 0.0211s/iter; left time: 24.5543s
	iters: 200, epoch: 5 | loss: 0.5785587
	speed: 0.0177s/iter; left time: 18.7614s
Epoch: 5 cost time: 3.776925563812256
Epoch: 5, Steps: 210 | Train Loss: 0.6152237 Vali Loss: 0.6393171 Test Loss: 0.8998335
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5969638
	speed: 0.0197s/iter; left time: 18.7183s
	iters: 200, epoch: 6 | loss: 0.5572095
	speed: 0.0161s/iter; left time: 13.7000s
Epoch: 6 cost time: 3.410249710083008
Epoch: 6, Steps: 210 | Train Loss: 0.6115481 Vali Loss: 0.6409614 Test Loss: 0.9174211
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8825381398200989, mae:0.7377858757972717
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8625975
	speed: 0.0296s/iter; left time: 57.9697s
	iters: 200, epoch: 1 | loss: 0.9388742
	speed: 0.0231s/iter; left time: 43.0253s
Epoch: 1 cost time: 4.807962894439697
Epoch: 1, Steps: 206 | Train Loss: 0.8448278 Vali Loss: 0.6878198 Test Loss: 1.2301519
Validation loss decreased (inf --> 0.687820).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7868893
	speed: 0.0168s/iter; left time: 29.5424s
	iters: 200, epoch: 2 | loss: 0.7703956
	speed: 0.0157s/iter; left time: 25.9892s
Epoch: 2 cost time: 3.356541872024536
Epoch: 2, Steps: 206 | Train Loss: 0.8217818 Vali Loss: 0.6942256 Test Loss: 1.2468178
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6854525
	speed: 0.0136s/iter; left time: 21.1071s
	iters: 200, epoch: 3 | loss: 0.8375790
	speed: 0.0121s/iter; left time: 17.5826s
Epoch: 3 cost time: 2.5636632442474365
Epoch: 3, Steps: 206 | Train Loss: 0.8011685 Vali Loss: 0.7077817 Test Loss: 1.2867616
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8117658
	speed: 0.0175s/iter; left time: 23.5646s
	iters: 200, epoch: 4 | loss: 0.7273036
	speed: 0.0149s/iter; left time: 18.5283s
Epoch: 4 cost time: 3.2095396518707275
Epoch: 4, Steps: 206 | Train Loss: 0.7819757 Vali Loss: 0.7044073 Test Loss: 1.3441969
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8083813
	speed: 0.0173s/iter; left time: 19.6175s
	iters: 200, epoch: 5 | loss: 0.8163416
	speed: 0.0184s/iter; left time: 19.0966s
Epoch: 5 cost time: 3.8705902099609375
Epoch: 5, Steps: 206 | Train Loss: 0.7719796 Vali Loss: 0.7151390 Test Loss: 1.3550041
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7409697
	speed: 0.0183s/iter; left time: 17.0762s
	iters: 200, epoch: 6 | loss: 0.8949300
	speed: 0.0147s/iter; left time: 12.2220s
Epoch: 6 cost time: 3.0853404998779297
Epoch: 6, Steps: 206 | Train Loss: 0.7651020 Vali Loss: 0.7178105 Test Loss: 1.3566707
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2301521301269531, mae:0.864745557308197
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8823547
	speed: 0.0178s/iter; left time: 34.8249s
	iters: 200, epoch: 1 | loss: 0.8965069
	speed: 0.0159s/iter; left time: 29.6624s
Epoch: 1 cost time: 3.393850326538086
Epoch: 1, Steps: 206 | Train Loss: 0.8434020 Vali Loss: 0.6911416 Test Loss: 1.2288395
Validation loss decreased (inf --> 0.691142).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8397565
	speed: 0.0152s/iter; left time: 26.5922s
	iters: 200, epoch: 2 | loss: 0.7910669
	speed: 0.0137s/iter; left time: 22.7500s
Epoch: 2 cost time: 2.9344310760498047
Epoch: 2, Steps: 206 | Train Loss: 0.8213024 Vali Loss: 0.6810458 Test Loss: 1.2794412
Validation loss decreased (0.691142 --> 0.681046).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7619424
	speed: 0.0159s/iter; left time: 24.6423s
	iters: 200, epoch: 3 | loss: 1.0295708
	speed: 0.0154s/iter; left time: 22.3445s
Epoch: 3 cost time: 3.2983996868133545
Epoch: 3, Steps: 206 | Train Loss: 0.7995533 Vali Loss: 0.7188932 Test Loss: 1.3702270
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6885653
	speed: 0.0195s/iter; left time: 26.2061s
	iters: 200, epoch: 4 | loss: 0.8557295
	speed: 0.0178s/iter; left time: 22.1542s
Epoch: 4 cost time: 3.741121292114258
Epoch: 4, Steps: 206 | Train Loss: 0.7865435 Vali Loss: 0.7033307 Test Loss: 1.3243492
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8092101
	speed: 0.0206s/iter; left time: 23.4512s
	iters: 200, epoch: 5 | loss: 0.7085983
	speed: 0.0174s/iter; left time: 18.0596s
Epoch: 5 cost time: 3.700986385345459
Epoch: 5, Steps: 206 | Train Loss: 0.7787032 Vali Loss: 0.7242377 Test Loss: 1.3358059
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6292827
	speed: 0.0186s/iter; left time: 17.2989s
	iters: 200, epoch: 6 | loss: 0.9231319
	speed: 0.0154s/iter; left time: 12.7730s
Epoch: 6 cost time: 3.1830036640167236
Epoch: 6, Steps: 206 | Train Loss: 0.7724492 Vali Loss: 0.7276176 Test Loss: 1.3443842
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8047284
	speed: 0.0139s/iter; left time: 10.1126s
	iters: 200, epoch: 7 | loss: 0.8316841
	speed: 0.0148s/iter; left time: 9.2202s
Epoch: 7 cost time: 3.221450090408325
Epoch: 7, Steps: 206 | Train Loss: 0.7704649 Vali Loss: 0.7277657 Test Loss: 1.3472115
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2794411182403564, mae:0.8827915787696838
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8271030
	speed: 0.0204s/iter; left time: 40.0784s
	iters: 200, epoch: 1 | loss: 0.7924480
	speed: 0.0178s/iter; left time: 33.1468s
Epoch: 1 cost time: 3.788879871368408
Epoch: 1, Steps: 206 | Train Loss: 0.8456122 Vali Loss: 0.6862798 Test Loss: 1.2434541
Validation loss decreased (inf --> 0.686280).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8969407
	speed: 0.0175s/iter; left time: 30.6832s
	iters: 200, epoch: 2 | loss: 0.7256514
	speed: 0.0178s/iter; left time: 29.4967s
Epoch: 2 cost time: 3.784318685531616
Epoch: 2, Steps: 206 | Train Loss: 0.8255757 Vali Loss: 0.6673965 Test Loss: 1.2264395
Validation loss decreased (0.686280 --> 0.667396).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7564130
	speed: 0.0171s/iter; left time: 26.4607s
	iters: 200, epoch: 3 | loss: 0.7439157
	speed: 0.0131s/iter; left time: 19.0260s
Epoch: 3 cost time: 2.7902536392211914
Epoch: 3, Steps: 206 | Train Loss: 0.8103923 Vali Loss: 0.6998271 Test Loss: 1.2844856
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8664030
	speed: 0.0179s/iter; left time: 24.0776s
	iters: 200, epoch: 4 | loss: 0.9216964
	speed: 0.0162s/iter; left time: 20.1380s
Epoch: 4 cost time: 3.441800832748413
Epoch: 4, Steps: 206 | Train Loss: 0.7923917 Vali Loss: 0.7208164 Test Loss: 1.3196037
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8858352
	speed: 0.0163s/iter; left time: 18.5037s
	iters: 200, epoch: 5 | loss: 0.8099498
	speed: 0.0164s/iter; left time: 17.0547s
Epoch: 5 cost time: 3.4729790687561035
Epoch: 5, Steps: 206 | Train Loss: 0.7839543 Vali Loss: 0.7354031 Test Loss: 1.3434529
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7382443
	speed: 0.0182s/iter; left time: 16.9896s
	iters: 200, epoch: 6 | loss: 0.7920890
	speed: 0.0171s/iter; left time: 14.1959s
Epoch: 6 cost time: 3.5929155349731445
Epoch: 6, Steps: 206 | Train Loss: 0.7791701 Vali Loss: 0.7382019 Test Loss: 1.3499480
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8416985
	speed: 0.0166s/iter; left time: 12.0429s
	iters: 200, epoch: 7 | loss: 0.6498876
	speed: 0.0149s/iter; left time: 9.3225s
Epoch: 7 cost time: 3.140700578689575
Epoch: 7, Steps: 206 | Train Loss: 0.7777997 Vali Loss: 0.7387484 Test Loss: 1.3526452
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2264392375946045, mae:0.8624827861785889
Seed: 123
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1894011
	speed: 0.0277s/iter; left time: 50.9810s
Epoch: 1 cost time: 4.214997053146362
Epoch: 1, Steps: 194 | Train Loss: 1.2271476 Vali Loss: 0.5677821 Test Loss: 1.4074506
Validation loss decreased (inf --> 0.567782).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3807486
	speed: 0.0195s/iter; left time: 32.1889s
Epoch: 2 cost time: 3.3419296741485596
Epoch: 2, Steps: 194 | Train Loss: 1.2049607 Vali Loss: 0.6201997 Test Loss: 1.3578318
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1269397
	speed: 0.0138s/iter; left time: 20.0991s
Epoch: 3 cost time: 2.831841230392456
Epoch: 3, Steps: 194 | Train Loss: 1.1695228 Vali Loss: 0.6687356 Test Loss: 1.3849620
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2568724
	speed: 0.0163s/iter; left time: 20.5313s
Epoch: 4 cost time: 3.13008451461792
Epoch: 4, Steps: 194 | Train Loss: 1.1477924 Vali Loss: 0.6887950 Test Loss: 1.3943365
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0199211
	speed: 0.0169s/iter; left time: 17.9647s
Epoch: 5 cost time: 3.3860251903533936
Epoch: 5, Steps: 194 | Train Loss: 1.1324312 Vali Loss: 0.7109828 Test Loss: 1.3939970
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0794977
	speed: 0.0228s/iter; left time: 19.8528s
Epoch: 6 cost time: 3.738764524459839
Epoch: 6, Steps: 194 | Train Loss: 1.1243209 Vali Loss: 0.7323272 Test Loss: 1.3893914
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.407450795173645, mae:0.9283950328826904
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2169210
	speed: 0.0174s/iter; left time: 32.0926s
Epoch: 1 cost time: 2.910362958908081
Epoch: 1, Steps: 194 | Train Loss: 1.2307283 Vali Loss: 0.5780739 Test Loss: 1.3839078
Validation loss decreased (inf --> 0.578074).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.4235064
	speed: 0.0155s/iter; left time: 25.5950s
Epoch: 2 cost time: 3.0197439193725586
Epoch: 2, Steps: 194 | Train Loss: 1.2031707 Vali Loss: 0.5916104 Test Loss: 1.3652254
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1343976
	speed: 0.0177s/iter; left time: 25.7050s
Epoch: 3 cost time: 3.5915706157684326
Epoch: 3, Steps: 194 | Train Loss: 1.1737223 Vali Loss: 0.6116207 Test Loss: 1.3594533
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2166771
	speed: 0.0222s/iter; left time: 27.9951s
Epoch: 4 cost time: 3.6320438385009766
Epoch: 4, Steps: 194 | Train Loss: 1.1496204 Vali Loss: 0.6345424 Test Loss: 1.3611121
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.0811567
	speed: 0.0165s/iter; left time: 17.5782s
Epoch: 5 cost time: 3.136892557144165
Epoch: 5, Steps: 194 | Train Loss: 1.1322682 Vali Loss: 0.6118133 Test Loss: 1.3698999
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2229574
	speed: 0.0161s/iter; left time: 14.0301s
Epoch: 6 cost time: 3.180976390838623
Epoch: 6, Steps: 194 | Train Loss: 1.1222498 Vali Loss: 0.6230574 Test Loss: 1.3734698
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.383907675743103, mae:0.9227077960968018
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.1214192
	speed: 0.0239s/iter; left time: 43.9204s
Epoch: 1 cost time: 4.500207185745239
Epoch: 1, Steps: 194 | Train Loss: 1.2304680 Vali Loss: 0.5568664 Test Loss: 1.4251026
Validation loss decreased (inf --> 0.556866).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.4092567
	speed: 0.0198s/iter; left time: 32.5380s
Epoch: 2 cost time: 3.456685781478882
Epoch: 2, Steps: 194 | Train Loss: 1.2035331 Vali Loss: 0.6369882 Test Loss: 1.3674388
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2737837
	speed: 0.0203s/iter; left time: 29.4962s
Epoch: 3 cost time: 3.2048285007476807
Epoch: 3, Steps: 194 | Train Loss: 1.1788968 Vali Loss: 0.6141176 Test Loss: 1.3876661
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.1316520
	speed: 0.0133s/iter; left time: 16.6888s
Epoch: 4 cost time: 2.1958930492401123
Epoch: 4, Steps: 194 | Train Loss: 1.1544878 Vali Loss: 0.6399310 Test Loss: 1.3898058
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.2088734
	speed: 0.0178s/iter; left time: 18.9462s
Epoch: 5 cost time: 3.0507044792175293
Epoch: 5, Steps: 194 | Train Loss: 1.1379928 Vali Loss: 0.6241065 Test Loss: 1.3998510
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.3204145
	speed: 0.0191s/iter; left time: 16.6349s
Epoch: 6 cost time: 3.6006827354431152
Epoch: 6, Steps: 194 | Train Loss: 1.1235714 Vali Loss: 0.6239936 Test Loss: 1.4156317
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_123<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.4251025915145874, mae:0.9318647980690002
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_96Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5800641
	speed: 0.0263s/iter; left time: 53.3724s
	iters: 200, epoch: 1 | loss: 0.5178981
	speed: 0.0191s/iter; left time: 36.8919s
Epoch: 1 cost time: 4.063780307769775
Epoch: 1, Steps: 213 | Train Loss: 0.5342068 Vali Loss: 0.5070987 Test Loss: 0.5856049
Validation loss decreased (inf --> 0.507099).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5464072
	speed: 0.0169s/iter; left time: 30.7329s
	iters: 200, epoch: 2 | loss: 0.5809726
	speed: 0.0148s/iter; left time: 25.5053s
Epoch: 2 cost time: 3.1855976581573486
Epoch: 2, Steps: 213 | Train Loss: 0.5170045 Vali Loss: 0.5065176 Test Loss: 0.5951901
Validation loss decreased (0.507099 --> 0.506518).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5327779
	speed: 0.0126s/iter; left time: 20.1897s
	iters: 200, epoch: 3 | loss: 0.4802524
	speed: 0.0106s/iter; left time: 15.8825s
Epoch: 3 cost time: 2.2832190990448
Epoch: 3, Steps: 213 | Train Loss: 0.5051382 Vali Loss: 0.5007105 Test Loss: 0.6156049
Validation loss decreased (0.506518 --> 0.500710).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5697868
	speed: 0.0200s/iter; left time: 27.7975s
	iters: 200, epoch: 4 | loss: 0.5044456
	speed: 0.0163s/iter; left time: 21.1138s
Epoch: 4 cost time: 3.538278818130493
Epoch: 4, Steps: 213 | Train Loss: 0.4978824 Vali Loss: 0.5029727 Test Loss: 0.6176385
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4619266
	speed: 0.0181s/iter; left time: 21.3373s
	iters: 200, epoch: 5 | loss: 0.5022709
	speed: 0.0154s/iter; left time: 16.6675s
Epoch: 5 cost time: 3.3467330932617188
Epoch: 5, Steps: 213 | Train Loss: 0.4934650 Vali Loss: 0.5085862 Test Loss: 0.6077611
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4915274
	speed: 0.0165s/iter; left time: 15.9830s
	iters: 200, epoch: 6 | loss: 0.4562611
	speed: 0.0152s/iter; left time: 13.1478s
Epoch: 6 cost time: 3.357384204864502
Epoch: 6, Steps: 213 | Train Loss: 0.4903963 Vali Loss: 0.5104908 Test Loss: 0.6115681
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5355783
	speed: 0.0142s/iter; left time: 10.6971s
	iters: 200, epoch: 7 | loss: 0.5284024
	speed: 0.0133s/iter; left time: 8.6707s
Epoch: 7 cost time: 2.972938299179077
Epoch: 7, Steps: 213 | Train Loss: 0.4893276 Vali Loss: 0.5087461 Test Loss: 0.6117887
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5322931
	speed: 0.0146s/iter; left time: 7.8802s
	iters: 200, epoch: 8 | loss: 0.5291647
	speed: 0.0143s/iter; left time: 6.2709s
Epoch: 8 cost time: 3.150912284851074
Epoch: 8, Steps: 213 | Train Loss: 0.4887950 Vali Loss: 0.5131893 Test Loss: 0.6120790
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6156049370765686, mae:0.6222934126853943
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.4750140
	speed: 0.0147s/iter; left time: 29.7953s
	iters: 200, epoch: 1 | loss: 0.5740757
	speed: 0.0148s/iter; left time: 28.4992s
Epoch: 1 cost time: 3.2773704528808594
Epoch: 1, Steps: 213 | Train Loss: 0.5338122 Vali Loss: 0.5122569 Test Loss: 0.5958159
Validation loss decreased (inf --> 0.512257).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5373628
	speed: 0.0196s/iter; left time: 35.6232s
	iters: 200, epoch: 2 | loss: 0.4726492
	speed: 0.0182s/iter; left time: 31.1943s
Epoch: 2 cost time: 3.953918695449829
Epoch: 2, Steps: 213 | Train Loss: 0.5165157 Vali Loss: 0.5021174 Test Loss: 0.6020600
Validation loss decreased (0.512257 --> 0.502117).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6149436
	speed: 0.0137s/iter; left time: 21.9789s
	iters: 200, epoch: 3 | loss: 0.5164680
	speed: 0.0142s/iter; left time: 21.3846s
Epoch: 3 cost time: 3.05039381980896
Epoch: 3, Steps: 213 | Train Loss: 0.5057441 Vali Loss: 0.4888677 Test Loss: 0.6069100
Validation loss decreased (0.502117 --> 0.488868).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5057826
	speed: 0.0194s/iter; left time: 27.0012s
	iters: 200, epoch: 4 | loss: 0.4749723
	speed: 0.0170s/iter; left time: 22.0282s
Epoch: 4 cost time: 3.714463233947754
Epoch: 4, Steps: 213 | Train Loss: 0.4979174 Vali Loss: 0.5056661 Test Loss: 0.6016012
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5119757
	speed: 0.0182s/iter; left time: 21.4456s
	iters: 200, epoch: 5 | loss: 0.5016118
	speed: 0.0185s/iter; left time: 19.9250s
Epoch: 5 cost time: 4.1478071212768555
Epoch: 5, Steps: 213 | Train Loss: 0.4939078 Vali Loss: 0.5088293 Test Loss: 0.6074623
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5356027
	speed: 0.0219s/iter; left time: 21.1401s
	iters: 200, epoch: 6 | loss: 0.4641259
	speed: 0.0201s/iter; left time: 17.3754s
Epoch: 6 cost time: 4.265092372894287
Epoch: 6, Steps: 213 | Train Loss: 0.4908166 Vali Loss: 0.5118833 Test Loss: 0.6114058
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4918768
	speed: 0.0187s/iter; left time: 14.1100s
	iters: 200, epoch: 7 | loss: 0.4814387
	speed: 0.0149s/iter; left time: 9.7605s
Epoch: 7 cost time: 3.199599504470825
Epoch: 7, Steps: 213 | Train Loss: 0.4898349 Vali Loss: 0.5121061 Test Loss: 0.6119307
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5071695
	speed: 0.0248s/iter; left time: 13.4077s
	iters: 200, epoch: 8 | loss: 0.4995033
	speed: 0.0209s/iter; left time: 9.2170s
Epoch: 8 cost time: 4.434682846069336
Epoch: 8, Steps: 213 | Train Loss: 0.4890689 Vali Loss: 0.5096580 Test Loss: 0.6113592
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.606909990310669, mae:0.616072952747345
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.5350816
	speed: 0.0222s/iter; left time: 45.0038s
	iters: 200, epoch: 1 | loss: 0.4991462
	speed: 0.0180s/iter; left time: 34.8126s
Epoch: 1 cost time: 3.872929096221924
Epoch: 1, Steps: 213 | Train Loss: 0.5357280 Vali Loss: 0.5118338 Test Loss: 0.5960987
Validation loss decreased (inf --> 0.511834).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5098585
	speed: 0.0164s/iter; left time: 29.7960s
	iters: 200, epoch: 2 | loss: 0.5102113
	speed: 0.0143s/iter; left time: 24.5752s
Epoch: 2 cost time: 3.090667963027954
Epoch: 2, Steps: 213 | Train Loss: 0.5146420 Vali Loss: 0.4955257 Test Loss: 0.6177775
Validation loss decreased (0.511834 --> 0.495526).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4293467
	speed: 0.0149s/iter; left time: 23.8673s
	iters: 200, epoch: 3 | loss: 0.5062574
	speed: 0.0163s/iter; left time: 24.6019s
Epoch: 3 cost time: 3.586034059524536
Epoch: 3, Steps: 213 | Train Loss: 0.5031244 Vali Loss: 0.5004288 Test Loss: 0.6137317
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4961085
	speed: 0.0152s/iter; left time: 21.2230s
	iters: 200, epoch: 4 | loss: 0.4213095
	speed: 0.0151s/iter; left time: 19.5070s
Epoch: 4 cost time: 3.303251028060913
Epoch: 4, Steps: 213 | Train Loss: 0.4938483 Vali Loss: 0.5013195 Test Loss: 0.6113566
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4519261
	speed: 0.0174s/iter; left time: 20.4936s
	iters: 200, epoch: 5 | loss: 0.4467426
	speed: 0.0188s/iter; left time: 20.2344s
Epoch: 5 cost time: 4.253389120101929
Epoch: 5, Steps: 213 | Train Loss: 0.4883956 Vali Loss: 0.5194269 Test Loss: 0.6116550
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4648242
	speed: 0.0145s/iter; left time: 13.9856s
	iters: 200, epoch: 6 | loss: 0.4879019
	speed: 0.0139s/iter; left time: 12.0024s
Epoch: 6 cost time: 3.060250759124756
Epoch: 6, Steps: 213 | Train Loss: 0.4850860 Vali Loss: 0.5220459 Test Loss: 0.6117870
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5115061
	speed: 0.0165s/iter; left time: 12.4024s
	iters: 200, epoch: 7 | loss: 0.4313072
	speed: 0.0144s/iter; left time: 9.3901s
Epoch: 7 cost time: 3.185457706451416
Epoch: 7, Steps: 213 | Train Loss: 0.4829046 Vali Loss: 0.5190340 Test Loss: 0.6101866
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_96_iTransformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.6177775859832764, mae:0.6223393678665161
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_192Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           192                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8168633
	speed: 0.0257s/iter; left time: 51.3910s
	iters: 200, epoch: 1 | loss: 0.5684490
	speed: 0.0181s/iter; left time: 34.4720s
Epoch: 1 cost time: 3.9190378189086914
Epoch: 1, Steps: 210 | Train Loss: 0.6637727 Vali Loss: 0.6073512 Test Loss: 0.8981649
Validation loss decreased (inf --> 0.607351).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6565081
	speed: 0.0129s/iter; left time: 23.0576s
	iters: 200, epoch: 2 | loss: 0.5894611
	speed: 0.0135s/iter; left time: 22.7727s
Epoch: 2 cost time: 3.105386972427368
Epoch: 2, Steps: 210 | Train Loss: 0.6457360 Vali Loss: 0.6060412 Test Loss: 0.8842689
Validation loss decreased (0.607351 --> 0.606041).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5854414
	speed: 0.0188s/iter; left time: 29.7671s
	iters: 200, epoch: 3 | loss: 0.5955973
	speed: 0.0172s/iter; left time: 25.4382s
Epoch: 3 cost time: 3.712249994277954
Epoch: 3, Steps: 210 | Train Loss: 0.6312125 Vali Loss: 0.6101874 Test Loss: 0.9155284
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6403593
	speed: 0.0167s/iter; left time: 22.8661s
	iters: 200, epoch: 4 | loss: 0.6386994
	speed: 0.0169s/iter; left time: 21.4172s
Epoch: 4 cost time: 3.674438714981079
Epoch: 4, Steps: 210 | Train Loss: 0.6182739 Vali Loss: 0.6350013 Test Loss: 0.9114106
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6076173
	speed: 0.0172s/iter; left time: 20.0062s
	iters: 200, epoch: 5 | loss: 0.6047279
	speed: 0.0169s/iter; left time: 17.9319s
Epoch: 5 cost time: 3.595409393310547
Epoch: 5, Steps: 210 | Train Loss: 0.6105975 Vali Loss: 0.6396757 Test Loss: 0.9268243
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5921943
	speed: 0.0138s/iter; left time: 13.1112s
	iters: 200, epoch: 6 | loss: 0.6717304
	speed: 0.0135s/iter; left time: 11.5001s
Epoch: 6 cost time: 2.931422710418701
Epoch: 6, Steps: 210 | Train Loss: 0.6053727 Vali Loss: 0.6430866 Test Loss: 0.9287589
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5763584
	speed: 0.0219s/iter; left time: 16.1970s
	iters: 200, epoch: 7 | loss: 0.6250099
	speed: 0.0197s/iter; left time: 12.6142s
Epoch: 7 cost time: 4.220992088317871
Epoch: 7, Steps: 210 | Train Loss: 0.6036117 Vali Loss: 0.6444788 Test Loss: 0.9316080
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.8842688798904419, mae:0.7387551665306091
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6645359
	speed: 0.0289s/iter; left time: 57.8197s
	iters: 200, epoch: 1 | loss: 0.7943743
	speed: 0.0222s/iter; left time: 42.1098s
Epoch: 1 cost time: 4.678613901138306
Epoch: 1, Steps: 210 | Train Loss: 0.6669285 Vali Loss: 0.6020508 Test Loss: 0.9068120
Validation loss decreased (inf --> 0.602051).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7629741
	speed: 0.0189s/iter; left time: 33.8679s
	iters: 200, epoch: 2 | loss: 0.5250603
	speed: 0.0155s/iter; left time: 26.1862s
Epoch: 2 cost time: 3.2486116886138916
Epoch: 2, Steps: 210 | Train Loss: 0.6476944 Vali Loss: 0.6040847 Test Loss: 0.9185018
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6841947
	speed: 0.0181s/iter; left time: 28.6277s
	iters: 200, epoch: 3 | loss: 0.7763087
	speed: 0.0151s/iter; left time: 22.2935s
Epoch: 3 cost time: 3.2258689403533936
Epoch: 3, Steps: 210 | Train Loss: 0.6353693 Vali Loss: 0.6200567 Test Loss: 0.8743988
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6186028
	speed: 0.0183s/iter; left time: 25.1295s
	iters: 200, epoch: 4 | loss: 0.6701114
	speed: 0.0166s/iter; left time: 21.0629s
Epoch: 4 cost time: 3.577967643737793
Epoch: 4, Steps: 210 | Train Loss: 0.6253471 Vali Loss: 0.6392769 Test Loss: 0.8890255
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5239338
	speed: 0.0248s/iter; left time: 28.8020s
	iters: 200, epoch: 5 | loss: 0.5058926
	speed: 0.0234s/iter; left time: 24.8021s
Epoch: 5 cost time: 4.891355752944946
Epoch: 5, Steps: 210 | Train Loss: 0.6182559 Vali Loss: 0.6329815 Test Loss: 0.9069769
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5681816
	speed: 0.0215s/iter; left time: 20.4889s
	iters: 200, epoch: 6 | loss: 0.6469391
	speed: 0.0164s/iter; left time: 13.9271s
Epoch: 6 cost time: 3.533029079437256
Epoch: 6, Steps: 210 | Train Loss: 0.6147224 Vali Loss: 0.6351195 Test Loss: 0.9012780
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.9068118929862976, mae:0.7494896650314331
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.6617557
	speed: 0.0199s/iter; left time: 39.8635s
	iters: 200, epoch: 1 | loss: 0.8378979
	speed: 0.0186s/iter; left time: 35.3311s
Epoch: 1 cost time: 3.960432529449463
Epoch: 1, Steps: 210 | Train Loss: 0.6659983 Vali Loss: 0.6012625 Test Loss: 0.8861929
Validation loss decreased (inf --> 0.601262).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6115620
	speed: 0.0175s/iter; left time: 31.2587s
	iters: 200, epoch: 2 | loss: 0.6530504
	speed: 0.0187s/iter; left time: 31.6805s
Epoch: 2 cost time: 4.1156370639801025
Epoch: 2, Steps: 210 | Train Loss: 0.6464324 Vali Loss: 0.6054336 Test Loss: 0.8857523
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5697021
	speed: 0.0183s/iter; left time: 28.9787s
	iters: 200, epoch: 3 | loss: 0.7764144
	speed: 0.0150s/iter; left time: 22.1465s
Epoch: 3 cost time: 3.1502246856689453
Epoch: 3, Steps: 210 | Train Loss: 0.6312380 Vali Loss: 0.6125483 Test Loss: 0.9080669
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5491202
	speed: 0.0173s/iter; left time: 23.6918s
	iters: 200, epoch: 4 | loss: 0.5929496
	speed: 0.0146s/iter; left time: 18.5581s
Epoch: 4 cost time: 3.146745204925537
Epoch: 4, Steps: 210 | Train Loss: 0.6195700 Vali Loss: 0.6166071 Test Loss: 0.9025182
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5665100
	speed: 0.0172s/iter; left time: 20.0054s
	iters: 200, epoch: 5 | loss: 0.6243004
	speed: 0.0165s/iter; left time: 17.5550s
Epoch: 5 cost time: 3.7354490756988525
Epoch: 5, Steps: 210 | Train Loss: 0.6108966 Vali Loss: 0.6449223 Test Loss: 0.9032637
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6185049
	speed: 0.0168s/iter; left time: 15.9698s
	iters: 200, epoch: 6 | loss: 0.6360516
	speed: 0.0172s/iter; left time: 14.6379s
Epoch: 6 cost time: 3.731661558151245
Epoch: 6, Steps: 210 | Train Loss: 0.6058981 Vali Loss: 0.6400095 Test Loss: 0.9180043
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_192_iTransformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:0.886193037033081, mae:0.7405489087104797
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_336Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.8024893
	speed: 0.0264s/iter; left time: 51.8164s
	iters: 200, epoch: 1 | loss: 0.9038282
	speed: 0.0198s/iter; left time: 36.8041s
Epoch: 1 cost time: 4.095779657363892
Epoch: 1, Steps: 206 | Train Loss: 0.8434554 Vali Loss: 0.6826060 Test Loss: 1.2372906
Validation loss decreased (inf --> 0.682606).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8469004
	speed: 0.0183s/iter; left time: 32.2017s
	iters: 200, epoch: 2 | loss: 0.8727909
	speed: 0.0149s/iter; left time: 24.6823s
Epoch: 2 cost time: 3.128459930419922
Epoch: 2, Steps: 206 | Train Loss: 0.8243387 Vali Loss: 0.6939716 Test Loss: 1.2345933
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0286897
	speed: 0.0164s/iter; left time: 25.3718s
	iters: 200, epoch: 3 | loss: 0.8769748
	speed: 0.0148s/iter; left time: 21.4206s
Epoch: 3 cost time: 3.150240898132324
Epoch: 3, Steps: 206 | Train Loss: 0.8045231 Vali Loss: 0.7054172 Test Loss: 1.2944523
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8176675
	speed: 0.0198s/iter; left time: 26.6120s
	iters: 200, epoch: 4 | loss: 0.8461749
	speed: 0.0161s/iter; left time: 20.0625s
Epoch: 4 cost time: 3.339816093444824
Epoch: 4, Steps: 206 | Train Loss: 0.7901701 Vali Loss: 0.7251595 Test Loss: 1.3185068
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7960202
	speed: 0.0172s/iter; left time: 19.5185s
	iters: 200, epoch: 5 | loss: 0.7025563
	speed: 0.0136s/iter; left time: 14.1494s
Epoch: 5 cost time: 2.8985841274261475
Epoch: 5, Steps: 206 | Train Loss: 0.7822419 Vali Loss: 0.7313244 Test Loss: 1.3320249
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8181767
	speed: 0.0206s/iter; left time: 19.1794s
	iters: 200, epoch: 6 | loss: 0.6617423
	speed: 0.0169s/iter; left time: 14.0678s
Epoch: 6 cost time: 3.5884640216827393
Epoch: 6, Steps: 206 | Train Loss: 0.7766883 Vali Loss: 0.7284276 Test Loss: 1.3414863
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.237290620803833, mae:0.8680527210235596
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.7478355
	speed: 0.0163s/iter; left time: 31.8980s
	iters: 200, epoch: 1 | loss: 0.7009112
	speed: 0.0154s/iter; left time: 28.7324s
Epoch: 1 cost time: 3.307130813598633
Epoch: 1, Steps: 206 | Train Loss: 0.8429583 Vali Loss: 0.7054122 Test Loss: 1.2243158
Validation loss decreased (inf --> 0.705412).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8588424
	speed: 0.0208s/iter; left time: 36.4238s
	iters: 200, epoch: 2 | loss: 0.7226233
	speed: 0.0178s/iter; left time: 29.3921s
Epoch: 2 cost time: 3.7819814682006836
Epoch: 2, Steps: 206 | Train Loss: 0.8209975 Vali Loss: 0.7335052 Test Loss: 1.2679319
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8294908
	speed: 0.0136s/iter; left time: 21.0359s
	iters: 200, epoch: 3 | loss: 0.8541973
	speed: 0.0119s/iter; left time: 17.2959s
Epoch: 3 cost time: 2.553131103515625
Epoch: 3, Steps: 206 | Train Loss: 0.8049489 Vali Loss: 0.7139919 Test Loss: 1.2695042
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9076807
	speed: 0.0184s/iter; left time: 24.7772s
	iters: 200, epoch: 4 | loss: 0.8128488
	speed: 0.0178s/iter; left time: 22.1409s
Epoch: 4 cost time: 3.740618944168091
Epoch: 4, Steps: 206 | Train Loss: 0.7911153 Vali Loss: 0.7333199 Test Loss: 1.3123122
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9502249
	speed: 0.0176s/iter; left time: 19.9582s
	iters: 200, epoch: 5 | loss: 0.7686653
	speed: 0.0162s/iter; left time: 16.8006s
Epoch: 5 cost time: 3.4508118629455566
Epoch: 5, Steps: 206 | Train Loss: 0.7812731 Vali Loss: 0.7574081 Test Loss: 1.3293018
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8295650
	speed: 0.0182s/iter; left time: 16.9409s
	iters: 200, epoch: 6 | loss: 0.7110056
	speed: 0.0170s/iter; left time: 14.0943s
Epoch: 6 cost time: 3.6097192764282227
Epoch: 6, Steps: 206 | Train Loss: 0.7776425 Vali Loss: 0.7551062 Test Loss: 1.3470541
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2243157625198364, mae:0.8628807663917542
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 0.9356170
	speed: 0.0155s/iter; left time: 30.4612s
	iters: 200, epoch: 1 | loss: 0.7910317
	speed: 0.0139s/iter; left time: 25.7975s
Epoch: 1 cost time: 2.908939838409424
Epoch: 1, Steps: 206 | Train Loss: 0.8472054 Vali Loss: 0.7073637 Test Loss: 1.2666773
Validation loss decreased (inf --> 0.707364).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9912273
	speed: 0.0155s/iter; left time: 27.2262s
	iters: 200, epoch: 2 | loss: 0.8319548
	speed: 0.0140s/iter; left time: 23.0938s
Epoch: 2 cost time: 2.9478261470794678
Epoch: 2, Steps: 206 | Train Loss: 0.8238073 Vali Loss: 0.7100940 Test Loss: 1.3212019
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9354175
	speed: 0.0197s/iter; left time: 30.5190s
	iters: 200, epoch: 3 | loss: 0.8048636
	speed: 0.0173s/iter; left time: 25.1158s
Epoch: 3 cost time: 3.6570634841918945
Epoch: 3, Steps: 206 | Train Loss: 0.7980179 Vali Loss: 0.7316150 Test Loss: 1.3259535
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7476845
	speed: 0.0181s/iter; left time: 24.2635s
	iters: 200, epoch: 4 | loss: 0.7668081
	speed: 0.0171s/iter; left time: 21.2617s
Epoch: 4 cost time: 3.6552040576934814
Epoch: 4, Steps: 206 | Train Loss: 0.7837862 Vali Loss: 0.7405850 Test Loss: 1.3425127
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8695077
	speed: 0.0156s/iter; left time: 17.7200s
	iters: 200, epoch: 5 | loss: 0.8383941
	speed: 0.0137s/iter; left time: 14.1718s
Epoch: 5 cost time: 2.876688241958618
Epoch: 5, Steps: 206 | Train Loss: 0.7766305 Vali Loss: 0.7448478 Test Loss: 1.3556447
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7581963
	speed: 0.0166s/iter; left time: 15.4259s
	iters: 200, epoch: 6 | loss: 0.7565828
	speed: 0.0166s/iter; left time: 13.7718s
Epoch: 6 cost time: 3.4694716930389404
Epoch: 6, Steps: 206 | Train Loss: 0.7737205 Vali Loss: 0.7442366 Test Loss: 1.3555243
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_336_iTransformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.2666772603988647, mae:0.8787099123001099
Seed: 456
GPU available True
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           gamma0.95_alpha0.8_96_720Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          ./dataset/synthetic/
  Data Path:          gamma0.95_alpha0.8.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           720                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             10                  Dec In:             10                  
  C Out:              10                  d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                3                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Task: long_term_forecast
Long Term Forecast
Exp: <class 'exp.exp_long_term_forecasting.Exp_Long_Term_Forecast'>
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2294029
	speed: 0.0245s/iter; left time: 45.1306s
Epoch: 1 cost time: 3.3843283653259277
Epoch: 1, Steps: 194 | Train Loss: 1.2256823 Vali Loss: 0.5705014 Test Loss: 1.3827856
Validation loss decreased (inf --> 0.570501).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1519508
	speed: 0.0121s/iter; left time: 19.9681s
Epoch: 2 cost time: 2.4509308338165283
Epoch: 2, Steps: 194 | Train Loss: 1.2044458 Vali Loss: 0.5979712 Test Loss: 1.3447766
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.1085480
	speed: 0.0172s/iter; left time: 24.9715s
Epoch: 3 cost time: 3.1361312866210938
Epoch: 3, Steps: 194 | Train Loss: 1.1748016 Vali Loss: 0.6078731 Test Loss: 1.3318350
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.2592885
	speed: 0.0170s/iter; left time: 21.4073s
Epoch: 4 cost time: 3.281749725341797
Epoch: 4, Steps: 194 | Train Loss: 1.1534918 Vali Loss: 0.6411915 Test Loss: 1.3605486
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.3798180
	speed: 0.0170s/iter; left time: 18.0845s
Epoch: 5 cost time: 3.27593731880188
Epoch: 5, Steps: 194 | Train Loss: 1.1406406 Vali Loss: 0.6476753 Test Loss: 1.3637124
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0124820
	speed: 0.0144s/iter; left time: 12.5291s
Epoch: 6 cost time: 2.6395952701568604
Epoch: 6, Steps: 194 | Train Loss: 1.1330804 Vali Loss: 0.6551259 Test Loss: 1.3599179
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3827855587005615, mae:0.9214329123497009
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.2407920
	speed: 0.0142s/iter; left time: 26.2062s
Epoch: 1 cost time: 2.778411865234375
Epoch: 1, Steps: 194 | Train Loss: 1.2282213 Vali Loss: 0.5588605 Test Loss: 1.3873992
Validation loss decreased (inf --> 0.558860).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.3410913
	speed: 0.0132s/iter; left time: 21.7065s
Epoch: 2 cost time: 2.5624454021453857
Epoch: 2, Steps: 194 | Train Loss: 1.2068793 Vali Loss: 0.5697302 Test Loss: 1.3724279
EarlyStopping counter: 1 out of 5
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.2406141
	speed: 0.0127s/iter; left time: 18.4678s
Epoch: 3 cost time: 2.3871688842773438
Epoch: 3, Steps: 194 | Train Loss: 1.1757800 Vali Loss: 0.6646031 Test Loss: 1.3763205
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0641750
	speed: 0.0161s/iter; left time: 20.3098s
Epoch: 4 cost time: 2.7948954105377197
Epoch: 4, Steps: 194 | Train Loss: 1.1542060 Vali Loss: 0.6683699 Test Loss: 1.3837049
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.2436700
	speed: 0.0136s/iter; left time: 14.5339s
Epoch: 5 cost time: 2.39260196685791
Epoch: 5, Steps: 194 | Train Loss: 1.1392929 Vali Loss: 0.6758966 Test Loss: 1.3770087
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2731998
	speed: 0.0140s/iter; left time: 12.2133s
Epoch: 6 cost time: 2.9608383178710938
Epoch: 6, Steps: 194 | Train Loss: 1.1281782 Vali Loss: 0.6744408 Test Loss: 1.3816319
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.3873991966247559, mae:0.9206123948097229
Use GPU: cuda:0
no_skip True
add a fuse layer of decoder
>>>>>>>start training : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456>>>>>>>>>>>>>>>>>>>>>>>>>>
data (10000, 2)
data (10000, 2)
data (10000, 2)
	iters: 100, epoch: 1 | loss: 1.0282706
	speed: 0.0183s/iter; left time: 33.6703s
Epoch: 1 cost time: 3.281754493713379
Epoch: 1, Steps: 194 | Train Loss: 1.2292311 Vali Loss: 0.5735677 Test Loss: 1.3981957
Validation loss decreased (inf --> 0.573568).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 1.1362624
	speed: 0.0162s/iter; left time: 26.6927s
Epoch: 2 cost time: 3.098156690597534
Epoch: 2, Steps: 194 | Train Loss: 1.2088287 Vali Loss: 0.5588278 Test Loss: 1.3686148
Validation loss decreased (0.573568 --> 0.558828).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 1.0924363
	speed: 0.0156s/iter; left time: 22.7334s
Epoch: 3 cost time: 2.818152666091919
Epoch: 3, Steps: 194 | Train Loss: 1.1871725 Vali Loss: 0.6050415 Test Loss: 1.3523871
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 1.0930078
	speed: 0.0104s/iter; left time: 13.0778s
Epoch: 4 cost time: 2.032966136932373
Epoch: 4, Steps: 194 | Train Loss: 1.1670692 Vali Loss: 0.6358835 Test Loss: 1.3539871
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 1.1643916
	speed: 0.0119s/iter; left time: 12.6347s
Epoch: 5 cost time: 2.0809571743011475
Epoch: 5, Steps: 194 | Train Loss: 1.1521799 Vali Loss: 0.6151831 Test Loss: 1.3661219
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.2760423
	speed: 0.0143s/iter; left time: 12.4284s
Epoch: 6 cost time: 2.4509758949279785
Epoch: 6, Steps: 194 | Train Loss: 1.1447561 Vali Loss: 0.6274512 Test Loss: 1.3707236
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 1.1647551
	speed: 0.0148s/iter; left time: 10.0067s
Epoch: 7 cost time: 3.1053969860076904
Epoch: 7, Steps: 194 | Train Loss: 1.1420844 Vali Loss: 0.6296464 Test Loss: 1.3699708
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_gamma0.95_alpha0.8_96_720_iTransformer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_noSkipTrue_FDCTrue_conv2d_456<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
mse:1.368614912033081, mae:0.9166238903999329
